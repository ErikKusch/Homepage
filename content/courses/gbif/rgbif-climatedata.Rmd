---
title: "Climate Data & GBIF Records"
author: Erik Kusch
date: '2023-11-01'
slug: climdata
categories:
  - GBIF
  - Biodiversity
  - Open Science
  - Climate Data
  - KrigR
tags:
  - GBIF
  - Biodiversity
  - Open Science
  - Climate Data
  - KrigR
subtitle: "Supplementing GBIF Records with Climate Data"
summary: 'A quick overview of `KrigR` use with GBIF records.'
authors: []
lastmod: '2023-11-01T00:00:00+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: 
output:
  blogdown::html_page:
    keep_md: true
    # toc: true
    # toc_depth: 1
    # number_sections: false
# header-includes:
#   <script src = "https://polyfill.io/v3/polyfill.min.js?features = es6"></script>
#   <script id = "MathJax-script" async src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
math: true
type: docs
toc: true 
menu:
  gbif:
    parent: Supplementary Exercises
    weight: 9
weight: 9
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, tidy='styler', tidy.opts=list(strict=TRUE), fig.width = 15, fig.height = 8)
options(width = 90)
source("PersonalSettings.R")
# htmlwidgets::onStaticRenderComplete('$.each( document.getElementsByTagName("svg"), function( index, value ){value.setAttribute("viewBox", null);});')
```

{{% alert normal %}}
<details>
  <summary>Preamble, Package-Loading, and GBIF API Credential Registering (click here):</summary>
```{r InstallAdvanced}
## Custom install & load function
install.load.package <- function(x){
  if (!require(x, character.only = TRUE)) {
    install.packages(x, repos = "http://cran.us.r-project.org")
  }
  require(x, character.only = TRUE)
}
## names of packages we want installed (if not installed yet) and loaded
package_vec <- c(
  "rgbif",
  "ggplot2", # for visualisation
  "tidybayes", # for more visualisations
  "data.table", # for data reformatting
  "ggpubr" # for t-tests directly in ggplot vis
)
## executing install & load for each package
sapply(package_vec, install.load.package)
```
```{r registeruser, eval=FALSE}
options(gbif_user = "my gbif username")
options(gbif_email = "my registred gbif e-mail")
options(gbif_pwd = "my gbif password")
```
</details> 
{{% /alert %}}

First, we obtain and load the data use for our publication like such:
```{r, echo = FALSE}
if(file.exists(file.path(getwd(), "registereddownload.RData"))){
  load(file.path(getwd(), "registereddownload.RData"))
}else{
  res <- occ_download(
  pred("taxonKey", sp_key),
  pred_in("basisOfRecord", c('HUMAN_OBSERVATION')),
  pred("country", "NO"),
  pred_gte("year", 2000),
  pred_lte("year", 2022)
)
  save(res, file = "registereddownload.RData")
}
res_meta <- occ_download_wait(res, status_ping = 5, curlopts = list(), quiet = FALSE)
res_get <- occ_download_get(res)
res_data <- occ_download_import(res_get)
# Limiting data according to quality control
preci_data <- res_data[which(res_data$coordinateUncertaintyInMeters < 10), ]
# Subsetting data for desired variables and data markers
data_subset <- preci_data[ ,
                        c("scientificName", "decimalLongitude","decimalLatitude", "basisOfRecord", "year", "month", "day", "eventDate", "countryCode", "municipality", "taxonKey", "species", "catalogNumber", "hasGeospatialIssues", "hasCoordinate", "datasetKey")]
```

```{r searchandgetkey, eval=FALSE}
# Download query
res <- occ_download(
  pred("taxonKey", sp_key),
  pred_in("basisOfRecord", c('HUMAN_OBSERVATION')),
  pred("country", "NO"),
  pred("hasCoordinate", TRUE),
  pred_gte("year", 2000),
  pred_lte("year", 2022)
)
# Downloading and Loading
res_meta <- occ_download_wait(res, status_ping = 5, curlopts = list(), quiet = FALSE)
res_get <- occ_download_get(res)
res_data <- occ_download_import(res_get)
# Limiting data according to quality control
preci_data <- res_data[which(res_data$coordinateUncertaintyInMeters < 10), ]
# Subsetting data for desired variables and data markers
data_subset <- preci_data[ ,
                        c("scientificName", "decimalLongitude","decimalLatitude", "basisOfRecord", "year", "month", "day", "eventDate", "countryCode", "municipality", "taxonKey", "species", "catalogNumber", "hasGeospatialIssues", "hasCoordinate", "datasetKey")]
```

{{% alert danger %}}
<!-- <details> -->
  <!-- <summary> -->
  For this exercise, we also need to load packages and set up API credentials for climate data retrieval:
  <!-- </summary> -->
  To prepare this section, please follow the [setup for `KrigR`](/courses/krigr/setup/). 
  
Subsequently, we load `KrigR`:
```{r InstallKrigR}
library(KrigR)
```
Next, we establish a directory structure to save our climate data:
```{r KrigRDirs}
Dir.Base <- getwd() # identifying the current directory
Dir.Data <- file.path(Dir.Base, "Data") # folder path for data
## create directory, if it doesn't exist yet
if(!dir.exists(Dir.Data)){dir.create(Dir.Data)}
```

Now, we register some plotting functions for ease of demonstration. I have prepared some plotting functions which you can download as [FUN_Plotting.R](https://raw.githubusercontent.com/ErikKusch/Homepage/master/content/courses/krigr/FUN_Plotting.R) and then source them in your environment like so:
```{r, PlotFun}
source("FUN_Plotting.R")
```

Finally, we register your CDS API credentials:
```{r registeruserKrigR, eval=FALSE}
API_User <- 12345
API_Key <- "YourApiKeyGoesHereAsACharacterString"
```
<!-- </details>  -->
{{% /alert %}}

Now we have all functionality in place to obtain state-of-the-art climate data which to match our GBIF records to for downstream applications like Species Distribution Models et cetera.

## Data Characteristics
To effectively obtain relevant climate data for our GBIF records, we need to know about some base characteristics of our GBIF data. Luckily, we control those through our query to GBIF in the first place. Therefore, we already know the two key criteria:

1. **Spatial Coverage**: Norway
2. **Temporal Coverage**: 2000-2022

To deal with the spatial aspect, let's obtain high-resolution shapefiles for Norway and its neighbouring countries (excluding Russia due to its size):
```{r, fig.height=7, results = "asis"}
Area_shp <- rnaturalearth::ne_countries(
  country = c("Norway", "Sweden", "Finland", "Iceland", "Denmark", "United Kingdom"), 
  scale = 10) 
plot(Area_shp)
```

As you can see, Norway posesses some territory outside the borader Scandinavian realm. Let's crop that out:
```{r, fig.height=7, results = "asis"}
NewExt <- extent(Area_shp)
NewExt[3] <- 49.57 # most southerly point of the UK
Area_shp <- crop(Area_shp, NewExt)
plot(Area_shp)
```
That looks like an adequate area for which to obtain climate data.

## Climate Data Retrieval
There are several ways to obtain climate data. Most of the time, you will still see people downloading data sets like [WorldClim](https://www.worldclim.org/) and calling it a day. For reasons I detail in my work surrounding [KrigR](/project/krigr), I **strongly disagree** with this practise. 

Instead, let me walk you through the `KrigR` pipeline for climate data retrieval.

### Single-Variable Layers
To start, let's simply download two biologically relevant pieces of climate data:

1. *Air Temperature* (setting the efficiency of metabolism and growing seasons)
2. *Soil Moisture* (a more direct measure of water availability than precipitation)

With `KrigR`, obtaining this data is straightforward:
```{r, echo = FALSE}
AT_ras <- raster(file.path(Dir.Data, "AT_ras.nc"))
```

```{r, eval = FALSE}
AT_ras <- download_ERA(
  Variable = "2m_temperature", # the variable we want
  DataSet = "era5-land", # the data set we chose
  DateStart = "2000-01-01", # time-range start
  DateStop = "2022-12-31", # time-range end
  TResolution = "year", # desired temporal resolution
  TStep = 23, # steps in desired temporal resolution
  Extent = Area_shp, # masking area
  Dir = Dir.Data, # where to store data
  FileName = "AT_ras", # what to call the stored NETCDF
  API_User = API_User,
  API_Key = API_Key,
  SingularDL = TRUE # whether to attempt pulling data as one single download
)
```

With the above code, we obtain air temperature data as a climatological 23-year mean between 2000 and 2022 for our greater Scandinavian area. We can visualise it as such:
```{r, fig.height=10, results = "asis"}
Plot_Raw(AT_ras, Shp = Area_shp, Dates = c("Mean Air Temperature 2000-2022"))
```

Now let's do the exact same but for soil moisture data:
```{r, echo = FALSE}
QS_ras <- raster(file.path(Dir.Data, "QS_ras.nc"))
```

```{r, eval = FALSE}
QS_ras <- download_ERA(
  Variable = "volumetric_soil_water_layer_1",
  DataSet = "era5-land",
  DateStart = "2000-01-01",
  DateStop = "2022-12-31",
  TResolution = "year",
  TStep = 23,
  Extent = Area_shp,
  Dir = Dir.Data,
  FileName = "QS_ras",
  API_User = API_User,
  API_Key = API_Key,
  SingularDL = TRUE
)
```
```{r, fig.height=10, results = "asis"}
Plot_Raw(QS_ras, Shp = Area_shp, COL = rev(viridis(100)),
         Legend = "Soil Moisture",
         Dates = c("Mean Soil Moisture 2000-2022"))
```

We now have our two single-layer raster objects corresponding to air temperature and soil moisture ready for matching them to GBIF data.

### Bioclimatic Layers

Ultimately, most macroecological uses of GBIF mediated records use some version of bioclimatic variables. Using `KrigR`, we can obtain these from state-of-the-art climate reanalysis products and even specify more pertinent water variables than the standard precipitation data. Since we are looking at a plant here, probably soil moisture may be most adequate:
```{r BC_Qsoil}
if(file.exists(file.path(Dir.Data, "Qsoil_BC.nc"))){
  BC_ras <- stack(file.path(Dir.Data, "Qsoil_BC.nc"))
  names(BC_ras) <- paste0("BIO", 1:19)
}else{
  BC_ras <- BioClim(
      Water_Var = "volumetric_soil_water_layer_1",
      Y_start = 2000,
      Y_end = 2022,
      Extent = Area_shp,
      Dir = Dir.Data,
      Keep_Monthly = TRUE,
      FileName = "Qsoil_BC.nc",
      API_User = API_User,
      API_Key = API_Key,
      Cores = parallel::detectCores(),
      TimeOut = Inf,
      SingularDL = FALSE
    )
}
```

The above function call needs to download and process a lot of data hence why I check if the data is already present in the first place. You will see this when running thios function yourself.

Now to visualise the bioclimatic data we have obtained for our study region:
```{r, fig.height=50, results = "asis"}
cowplot::plot_grid(
  Plot_BC(BC_ras, Shp = Area_shp, Water_Var = "Soil Moisture", which = 1),
  Plot_BC(BC_ras, Shp = Area_shp, Water_Var = "Soil Moisture", which = 2:19),
  ncol = 1, rel_heights = c(1.3, 9)
  )
```

## Matching Climate Data with GBIF Records

To figure out climatological conditions at the locations of our GBIF mediated records, it usually pays to generate a spatial object from our data frame of occurrences:
```{r}
occ_sp <- data_subset
coordinates(occ_sp) <- ~ decimalLongitude+decimalLatitude
```

With this, we can now match GBIF records to their local conditions according to our climate data objects.

### Single-Layers

Starting with the single-layer rasters, let's create a stack of them and extract climate values at GBIF presence locations in one step. This creates a wide data frame which, for plotting purposes, we transform into a long format data frame:
```{r}
SL_stack <- stack(AT_ras, QS_ras)
names(SL_stack) <- c("AT", "QS")
SL_vals <- raster::extract(SL_stack, occ_sp, df = TRUE)
head(SL_vals)
SL_vals <- data.table::melt(na.omit(SL_vals), 
                            id.vars = "ID")
head(SL_vals)
```

Now, we can plot histograms of climate conditions where we find our study organism:
```{r, fig.height=5}
cols <- list(AT = inferno(1e2),
             QS = rev(viridis(1e2)))
plotlist <- lapply(unique(SL_vals$variable), FUN = function(x){
  p <- ggplot(SL_vals[SL_vals$variable == x, ], aes(x = value)) + 
    geom_histogram(bins = 1e2, fill = cols[[x]]) +
    theme_bw()
  return(p)
})
cowplot::plot_grid(plotlist = plotlist, ncol = 2)
```

To augment this analysis, we might want to identify climate conditions where our study organism is not found. To not bias this analysis due to our large study region for which we did not query GBIF records, let's establish a buffer around presence points:
```{r}
occ_sf <- st_as_sf(occ_sp)
buffer_sf <- st_union(st_buffer(occ_sf, 1)) # 1 degree buffer around points
```

To visualise this buffer we do the following:
```{r, fig.height=10, results = "asis"}
plot(AT_ras)
plot(st_union(buffer_sf), col = "red", add = TRUE)
plot(occ_sf, add = TRUE, col = "black", cex = 0.5, pch = 4)
```

Now we can limit our single-layer climate data to this new buffer area:
```{r}
SL_crop <- crop(SL_stack, extent(st_bbox(buffer_sf)))
SL_crop <- mask(SL_crop, as(buffer_sf, "Spatial"))
```

and subsequently visualise the resulting climate data:
```{r, fig.height=7, results = "asis"}
cowplot::plot_grid(
  Plot_Raw(SL_crop$AT, Shp = as(buffer_sf, "Spatial"), 
         Dates = c("Mean Air Temperature 2000-2022")),
  Plot_Raw(SL_crop$QS, Shp = as(buffer_sf, "Spatial"), 
           COL = rev(viridis(100)),
         Legend = "Soil Moisture",
         Dates = c("Mean Soil Moisture 2000-2022"))
)
```
Now, we can figure out (1) which cells of this raster contain presences, (2) identify which cells do not, (3) obtain coordinates of cells containing no GBIF presences and (4) extract climate conditions in absence cells: 
```{r}
Pres_cells <- raster::cellFromXY(SL_stack, occ_sp)
Abs_cells <- 1:ncell(SL_stack)[!(1:ncell(SL_stack) %in% Pres_cells)]

SLAbs_vals <- raster::extract(SL_stack,
                raster::xyFromCell(SL_stack, Abs_cells),
                df = TRUE) 
SLAbs_vals <- na.omit(SLAbs_vals)
head(SLAbs_vals)
SLAbs_vals <- data.table::melt(SLAbs_vals, id.vars = "ID")
```

Now to visualise the climate conditions in locations of GBIF presence and absence of our study organism. I also add a t-test comparison between the two presence options to the plot:
```{r, fig.height=7, results = "asis"}
SL_vals$Presence <- "Presence"
SLAbs_vals$Presence <- "Absence"
SLPlot_vals <- rbind(SL_vals, SLAbs_vals)
ggplot(SLPlot_vals, aes(y = value, x = Presence, 
                        fill = variable, 
                        group = Presence)) + 
  geom_violin() +
  geom_boxplot(width = 0.1, fill = "white") +
  stat_compare_means(comparisons = list(c("Presence", "Absence")), 
                     method = 't.test', label = 'p.signif') +
  facet_wrap(~variable, scales = "free") + 
  theme_bw() + guides(fill="none")
```

With this in hand, we could now continue to figure out what exactly drives presence and absence of our study organism.


### Bioclimatic Variables

Finally, let's also match our GBIF records with bioclimatic data:
```{r}
BC_vals <- raster::extract(BC_ras, occ_sp, df = TRUE)
head(BC_vals)
BC_vals <- data.table::melt(na.omit(BC_vals), id.vars = "ID")
```

Again, we create plots for the extracted values. This time however, we use a different frequency visualisation option:
```{r, fig.height=40, results = "asis"}
cols <- list(AT = inferno(1e2),
             QS = rev(viridis(1e2)))
plotlist <- lapply(unique(BC_vals$variable), FUN = function(x){
  y <- ifelse(as.numeric(gsub("\\D", "", x)) < 12, 1, 2)
  p <- ggplot(BC_vals[BC_vals$variable == x, ], aes(x = value)) + 
  stat_halfeye(fill = cols[[y]][50]) + 
  # geom_histogram(bins = 1e2, fill = cols[[y]]) +
  theme_bw() + labs(title = x)
  return(p)
})
cowplot::plot_grid(
  plotlist[[1]],
  cowplot::plot_grid(plotlist = plotlist[-1], ncol = 2),
  ncol = 1, rel_heights = c(1.3, 9)
  )
```

{{% alert success %}}
You are finished - you should now be able to obtain relevant climate data to match your GBIF records to as well as carry out some basic spatial operations such as buffering points, merging polygons and handling raster files.
{{% /alert %}}

## Session Info
```{r, echo = FALSE}
sessionInfo()
```