---
title: "Downloading & Processing"
author: Erik Kusch
date: '2022-05-26'
slug: download
categories:
  - KrigR
  - Climate Data
tags:
  - Climate Data
  - Statistical Downscaling
  - KrigR
subtitle: "Accessing State-of-the-Art Climate Data with `KrigR`"
summary: 'Download specifications and considerations with `KrigR`.'
authors: []
lastmod: '2021-05-26T20:00:00+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: 
output:
  blogdown::html_page:
    keep_md: true
    # toc: true
    # toc_depth: 1
    # number_sections: false
# header-includes:
#   <script src = "https://polyfill.io/v3/polyfill.min.js?features = es6"></script>
#   <script id = "MathJax-script" async src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
math: true
type: docs
toc: true 
menu:
  krigr:
    parent: Workshop
    weight: 10
weight: 10
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">

</div>

<p>{{% hint danger %}}
This part of the workshop is dependant on set-up and preparation done previously <a href="/courses/krigr/prep/">here</a>.
{{% /hint %}}</p>
<p>First, we load <code>KrigR</code>:</p>
<pre class="r"><code>library(KrigR)</code></pre>
<p>{{% hint info %}}
Downloads and data processing with <code>KrigR</code> are staged and executed with the <code>download_ERA()</code>function.
{{% /hint %}}</p>
<p><code>download_ERA()</code> is a very versatile function and I will show you it’s capabilities throughout this material.</p>
<p>{{% hint warning %}}
We will start with a <strong>simple calls</strong> to <code>KrigR</code> and subsequently make them <strong>more sophisticated</strong> during this workshop.
{{% /hint %}}</p>
<div id="downloading-climate-data" class="section level2">
<h2>Downloading Climate Data</h2>
<p>Let’s start with a very basic call to <code>download_ERA()</code>.</p>
<p>For this part of the workshop, we download air temperature for my birth month (January 1995) using the extent of our <a href="/courses/prep/#our-workshop-target-region">target region</a>.</p>
<p>See the code chunk below for explanations on each function argument. If you want to know about the defaults for any argument in <code>download_ERA()</code> simply run <code>?download_ERA()</code>. Doing so should make it obvious why we specify the function as we do below.</p>
<p>{{% hint %}}
Notice that the downloading of ERA-family reanalysis data may take a short while to start as the download request gets queued with the CDS of the ECMWF before it is executed.
{{% /hint %}}</p>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/FirstDL.nc">FirstDL.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>FirstDL &lt;- download_ERA(
    Variable = &quot;2m_temperature&quot;, # the variable we want to obtain data for
    DataSet = &quot;era5-land&quot;, # the data set we want to obtain data from
    DateStart = &quot;1995-01-01&quot;, # the starting date of our time-window
    DateStop = &quot;1995-01-31&quot;, # the final date of our time-window
    Extent = Extent_ext, # the spatial preference we are after
    Dir = Dir.Data, # where to store the downloaded data
    FileName = &quot;FirstDL&quot;, # a name for our downloaded file
    API_User = API_User, # your API User Number
    API_Key = API_Key # your API User Key
  )</code></pre>
<pre><code>## download_ERA() is starting. Depending on your specifications, this can take a significant time.</code></pre>
<pre><code>## User 39340 for cds service added successfully in keychain</code></pre>
<pre><code>## Staging 1 download(s).</code></pre>
<pre><code>## 0001_FirstDL.nc download queried</code></pre>
<pre><code>## Requesting data to the cds service with username 39340</code></pre>
<pre><code>## - staging data transfer at url endpoint or request id:</code></pre>
<pre><code>##   d19d450c-2a1a-4974-9da4-c022a4db654f</code></pre>
<pre><code>## - timeout set to 10.0 hours</code></pre>
<pre><code>## - polling server for a data transfer \ polling server for a data transfer | polling
## server for a data transfer / polling server for a data transfer - polling server for a
## data transfer \ polling server for a data transfer | polling server for a data transfer /
## polling server for a data transfer - polling server for a data transfer \ polling server
## for a data transfer | polling server for a data transfer / polling server for a data
## transfer - polling server for a data transfer \ polling server for a data transfer |
## polling server for a data transfer / polling server for a data transfer - polling server
## for a data transfer \ polling server for a data transfer | polling server for a data
## transfer / polling server for a data transfer - polling server for a data transfer \
## polling server for a data transfer | polling server for a data transfer / polling server
## for a data transfer - polling server for a data transfer</code></pre>
<pre><code>## 
  |                                                                                      
  |                                                                                |   0%
  |                                                                                      
  |================================================================================| 100%</code></pre>
<pre><code>## - moved temporary file to -&gt; C:/Users/erike/Documents/Website/content/courses/krigr/Data/0001_FirstDL.nc
## - request purged from queue!
## Checking for known data issues.
## Loading downloaded data for masking and aggregation.
## Aggregating to temporal resolution of choice</code></pre>
<p>As you can see the <code>download_ERA()</code> function updates you on what it is currently working on at each major step. I implemented this to make sure people don’t get too anxious staring at an empty console in <code>R</code>. If this feature is not appealing to you, you can turn this progress tracking off by setting <code>verbose = FALSE</code> in the function call to <code>download_ERA()</code>.</p>
<p>{{% hint warning %}}
For the rest of this workshop, I suppress messages from <code>download_ERA()</code> via other means so that when you execute, you get progress tracking.
{{% /hint %}}</p>
<p>I will make exceptions to this rule when there are special things I want to demonstrate.</p>
<p>Now, let’s look at the raster that was produced:</p>
<pre class="r"><code>FirstDL</code></pre>
<pre><code>## class      : RasterStack 
## dimensions : 34, 54, 1836, 1  (nrow, ncol, ncell, nlayers)
## resolution : 0.09999999, 0.09999998  (x, y)
## extent     : 9.72, 15.12, 49.74, 53.14  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## names      :       X1 
## min values : 268.8695 
## max values : 274.6665</code></pre>
<p>One layer (i.e., one month) worth of data. That seems to have worked. If you are keen-eyed, you will notice that the extent on this object does not align with the extent we supplied with <code>Extent_ext</code>. The reason? To download the data, we need to snap to the nearest full cell in the data set from which we query our downloads. <code>KrigR</code> always ends up widening the extent to ensure all the data you desire will be downloaded.</p>
<p>Finally, let’s visualise our downloaded data with one of our <a href="/courses/krigr/prep/#visualising-our-study-setting">user-defined plotting functions</a>:</p>
<pre class="r"><code>Plot_Raw(FirstDL, Dates = &quot;01-1995&quot;)</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/FirstDLVis-1.png" width="1440" /></p>
<p>That is all there is to downloading ERA5(-Land) data with <code>KrigR</code>. You can already see how, even at the relatively course resolution of ERA5-Land, the mountain ridges along the German-Czech border are showing up. This will become a lot clearer of a pattern once we <a href="/courses/krigr/kriging/">downscale our data</a>.</p>
<p>{{% hint info %}}
<code>download_ERA()</code> provides you with a lot more functionality than <em>just</em> access to the ERA5(-Land) data sets.
{{% /hint %}}</p>
<p>{{% hint %}}
With <code>download_ERA()</code>, you can also carry out processing of the downloaded data. Data processing with <code>download_ERA()</code> includes:<br />
1. <em>Spatial Limitation</em> to cut down on the data that is stored on your end.<br />
2. <em>Temporal Aggregation</em> to establish data at the temporal resolution you desire.<br />
{{% /hint %}}</p>
</div>
<div id="spatial-limitation" class="section level2">
<h2>Spatial Limitation</h2>
<p>Let’s start with spatial limitation. As discussed <a href="/courses/krigr/prep/#spatial-preferences-in-krigr">previously</a>, <code>download_ERA()</code> can handle a variety of inputs describing spatial preferences.</p>
<p>{{% hint %}}
<code>KrigR</code> is capable of learning about your spatial preferences in three ways:</p>
<ol style="list-style-type: decimal">
<li>As an <code>extent</code> input (a rectangular box).<br />
</li>
<li>As a <code>SpatialPolygons</code> input (a polygon or set of polygons).<br />
</li>
<li>As a set of locations stored in a <code>data.frame</code>.</li>
</ol>
<p>These spatial preferences are registered in <code>KrigR</code> functions using the <code>Extent</code> argument.
{{% /hint %}}</p>
<p>You might now ask yourself: How does <code>KrigR</code> achieve spatial limitation of the data? Couldn’t we just simply download only the data we are interested in?</p>
<p>The ECMWF CDS gives us tremendous capability of retrieving only the data we want. However, the CDS only recognises rectangular boxes (i.e., <code>extent</code>s) for spatial limitation. Consequently, we always have to download data corresponding to a rectangular box in space. When informing <code>KrigR</code> of your spatial preferences using a <code>data.frame</code> or <code>SpatialPolygons</code>, <code>download_ERA()</code> automatically (1) identifies the smallest <code>extent</code> required by your input, (2) downloads data corresponding to this <code>extent</code>, and (3) masks our any data not queried by you.</p>
<p>{{% hint info %}}
Using <code>KrigR</code>’s spatial limitation features ensures faster computation and smaller file sizes (depending on file type).
{{% /hint %}}</p>
<p>In the following, I demonstrate how to use the <code>Extent</code> argument in <code>download_ERA()</code>.</p>
<div id="shape-spatialpolygons" class="section level3">
<h3>Shape (<code>SpatialPolygons</code>)</h3>
<p>Let me show you how <code>SpatialPolygons</code> show up in our data with <code>download_ERA()</code>. Remember that these <code>SpatialPolygons</code> originate <a href="/courses/krigr/prep/#shape-of-interest-spatialpolygons">here</a>. First, we query our download as follows:</p>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/SpatialPolygons_DL.nc">SpatialPolygons_DL.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>SpatialPolygons_DL &lt;- download_ERA(
  Variable = &quot;2m_temperature&quot;,
  DataSet = &quot;era5-land&quot;,
  DateStart = &quot;1995-01-01&quot;,
  DateStop = &quot;1995-01-31&quot;,
  Extent = Shape_shp, # we simply switch the Extent Argument
  Dir = Dir.Data,
  FileName = &quot;SpatialPolygons_DL&quot;,
  API_User = API_User,
  API_Key = API_Key
)  
Plot_Raw(SpatialPolygons_DL, Dates = &quot;01-1995&quot;, Shp = Shape_shp)</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/unnamed-chunk-3-1.png" width="1440" /></p>
<p>You will find that the data retained with the spatial limitation in <code>download_ERA()</code> contains all raster cells of which even a fraction falls within the bounds of the <code>SpatialPolygons</code> you supplied. This is different from standard <code>raster</code> masking through which only cells whose centroids fall within the <code>SpatialPolygons</code> are retained.</p>
<p>{{% hint info %}}
<code>raster</code> masking in <code>KrigR</code> always ensures that the entire area of your spatial preferences are retained.
{{% /hint %}}</p>
</div>
<div id="points-data.frame" class="section level3">
<h3>Points (<code>data.frame</code>)</h3>
<p>Now we move on to point-locations. Often times, we are researching very specific sets of coordinates, rather than entire regions. <code>download_ERA()</code> is capable of limiting data to only small areas (of a size of your choosing) around your point-locations. For our purposes here, we make use of a set of mountain-top coordinates throughout our study region. Remember that these coordinates (stored in a <code>data.frame</code>) originate <a href="/courses/krigr/prep/#points-of-interest-dataframe">here</a>.</p>
<p>This time around, we need to tell <code>download_ERA()</code> about not just the <code>Extent</code>, but also specify how much of a buffer (<code>Buffer</code> in <span class="math inline">\(°\)</span>) to retain data for around each individual (<code>ID</code>) location.</p>
<p>{{% hint %}}
The <code>data.frame</code> input to the <code>Extent</code> must contain a column called <code>Lat</code> and a column called <code>Lon</code>:</p>
<p>In addition, one must also specify:<br />
1. A <code>Buffer</code> in <span class="math inline">\(°\)</span> to be drawn around each location.<br />
2. The name of the <code>ID</code> column in your <code>data.frame</code> which indexes each individual location.<br />
{{% /hint %}}</p>
<p>{{% hint %}}
Our <a href="/courses/outlook/">development goals</a> include support for a broader range of point-location specifications.
{{% /hint %}}</p>
<p>Let’s stage such a download:</p>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/points_DL.nc">points_DL.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>points_DL &lt;- download_ERA(
  Variable = &quot;2m_temperature&quot;,
  DataSet = &quot;era5-land&quot;,
  DateStart = &quot;1995-01-01&quot;,
  DateStop = &quot;1995-01-31&quot;,
  Extent = Mountains_df, # our data.frame with Lat and Lon columns
  Buffer = 0.5, # a half-degree buffer
  ID = &quot;Mountain&quot;, # the ID column in our data.frame
  Dir = Dir.Data,
  FileName = &quot;points_DL&quot;,
  API_User = API_User,
  API_Key = API_Key
)
Plot_Raw(points_DL, Dates = &quot;01-1995&quot;) + 
  geom_point(aes(x = Lon, y = Lat), data = data.frame(Mountains_sp), 
             colour = &quot;green&quot;, size = 10, pch = 14)</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/unnamed-chunk-5-1.png" width="1440" /></p>
<p>Above you can see how the mountain tops we are interested in lie exactly at the centre of the retained data. As we will see later, such spatial limitation greatly reduces computation cost of statistical downscaling procedures.</p>
</div>
</div>
<div id="temporal-aggregation" class="section level2">
<h2>Temporal Aggregation</h2>
<p>So far, we have downloaded a single layer of data (i.e., one monthly average layer) from the CDS. However, ERA5(-Land) products come at <strong>hourly temporal resolutions</strong> from which we can generate climate data at almost any temporal resolution we may require. This is what <strong>temporal aggregation</strong> in <code>download_ERA()</code> is for.</p>
<p>{{% hint info %}}
With <strong>temporal aggregation</strong> in <code>download_ERA()</code> you can achieve almost any temporal resolution and aggregate metric you may desire.
{{% /hint %}}</p>
<p>{{% hint %}}
Temporal aggregation with <code>download_ERA()</code> uses the arguments:<br />
- <code>TResolution</code> and <code>TStep</code> to achieve desired temporal resolutions<br />
- <code>FUN</code> to calculate desired aggregate metrics<br />
{{% /hint %}}</p>
<div id="temporal-resolution-tresolution-and-tstep" class="section level3">
<h3>Temporal Resolution (<code>TResolution</code> and <code>TStep</code>)</h3>
<p>Let’s start by querying data at non-CDS temporal resolutions.</p>
<p>{{% hint %}}
The <code>download_ERA()</code> function in the <code>KrigR</code> package accepts the following arguments which you can use to control the temporal resolution of your climate data:<br />
- <code>TResolution</code> controls the time-line that <code>TStep</code> indexes. You can specify anything from the following: <code>'hour'</code>, <code>'day'</code>, <code>'month'</code>, or <code>'year'</code>. The default is <code>'month'</code>.<br />
- <code>TStep</code> controls how many time-steps to aggregate into one layer of data each. Aggregation is done via taking the mean per cell in each raster comprising time steps that go into the final, aggregated time-step. The default is <code>1</code>.<br />
{{% /hint %}}</p>
<p>For now, let’s download hourly data from the CDS (this achieved by specifying a <code>TResolution</code> of <code>"hour"</code> or <code>"day"</code>) and aggregate these to 1-day intervals. To make the result easier to visualise, we focus only on the first four days of January 1995:</p>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/TimeSeries.nc">TimeSeries.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>TimeSeries &lt;- download_ERA(
  Variable = &quot;2m_temperature&quot;,
  DataSet = &quot;era5-land&quot;,
  DateStart = &quot;1995-01-01&quot;,
  DateStop = &quot;1995-01-04&quot;,
  TResolution = &quot;day&quot;, # aggregate to days
  TStep = 1, # aggregate to 1 day each
  Extent = Shape_shp,
  Dir = Dir.Data,
  FileName = &quot;TimeSeries&quot;,
  API_User = API_User,
  API_Key = API_Key
)
Plot_Raw(TimeSeries, Dates = c(&quot;01-1995&quot;, &quot;02-1995&quot;, 
                               &quot;03-1995&quot;, &quot;04-1995&quot;),
         Shp = Shape_shp)</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/unnamed-chunk-7-1.png" width="1440" />
Looks like a cold front rolled over my home area at the beginning of 1995.</p>
<p>{{% hint info %}}
<code>KrigR</code> automatically identifies which data set to download from given your temporal aggregation specification.
{{% /hint %}}</p>
<p>As soon as <code>TResolution</code> is set to <code>'month'</code> or <code>'year'</code>, the package automatically downloads monthly mean data from the CDS. We do this to make the temporal aggregation calculation more light-weight on your computing units and to make downloads less heavy.</p>
<p>Let’s run through a few examples to make clear how desired temporal resolution of data can be achieved using the <code>KrigR</code> package:</p>
<table>
<tr>
<th>
What We Want
</th>
<th>
TResolution
</th>
<th>
TStep
</th>
</tr>
<tr>
<td>
Hourly intervals
</td>
<td>
hour
</td>
<td>
1
</td>
</tr>
<tr>
<td>
6-hour intervals
</td>
<td>
hour
</td>
<td>
6
</td>
</tr>
<tr>
<td>
Half-day intervals
</td>
<td>
hour
</td>
<td>
12
</td>
</tr>
<tr>
<td>
Daily intervals
</td>
<td>
day
</td>
<td>
1
</td>
</tr>
<tr>
<td>
3-day intervals
</td>
<td>
day
</td>
<td>
3
</td>
</tr>
<tr>
<td>
Weekly intervals
</td>
<td>
day
</td>
<td>
7
</td>
</tr>
<tr>
<td>
Monthly aggregates
</td>
<td>
month
</td>
<td>
1
</td>
</tr>
<tr>
<td>
4-month intervals
</td>
<td>
month
</td>
<td>
4
</td>
</tr>
<tr>
<td>
Annual intervals
</td>
<td>
year
</td>
<td>
1
</td>
</tr>
<tr>
<td>
10-year intervals
</td>
<td>
year
</td>
<td>
10
</td>
</tr>
</table>
<p>{{% hint warning %}}
Specifying <code>TResolution</code> of <code>'month'</code> will result in the download of full month aggregates for every month included in your time series.
{{% /hint %}}</p>
<p>For example, <code>DateStart = "2000-01-20"</code>, <code>DateStop = "2000-02-20"</code> with <code>TResolution = 'month'</code>, and <code>TStep = 1</code> <strong>does not</strong> result in the mean aggregate for the month between the 20/01/200 and the 20/02/2000, but <strong>does result</strong> in the monthly aggregates for January and February 2000. If you desire the former, you would need to specify <code>DateStart = "2000-01-20"</code>, <code>DateStop = "2000-02-20"</code> with <code>TResolution = 'day'</code>, and <code>TStep = 32</code> (the number of days between the two dates).</p>
</div>
<div id="aggregate-metrics-fun" class="section level3">
<h3>Aggregate Metrics (<code>FUN</code>)</h3>
<p>Aggregate metrics can be particularly useful for certain study settings when climate variability or exposure to extreme events are sought after.</p>
<p>{{% hint %}}
The <code>FUN</code> argument in <code>download_ERA()</code> controls which values to calculate for the temporal aggregates, e.g.: <code>'min'</code>, <code>'max'</code>, or <code>'mean'</code> (default).</p>
<p>Any function which returns a single value when fed a vector of values is supported.
{{% /hint %}}</p>
<p>Let’s say we are interested in the variability of temperature across our study region in daily intervals. Again, we shorten our time-series to just four days:</p>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/TimeSeriesSD.nc">TimeSeriesSD.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>TimeSeriesSD &lt;- download_ERA(
  Variable = &quot;2m_temperature&quot;,
  DataSet = &quot;era5-land&quot;,
  DateStart = &quot;1995-01-01&quot;,
  DateStop = &quot;1995-01-04&quot;,
  TResolution = &quot;day&quot;,
  TStep = 1,
  FUN = sd, # query standard deviation
  Extent = Shape_shp,
  Dir = Dir.Data,
  FileName = &quot;TimeSeriesSD&quot;,
  API_User = API_User,
  API_Key = API_Key
)
Plot_Raw(TimeSeriesSD, Dates = c(&quot;01-1995&quot;, &quot;02-1995&quot;, 
                                 &quot;03-1995&quot;, &quot;04-1995&quot;),
         Shp = Shape_shp)</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/unnamed-chunk-9-1.png" width="1440" />
Seems like the temperatures fluctuated most on the third and fourth of January, but the area of temperature fluctuations changed location between those two days.</p>
<p>{{% hint info %}}
You should now be able to query data for any location you study and achieve temporal resolutions and aggregate metrics which your study requires.
{{% /hint %}}</p>
</div>
</div>
<div id="dynamical-data-uncertainty" class="section level2">
<h2>Dynamical Data Uncertainty</h2>
<p>With climate reanalyses, you also gain access to uncertainty flags of the data stored in the reanalysis product. For the ERA5-family of products, this uncertainty can be obtained by assessing the standard deviation of the 10 ensemble members which make up the underlying ERA5 model exercise.</p>
<p>With <code>download_ERA()</code> you can obtain this information as follows:</p>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/SpatialPolygonsEns_DL.nc">SpatialPolygonsEns_DL.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>SpatialPolygonsEns_DL &lt;- download_ERA(
    Variable = &quot;2m_temperature&quot;,
    DataSet = &quot;era5&quot;,
    Type = &quot;ensemble_members&quot;,
    DateStart = &quot;1995-01-01&quot;,
    DateStop = &quot;1995-01-02&quot;,
    TResolution = &quot;day&quot;,
    TStep = 1,
    FUN = sd,
    Extent = Shape_shp,
    Dir = Dir.Data,
    FileName = &quot;SpatialPolygonsEns_DL&quot;,
    API_User = API_User,
    API_Key = API_Key
  )
Plot_Raw(SpatialPolygonsEns, Dates = c(&quot;01-1995&quot;, &quot;02-1995&quot;),
         Shp = Shape_shp, COL = rev(viridis(100)))</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/unnamed-chunk-11-1.png" width="1440" /></p>
<p>As you can see here, there is substantial disagreement between the ensemble members of daily average temperatures across our study region. This uncertainty among ensemble members is greatest at high temporal resolution and becomes negligible at coarse temporal resolution. We document this phenomenon in <a href="https://iopscience.iop.org/article/10.1088/1748-9326/ac39bf">this publication (Figure 1)</a>.</p>
</div>
<div id="final-downloads-for-workshop-progress" class="section level2">
<h2>Final Downloads for Workshop Progress</h2>
<p>Now that we know how to use spatial limitation and temporal aggregation with <code>download_ERA()</code> it is time to generate the data products we will use for the rest of this workshop material.</p>
<div id="climate-data" class="section level3">
<h3>Climate Data</h3>
<p>{{% hint info %}}
To streamline this workshop material, I will focus on just three short-time series of data with different spatial limitations. I visualise them all side-by-side further down.
{{% /hint %}}</p>
<details>
<summary>
Click here for download calls
</summary>
<div id="extent-data" class="section level4">
<h4><code>extent</code> Data</h4>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/ExtentRaw.nc">ExtentRaw.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>Extent_Raw &lt;- download_ERA(
  Variable = &quot;2m_temperature&quot;,
  DataSet = &quot;era5-land&quot;,
  DateStart = &quot;1995-01-01&quot;,
  DateStop = &quot;1995-01-04&quot;,
  TResolution = &quot;day&quot;,
  TStep = 1,
  Extent = Extent_ext,
  Dir = Dir.Data,
  FileName = &quot;ExtentRaw&quot;,
  API_User = API_User,
  API_Key = API_Key
)</code></pre>
</div>
<div id="spatialpolygons-data" class="section level4">
<h4><code>SpatialPolygons</code> Data</h4>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/SpatialPolygonsRaw.nc">SpatialPolygonsRaw.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>SpatialPolygons_Raw &lt;- download_ERA(
  Variable = &quot;2m_temperature&quot;,
  DataSet = &quot;era5-land&quot;,
  DateStart = &quot;1995-01-03&quot;,
  DateStop = &quot;1995-01-03&quot;,
  TResolution = &quot;day&quot;,
  TStep = 1,
  Extent = Shape_shp,
  Dir = Dir.Data,
  FileName = &quot;SpatialPolygonsRaw&quot;,
  API_User = API_User,
  API_Key = API_Key
)</code></pre>
</div>
<div id="pointdata.frame-data" class="section level4">
<h4>Point(<code>data.frame</code>) Data</h4>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/PointsRaw.nc">PointsRaw.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>Points_Raw &lt;- download_ERA(
  Variable = &quot;2m_temperature&quot;,
  DataSet = &quot;era5-land&quot;,
  DateStart = &quot;1995-01-01&quot;,
  DateStop = &quot;1995-01-4&quot;,
  TResolution = &quot;day&quot;,
  TStep = 1,
  Extent = Mountains_df,
  Buffer = 0.5,
  ID = &quot;Mountain&quot;,
  Dir = Dir.Data,
  FileName = &quot;PointsRaw&quot;,
  API_User = API_User,
  API_Key = API_Key
)</code></pre>
</details>
<p>Now let’s visualise these data for a better understanding of what they contain:</p>
<pre class="r"><code>Extent_gg &lt;- Plot_Raw(Extent_Raw[[1]], Dates = &quot;Extent&quot;)
SP_gg &lt;- Plot_Raw(SpatialPolygons_Raw[[1]], Dates = &quot;SpatialPolygons&quot;)
Points_gg &lt;- Plot_Raw(Points_Raw[[1]], Dates = &quot;SpatialPolygons&quot;)
plot_grid(Extent_gg, SP_gg, Points_gg, ncol = 3)</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/dataviz-1.png" width="1440" /></p>
</div>
</div>
<div id="dynamical-data-uncertainty-1" class="section level3">
<h3>Dynamical Data Uncertainty</h3>
<p>{{% hint info %}}
For an aggregate understanding of data uncertainty, we also obtain dynamical uncertainty for our target region and time frame. For simplicity, we do so only for the <code>SpatialPolygons</code> specification.
{{% /hint %}}</p>
<details>
<summary>
Click here for download call
</summary>
<details>
<summary>
Click here for file if download takes too long:
</summary>
Download
<a href="/courses/krigr/Data/SpatialPolygonsEns.nc">SpatialPolygonsEns.nc</a> and place it into your data directory.
</details>
<pre class="r"><code>SpatialPolygonsEns &lt;- download_ERA(
    Variable = &quot;2m_temperature&quot;,
    DataSet = &quot;era5&quot;,
    Type = &quot;ensemble_members&quot;,
    DateStart = &quot;1995-01-01&quot;,
    DateStop = &quot;1995-01-04&quot;,
    TResolution = &quot;day&quot;,
    TStep = 1,
    FUN = sd,
    Extent = Shape_shp,
    Dir = Dir.Data,
    FileName = &quot;SpatialPolygonsEns&quot;,
    API_User = API_User,
    API_Key = API_Key
  )</code></pre>
</details>
<pre class="r"><code>Plot_Raw(SpatialPolygonsEns, Dates = c(&quot;01-1995&quot;, &quot;02-1995&quot;, 
                                          &quot;03-1995&quot;, &quot;04-1995&quot;),
         Shp = Shape_shp, COL = rev(viridis(100)))</code></pre>
<p><img src="/courses/krigr/krigr-downloads_files/figure-html/unnamed-chunk-17-1.png" width="1440" /></p>
<p>We will see how these uncertainties stack up against other sources of uncertainty when we arrive at <a href="/courses/krigr/kriging/#aggregate-uncertainty">aggregate uncertainty</a> of our final product.</p>
</div>
</div>
<div id="considerations-for-download_era" class="section level2">
<h2>Considerations for <code>download_ERA()</code></h2>
<p><code>download_ERA()</code> is a complex function with many things happening under the hood. To make sure you have the best experience with this interface to the ERA5(-Land) products through <code>R</code>, I have compiled a few bits of <em>good-to-know</em> information about the workings of <code>download_ERA()</code>.</p>
<div id="effeciency" class="section level3">
<h3>Effeciency</h3>
<p>Download speeds with <code>download_ERA()</code> are largely tied to CDS queue time, but there are some things worth considering when querying downloads of time-series data.</p>
<p>{{% hint warning %}}
The <code>download_ERA()</code> function automatically breaks down download requests into monthly intervals thus circumventing the danger of running into making a download request that is too big for the CDS.
{{% /hint %}}</p>
<p>For example, <code>DateStart = "2000-01-20"</code>, <code>DateStop = "2000-02-20"</code> with <code>TResolution = 'day'</code>, and <code>TStep = 8</code> will lead to two download requests to the CDS: (1) hourly data in the range 20/01/2000 00:00 to 31/01/2000 23:00, and (2) hourly data in the range 01/02/2000 00:00 to 20/02/2000 23:00. These data sets are subsequently fused in <code>R</code>, aggregated to daily aggregates, and finally, aggregated to four big aggregates.<br />
This gives you a lot of flexibility, but always keep in mind that third-party data sets might not account for leap-years so make sure the dates of third-party data (should you chose to use some) lines up with the ones as specified by your calls to the functions of the <code>KrigR</code> package.</p>
<div id="singulardl" class="section level4">
<h4><code>SingularDL</code></h4>
<p>ECMWF CDS downloads come with a hard limit of 100,000 layers worth of data. This corresponds to more than 1 month worth of data. As a matter of fact, even ar hourly time-scales, you could theoretically download ~11 years worth of data without hitting this limit. In this particular case, <code>download_ERA()</code> stages, by default, 132 individual downloads (1 per month) when the CDS would be just fine accepting the download request for all the data in one download call.</p>
<p>Is there any way to bypass the monthly downloads in <code>download_ERA()</code>? Yes, there is. With the <code>SingularDL</code> argument.</p>
<p>{{% hint info %}}
Setting <code>SingularDL = TRUE</code> in <code>download_ERA()</code> bypasses the automatic month-wise download staging. A pre-staging check breaks the operation if you query more than the CDS hard limit on data.
{{% /hint %}}</p>
<p>{{% hint %}}
Our <a href="/courses/outlook/">development goals</a> include changing month-wise default downloads to downloads of 100,000 layers at a time.
{{% /hint %}}</p>
</div>
<div id="cores" class="section level4">
<h4><code>Cores</code></h4>
<p>Continuing on from the previous point, let’s consider you want to obtain more than 100,000 layers worth of data for your analysis and thus can’t make use of the <code>SingularDL</code> argument.
By default <code>download_ERA()</code> stages downloads sequentially. Most modern PCs come with multiple cores each of which could theoretically stage it’s own download in parallel. Couldn’t we make use of this for more efficient download staging? Yes, we can with the <code>Cores</code> argument.</p>
<p>{{% hint info %}}
Using the <code>Cores</code> argument in <code>download_ERA()</code> you can specify how many downloads to stage in parallel rather than sequentially.
{{% /hint %}}</p>
</div>
<div id="disk-space" class="section level4">
<h4>Disk Space</h4>
<p><code>KrigR</code> uses NETCDF (.nc) files as they represent the standard in climate science. NETCDF file size is not connected to data content in the raster but number of cells. Other formats, such as GeoTiff (.tif) do however scale in file size with non-NA cell number in the saved rasters.</p>
<p>{{% hint %}}
Our <a href="/courses/outlook/">development goals</a> include giving the user control over the file type as which <code>KrigR</code>-derived products are saved.
{{% /hint %}}</p>
<p>For example, the file size of the above <code>FirstDL</code> raster is 7kb while the <code>SpatialPolygons</code> and <code>data.frame</code> driven data is saved as GeoTiffs of 4kb and 3kb, respectively.</p>
<p>{{% hint %}}
If you need to optimise storage space, particularly when using <a href="/courses/krigr/download/#spatial-limitation">spatial limitation</a> with <code>KrigR</code>, I can thus recommend re-saving <code>KrigR</code> outputs as GeoTiffs.
{{% /hint %}}</p>
</div>
</div>
<div id="cummulative-variables-precipfix" class="section level3">
<h3>Cummulative Variables (<code>PrecipFix</code>)</h3>
<p>{{% hint danger %}}
Some variables in the ERA5(-Land) data sets are stored as cumulative records for pre-set time-windows, but temporal aggregation in <code>download-ERA()</code> cannot handle such data.
{{% /hint %}}</p>
<p>Consequently, cumulative records need to be transformed into single-time-step records with respect to their base temporal resolution and cumulative aggregation interval like so:</p>
<p><img src="/post/krigr-mats/PrecipFix.jpg" width="900"/></p>
<p>{{% hint %}}
To make cumulatively stored variables compatible with temporal aggregation in <code>download_ERA()</code> simple toggle <code>PrecipFix = TRUE</code> in the function call.
{{% /hint %}}</p>
<p>{{% hint info %}}
To identify which variables are stored cumulatively, we recommend searching for variables listed as “This variable is accumulated from the beginning of the forecast time to the end of the forecast step.” on the data set documentation page (e.g., <a href="https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview">ERA5-Land</a>).
{{% /hint %}}</p>
<p>{{% hint %}}
Our <a href="/courses/outlook/">development goals</a> include an error check for specification of <code>PrecipFix = TRUE</code> on non-cumulatively stored variables.
{{% /hint %}}</p>
</div>
<div id="stability" class="section level3">
<h3>Stability</h3>
<p><code>download_ERA()</code> requires a stable connection to the ECWMF CDS. Sometimes, however, a connection may drop or the CDS queue is so long that our downloads just fail. To mitigate the annoyance caused by these issues, I have implemented to extra arguments to the <code>download_ERA()</code> function call:</p>
<div id="timeout" class="section level4">
<h4><code>TimeOut</code></h4>
<p><code>TimeOut</code> is a numeric argument which specifies how many seconds to wait for the CDS to return the queried data. The default equates to 10 hours.</p>
</div>
<div id="trydown" class="section level4">
<h4><code>TryDown</code></h4>
<p><code>TryDown</code> is a numeric argument which specifies how often to retry a download before giving up and moving on or stopping the execution of <code>download_ERA()</code>. The default is 10.</p>
</div>
</div>
</div>
<div id="session-info" class="section level2">
<h2>Session Info</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.5 (2021-03-31)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19043)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252   
## [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                           
## [5] LC_TIME=English_United Kingdom.1252    
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] mapview_2.10.2          rnaturalearthdata_0.1.0 rnaturalearth_0.1.0    
##  [4] gimms_1.2.0             ggmap_3.0.0             cowplot_1.1.1          
##  [7] viridis_0.6.0           viridisLite_0.4.0       ggplot2_3.3.6          
## [10] tidyr_1.1.3             KrigR_0.1.2             httr_1.4.2             
## [13] stars_0.5-3             abind_1.4-5             fasterize_1.0.3        
## [16] sf_1.0-0                lubridate_1.7.10        automap_1.0-14         
## [19] doSNOW_1.0.19           snow_0.4-3              doParallel_1.0.16      
## [22] iterators_1.0.13        foreach_1.5.1           rgdal_1.5-23           
## [25] raster_3.4-13           sp_1.4-5                stringr_1.4.0          
## [28] keyring_1.2.0           ecmwfr_1.3.0            ncdf4_1.17             
## 
## loaded via a namespace (and not attached):
##  [1] bitops_1.0-7             satellite_1.0.2          xts_0.12.1              
##  [4] webshot_0.5.2            tools_4.0.5              bslib_0.2.4             
##  [7] utf8_1.2.1               R6_2.5.0                 zyp_0.10-1.1            
## [10] KernSmooth_2.23-18       DBI_1.1.1                colorspace_2.0-0        
## [13] withr_2.4.2              tidyselect_1.1.0         gridExtra_2.3           
## [16] leaflet_2.0.4.1          curl_4.3.2               compiler_4.0.5          
## [19] leafem_0.1.3             gstat_2.0-7              labeling_0.4.2          
## [22] bookdown_0.22            sass_0.3.1               scales_1.1.1            
## [25] classInt_0.4-3           proxy_0.4-25             digest_0.6.27           
## [28] rmarkdown_2.7            base64enc_0.1-3          jpeg_0.1-8.1            
## [31] pkgconfig_2.0.3          htmltools_0.5.1.1        highr_0.9               
## [34] fastmap_1.1.0            htmlwidgets_1.5.3        rlang_0.4.11            
## [37] FNN_1.1.3                farver_2.1.0             jquerylib_0.1.4         
## [40] generics_0.1.0           zoo_1.8-9                jsonlite_1.7.2          
## [43] crosstalk_1.1.1          dplyr_1.0.5              magrittr_2.0.1          
## [46] Rcpp_1.0.7               munsell_0.5.0            fansi_0.4.2             
## [49] lifecycle_1.0.0          stringi_1.5.3            yaml_2.2.1              
## [52] plyr_1.8.6               grid_4.0.5               crayon_1.4.1            
## [55] lattice_0.20-41          knitr_1.33               pillar_1.6.0            
## [58] boot_1.3-27              rjson_0.2.20             spacetime_1.2-4         
## [61] stats4_4.0.5             codetools_0.2-18         glue_1.4.2              
## [64] evaluate_0.14            blogdown_1.3             vctrs_0.3.7             
## [67] png_0.1-7                RgoogleMaps_1.4.5.3      gtable_0.3.0            
## [70] purrr_0.3.4              reshape_0.8.8            assertthat_0.2.1        
## [73] cachem_1.0.4             xfun_0.22                lwgeom_0.2-6            
## [76] e1071_1.7-6              rnaturalearthhires_0.2.0 class_7.3-18            
## [79] Kendall_2.2              tibble_3.1.1             intervals_0.15.2        
## [82] memoise_2.0.0            units_0.7-2              ellipsis_0.3.2</code></pre>
</div>
