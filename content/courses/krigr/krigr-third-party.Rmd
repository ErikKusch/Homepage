---
title: "Third-Party Data"
author: Erik Kusch
date: '2022-05-26'
slug: third-party
categories:
  - KrigR
  - Climate Data
tags:
  - Climate Data
  - Statistical Downscaling
  - KrigR
subtitle: "Using KrigR with third-party data"
summary: 'Using `KrigR` with third-party data.'
authors: []
lastmod: '2021-05-26T20:00:00+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: 
output:
  blogdown::html_page:
    keep_md: true
    # toc: true
    # toc_depth: 1
    # number_sections: false
# header-includes:
#   <script src = "https://polyfill.io/v3/polyfill.min.js?features = es6"></script>
#   <script id = "MathJax-script" async src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
math: true
type: docs
toc: true 
menu:
  krigr:
    parent: Workshop
    weight: 25
weight: 25
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, tidy='styler', tidy.opts=list(strict=TRUE), fig.width = 15, fig.height = 8)
options(width = 90)
rm(list=ls())
if("KrigR" %in% rownames(installed.packages()) == FALSE){ # KrigR check
  Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS="true")
  devtools::install_github("https://github.com/ErikKusch/KrigR")
}
source("PersonalSettings.R") # I do this here to specify number of cores and API credentials and am thus not sharing this file
```

```{r, sourcing-previous, echo = FALSE}
source_rmd <- function(file, local = FALSE, ...){
  options(knitr.duplicate.label = 'allow')

  tempR <- tempfile(tmpdir = ".", fileext = ".R")
  on.exit(unlink(tempR))
  knitr::purl(file, output=tempR, quiet = TRUE)

  envir <- globalenv()
  source(tempR, local = envir, ...)
}
source_rmd("krigr-locations.Rmd")
```

{{% hint danger %}}
This part of the workshop is dependant on set-up and preparation done previously [here](/courses/krigr/prep/).
{{% /hint %}}

First, we load `KrigR`:

```{r}
library(KrigR)
```

## Matching Third-Party Data

I expect that you won't want to downscale to specific resolutions most of the time, but rather, match an already existing spatial data set in terms of spatial resolution and extent. Again, the `KrigR` package got you covered!

{{% hint warning %}}
Usually, you probably want to downscale data to match a certain pre-existing data set rather than a certain resolution.
{{% /hint %}}

Here, we illustrate this with an NDVI-based example. The NDVI is a satellite-derived vegetation index which tells us how green the Earth is. It comes in bi-weekly intervals and at a spatial resolution of `.08333` (roughly 9km). Here, we download all NDVI data for the year 2015 and then create the annual mean. This time, we do so for all of Germany because of its size and topographical variety.

### Third-Party Data

```{r ShapesGer}
Shape_shp <- ne_countries(country = "Germany")
```

```{r, echo = FALSE}
if(!file.exists(file.path(Dir.Data, "NDVI.nc"))){
gimms_files <- file.path(Dir.Data, list.files(Dir.Data, pattern = "ndvi3g_geo_v1_2015")[1:2])
gimms_raster <- rasterizeGimms(x = gimms_files, # the data we rasterize
                               remove_header = TRUE # we don't need the header of the data
                               )
indices <- monthlyIndices(gimms_files) # generate month indices from the data
gimms_raster_mvc <- monthlyComposite(gimms_raster, # the data
                                     indices = indices # the indices
                                     )
Negatives <- which(values(gimms_raster_mvc) < 0) # identify all negative values
values(gimms_raster_mvc)[Negatives] <- 0 # set threshold for barren land (NDVI<0)
gimms_raster_mvc <- crop(gimms_raster_mvc, extent(Shape_shp)) # crop to extent
gimms_mask <- KrigR::mask_Shape(gimms_raster_mvc[[1]], Shape = Shape_shp) # create mask with KrigR-internal function to ensure all edge cells are contained
NDVI_ras <- mask(gimms_raster_mvc, gimms_mask) # mask out shape
NDVI_ras <- calc(NDVI_ras, fun = mean, na.rm = TRUE) # annual mean
writeRaster(NDVI_ras, format = "CDF", file = file.path(Dir.Data, "NDVI"), overwrite = TRUE) # save file
}else{
  NDVI_ras <- stack(file.path(Dir.Data, "NDVI.nc"))
}
```

```{r, eval = FALSE}
## downloading gimms data
gimms_files <- downloadGimms(x = as.Date("2015-01-01"), # download from January 1982
                             y = as.Date("2015-12-31"), # download to December 1982
                             dsn = Dir.Data, # save downloads in data folder
                             quiet = FALSE # show download progress
                             )
## prcoessing gimms data
gimms_raster <- rasterizeGimms(x = gimms_files, # the data we rasterize
                               remove_header = TRUE # we don't need the header of the data
                               )
indices <- monthlyIndices(gimms_files) # generate month indices from the data
gimms_raster_mvc <- monthlyComposite(gimms_raster, # the data
                                     indices = indices # the indices
                                     )
Negatives <- which(values(gimms_raster_mvc) < 0) # identify all negative values
values(gimms_raster_mvc)[Negatives] <- 0 # set threshold for barren land (NDVI<0)
gimms_raster_mvc <- crop(gimms_raster_mvc, extent(Shape_shp)) # crop to extent
gimms_mask <- KrigR::mask_Shape(gimms_raster_mvc[[1]], Shape = Shape_shp) # create mask ith KrigR-internal function to ensure all edge cells are contained
NDVI_ras <- mask(gimms_raster_mvc, gimms_mask) # mask out shape
NDVI_ras <- calc(NDVI_ras, fun = mean, na.rm = TRUE) # annual mean
writeRaster(NDVI_ras, format = "CDF", file = file.path(Dir.Data, "NDVI")) # save file
```

So what does this raster look like?

```{r}
NDVI_ras
```

And a visualisation of the same:
```{r, results = "asis", fig.height = 15, fig.keep='all'}
Plot_Raw(NDVI_ras, 
         Shp = Shape_shp,
         Dates = "Mean NDVI 2015", 
         COL = viridis(100, begin = 0.5, direction = -1))
```
As stated above, we want to match this with our output.  

### `KrigR` Workflow

We could do this whole analysis in our three steps as outlined above, but why bother when the [pipeline](/courses/krigr/quickstart/#the-pipeline) gets the job done just as well?

{{% hint info %}}
Matching Kriging outputs with a pre-existing data set is as easy as plugging the pre-existing raster into the `Target_res` argument of the `krigR()` or the `download_DEM()` function.
{{% /hint %}}

This time we want to downscale from ERA5 resolution (roughly 30km) because the ERA5-Land data already matches the NDVI resolution (roughly 9km). Here's how we do this:
```{r era5Pipe, message = TRUE, warning = TRUE}
NDVI_Krig <- krigR(
  ## download_ERA block
  Variable = '2m_temperature',
  Type = 'reanalysis',
  DataSet = 'era5',
  DateStart = '2015-01-01',
  DateStop = '2015-12-31',
  TResolution = 'year',
  TStep = 1,
  Extent = Shape_shp,
  API_User = API_User,
  API_Key = API_Key,
  SingularDL = TRUE,
  ## download_DEM block
  Target_res = NDVI_ras,
  Source = "Drive",
  ## krigR block
  Cores = 1,
  FileName = "AirTemp_NDVI.nc",
  nmax = 80, 
  Dir = Dir.Exports)
```

So? Did we match the pre-existing data?
```{r}
NDVI_Krig[[1]]
```
We nailed this!

Let's take one final look at our (A) raw ERA5 data, (B) NDVI data, (C) Kriged ERA5 data, and (D) standard error of our Kriging output:

<details><summary> Click here for download plotting calls </summary>
```{r, fig.height = 15}
### ERA-Plot
ERA_df <- as.data.frame(raster(file.path(Dir.Exports, "2m_temperature_2015-01-01_2015-12-31_year.nc")), xy = TRUE) # turn raster into dataframe
colnames(ERA_df)[c(-1,-2)] <- "Air Temperature 2015 (ERA5)"
ERA_df <- gather(data = ERA_df, key = Values, value = "value", colnames(ERA_df)[c(-1,-2)]) #  make ggplot-ready
Raw_plot <- ggplot() + # create a plot
  geom_raster(data = ERA_df , aes(x = x, y = y, fill = value)) + # plot the raw data
  facet_wrap(~Values) + # split raster layers up
  theme_bw() + labs(x = "Longitude", y = "Latitude") + # make plot more readable
  scale_fill_gradientn(name = "Air Temperature [K]", colours = inferno(100)) + # add colour and legend
  geom_polygon(data = Shape_shp, aes(x = long, y = lat, group = group), colour = "black", fill = "NA") # add shape
### NDVI-Plot
NDVI_df <- as.data.frame(NDVI_ras, xy = TRUE) # turn raster into dataframe
colnames(NDVI_df)[c(-1,-2)] <- "NDVI 2015"
NDVI_df <- gather(data = NDVI_df, key = Values, value = "value", colnames(NDVI_df)[c(-1,-2)]) #  make ggplot-ready
NDVI_plot <- ggplot() + # create a plot
  geom_raster(data = NDVI_df , aes(x = x, y = y, fill = value)) + # plot the raw data
  facet_wrap(~Values) + # split raster layers up
  theme_bw() + labs(x = "Longitude", y = "Latitude") + # make plot more readable
  scale_fill_gradientn(name = "NDVI", colours = rev(terrain.colors(100))) + # add colour and legend
  geom_polygon(data = Shape_shp, aes(x = long, y = lat, group = group), colour = "black", fill = "NA") # add shape
### KRIGED-Plots
Dates = c("Kriged Air Temperature 2015 (NDVI Resolution)")
Type_vec <- c("Prediction", "Standard Error") # these are the output types of krigR
Colours_ls <- list(inferno(100), rev(viridis(100))) # we want separate colours for the types
Plots_ls <- as.list(NA, NA) # this list will be filled with the output plots
KrigDF_ls <- as.list(NA, NA) # this list will be filled with the output data
for(Plot in 1:2){ # loop over both output types
  Krig_df <- as.data.frame(NDVI_Krig[[Plot]], xy = TRUE) # turn raster into dataframe
  colnames(Krig_df)[c(-1,-2)] <- paste(Type_vec[Plot], Dates) # set colnames
  Krig_df <- gather(data = Krig_df, key = Values, value = "value", colnames(Krig_df)[c(-1,-2)]) # make ggplot-ready
  Plots_ls[[Plot]] <- ggplot() + # create plot
    geom_raster(data = Krig_df , aes(x = x, y = y, fill = value)) + # plot the kriged data
    facet_wrap(~Values) + # split raster layers up
    theme_bw() + labs(x = "Longitude", y = "Latitude") + # make plot more readable
    scale_fill_gradientn(name = "Air Temperature [K]", colours = Colours_ls[[Plot]]) + # add colour and legend
    theme(plot.margin = unit(c(0, 0, 0, 0), "cm")) + # reduce margins (for fusing of plots)
    geom_polygon(data = Shape_shp, aes(x = long, y = lat, group = group), colour = "black", fill = "NA") # add shape
  KrigDF_ls[[Plot]] <- Krig_df
} # end of type-loop
```

```{r echo = FALSE}
unlink(file.path(Dir.Exports, "2m_temperature_2015-01-01_2015-12-31_year.nc"), recursive = TRUE) # remove NDVI file for potential reruns
```
</details>

```{r, fig.height = 15, results='asis', fig.keep='all'}
plot_grid(plotlist = list(Raw_plot, NDVI_plot, Plots_ls[[1]], Plots_ls[[2]]), 
          nrow = 2, labels = "AUTO")
```

So what can we learn from this? Let's plot the relation between temperature and NDVI:
```{r, fig.height = 5, results='asis', fig.keep='all'}
plot_df <- as.data.frame(cbind(KrigDF_ls[[1]][,4], 
                               KrigDF_ls[[2]][,4],
                               NDVI_df[,4]))
colnames(plot_df) <- c("Temperature", "Uncertainty", "NDVI")
ggplot(plot_df,
       aes(x = Temperature, y = NDVI, size = Uncertainty)) + 
  geom_point(alpha = 0.15) + 
  theme_bw()
```

Looks like NDVI increases as mean annual temperatures rise, but reaches a peak around 281-282 Kelvin with a subsequent decrease as mean annual temperatures rise higher.

## Using Third-Party Data

{{% hint danger %}}
**ATTENTION:** Kriging only works on **square-cell spatial products**!
{{% /hint %}}

The `krigR()` function is designed to work with non-ERA5(-Land) data as well as non-GMTED2010 covariate data. To downscale your own spatial products using different covariate data than the GMTED2010 DEM we use as a default, you need to step into the three-step workflow. 

{{% hint warning %}}
Most spatial products won't be reliably downscaled using only elevation covariate data.
{{% /hint %}}

`krigR()` supports any combination of ERA5-family reanalysis, GMTED2010, third-party climate data, and third-party covariate data. Here, we just demonstrate the use of other covariates than the GMTED2010 used by `KrigR` by default.  

The product we will focus on here is the soil moisture data contained in our `BCq_ras` product established [here](/courses/krigr/bioclim/#water-availability-variables). With this data set, we also revert back to our original [study region](/courses/krigr/prep/#shape-of-interest-spatialpolygons):

```{r Shapes, echo = FALSE}
Shape_shp <- ne_states(country = c("Germany", "Czech Republic"))
Shape_shp <- Shape_shp[Shape_shp$name_en %in% c("Saxony", "Saxony-Anhalt", "Thuringia", 
                                                "Ústí nad Labem Region", "Karlovy Vary Region"), ]
```

The reason we focus on soil moisture for this exercise? In [this publication (Figure 3)](https://iopscience.iop.org/article/10.1088/1748-9326/ac39bf), we demonstrate that soil moisture data can be statistically downscales using kriging with some third-party covariates. As such, we pick up from where we left off when we discussed [kriging of bioclimatic products](/courses/krigr/bioclim/#water-availability-3).

<details>
  <summary>Click here for file:</summary>
      Download 
<a href="/courses/krigr/Data/Qsoil_BC.nc">Qsoil_BC.nc</a> and place it into your data directory.
</details> 

```{r}
BCq_ras <- stack(file.path(Dir.Data, "Qsoil_BC.nc"))
```

### Third-Party Data Covariates

In [this publication](https://iopscience.iop.org/article/10.1088/1748-9326/ac39bf), we demonstrate how soil moisture data can be reliably statistically downscaled using soil property data which we obtain from the [Land-Atmosphere Interaction Research Group at Sun Yat-sen University](http://globalchange.bnu.edu.cn/research/soil4.jsp).

Below, you will find the code needed to obtain the data of global coverage at roughly 1km spatial resolution. The code chunk below also crops and masks the data according to our study region and subsequently deletes the storage-heavy global files (3.5GB each in size). This process takes a long time due to download speeds.

<details>
  <summary>Click here for the covariate file to save yourself downloading and processing of global data:</summary>
      Download 
<a href="/courses/krigr/Covariates/SoilCovs.nc">SoilCovs.nc</a> and place it into your covariates directory.
</details> 

```{r}
# documentation of these can be found here http://globalchange.bnu.edu.cn/research/soil4.jsp
SoilCovs_vec <- c("tkdry", "tksat", "csol", "k_s", "lambda", "psi", "theta_s") # need these names for addressing soil covariates
if(!file.exists(file.path(Dir.Covariates, "SoilCovs.nc"))){
  print("#### Loading SOIL PROPERTY covariate data. ####") 
  # create lists to combine soil data into one
  SoilCovs_ls <- as.list(rep(NA, length(SoilCovs_vec)))
  names(SoilCovs_ls) <- c(SoilCovs_vec)
  ## Downloading, unpacking, and loading
  for(Soil_Iter in SoilCovs_vec){
    if(!file.exists(file.path(Dir.Covariates, paste0(Soil_Iter, ".nc")))) { # if not downloaded and processed yet
      print(paste("Handling", Soil_Iter, "data."))
      Dir.Soil <- file.path(Dir.Covariates, Soil_Iter)
      dir.create(Dir.Soil)
      download.file(paste0("http://globalchange.bnu.edu.cn/download/data/worldptf/", Soil_Iter,".zip"),
                    destfile = file.path(Dir.Soil, paste0(Soil_Iter, ".zip"))
      ) # download data
      unzip(file.path(Dir.Soil, paste0(Soil_Iter, ".zip")), exdir = Dir.Soil) # unzip data
      File <- list.files(Dir.Soil, pattern = ".nc")[1] # only keep first soil layer
      Soil_ras <- raster(file.path(Dir.Soil, File)) # load data
      SoilCovs_ls[[which(names(SoilCovs_ls) == Soil_Iter)]] <- Soil_ras # save to list
      writeRaster(x = Soil_ras, filename = file.path(Dir.Covariates, Soil_Iter), format = "CDF")
      unlink(Dir.Soil, recursive = TRUE)
    }else{
      print(paste(Soil_Iter, "already downloaded and processed."))
      SoilCovs_ls[[which(names(SoilCovs_ls) == Soil_Iter)]] <- raster(file.path(Dir.Covariates, paste0(Soil_Iter, ".nc")))
    }
  }
  ## data handling and manipulation
  SoilCovs_stack <- stack(SoilCovs_ls) # stacking raster layers from list
  SoilCovs_stack <- crop(SoilCovs_stack, extent(BCq_ras)) # cropping to extent of data we have
  SoilCovs_mask <- KrigR::mask_Shape(SoilCovs_stack[[1]], Shape = Shape_shp) # create mask with KrigR-internal function to ensure all edge cells are contained
  SoilCovs_stack <- mask(SoilCovs_stack, SoilCovs_mask) # mask out shape
  ## writing the data
  writeRaster(x = SoilCovs_stack, filename = file.path(Dir.Covariates, "SoilCovs"), format = "CDF")
  ## removing the global files due to their size
  unlink(file.path(Dir.Covariates, paste0(SoilCovs_vec, ".nc")))
}
SoilCovs_stack <- stack(file.path(Dir.Covariates, "SoilCovs.nc"))
names(SoilCovs_stack) <- SoilCovs_vec
```

Let's have a look at these data:

```{r}
SoilCovs_stack
```

Now we need to establish target and training resolution of our covariate data.

First, we focus on the training resolution covariate data. We match our covariate data to our spatial product which we wish to downscale by resampling the covariate data to the coarser resolution:
```{r results = 'hide', fig.keep = 'all', fig.height = 12}
Coarsecovs <- resample(x = SoilCovs_stack, y = BCq_ras)
```

Second, we aggregate the covariate data to our desired resolution. In this case, 0.02 as done previously [here](/courses/krigr/bioclim/#kriging-bioclimatic-products):

```{r results = 'hide', fig.keep = 'all', fig.height = 12}
Finecovs <- aggregate(SoilCovs_stack, fact = 0.02/res(SoilCovs_stack)[1])
```

Finally, we combine these into a list like the output of `download_DEM()`:

```{r SoilCovs, results = 'hide', fig.keep = 'all', fig.height = 35}
Covs_ls <- list(Coarsecovs, Finecovs)
Plot_Covs(Covs = Covs_ls, Shape_shp)
```

{{% hint %}}
Our [development goals](/courses/outlook/) include creating a function that automatically carries out all of the above for you with a specification alike to `download_DEM()`.
{{% /hint %}}

### Kriging Third-Party Data

Finally, we can statistically downscale our soil moisture data using the soil property covariates. For this, we need to specify a new `KrigingEquation`. 

{{% hint %}}
With the `KrigingEquation` argument, you may specify non-linear combinations of covariates for your call to `krigR()`.
{{% /hint %}}

{{% hint info %}}
If you don't specify a `KrigingEquation` in `krigR()` and your covariates do not contain a layer called `"DEM"`, `krigR()` will notify you that its default formula cannot be executed and will attempt to build an additive formula from the data it can find. `krigr()` will inform you of this and ask for your approval before proceeding.
{{% /hint %}}

This auto-generated formula would be the same as the one we specify here - an additive combination of all covariates found both at coarse and fine resolutions. Of course, this formula can also be specified to reflect interactive effects.

Here, I automate the generation of our `KrigingEquation`:

```{r}
KrigingEquation <- paste0("ERA ~ ", paste(SoilCovs_vec, collapse = " + "))
KrigingEquation
```

In accordance with our [downscaling of the temperature-portion of the bioclimatic data](/courses/krigr/bioclim/#temperatures-3), (1) I only hand the last 8 layers to the kriging call because those are the soil moisture data, (2) I leave out the `Cores` argument, so that `krigR()` determines how many cores your machine has and uses all of them to speed up the computation of the multi-layer raster, and (3) I set `nmax` to 80 to approximate a typical weather system in size:

```{r results = 'hide', fig.keep = 'all', warning=TRUE}
BC_Water_Krig  <- krigR(Data = BCq_ras[[12:19]], 
                    Covariates_coarse = Covs_ls[[1]], 
                    Covariates_fine = Covs_ls[[2]],
                    KrigingEquation = KrigingEquation, 
                    FileName = "BC_Water_Krig",
                    Dir = Dir.Covariates,
                    nmax = 80
)
```

#### BIO12 - Annual Mean Soil Moisture

{{% hint normal %}}
Interpolating this data is just like statistically downscaling any other soil moisture product and can be done without any problems.
{{% /hint %}}

<details>
  <summary>Click here for plotting call and plot:</summary>
  
{{% hint normal %}}
Look at how well the river Elbe sows up in this!
{{% /hint %}}
```{r fig.keep = 'all', results = "asis", fig.height = 20}
Plot_Krigs(lapply(BC_Water_Krig[-3], "[[", 1), 
           Shp = Shape_shp,
           Dates = "BIO12 - Annual Mean Soil Moisture")
```       
</details>

#### BIO13 - Soil Moisture of Wettest Month

{{% hint normal %}}
Interpolating this data is just like statistically downscaling any other soil moisture product and can be done without any problems.
{{% /hint %}}

<details>
  <summary>Click here for plotting call and plot:</summary>
  
```{r fig.keep = 'all', results = "asis", fig.height = 20}
Plot_Krigs(lapply(BC_Water_Krig[-3], "[[", 2), 
           Shp = Shape_shp,
           Dates = "BIO13 - Soil Moisture of Wettest Month")
```       
</details>

#### BIO14 - Soil Moisture of Driest Month

{{% hint normal %}}
Interpolating this data is just like statistically downscaling any other soil moisture product and can be done without any problems.
{{% /hint %}}

<details>
  <summary>Click here for plotting call and plot:</summary>
  
```{r fig.keep = 'all', results = "asis", fig.height = 20}
Plot_Krigs(lapply(BC_Water_Krig[-3], "[[", 3), 
           Shp = Shape_shp,
           Dates = "BIO13 - Soil Moisture of Driest Month")
```       
</details>

#### BIO15 - Soil Moisture Seasonality

{{% hint warning %}}
This data product is calculated using the standard deviation of mean values throughout our time frame. Conclusively, it would be interpolated better by first statistically downscaling the underlying data rather than the final bioclimatic variable.
{{% /hint %}}

<details>
  <summary>Click here for plotting call and plot:</summary>
  
```{r fig.keep = 'all', results = "asis", fig.height = 20}
Plot_Krigs(lapply(BC_Water_Krig[-3], "[[", 4), 
           Shp = Shape_shp,
           Dates = "BIO15 - Precipitation Seasonality")
```       
</details>

#### BIO16 & BIO17 - Soil Moisture of Wettest and Driest Quarter

{{% hint danger %}}
**I do not recommend you use these kriging outputs!** They rely on mean quarterly soil moisture data which is not being interpolated here. Subsequently, the patchiness of the underlying data is lost and with it: information.
{{% /hint %}}

<details>
  <summary>Click here for plotting call and plot:</summary>
```{r fig.keep = 'all', results = "asis", fig.height = 13}
Plot_Krigs(lapply(BC_Water_Krig[-3], "[[", 5:6), 
           Shp = Shape_shp,
           Dates = c("BIO16 - Soil Moisture of Wettest Quarter", 
                     "BIO17 - Soil Moisture of Driest Quarter")
           )
```
</details>


#### BIO18 & BIO19 - Precipitation of Warmest and Coldest Quarter

{{% hint danger %}}
**I do not recommend you use these kriging outputs!** They rely on mean quarterly temperature data which is not being interpolated here. Subsequently, the patchiness of the underlying data is lost and with it: information.
{{% /hint %}}

<details>
  <summary>Click here for plotting call and plot:</summary>
```{r fig.keep = 'all', results = "asis", fig.height = 13}
Plot_Krigs(lapply(BC_Water_Krig[-3], "[[", 7:8), 
           Shp = Shape_shp,
           Dates = c("BIO16 - Soil Moisture of Warmest Quarter", 
                     "BIO17 - Soil Moisture of Coldest Quarter")
           )
```
</details>

This concludes our exercise for using third-party data in `KrigR`.

## Session Info
```{r}
sessionInfo()
```