<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Erik Kusch</title>
    <link>https://www.erikkusch.com/author/erik-kusch/</link>
      <atom:link href="https://www.erikkusch.com/author/erik-kusch/index.xml" rel="self" type="application/rss+xml" />
    <description>Erik Kusch</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-gb</language><copyright>Â© 2024</copyright><lastBuildDate>Tue, 11 Jun 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.erikkusch.com/img/%C3%A5motdalshytta.jpg</url>
      <title>Erik Kusch</title>
      <link>https://www.erikkusch.com/author/erik-kusch/</link>
    </image>
    
    <item>
      <title></title>
      <link>https://www.erikkusch.com/courses/bftp-biome-detection/data-allocation/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/bftp-biome-detection/data-allocation/</guid>
      <description>&lt;h2 id=&#34;preparing-the-work&#34;&gt;Preparing The Work&lt;/h2&gt;
&lt;p&gt;First of all, most &lt;code&gt;.R&lt;/code&gt; scripts will follow the same kind of structure:&lt;/p&gt;
&lt;h3 id=&#34;head&#34;&gt;Head&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Head&lt;/strong&gt; is used as an information statement at the top of your code document that informs the user of the contents, author, and (sometimes) date of the last edit on said document. This is highly useful when you are intending to give your document to other people at some point. The head for our analysis might look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# ####################################################################### #
# PROJECT: [BFTP] Identifying Biomes And Their Shifts Using Remote Sensing
# CONTENTS: Functionality to download, aggregate, and crop/mask NDVI data
# AUTHOR: Erik Kusch
# EDIT: 09/03/20
# ####################################################################### #
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;preamble&#34;&gt;Preamble&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Preamble&lt;/strong&gt; is where you set up the most important parameters/guidelines for your coding script. Personally, I &lt;em&gt;highly&lt;/em&gt; recommend to make your first line in the preamble read &lt;code&gt;rm(list=ls())&lt;/code&gt;. This nifty line of code clears your entire working environment in &lt;code&gt;R&lt;/code&gt; meaning that you work from a clean slate thus eliminating all possible interference of previous work. If your code works as intended after this line, it means that your project is &lt;em&gt;internally consistent&lt;/em&gt; and &lt;em&gt;self-contained&lt;/em&gt; which makes your analysis &lt;strong&gt;reproducible&lt;/strong&gt; (we want that!).&lt;/p&gt;
&lt;p&gt;Afterwards, I like to establish a &lt;em&gt;directory&lt;/em&gt; (i.e. &amp;ldquo;folder&amp;rdquo;) structure. After all, no one likes a cluttered folder on their hard drive.Therefore, we identify our current working directory (wd) with &lt;code&gt;getwd()&lt;/code&gt; and save it as an object in &lt;code&gt;R&lt;/code&gt; which we call &lt;code&gt;Dir.Base&lt;/code&gt;. This is the folder in which our document is located and where &lt;code&gt;R&lt;/code&gt; is looking for and saving files to. We don&amp;rsquo;t want to dump everything there. Conclusively, we need to create our own folders within our project folder. We would like to call these folders &amp;ldquo;Data&amp;rdquo; and &amp;ldquo;Plots&amp;rdquo; (the purpose of these folders should be obvious from their names). To actually create these folders on your hard drive, we must first establish the folder paths. We do so by using the &lt;code&gt;paste()&lt;/code&gt; command in &lt;code&gt;R&lt;/code&gt; which combines objects and writes the &lt;code&gt;sep&lt;/code&gt; argument between the combined objects. Here, we take the path to our project folder (&lt;code&gt;Dir.Base &lt;/code&gt;) and combine it with the name of the folder we want (e.g. &amp;ldquo;Data&amp;rdquo;) while using the backslash (&amp;quot;/&amp;quot;) between these two objects as it indicates the jump in a folder hierarchy. The folder is then created using the &lt;code&gt;dir.create()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Our preamble then looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing the entire environment
Dir.Base &amp;lt;- getwd() # identifying the current directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # generating the folder path for data folder
dir.create(Dir.Data) # creating the data folder
Dir.Plots &amp;lt;- paste(Dir.Base, &amp;quot;Plots&amp;quot;, sep=&amp;quot;/&amp;quot;) # generating the folder path for figures folder
dir.create(Dir.Plots) # creating the figures folder
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Usually, this is also where we load &lt;em&gt;packages&lt;/em&gt; for more functionality of our analyses. However, this time, we will do so when they are necessary to give you a better overview and explanation what they do.&lt;/p&gt;
&lt;h3 id=&#34;coding&#34;&gt;Coding&lt;/h3&gt;
&lt;p&gt;All of the important &lt;strong&gt;Coding&lt;/strong&gt; happens after the head and the preamble are written and run in &lt;code&gt;R&lt;/code&gt;. Basically, this is the rest of this document.&lt;/p&gt;
&lt;h2 id=&#34;downloading-ndvi-data&#34;&gt;Downloading NDVI Data&lt;/h2&gt;
&lt;p&gt;First of all, we need to download the NDVI data that we are interested in. One particularly useful repository for this is the Global Inventory Modelling and Mapping Studies (GIMMS) 3g v.1 data set obtained via the Advanced Very High Resolution Radiometer (AVHRR). This time series goes back all the way to January 1982 and contains bi-weekly, global projects of NDVI values.&lt;/p&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Firstly, we need some packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gimms&lt;/code&gt; is a package which enables us to download the GIMMS 3g v.1 data set directly through &lt;code&gt;R&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;raster&lt;/code&gt; is a package which allows us to establish, handle, and save spatial gridded products of any variable we want (NDVI in this case)&lt;br&gt;
We install and load our packages as follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;gimms&amp;quot;) # for GIMMS NDVI data download
library(gimms)
install.packages(&amp;quot;raster&amp;quot;) # for spatial raster format
library(raster)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;downloading&#34;&gt;Downloading&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s download the GIMMS 3g v.1 NDVI data for the entire year of 1982:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gimms_files &amp;lt;- downloadGimms(x = as.Date(&amp;quot;1982-01-01&amp;quot;), # download from January 1982
                             y = as.Date(&amp;quot;1982-12-31&amp;quot;), # download to December 1982
                             dsn = Dir.Data, # save downloads in data folder
                             quiet = FALSE # show download progress
                             )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we want to turn our downloaded data into a raster so we can do spatial analyses with it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gimms_raster &amp;lt;- rasterizeGimms(x = gimms_files, # the data we rasterize
                               remove_header = TRUE # we don&#39;t need the header of the data
                               )
gimms_raster # some information about the raster stack we created here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterStack 
## dimensions : 2160, 4320, 9331200, 24  (nrow, ncol, ncell, nlayers)
## resolution : 0.083, 0.083  (x, y)
## extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## names      : ndvi.1.1, ndvi.2.1, ndvi.3.1, ndvi.4.1, ndvi.5.1, ndvi.6.1, ndvi.7.1, ndvi.8.1, ndvi.9.1, ndvi.10.1, ndvi.11.1, ndvi.12.1, ndvi.1.2, ndvi.2.2, ndvi.3.2, ... 
## min values :     -0.3,     -0.3,     -0.3,     -0.3,     -0.3,     -0.3,     -0.3,     -0.3,     -0.3,      -0.3,      -0.3,      -0.3,     -0.3,     -0.3,     -0.3, ... 
## max values :     0.99,     0.99,     1.00,     0.99,     0.99,     0.99,     1.00,     1.00,     0.99,      0.99,      1.00,      1.00,     1.00,     1.00,     1.00, ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, you can see that we have successfully created a &lt;code&gt;RasterStack&lt;/code&gt; with 24 layers (two for each month because measurements were bi-weekly), for the entire earth (extent of -180, 180, -90, 90). We can also see that there are some values below 0 which we don&amp;rsquo;t expect for the NDVI and we will fix this in a second. For now, just notice that we have successfully downloaded the data.&lt;/p&gt;
&lt;h2 id=&#34;aggregating-ndvi-data&#34;&gt;Aggregating NDVI Data&lt;/h2&gt;
&lt;p&gt;With our data successfully downloaded, it is now time to prepare the data further for our analysis.&lt;/p&gt;
&lt;h3 id=&#34;composites&#34;&gt;Composites&lt;/h3&gt;
&lt;p&gt;Firstly, we want to deal with monthly NDVI values. To do so, we want to build monthly maximum composites. Luckily, the &lt;code&gt;gimms&lt;/code&gt; package has just the right option for us:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;indices &amp;lt;- monthlyIndices(gimms_files) # generate month indices from the data
gimms_raster_mvc &amp;lt;- monthlyComposite(gimms_raster, # the data
                                     indices = indices # the indices
                                     )
gimms_raster_mvc # some information about our monthly composite raster stack
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterStack 
## dimensions : 2160, 4320, 9331200, 12  (nrow, ncol, ncell, nlayers)
## resolution : 0.083, 0.083  (x, y)
## extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## names      : index_1.1, index_1.2, index_1.3, index_1.4, index_1.5, index_1.6, index_1.7, index_1.8, index_1.9, index_1.10, index_1.11, index_1.12 
## min values :     -0.30,     -0.30,     -0.30,     -0.29,     -0.30,     -0.30,     -0.30,     -0.30,     -0.30,      -0.30,      -0.30,      -0.30 
## max values :      0.99,      1.00,      0.99,      1.00,      0.99,      1.00,      1.00,      1.00,      1.00,       1.00,       0.99,       0.99
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see above, our new raster stack has the same dimensions, resolution, coordinate reference system (crs), and extent as the previous one. However, we have reduced the number of layers to 12 (one for each month).&lt;/p&gt;
&lt;p&gt;Since there are still negative values present (an artifact of how NASA stores the data or cloud cover), we simply set these to 0:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Negatives &amp;lt;- which(values(gimms_raster_mvc) &amp;lt; 0) # identify all negative values
values(gimms_raster_mvc)[Negatives] &amp;lt;- 0 # set threshold for barren land (NDVI&amp;lt;0)
gimms_raster_mvc
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterBrick 
## dimensions : 2160, 4320, 9331200, 12  (nrow, ncol, ncell, nlayers)
## resolution : 0.083, 0.083  (x, y)
## extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : memory
## names      : index_1.1, index_1.2, index_1.3, index_1.4, index_1.5, index_1.6, index_1.7, index_1.8, index_1.9, index_1.10, index_1.11, index_1.12 
## min values :         0,         0,         0,         0,         0,         0,         0,         0,         0,          0,          0,          0 
## max values :      0.99,      1.00,      0.99,      1.00,      0.99,      1.00,      1.00,      1.00,      1.00,       1.00,       0.99,       0.99
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See how all of the &lt;code&gt;min values&lt;/code&gt; are now on 0!&lt;/p&gt;
&lt;p&gt;Lastly, we want to see what our data looks like (visual inspection is an important step to sanity check your work). We do so as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(gimms_raster_mvc)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;01---data_allocation_files/figure-html/Aggr3-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What a beautiful seasonal trend of greening we can observe (I&amp;rsquo;ll stop nerding out here before it get&amp;rsquo;s out of hand, don&amp;rsquo;t worry)!&lt;/p&gt;
&lt;h3 id=&#34;annual-values&#34;&gt;Annual Values&lt;/h3&gt;
&lt;p&gt;Lastly, we may wish (and in fact, you will have to) aggregate our data to annual and even more-than-annual means and seasonality measures.&lt;/p&gt;
&lt;h4 id=&#34;mean-values&#34;&gt;Mean Values&lt;/h4&gt;
&lt;p&gt;To establish annual mean values, we simply take the mean for each cell in our raster stack for all the layers as such:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gimms_annual &amp;lt;- calc(gimms_raster_mvc, # data from which to calculate
                     fun=mean, # function which to calculate with
                     na.rm = TRUE # ignore NAs
                     )
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;seasonality-values&#34;&gt;Seasonality Values&lt;/h4&gt;
&lt;p&gt;Measures of seasonality are defined as the span between the maximum value of a cell and the minimum value of the same cell. So, we calculate a maximum raster and a minimum raster and then simply subtract the minimum from the maximum as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;maxi &amp;lt;- calc(gimms_raster_mvc, fun=max)
mini &amp;lt;- calc(gimms_raster_mvc, fun=min)
gimms_seasonality &amp;lt;- maxi-mini
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;\pagebreak&lt;/p&gt;
&lt;h4 id=&#34;plots&#34;&gt;Plots&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s have a look at our annual mean and seasonality:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(gimms_annual, main = &amp;quot;Mean&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;01---data_allocation_files/figure-html/Aggr6-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(gimms_seasonality, main = &amp;quot;Seasonality&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;01---data_allocation_files/figure-html/Aggr6-2.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;cropping-ndvi-data&#34;&gt;Cropping NDVI Data&lt;/h2&gt;
&lt;p&gt;Our data is still on a global scale. We are only interested in data across Alaska, though. Let&amp;rsquo;s deal with that.&lt;/p&gt;
&lt;h3 id=&#34;packages--data&#34;&gt;Packages &amp;amp; Data&lt;/h3&gt;
&lt;p&gt;Again, we have to install some packages and load them.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;sp&amp;quot;) # for spatialpolygons format
library(sp)
install.packages(&amp;quot;rgdal&amp;quot;) # for shapefiles
library(rgdal)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Secondly, we require the actual shape files. Personally, I am a big fan of the Natural Earth Shape files (\url{http://www.naturalearthdata.com/downloads/10m-cultural-vectors/}) because of all the different shape files I can get there. Here, we are interested in states/provinces and so want to download the data from here: \url{https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_1_states_provinces.zip}. Thankfully, &lt;code&gt;R&lt;/code&gt;let&amp;rsquo;s us do the downloading as well as the unpacking of archived (.zip) data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Downloading
download.file(&amp;quot;https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_1_states_provinces.zip&amp;quot;,
              destfile = paste(Dir.Data, &amp;quot;Shapes.zip&amp;quot;, sep=&amp;quot;/&amp;quot;)) # destination file
# Unzipping
unzip(paste(Dir.Data, &amp;quot;Shapes.zip&amp;quot;, sep=&amp;quot;/&amp;quot;), # which file to unzip
      exdir = Dir.Data) # where to unzip to
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we want to load our shape files into &lt;code&gt;R&lt;/code&gt;. We do this using the &lt;code&gt;readOGR()&lt;/code&gt; function in &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Shapes &amp;lt;- readOGR(Dir.Data, # where to look for the file
                  &amp;quot;ne_10m_admin_1_states_provinces&amp;quot;, # the file name
                  verbose = FALSE) # we don&#39;t want an overview of the loaded data
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;crop--mask&#34;&gt;Crop &amp;amp; Mask&lt;/h3&gt;
&lt;p&gt;Now, we are ready to use our shape file for Alaska. First, we have to find out which of our shape files is for Alaska:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Position &amp;lt;- which(Shapes$name_en == &amp;quot;Alaska&amp;quot;) # find the english name that&#39;s &amp;quot;Alaska&amp;quot; in our shapefiles
Alaska_Shp &amp;lt;- Shapes[Position,] # extract the Alaska shapefile
plot(Alaska_Shp) # plot it for inspection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;01---data_allocation_files/figure-html/Crop4-1.png&#34; width=&#34;1152&#34; /&gt;
We really don&amp;rsquo;t care much about that island chain all the way to the right in our plot.&lt;/p&gt;
&lt;p&gt;This is likely to be an extent-caused issue and we should crop our shape file extent to the easternmost point of Alaska on the continent:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;extent(Alaska_Shp) # extent clearly shows the super-eastern coordinates
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : Extent 
## xmin       : -179 
## xmax       : 180 
## ymin       : 51 
## ymax       : 71
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Crop
Alaska_Shp &amp;lt;- crop(Alaska_Shp, # what to crop
                   extent(-190, -130, 51, 71)) # which extent to crop to
plot(Alaska_Shp) # visualising the cropped product
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;01---data_allocation_files/figure-html/Crop5-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Lovely. That resolved the issue. We are ready for final cropping of our data and saving of the cropped data.&lt;/p&gt;
&lt;h4 id=&#34;mean-values-1&#34;&gt;Mean Values&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s deal with the annual mean for 1982:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Crop
gimms_annual &amp;lt;- crop(gimms_annual, # mean annual data
                     extent(Alaska_Shp)) # cropped Alaska extent
# Mask (this keeps only cells that fall into our shapefile)
gimms_annual &amp;lt;- mask(gimms_annual, # cropped annual means
                     Alaska_Shp) # cropped Alaska shapefile
plot(gimms_annual, main =&amp;quot;Annual Mean 1982&amp;quot;) # inspection time!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;01---data_allocation_files/figure-html/Crop6-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Save data
writeRaster(x = gimms_annual, # which raster to save
            file = paste(Dir.Data, &amp;quot;1982Mean&amp;quot;, sep=&amp;quot;/&amp;quot;), # which file to save to
            format = &amp;quot;CDF&amp;quot;, overwrite = TRUE) # which format to use and whether to overwrite
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterLayer 
## dimensions : 237, 590, 139830  (nrow, ncol, ncell)
## resolution : 0.083, 0.083  (x, y)
## extent     : -179, -130, 51, 71  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : 1982Mean.nc 
## names      : layer 
## values     : 0, 0.84  (min, max)
## zvar       : layer
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;seasonality-values-1&#34;&gt;Seasonality Values&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Crop
gimms_seasonality &amp;lt;- crop(gimms_seasonality, # mean seasonality data
                     extent(Alaska_Shp)) # cropped Alaska extent
# Mask (this keeps only cells that fall into our shapefile)
gimms_seasonality &amp;lt;- mask(gimms_seasonality, # cropped seasonality data
                     Alaska_Shp) # cropped Alaska shapefile
plot(gimms_seasonality, main = &amp;quot;Seasonality 1982&amp;quot;) # inspection time!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;01---data_allocation_files/figure-html/Crop7-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Save data
writeRaster(x = gimms_seasonality, # which raster to save
            file = paste(Dir.Data, &amp;quot;1982Season&amp;quot;, sep=&amp;quot;/&amp;quot;), # which file to save to
            format = &amp;quot;CDF&amp;quot;, overwrite = TRUE) # which format to use and whether to overwrite
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterLayer 
## dimensions : 237, 590, 139830  (nrow, ncol, ncell)
## resolution : 0.083, 0.083  (x, y)
## extent     : -179, -130, 51, 71  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : 1982Season.nc 
## names      : layer 
## values     : 0, 1  (min, max)
## zvar       : layer
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to R</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/introduction-to-r/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/introduction-to-r/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are the solutions to the exercises contained within the handout to Introduction to R which walks you through the basics of the &lt;code&gt;R&lt;/code&gt; machinery. &lt;code&gt;R&lt;/code&gt; is a coding language that can be highly individualised and hence there are often multiple solutions to the same problem. Within these solutions, I shall only present you with one solution for every given task. However, do keep in mind that there is probably a myriad of other ways to achieve your goal.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/02---Introduction-to-R_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;!-- [Lecture Slides](erikkusch.com/courses/An Introduction to Biostatistics/02---Introduction-to-R_Handout.html) for this session. --&gt;
&lt;h2 id=&#34;creating-and-inspecting-objects&#34;&gt;Creating and Inspecting Objects&lt;/h2&gt;
&lt;h3 id=&#34;vector&#34;&gt;Vector&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A vector reading: &amp;ldquo;A&amp;rdquo;, &amp;ldquo;B&amp;rdquo;, &amp;ldquo;C&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Letters_vec &amp;lt;- c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;)
Letters_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;A&amp;quot; &amp;quot;B&amp;quot; &amp;quot;C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Letters_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A vector reading: 1, 2, 3&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Numbers_vec &amp;lt;- c(1, 2, 3)
Numbers_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Numbers_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A vector reading: &lt;code&gt;TRUE&lt;/code&gt;, &lt;code&gt;FALSE&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Logic_vec &amp;lt;- c(TRUE, FALSE)
Logic_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  TRUE FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Logic_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A vector of the elements of the first three vectors&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Big_vec &amp;lt;- c(Letters_vec, Numbers_vec, Logic_vec)
Big_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;A&amp;quot;     &amp;quot;B&amp;quot;     &amp;quot;C&amp;quot;     &amp;quot;1&amp;quot;     &amp;quot;2&amp;quot;     &amp;quot;3&amp;quot;     &amp;quot;TRUE&amp;quot;  &amp;quot;FALSE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Big_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A vector reading as a sequence of full numbers from 1 to 20&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Seq_vec &amp;lt;- c(1:20)
Seq_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Seq_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 20
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;factor&#34;&gt;Factor&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A factor reading: &amp;ldquo;A&amp;rdquo;, &amp;ldquo;B&amp;rdquo;, &amp;ldquo;C&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Letters_fac &amp;lt;- factor(x = c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;))
Letters_fac
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] A B C
## Levels: A B C
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Letters_fac)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A factor reading: 1, 2, 3&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Numbers_fac &amp;lt;- factor(x = c(1, 2, 3))
Numbers_fac
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3
## Levels: 1 2 3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Numbers_fac)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A factor reading: 1, 2, 3 but only levels 1 and 2 are allowed&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Constrained_fac &amp;lt;- factor(x = c(1, 2, 3), levels = c(1, 2))
Constrained_fac
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1    2    &amp;lt;NA&amp;gt;
## Levels: 1 2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Constrained_fac)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;A factor reading: 1, 2, 3 levels 1 - 4 are allowed&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Expanded_fac &amp;lt;- factor(x = c(1, 2, 3), levels = c(1, 2, 3, 4))
Expanded_fac
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3
## Levels: 1 2 3 4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Expanded_fac)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;matrix&#34;&gt;Matrix&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The first two vectors we established in distinct columns of a matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Combine_mat &amp;lt;- matrix(data = c(Numbers_vec, Letters_vec), ncol = 2)
Combine_mat
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,] &amp;quot;1&amp;quot;  &amp;quot;A&amp;quot; 
## [2,] &amp;quot;2&amp;quot;  &amp;quot;B&amp;quot; 
## [3,] &amp;quot;3&amp;quot;  &amp;quot;C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Combine_mat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3 2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The first two vectors we established in distinct rows of a matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Pivot_mat &amp;lt;- matrix(data = c(Numbers_vec, Letters_vec), nrow = 2, byrow = TRUE)
Pivot_mat
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3]
## [1,] &amp;quot;1&amp;quot;  &amp;quot;2&amp;quot;  &amp;quot;3&amp;quot; 
## [2,] &amp;quot;A&amp;quot;  &amp;quot;B&amp;quot;  &amp;quot;C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Pivot_mat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The above matrix with meaningful names&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Names_mat &amp;lt;- Pivot_mat
dimnames(Names_mat) &amp;lt;- list(c(&amp;quot;Numbers&amp;quot;, &amp;quot;Letters&amp;quot;))
Names_mat
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         [,1] [,2] [,3]
## Numbers &amp;quot;1&amp;quot;  &amp;quot;2&amp;quot;  &amp;quot;3&amp;quot; 
## Letters &amp;quot;A&amp;quot;  &amp;quot;B&amp;quot;  &amp;quot;C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Names_mat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;data-frame&#34;&gt;Data Frame&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The first matrix we established as a data frame&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Combine_df &amp;lt;- data.frame(Combine_mat)
Combine_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X1 X2
## 1  1  A
## 2  2  B
## 3  3  C
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Combine_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3 2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The previous data frame with meaningful names&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Names_df &amp;lt;- Combine_df
colnames(Names_df) &amp;lt;- c(&amp;quot;Numbers&amp;quot;, &amp;quot;Letters&amp;quot;)
Names_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Numbers Letters
## 1       1       A
## 2       2       B
## 3       3       C
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Names_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3 2
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;list&#34;&gt;List&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The first two vectors we created&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Vectors_ls &amp;lt;- list(Numbers_vec, Letters_vec)
Vectors_ls
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 1 2 3
## 
## [[2]]
## [1] &amp;quot;A&amp;quot; &amp;quot;B&amp;quot; &amp;quot;C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Vectors_ls)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;statements-and-loops&#34;&gt;Statements and Loops&lt;/h2&gt;
&lt;h3 id=&#34;statements&#34;&gt;Statements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Numbers_vec&lt;/code&gt; contains more elements than &lt;code&gt;Letters_fac&lt;/code&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Numbers_vec) &amp;gt; length(Letters_fac)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The first column of &lt;code&gt;Combine_df&lt;/code&gt; is shorter than &lt;code&gt;Vectors_ls&lt;/code&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(Combine_df[, 1]) &amp;lt; length(Vectors_ls)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The elements of &lt;code&gt;Letters_vec&lt;/code&gt; are the same as the elements of &lt;code&gt;Letters_fac&lt;/code&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Letters_vec == Letters_fac
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE TRUE TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loops&#34;&gt;Loops&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Print each element of &lt;code&gt;Vectors_ls&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;for (i in 1:length(Vectors_ls)) {
    print(Vectors_ls[[i]])
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3
## [1] &amp;quot;A&amp;quot; &amp;quot;B&amp;quot; &amp;quot;C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Print each element of &lt;code&gt;Numbers_vec&lt;/code&gt; + 1&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Numbers_veca &amp;lt;- Numbers_vec + 1
for (i in 1:length(Numbers_veca)) {
    print(Numbers_veca[i])
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2
## [1] 3
## [1] 4
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Subtract 1 from each element of the first column of &lt;code&gt;Combine_mat&lt;/code&gt; and print each element separately&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Mat_column &amp;lt;- Combine_mat[, 1]  # extract data
Mat_column &amp;lt;- as.numeric(Mat_column)  # convert to numeric
Mat_column &amp;lt;- Mat_column - 1  # substract 1
for (i in 1:length(Mat_column)) {
    print(Mat_column[i])
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0
## [1] 1
## [1] 2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;useful-commands&#34;&gt;Useful Commands&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Read out your current working directory (not showing you the result as it is different on every machine, it should start like this &amp;ldquo;C:/Users/&amp;hellip;.&amp;quot;)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;getwd()
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Inspect the &lt;code&gt;Vectors_ls&lt;/code&gt; object using the &lt;code&gt;View()&lt;/code&gt; function (again, I am not showing you the result as this only works directly in &lt;code&gt;R&lt;/code&gt; or Rstudio)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;View(Vectors_ls)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Inspect the &lt;code&gt;Combine_df&lt;/code&gt; object using the &lt;code&gt;View()&lt;/code&gt; function (again, I am not showing you the result as this only works directly in &lt;code&gt;R&lt;/code&gt; or Rstudio)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;View(Combine_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Get the help documentation for the &lt;code&gt;as.matrix()&lt;/code&gt; function (again, I am not showing you the result as this only works directly in &lt;code&gt;R&lt;/code&gt; or Rstudio)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;`?`(as.matrix)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Install and load the &lt;code&gt;dplyr&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;dplyr&amp;quot;)
library(dplyr)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Remove the &lt;code&gt;Logic_vec&lt;/code&gt; object from your working environment&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(Logic_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Clear your entire working environment&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ls()  # this command shows you all the object in the environment
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Big_vec&amp;quot;         &amp;quot;Combine_df&amp;quot;      &amp;quot;Combine_mat&amp;quot;     &amp;quot;Constrained_fac&amp;quot;
##  [5] &amp;quot;Expanded_fac&amp;quot;    &amp;quot;i&amp;quot;               &amp;quot;Letters_fac&amp;quot;     &amp;quot;Letters_vec&amp;quot;    
##  [9] &amp;quot;Mat_column&amp;quot;      &amp;quot;Names_df&amp;quot;        &amp;quot;Names_mat&amp;quot;       &amp;quot;Numbers_fac&amp;quot;    
## [13] &amp;quot;Numbers_vec&amp;quot;     &amp;quot;Numbers_veca&amp;quot;    &amp;quot;Pivot_mat&amp;quot;       &amp;quot;Seq_vec&amp;quot;        
## [17] &amp;quot;Vectors_ls&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list = ls())
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Cluster Analysis</title>
      <link>https://www.erikkusch.com/courses/bftp-biome-detection/cluster-analysis/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/bftp-biome-detection/cluster-analysis/</guid>
      <description>&lt;h2 id=&#34;preparing-the-work&#34;&gt;Preparing The Work&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s create our basic structure for this document:&lt;/p&gt;
&lt;h3 id=&#34;head&#34;&gt;Head&lt;/h3&gt;
&lt;p&gt;Not much has changed in the &lt;strong&gt;head&lt;/strong&gt; when compared to our last exercise. We merely change the &lt;em&gt;contents&lt;/em&gt; and and the &lt;em&gt;edit&lt;/em&gt; tag, since the rest stays the same for the entire project.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# ####################################################################### #
# PROJECT: [BFTP] Identifying Biomes And Their Shifts Using Remote Sensing
# CONTENTS: Functionality to identify clusters of NDVI mean and seasonality
# AUTHOR: Erik Kusch
# EDIT: 18/03/20
# ####################################################################### #
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;preamble&#34;&gt;Preamble&lt;/h3&gt;
&lt;p&gt;I am keeping the same &lt;strong&gt;preamble&lt;/strong&gt; as last time because we will need to index the data and the plot directory in this exercise. Our preamble then looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing the entire environment
Dir.Base &amp;lt;- getwd() # identifying the current directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # generating the folder path for data folder
Dir.Plots &amp;lt;- paste(Dir.Base, &amp;quot;Plots&amp;quot;, sep=&amp;quot;/&amp;quot;) # generating the folder path for figures folder
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice, that we do not call the function &lt;code&gt;dir.create()&lt;/code&gt; this time. We don&amp;rsquo;t need to do so, because we already created the two directories established above in our last exercise. Usually, we would create this entire analysis of your BFTP project in one &lt;code&gt;R&lt;/code&gt; code script. In this case, we would only have one preamble which defines and creates directories instead of doing this step for every single sub-part of the analysis. Alas, we want to break this down for you. Therefore, you see this preamble here and will again in the next exercise.&lt;/p&gt;
&lt;p&gt;Again, this is where would load packages, but I am going to install and load the necessary packages when needed to show you what they are good for. Personally, I recommend you always load all necessary packages at the beginning of your code file and leave comments as to what you load them for. This will make it easier to remove packages you don&amp;rsquo;t need anymore when you change things.&lt;/p&gt;
&lt;h3 id=&#34;coding&#34;&gt;Coding&lt;/h3&gt;
&lt;p&gt;Again, all of the important &lt;strong&gt;Coding&lt;/strong&gt; happens after the head and the preamble are written and run in &lt;code&gt;R&lt;/code&gt;. Basically, this is the rest of this document once more.&lt;/p&gt;
&lt;h2 id=&#34;cluster-analysis&#34;&gt;Cluster Analysis&lt;/h2&gt;
&lt;p&gt;Cluster analyses come in many forms. Here, we are interested in a k-means clustering approach. These approaches identify $k$ (a number) clusters. One of the most prominent ways to do this in &lt;code&gt;R&lt;/code&gt; is undoubtedly the &lt;code&gt;mclust&lt;/code&gt; &lt;code&gt;R&lt;/code&gt; package. Clusters can be thought of as groupings of data in multi-dimensional space. The number of dimensions is equal to the number of clustering components. In the &lt;code&gt;mclust&lt;/code&gt; &lt;code&gt;R&lt;/code&gt; package, the characteristics of these clusters (orientation, volume, shape) are, if not specified otherwise, estimated from the data.&lt;/p&gt;
&lt;!-- They can be set to vary between clusters or constrained to be the same for all clusters. Depending on cluster characteristics, `mclust` distinguishes 20 individual models which you can see in table \ref{tab:MClustModels}, but are not expected to understand fully.   --&gt;
&lt;!-- \begin{table}[ht!] --&gt;
&lt;!--   \centering --&gt;
&lt;!--   \caption[Models in mclust]{\textbf{Models in mclust:} The r-package mclust distinguishes 20 different models for data clustering based on distribution and cluster characteristics.} --&gt;
&lt;!--     \begin{tabular}{|lcccc|} --&gt;
&lt;!--     Acronym &amp; Distribution &amp; Volume &amp; Shape &amp; Orientation \\ --&gt;
&lt;!--     \hline --&gt;
&lt;!--     E     &amp; univariate &amp; equal &amp; -     &amp; - \\ --&gt;
&lt;!--     V     &amp; univariate &amp; variable &amp; -     &amp; - \\ \hdashline --&gt;
&lt;!--     EII   &amp; spherical  &amp; equal &amp; equal &amp; NA \\ --&gt;
&lt;!--     VII   &amp; spherical  &amp; variable &amp; equal &amp; NA \\ \hdashline --&gt;
&lt;!--     EEI   &amp; diagonal &amp; equal &amp; equal &amp; coordinate axes \\ --&gt;
&lt;!--     VEI   &amp; diagonal &amp; variable &amp; equal &amp; coordinate axes \\ --&gt;
&lt;!--     EVI   &amp; diagonal &amp; equal &amp; variable &amp; coordinate axes \\ --&gt;
&lt;!--     VVI   &amp; diagonal &amp; variable &amp; variable &amp; coordinate axes \\ \hdashline --&gt;
&lt;!--     EEE   &amp; ellipsoidal &amp; equal &amp; equal &amp; equal \\ --&gt;
&lt;!--     EVE   &amp; ellipsoidal &amp; equal &amp; variable &amp; equal \\ --&gt;
&lt;!-- 	VEE   &amp; ellipsoidal &amp; variable &amp; equal &amp; equal \\     --&gt;
&lt;!--     VVE   &amp; ellipsoidal &amp; variable &amp; variable &amp; equal \\ --&gt;
&lt;!--     EEV   &amp; ellipsoidal &amp; equal &amp; equal &amp; variable \\ --&gt;
&lt;!--     VEV   &amp; ellipsoidal &amp; variable &amp; equal &amp; variable \\ --&gt;
&lt;!--     EEV   &amp; ellipsoidal &amp; equal &amp; variable &amp; variable \\ --&gt;
&lt;!--     VVV   &amp; ellipsoidal &amp; variable &amp; variable &amp; variable \\ \hdashline --&gt;
&lt;!--     X	  &amp; \multicolumn{4}{c|}{univariate normal} \\ --&gt;
&lt;!--     XII	  &amp; \multicolumn{4}{c|}{spherical multivariate normal} \\ --&gt;
&lt;!--     XXI	  &amp; \multicolumn{4}{c|}{diagonal multivariate normal} \\ --&gt;
&lt;!--     XXX	  &amp; \multicolumn{4}{c|}{ellipsoidal multivariate normal} \\ --&gt;
&lt;!--     \hline --&gt;
&lt;!--     \end{tabular}% --&gt;
&lt;!--   \label{tab:MClustModels}% --&gt;
&lt;!-- \end{table} --&gt;
&lt;p&gt;&lt;code&gt;mclust&lt;/code&gt; provides the user with a very autonomous process of model calculation and selection. First, if not specified otherwise, &lt;code&gt;mclust&lt;/code&gt; calculates all available models for a range of cluster component numbers (by default one to nine clusters). Secondly, once the models are established, &lt;code&gt;mclust&lt;/code&gt; selects the most appropriate of the models according to their respective Bayesian Information Criterion (BIC) value. The BIC is an indicator of model quality: the lower the BIC, the better the model fits the data. Conclusively, &lt;code&gt;mclust&lt;/code&gt; chooses the model with the lowest BIC available for clustering the data.&lt;/p&gt;
&lt;!-- As an example: for a clustering of data with four individual variables, `mclust` will, by default, calculate 126 individual models (14 model classes $*$ 9 cluster possibilities). It will calculate models from only 14 classes, since E, V, X, XII, XXI and XXX models are only appropriate for single variable clustering.   --&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;Before we can get started with our analysis, we have to load our NDVI mean and seasonality data (see last exercise) back into &lt;code&gt;R&lt;/code&gt;, we do this as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(raster) # the raster package for rasters
Mean1982_ras &amp;lt;- raster(paste(Dir.Data, &amp;quot;1982Mean.nc&amp;quot;, sep=&amp;quot;/&amp;quot;)) # loading means
Season1982_ras &amp;lt;- raster(paste(Dir.Data, &amp;quot;1982Season.nc&amp;quot;, sep=&amp;quot;/&amp;quot;)) # loading seasonalities
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have loaded the data into &lt;code&gt;R&lt;/code&gt;, it is time to introduce you to another useful feature of the &lt;code&gt;raster&lt;/code&gt; package - the &lt;strong&gt;stack&lt;/strong&gt;. With a stack of rasters, you can do exactly what the name suggests, stack rasters of the same resolution, and extent into one &lt;code&gt;R&lt;/code&gt; object. You do this by calling the &lt;code&gt;stack()&lt;/code&gt;function in &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;All1982_ras &amp;lt;- stack(Mean1982_ras, Season1982_ras) # creating a stack
names(All1982_ras) &amp;lt;- c(&amp;quot;Mean&amp;quot;, &amp;quot;Seasonality&amp;quot;) # assign names to stack layers
All1982_ras
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterStack 
## dimensions : 237, 590, 139830, 2  (nrow, ncol, ncell, nlayers)
## resolution : 0.083, 0.083  (x, y)
## extent     : -179, -130, 51, 71  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## names      : Mean, Seasonality 
## min values :    0,           0 
## max values : 0.84,        1.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this object contains both rasters as &lt;em&gt;layers&lt;/em&gt; which we have already assigned names to.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s see how plotting works with this. This time, I am adding a couple of arguments to the &lt;code&gt;plot()&lt;/code&gt; function to make the plots nicer than before:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(All1982_ras, # what to plot
     colNA = &amp;quot;black&amp;quot;, # which colour to assign to NA values
     legend.shrink=1, # vertical size of legend
     legend.width=2 # horizontal size of legend
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;02---classifications_files/figure-html/Loading3-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Using stacks makes plotting easier in &lt;code&gt;R&lt;/code&gt; if you want to plot more than one raster at a time.&lt;/p&gt;
&lt;h3 id=&#34;data-extraction&#34;&gt;Data Extraction&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;re now ready to extract data from our data sets. &lt;code&gt;mclust&lt;/code&gt; let&amp;rsquo;s us assess multi-dimensional clusters but wants the data to be handed over in one file - as a matrix, to be precise. Let&amp;rsquo;s see what happens when we just look the first few (&lt;code&gt;head()&lt;/code&gt;) values (&lt;code&gt;values()&lt;/code&gt;) of our raster stack:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(values(All1982_ras))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Mean Seasonality
## [1,]   NA          NA
## [2,]   NA          NA
## [3,]   NA          NA
## [4,]   NA          NA
## [5,]   NA          NA
## [6,]   NA          NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the data gets extracted but there are NA values here. This is because the top-left corner of our rasters (which is where values start) contains a lot of NA cells.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see what kind of object this is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(values(All1982_ras))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;matrix&amp;quot; &amp;quot;array&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is a matrix! Just what &lt;code&gt;mclust&lt;/code&gt; wants! Let&amp;rsquo;s actually create that as an object:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Vals1982_mat &amp;lt;- values(All1982_ras)
rownames(Vals1982_mat) &amp;lt;- 1:dim(Vals1982_mat)[1] # rownames to index raster cell number
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, let&amp;rsquo;s carry out a sanity check to make sure that we really have ported all values from both source rasters to our matrix. For this to be the case, the rownumber of our matrix (&lt;code&gt;dim()[1]&lt;/code&gt;) needs to be the same as the amount (&lt;code&gt;length()&lt;/code&gt;) of values (&lt;code&gt;values()&lt;/code&gt;) in our rasters:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Vals1982_mat)[1] == length(values(Mean1982_ras)) &amp;amp; 
  dim(Vals1982_mat)[1] == length(values(Season1982_ras))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This checks out!&lt;/p&gt;
&lt;h3 id=&#34;data-prepartion&#34;&gt;Data Prepartion&lt;/h3&gt;
&lt;p&gt;As you remember, there were plenty of NA values in our data set. No cluster algorithm can handle these. Therefore, we need to get rid of them. This is done as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Vals1982_mat &amp;lt;- na.omit(Vals1982_mat) # omit all rows which contain at least one NA record
dim(Vals1982_mat) # new dimensions of our matrix
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 39460     2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This seriously cut our data down and will speed up our clustering approach a lot.&lt;/p&gt;
&lt;h3 id=&#34;cluster-identification&#34;&gt;Cluster Identification&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s install and load the &lt;code&gt;mclust&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;mclust&amp;quot;)
library(mclust)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;cluster-model-selection&#34;&gt;Cluster Model Selection&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start with the &lt;code&gt;mclust&lt;/code&gt; functionality to identify the best fitting clustering with a range of 1 to 9 clusters. To do so, we first need to identify the BIC fit for all of our possible cluster models. &lt;code&gt;mclust&lt;/code&gt; does this automatically:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dataBIC &amp;lt;- mclustBIC(Vals1982_mat) # identify BICs for different models
print(summary(dataBIC)) # show summary of top-ranking models
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best BIC values:
##           EVV,8    EVV,9  EVE,8
## BIC      136809 136800.2 135504
## BIC diff      0     -8.6  -1304
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above tells us that the best performing model was of type EVV (ellipsoidal distribution,  equal volume, variable shape, and variable orientation of clusters) identifying 9 clusters.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see a visual overview of this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(dataBIC)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;02---classifications_files/figure-html/MClust1b-1.png&#34; width=&#34;1152&#34; /&gt;
Here, you can see different models compared to each other given certain numbers of clusters that have been considered.&lt;/p&gt;
&lt;p&gt;Now we can build our model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mod &amp;lt;- Mclust(Vals1982_mat, # data for the cluster model
                   G = 7 # BIC index for model to be built
                   )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have our full model! How many clusters did it identify?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mod$G # number of groups/clusters in model
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No surprises here, we&amp;rsquo;ve got 7 clusters.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s look at the mean values of the clusters:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mod[[&amp;quot;parameters&amp;quot;]][[&amp;quot;mean&amp;quot;]] # mean values of clusters
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             [,1] [,2] [,3]  [,4] [,5] [,6] [,7]
## Mean        0.36 0.53 0.67 0.081 0.44 0.26 0.21
## Seasonality 0.76 0.56 0.35 0.269 0.72 0.64 0.59
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These can be interpreted biologically, but I will leave that to you.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s see how well these clusters distinguish the mean-seasonality space:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(mod, what = &amp;quot;uncertainty&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;02---classifications_files/figure-html/MClust1f-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How do we map this? We &lt;em&gt;predict&lt;/em&gt; our clusters for our initial data as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ModPred &amp;lt;- predict.Mclust(mod, Vals1982_mat) # prediction
Pred_ras &amp;lt;- Mean1982_ras # establishing a rediction raster
values(Pred_ras) &amp;lt;- NA # set everything to NA
# set values of prediction raster to corresponding classification according to rowname
values(Pred_ras)[as.numeric(rownames(Vals1982_mat))] &amp;lt;- as.vector(ModPred$classification)
Pred_ras
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterLayer 
## dimensions : 237, 590, 139830  (nrow, ncol, ncell)
## resolution : 0.083, 0.083  (x, y)
## extent     : -179, -130, 51, 71  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : memory
## names      : layer 
## values     : 1, 7  (min, max)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this has the same extent and resolution as our source rasters but the values range from 1 to 7. These are our cluster assignments.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s plot this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;colours &amp;lt;- rainbow(mod$G) # define 7 colours
plot(Pred_ras, # what to plot
     col = colours, # colours for groups
     colNA = &amp;quot;black&amp;quot;, # which colour to assign to NA values
     legend.shrink=1, # vertical size of legend
     legend.width=2 # horizontal size of legend
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;02---classifications_files/figure-html/MClust1h-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How often do we observe which assignment?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(values(Pred_ras))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     1     2     3     4     5     6     7 
## 13101  1902  1118  2939  5608  8047  6745
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;pre-defined-number&#34;&gt;Pre-Defined Number&lt;/h4&gt;
&lt;p&gt;As biologists, we have got decades of work already present concerning biome distributions across the Earth. One such classification are the Terrestrial Ecoregions of the World (\url{https://www.worldwildlife.org/publications/terrestrial-ecoregions-of-the-world}). We want to identify how many biomes this data set identifies across Australia.&lt;/p&gt;
&lt;p&gt;Firstly, we download the data and unpack it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# downloading Terrestrial Ecoregion Shapefile as zip
download.file(&amp;quot;http://assets.worldwildlife.org/publications/15/files/original/official_teow.zip&amp;quot;,
              destfile = file.path(Dir.Data, &amp;quot;wwf_ecoregions.zip&amp;quot;)
              )
# unpacking the zip
unzip(file.path(Dir.Data, &amp;quot;wwf_ecoregions.zip&amp;quot;), 
      exdir = file.path(Dir.Data, &amp;quot;WWF_ecoregions&amp;quot;)
      )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Secondly, we load the data into &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# loading shapefile for biomes
wwf &amp;lt;- readOGR(file.path(Dir.Data, &amp;quot;WWF_ecoregions&amp;quot;, &amp;quot;official&amp;quot;, &amp;quot;wwf_terr_ecos.shp&amp;quot;),
               verbose = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thirdly, we need to limit the global terrestrial ecoregion shapefile to the state of Alaska and need our Alaska shapefile for this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Shapes &amp;lt;- readOGR(Dir.Data, # where to look for the file
                  &amp;quot;ne_10m_admin_1_states_provinces&amp;quot;, # the file name
                  verbose = FALSE) # we don&#39;t want an overview of the loaded data
Position &amp;lt;- which(Shapes$name_en == &amp;quot;Alaska&amp;quot;) # find the english name that&#39;s &amp;quot;Alaska&amp;quot;
Alaska_Shp &amp;lt;- Shapes[Position,] # extract the Alaska shapefile
Alaska_Shp &amp;lt;- crop(Alaska_Shp, # what to crop
                   extent(-190, -130, 51, 71)) # which extent to crop to
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we need to limit the global biome shapefile to the shape of Alaska:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;wwf_ready &amp;lt;- crop(wwf, extent(Alaska_Shp)) # cropping to Alaska extent
wwf_ready &amp;lt;- intersect(Alaska_Shp, wwf) # masking of two shapefiles
plot(wwf_ready,  # plotting final shape
     col = wwf_ready@data[[&amp;quot;BIOME&amp;quot;]] # use BIOME specification for colours
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;02---classifications_files/figure-html/MClust2c-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We first identify the BICs:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# identify BICs for different models
dataBIC2 &amp;lt;- mclustBIC(Vals1982_mat, 
                     G = length(unique(wwf_ready@data[[&amp;quot;G200_BIOME&amp;quot;]]))) 
print(summary(dataBIC2)) # show summary of top-ranking models
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best BIC values:
##           EVV,4  VVE,4  EVE,4
## BIC      133035 132345 125463
## BIC diff      0   -690  -7572
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the shapefile gives us 4 clusters across Alaska even though the map only shows 3. The fourth biome is only represented by a single polygon across all of Alaska and we might want to reduce the set to 3.&lt;/p&gt;
&lt;p&gt;For now, we are running with the idea of 4 clusters:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mod2 &amp;lt;- Mclust(Vals1982_mat, # data for the cluster model
                   G = 4 # BIC index for model to be built
                   )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have our full model!&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s look at the mean values of the clusters:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mod2[[&amp;quot;parameters&amp;quot;]][[&amp;quot;mean&amp;quot;]] # mean values of clusters
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             [,1] [,2] [,3] [,4]
## Mean        0.41 0.13 0.60 0.27
## Seasonality 0.73 0.39 0.44 0.67
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, I leave the biological interpretation to you.&lt;/p&gt;
&lt;p&gt;Finally, we will plot our assignments in mean-seasonality space:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(mod2, what = &amp;quot;uncertainty&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;02---classifications_files/figure-html/MClust2h-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, let&amp;rsquo;s &lt;em&gt;predict&lt;/em&gt; our clusters for our initial data as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ModPred2 &amp;lt;- predict.Mclust(mod2, Vals1982_mat) # prediction
Pred2_ras &amp;lt;- Mean1982_ras # establishing a rediction raster
values(Pred2_ras) &amp;lt;- NA # set everything to NA
# set values of prediction raster to corresponding classification according to rowname
values(Pred2_ras)[as.numeric(rownames(Vals1982_mat))] &amp;lt;- as.vector(ModPred2$classification)
Pred2_ras
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## class      : RasterLayer 
## dimensions : 237, 590, 139830  (nrow, ncol, ncell)
## resolution : 0.083, 0.083  (x, y)
## extent     : -179, -130, 51, 71  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs 
## source     : memory
## names      : layer 
## values     : 1, 4  (min, max)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this has the same extent and resolution as our source rasters but the values range from 1 to 4. These are our cluster assignments.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s plot this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;colours &amp;lt;- rainbow(mod2$G) # define 4 colours
plot(Pred2_ras, # what to plot
     col = colours, # colours for groups
     colNA = &amp;quot;black&amp;quot;, # which colour to assign to NA values
     legend.shrink=1, # vertical size of legend
     legend.width=2 # horizontal size of legend
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;02---classifications_files/figure-html/MClust2j-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;How often do we observe which assignment?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(values(Pred2_ras))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     1     2     3     4 
## 12223  4066  2327 20844
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;saving-workspace&#34;&gt;Saving Workspace&lt;/h2&gt;
&lt;h3 id=&#34;what-is-it-and-why-do-we-do-it&#34;&gt;What Is It And Why Do We Do It?&lt;/h3&gt;
&lt;p&gt;The workspace records all of our elements in &lt;code&gt;R&lt;/code&gt;. Since we want to pick up from this point in our next exercise, we want to save the workspace and restore it at a later point to assess all of our elements again.&lt;/p&gt;
&lt;h3 id=&#34;saving-and-loading-the-workspace&#34;&gt;Saving And Loading The Workspace&lt;/h3&gt;
&lt;p&gt;Saving a workspace goes as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# save workspace
save.image(file = (paste(Dir.Base, &amp;quot;Workspace.RData&amp;quot;, sep=&amp;quot;/&amp;quot;)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s load it again:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clean workspace
load(file = &amp;quot;Workspace.RData&amp;quot;) # load workspace
ls() # list elements in workspace
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Alaska_Shp&amp;quot;     &amp;quot;All1982_ras&amp;quot;    &amp;quot;colours&amp;quot;       
##  [4] &amp;quot;dataBIC&amp;quot;        &amp;quot;dataBIC2&amp;quot;       &amp;quot;Dir.Base&amp;quot;      
##  [7] &amp;quot;Dir.Data&amp;quot;       &amp;quot;Dir.Plots&amp;quot;      &amp;quot;Mean1982_ras&amp;quot;  
## [10] &amp;quot;mod&amp;quot;            &amp;quot;mod2&amp;quot;           &amp;quot;ModPred&amp;quot;       
## [13] &amp;quot;ModPred2&amp;quot;       &amp;quot;Position&amp;quot;       &amp;quot;Pred_ras&amp;quot;      
## [16] &amp;quot;Pred2_ras&amp;quot;      &amp;quot;Season1982_ras&amp;quot; &amp;quot;Shapes&amp;quot;        
## [19] &amp;quot;Vals1982_mat&amp;quot;   &amp;quot;wwf&amp;quot;            &amp;quot;wwf_ready&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All our files are back!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Primer For Statistical Tests</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/a-primer-for-statistical-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/a-primer-for-statistical-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are the solutions to the exercises contained within the handout to A Primer For Statistical Tests which walks you through the basics of variables, their scales and distributions. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.&lt;/p&gt;
&lt;p&gt;I have prepared some I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/03---A-Primer-For-Statistical-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/Primer.RData&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;loading-the-r-environment-object&#34;&gt;Loading the &lt;code&gt;R&lt;/code&gt; Environment Object&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(&amp;quot;Data/Primer.RData&amp;quot;)  # load data file from Data folder
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;variables&#34;&gt;Variables&lt;/h2&gt;
&lt;h3 id=&#34;finding-variables&#34;&gt;Finding Variables&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ls()  # list all elements in working environment
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Colour&amp;quot;               &amp;quot;Depth&amp;quot;                &amp;quot;IndividualsPassingBy&amp;quot;
## [4] &amp;quot;Length&amp;quot;               &amp;quot;Reproducing&amp;quot;          &amp;quot;Sex&amp;quot;                 
## [7] &amp;quot;Size&amp;quot;                 &amp;quot;Temperature&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;colour&#34;&gt;&lt;code&gt;Colour&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Colour)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(table(Colour))  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VColour-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;character&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Nominal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Categorical data that can&amp;rsquo;t be ordered&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;depth&#34;&gt;&lt;code&gt;Depth&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Depth)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Depth)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VDepth-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Interval/Discrete&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Continuous data with a non-absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Debatable (is 0 depth absence of depth?)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;individualspassingby&#34;&gt;&lt;code&gt;IndividualsPassingBy&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(IndividualsPassingBy)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(IndividualsPassingBy)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VIndPass-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Only integer numbers with an absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;length&#34;&gt;&lt;code&gt;Length&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Length)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Length)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VLength-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Relation/Ratio&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Continuous data with an absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;reproducing&#34;&gt;&lt;code&gt;Reproducing&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Reproducing)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Reproducing)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VRepro-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Only integer numbers with an absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;sex&#34;&gt;&lt;code&gt;Sex&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Sex)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;factor&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(table(Sex))  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VSex-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;factor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Only two possible outcomes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;size&#34;&gt;&lt;code&gt;Size&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Size)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(table(Size))  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VSize-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;character&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ordinal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Categorical data that can be ordered&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;temperature&#34;&gt;&lt;code&gt;Temperature&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Temperature)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Temperature)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VTemp-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Interval/Discrete&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Continuous data with a non-absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes (the data is clearly recorded in degree Celsius)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;distributions&#34;&gt;Distributions&lt;/h2&gt;
&lt;h3 id=&#34;length-1&#34;&gt;&lt;code&gt;Length&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(Length))  # distribution plot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DLength-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shapiro.test(Length)  # normality check
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  Length
## W = 0.99496, p-value = 0.4331
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is &lt;strong&gt;normal distributed&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;reproducing-1&#34;&gt;&lt;code&gt;Reproducing&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(Reproducing))  # distribution
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DRepro-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shapiro.test(Reproducing)  # normality check
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  Reproducing
## W = 0.98444, p-value = 0.2889
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is &lt;strong&gt;binomial distributed&lt;/strong&gt; (i.e. &amp;ldquo;How many individuals manage to reproduce&amp;rdquo;) but looks &lt;strong&gt;normal distributed&lt;/strong&gt;. The normal distribution doesn&amp;rsquo;t make sense here because it implies continuity whilst the data only comes in integers.&lt;/p&gt;
&lt;h3 id=&#34;individualspassingby-1&#34;&gt;&lt;code&gt;IndividualsPassingBy&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(IndividualsPassingBy))  # distribution
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DIndiv-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shapiro.test(IndividualsPassingBy)  # normality check
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  IndividualsPassingBy
## W = 0.96905, p-value = 0.0187
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is &lt;strong&gt;poisson distributed&lt;/strong&gt; (i.e. &amp;ldquo;How many individuals pass by an observer in a given time frame?&amp;quot;).&lt;/p&gt;
&lt;h3 id=&#34;depth-1&#34;&gt;&lt;code&gt;Depth&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(Depth))  # distribution
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DDepth-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The data is &lt;strong&gt;uniform distributed&lt;/strong&gt;. You don&amp;rsquo;t know this distribution class from the lectures and I only wanted to confuse you with this to show you that there&amp;rsquo;s much more out there than I can show in our lectures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Primer For Statistical Tests</title>
      <link>https://www.erikkusch.com/courses/biostat101/a-primer-for-statistical-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/a-primer-for-statistical-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are the solutions to the exercises contained within the handout to A Primer For Statistical Tests which walks you through the basics of variables, their scales and distributions. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.&lt;/p&gt;
&lt;div class=&#34;alert alert-success&#34;&gt;
  &lt;div&gt;
    &lt;details&gt;
  &lt;summary&gt;Theory slides for this session.&lt;/summary&gt;
  Click the outline of the presentation below to get to the HTML version of the slides for this session.
    &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/03---A-Primer-For-Statistical-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/03---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;
&lt;/details&gt; 
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/Primer.RData&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;loading-the-r-environment-object&#34;&gt;Loading the &lt;code&gt;R&lt;/code&gt; Environment Object&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(&amp;quot;Data/Primer.RData&amp;quot;)  # load data file from Data folder
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;variables&#34;&gt;Variables&lt;/h2&gt;
&lt;h3 id=&#34;finding-variables&#34;&gt;Finding Variables&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ls()  # list all elements in working environment
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Colour&amp;quot;               &amp;quot;Depth&amp;quot;                &amp;quot;IndividualsPassingBy&amp;quot;
## [4] &amp;quot;Length&amp;quot;               &amp;quot;Reproducing&amp;quot;          &amp;quot;Sex&amp;quot;                 
## [7] &amp;quot;Size&amp;quot;                 &amp;quot;Temperature&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;colour&#34;&gt;&lt;code&gt;Colour&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Colour)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(table(Colour))  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VColour-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;character&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Nominal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Categorical data that can&amp;rsquo;t be ordered&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;depth&#34;&gt;&lt;code&gt;Depth&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Depth)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Depth)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VDepth-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Interval/Discrete&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Continuous data with a non-absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Debatable (is 0 depth absence of depth?)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;individualspassingby&#34;&gt;&lt;code&gt;IndividualsPassingBy&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(IndividualsPassingBy)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(IndividualsPassingBy)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VIndPass-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Only integer numbers with an absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;length&#34;&gt;&lt;code&gt;Length&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Length)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Length)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VLength-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Relation/Ratio&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Continuous data with an absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;reproducing&#34;&gt;&lt;code&gt;Reproducing&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Reproducing)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Reproducing)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VRepro-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Integer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Only integer numbers with an absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;sex&#34;&gt;&lt;code&gt;Sex&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Sex)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;factor&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(table(Sex))  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VSex-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;factor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Binary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Only two possible outcomes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;size&#34;&gt;&lt;code&gt;Size&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Size)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(table(Size))  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VSize-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;character&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ordinal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Categorical data that can be ordered&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;temperature&#34;&gt;&lt;code&gt;Temperature&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Temperature)  # mode
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;barplot(Temperature)  # fitting?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/VTemp-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Question&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Answer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Mode?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;numeric&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Which scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Interval/Discrete&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;What&amp;rsquo;s implied?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Continuous data with a non-absence point of origin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;Does data fit scale?&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Yes (the data is clearly recorded in degree Celsius)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;distributions&#34;&gt;Distributions&lt;/h2&gt;
&lt;h3 id=&#34;length-1&#34;&gt;&lt;code&gt;Length&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(Length))  # distribution plot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DLength-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shapiro.test(Length)  # normality check
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  Length
## W = 0.99496, p-value = 0.4331
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is &lt;strong&gt;normal distributed&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;reproducing-1&#34;&gt;&lt;code&gt;Reproducing&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(Reproducing))  # distribution
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DRepro-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shapiro.test(Reproducing)  # normality check
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  Reproducing
## W = 0.98444, p-value = 0.2889
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is &lt;strong&gt;binomial distributed&lt;/strong&gt; (i.e. &amp;ldquo;How many individuals manage to reproduce&amp;rdquo;) but looks &lt;strong&gt;normal distributed&lt;/strong&gt;. The normal distribution doesn&amp;rsquo;t make sense here because it implies continuity whilst the data only comes in integers.&lt;/p&gt;
&lt;h3 id=&#34;individualspassingby-1&#34;&gt;&lt;code&gt;IndividualsPassingBy&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(IndividualsPassingBy))  # distribution
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DIndiv-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shapiro.test(IndividualsPassingBy)  # normality check
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  IndividualsPassingBy
## W = 0.96905, p-value = 0.0187
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is &lt;strong&gt;poisson distributed&lt;/strong&gt; (i.e. &amp;ldquo;How many individuals pass by an observer in a given time frame?&amp;quot;).&lt;/p&gt;
&lt;h3 id=&#34;depth-1&#34;&gt;&lt;code&gt;Depth&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(density(Depth))  # distribution
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---A-Primer-For-Statistical-Tests_files/figure-html/DDepth-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The data is &lt;strong&gt;uniform distributed&lt;/strong&gt;. You don&amp;rsquo;t know this distribution class from the lectures and I only wanted to confuse you with this to show you that there&amp;rsquo;s much more out there than I can show in our lectures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Change Analysis</title>
      <link>https://www.erikkusch.com/courses/bftp-biome-detection/change-analysis/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/bftp-biome-detection/change-analysis/</guid>
      <description>&lt;h2 id=&#34;preparing-the-work&#34;&gt;Preparing The Work&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s create our basic structure for this document:&lt;/p&gt;
&lt;h3 id=&#34;head&#34;&gt;Head&lt;/h3&gt;
&lt;p&gt;Not much has changed in the &lt;strong&gt;head&lt;/strong&gt; when compared to our last exercise. We merely change the &lt;em&gt;contents&lt;/em&gt; and and the &lt;em&gt;edit&lt;/em&gt; tag, since the rest stays the same for the entire project.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# ####################################################################### #
# PROJECT: [BFTP] Identifying Biomes And Their Shifts Using Remote Sensing
# CONTENTS: Functionality to identify and analyse changes in spatial cluster distributions
# AUTHOR: Erik Kusch
# EDIT: 19/03/20
# ####################################################################### #
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;preamble&#34;&gt;Preamble&lt;/h3&gt;
&lt;p&gt;I am keeping the same &lt;strong&gt;preamble&lt;/strong&gt; as last time because we will need to index the data and the plot directory in this exercise. Our preamble then looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing the entire environment
Dir.Base &amp;lt;- getwd() # identifying the current directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # generating the folder path for data folder
Dir.Plots &amp;lt;- paste(Dir.Base, &amp;quot;Plots&amp;quot;, sep=&amp;quot;/&amp;quot;) # generating the folder path for figures folder
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice, that we do not call the function &lt;code&gt;dir.create()&lt;/code&gt; this time. We don&amp;rsquo;t need to do so, because we already created the two directories established above in our last exercise. Usually, we would create this entire analysis of your BFTP project in one &lt;code&gt;R&lt;/code&gt; code script. In this case, we would only have one preamble which defines and creates directories instead of doing this step for every single sub-part of the analysis. Alas, we want to break this down for you. Therefore, you see this preamble here and will again in the next exercise.&lt;/p&gt;
&lt;p&gt;This time, we actually do load packages here as we really only need the &lt;code&gt;raster&lt;/code&gt; package. By now, I am assuming you know what we use it for:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(raster) # the raster package for rasters
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additionally, we reload our &lt;code&gt;.RData&lt;/code&gt; workspace from the last exercise to gain back our &lt;code&gt;mclust&lt;/code&gt; model objects in particular.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(file = &amp;quot;Workspace.RData&amp;quot;) # load workspace
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;coding&#34;&gt;Coding&lt;/h3&gt;
&lt;p&gt;Again, all of the important &lt;strong&gt;Coding&lt;/strong&gt; happens after the head and the preamble are written and run in &lt;code&gt;R&lt;/code&gt;. Basically, this is the rest of this document once more.&lt;/p&gt;
&lt;h2 id=&#34;change-analysis&#34;&gt;Change Analysis&lt;/h2&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;Firstly, we need the raw NDVI mean and seasonality data for the time frames we want to compare. Let&amp;rsquo;s deal with that right quick.&lt;/p&gt;
&lt;h4 id=&#34;1982&#34;&gt;1982&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s load our 1982 NDVI mean and seasonality data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Mean1982_ras &amp;lt;- raster(paste(Dir.Data, &amp;quot;1982Mean.nc&amp;quot;, sep=&amp;quot;/&amp;quot;)) # loading means
Season1982_ras &amp;lt;- raster(paste(Dir.Data, &amp;quot;1982Season.nc&amp;quot;, sep=&amp;quot;/&amp;quot;)) # loading seasonalities
All1982_ras &amp;lt;- stack(Mean1982_ras, Season1982_ras) # creating a stack
names(All1982_ras) &amp;lt;- c(&amp;quot;Mean&amp;quot;, &amp;quot;Seasonality&amp;quot;) # assign names to stack layers
Vals1982_mat &amp;lt;- values(All1982_ras) # extract data
rownames(Vals1982_mat) &amp;lt;- 1:dim(Vals1982_mat)[1] # rownames to index raster cell number
Vals1982_mat &amp;lt;- na.omit(Vals1982_mat) # omit all rows which contain at least one NA record
summary(Vals1982_mat) # a summary of the data
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Mean       Seasonality  
##  Min.   :0.00   Min.   :0.00  
##  1st Qu.:0.22   1st Qu.:0.55  
##  Median :0.33   Median :0.67  
##  Mean   :0.32   Mean   :0.64  
##  3rd Qu.:0.41   3rd Qu.:0.76  
##  Max.   :0.84   Max.   :1.00
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2015&#34;&gt;2015&lt;/h4&gt;
&lt;p&gt;In order to assess how biome distributions have changed, we need another time frame to compare our 1982 data to. For this, I have re-run the code from our first BFTP exercise for the year 2015. We now load that data into &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Mean2015_ras &amp;lt;- raster(paste(Dir.Data, &amp;quot;2015Mean.nc&amp;quot;, sep=&amp;quot;/&amp;quot;)) # loading means
Season2015_ras &amp;lt;- raster(paste(Dir.Data, &amp;quot;2015Season.nc&amp;quot;, sep=&amp;quot;/&amp;quot;)) # loading seasonalities
All2015_ras &amp;lt;- stack(Mean2015_ras, Season2015_ras) # creating a stack
names(All2015_ras) &amp;lt;- c(&amp;quot;Mean&amp;quot;, &amp;quot;Seasonality&amp;quot;) # assign names to stack layers
Vals2015_mat &amp;lt;- values(All2015_ras) # extract data
rownames(Vals2015_mat) &amp;lt;- 1:dim(Vals2015_mat)[1] # rownames to index raster cell number
Vals2015_mat &amp;lt;- na.omit(Vals2015_mat) # omit all rows which contain at least one NA record
summary(Vals2015_mat) # a summary of the data
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Mean       Seasonality  
##  Min.   :0.00   Min.   :0.00  
##  1st Qu.:0.25   1st Qu.:0.56  
##  Median :0.33   Median :0.67  
##  Mean   :0.34   Mean   :0.64  
##  3rd Qu.:0.43   3rd Qu.:0.77  
##  Max.   :0.83   Max.   :1.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice, that the output of the &lt;code&gt;summary()&lt;/code&gt; function is different for both matrices built from raster data values. This is important to ensure that our analysis actually references different time frames.&lt;/p&gt;
&lt;p&gt;\newpage&lt;/p&gt;
&lt;h3 id=&#34;predictions&#34;&gt;Predictions&lt;/h3&gt;
&lt;p&gt;Secondly, we want to compare cluster assignments. To do so, we need to use our &lt;code&gt;mclust&lt;/code&gt; models to predict cluster assignments for each cell in our target region raster using the NDVI mean and seasonality data that we loaded previously.&lt;/p&gt;
&lt;h4 id=&#34;1982-1&#34;&gt;1982&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s deal with the 1982 data first. &lt;code&gt;mod2&lt;/code&gt; is the &lt;code&gt;mclust&lt;/code&gt; model object for 4 clusters from our last exercise. Here, we predict clusters and place them on a raster:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ModPred1982 &amp;lt;- predict.Mclust(mod2, Vals1982_mat) # prediction
Pred1982_ras &amp;lt;- Mean1982_ras # establishing a rediction raster
values(Pred1982_ras) &amp;lt;- NA # set everything to NA
# set values of prediction raster to corresponding classification according to rowname
values(Pred1982_ras)[as.numeric(rownames(Vals1982_mat))] &amp;lt;- as.vector(ModPred1982$classification)
colours &amp;lt;- rainbow(mod2$G) # define 4 colours
plot(Pred1982_ras, # what to plot
     col = colours, # colours for groups
     colNA = &amp;quot;black&amp;quot;, # which colour to assign to NA values
     legend.shrink=1, # vertical size of legend
     legend.width=2 # horizontal size of legend
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---change_files/figure-html/Pred1-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;\newpage&lt;/p&gt;
&lt;h4 id=&#34;2015-1&#34;&gt;2015&lt;/h4&gt;
&lt;p&gt;Now, we deal with the 2015 time frame. Notice, that we are using the &lt;code&gt;mod2&lt;/code&gt; &lt;code&gt;mclust&lt;/code&gt; model which was established for 1982 in our last exercise. It is important that we use the same model when predicting our classes between time frames to ensure comparability. After all, we want to make sure that cluster 1 is the same in 1982 as 2015. It is debatable whether we should use a cluster model built from just one year of data or even from the same time frame as one of the the time frames which are to be compared. In fact, I would argue that we should establish a &lt;code&gt;mclust&lt;/code&gt; model for the mean annual NDVI and mean annual seasonality of NDVI across the entire time for which data is available. For now, we simply use the 1982-reliant model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ModPred2015 &amp;lt;- predict.Mclust(mod2, Vals2015_mat) # prediction
Pred2015_ras &amp;lt;- Mean2015_ras # establishing a rediction raster
values(Pred2015_ras) &amp;lt;- NA # set everything to NA
# set values of prediction raster to corresponding classification according to rowname
values(Pred2015_ras)[as.numeric(rownames(Vals2015_mat))] &amp;lt;- as.vector(ModPred2015$classification)
colours &amp;lt;- rainbow(mod2$G) # define 4 colours
plot(Pred2015_ras, # what to plot
     col = colours, # colours for groups
     colNA = &amp;quot;black&amp;quot;, # which colour to assign to NA values
     legend.shrink=1, # vertical size of legend
     legend.width=2 # horizontal size of legend
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---change_files/figure-html/Pred2-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can already see some cluster assignment changes on Nunivak island.&lt;/p&gt;
&lt;p&gt;\newpage&lt;/p&gt;
&lt;h3 id=&#34;initial-assesment&#34;&gt;Initial Assesment&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s first assess how many raster cells have changed cluster assignment between our two time frames:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# identify how many cell assignments don&#39;t match between rasters
Change &amp;lt;- sum(ModPred1982$classification != ModPred2015$classification)
# divide number of mismatches by number of all cells
Change/length(ModPred2015$classification)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.22
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, there is a proportion of 0.22 raster cells which have changed cluster assignment between the two time frames. Now, let&amp;rsquo;s put this on a map:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PredChange_ras &amp;lt;- Mean2015_ras # establishing a rediction raster
values(PredChange_ras) &amp;lt;- NA # set everything to NA
# set values of prediction raster to corresponding classification according to rowname
values(PredChange_ras)[as.numeric(rownames(Vals2015_mat))] &amp;lt;- 
  ModPred1982$classification != ModPred2015$classification
colours &amp;lt;- c(&amp;quot;green&amp;quot;, &amp;quot;red&amp;quot;) # define 2 colours
plot(PredChange_ras, col = colours, colNA = &amp;quot;black&amp;quot;,
     legend.shrink=1, legend.width=2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;03---change_files/figure-html/qualb-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I leave it to you to interpret these patterns (there actually is an interpretation to be had here).&lt;/p&gt;
&lt;p&gt;\newpage&lt;/p&gt;
&lt;h3 id=&#34;in-depth-assesment&#34;&gt;In-Depth Assesment&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;d argue that a simple understanding whether things have changed won&amp;rsquo;t be what we want to report. What we want, is to know which cluster took over the cells of which raster. I.e., I&amp;rsquo;d like to answer the question: &amp;ldquo;Which clusters take over the regions of other clusters and which ones?&amp;rdquo;. I hope you&amp;rsquo;re interested in this, too. Here&amp;rsquo;s how we can analyse this: For each cluster assignment we:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify the cells corresponding to it in 1982/the past&lt;/li&gt;
&lt;li&gt;Count how many of these cells are classified as the same cluster in 2015/the present&lt;/li&gt;
&lt;li&gt;Repeat the above for all combinations of cluster assignments imaginable&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;NClusters &amp;lt;- mod2$G # identify the number of clusters
present &amp;lt;- as.vector(Pred2015_ras) # assignments in 2015
past &amp;lt;- as.vector(Pred1982_ras) # assignments in 1982
# this matrix will hold the data, rows will show past state, columns will show present state
changematrix &amp;lt;- matrix(rep(NA, NClusters^2), nrow=NClusters, ncol=NClusters)
changevec &amp;lt;- rep(NA, NClusters) # this vector will fill rows in our matrix
for(k in 1:NClusters){ # loop over clusters in past
  changerun &amp;lt;- changevec 
  changeperc &amp;lt;- changevec
  for(m in 1:NClusters){ # loop over clusters in present
    presentcells &amp;lt;- which(present==m) # figure out which cells hold value m
    pastcells &amp;lt;- which(past==k) # figure out which cells hold value k
    # figure out how many of the cell denominators are shared by the two vectors
    rate &amp;lt;- length(Reduce(intersect, list(pastcells,presentcells))) 
    changerun[m] &amp;lt;- rate # save rate to changerun in place m
  } # end of present-loop
  changematrix[k,] &amp;lt;- changerun # save changerun to k row in matrix
  for(n in 1:NClusters){ # turn rates into portions
    # divide number of in a cell by total number of cells in its row
    changeperc[n] &amp;lt;- changematrix[k,n] / sum(changematrix[k,])
  } # end of percentages
  changematrix[k,] &amp;lt;- changeperc # save changeperc to row k
} # end of past-loop
changematrix &amp;lt;- changematrix*100 # turn everything into percentages
rownames(changematrix) &amp;lt;- paste0(&amp;quot;Past&amp;quot;, 1:NClusters)
colnames(changematrix) &amp;lt;- paste0(&amp;quot;Present&amp;quot;, 1:NClusters)
changematrix # show the matrix
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Present1 Present2 Present3 Present4
## Past1     82.0     0.84    4.459       13
## Past2      3.5    60.35    0.074       36
## Past3     23.8     0.00   76.235        0
## Past4     16.9     3.01    0.029       80
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, there&amp;rsquo;s quite a bit going on here. Let me explain how to read this. From past (1982) to present (2015), 82.03% of raster cells assigned to cluster 1 in 1982 are assigned to cluster 1 in 2015 as well. 0.84% of raster cells previously assigned to cluster 1 are classified as cluster 2 in 2015. Notice, how all rows sum up to 100% each. Representing the total of assigned raster cells in the 1982 record.&lt;/p&gt;
&lt;p&gt;Given the biological counterparts of the clusters, how would you interpret these shifts?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research Project</title>
      <link>https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/</guid>
      <description>&lt;h2 id=&#34;our-resarch-project&#34;&gt;Our Resarch Project&lt;/h2&gt;
&lt;p&gt;Here (and over the next few exercises in this &amp;ldquo;course&amp;rdquo;), we are looking at a big (and entirely fictional) data base of the common house sparrow (&lt;em&gt;Passer domesticus&lt;/em&gt;). In particular, we are interested in the &lt;strong&gt;Evolution of &lt;em&gt;Passer domesticus&lt;/em&gt; in Response to Climate Change&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;I have created a large data set for this exercise which is available in a cleaned and properly handled version &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/excursions-into-biostatistics/Data.rar&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;reading-the-data-into-r&#34;&gt;Reading the Data into &lt;code&gt;R&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start by reading the data into &lt;code&gt;R&lt;/code&gt; and taking an initial look at it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sparrows_df &amp;lt;- readRDS(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowData.rds&amp;quot;))
Sparrows_df &amp;lt;- Sparrows_df[!is.na(Sparrows_df$Weight), ]
head(Sparrows_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Index Latitude Longitude     Climate Population.Status Weight Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type
## 1    SI       60       100 Continental            Native  34.05  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 2    SI       60       100 Continental            Native  34.86  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 3    SI       60       100 Continental            Native  32.34  12.66       6.64  Black Female        Shrub          35.60              1       3.21     C      Large               Yes         Avian
## 4    SI       60       100 Continental            Native  34.78  15.09       7.00  Brown Female        Shrub          47.75              0         NA     E      Large               Yes         Avian
## 5    SI       60       100 Continental            Native  35.01  13.82       6.81   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 6    SI       60       100 Continental            Native  32.36  12.67       6.64  Brown Female        Shrub          32.47              1       3.17     E      Large               Yes         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;variables&#34;&gt;Variables&lt;/h4&gt;
&lt;p&gt;When building models or trying to explain anything about our data set, we need to consider all the different variables and the information contained therein. In this data set, we have access to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Index&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - an abbreviation of &lt;code&gt;Site&lt;/code&gt; records&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Latitude&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - an identifier of where specific sparrow measurements where taken&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Longitude&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - an identifier of where specific sparrow measurements where taken&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Climate&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - local climate types that sparrows are subjected to (e.g. coastal, continental, and semi-coastal)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Population.Status&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - population status (e.g. native or introduced)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Weight&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - sparrow weight [g]; Range: 13-40g&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Height&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - sparrow height/length [cm]; Range: 10-22cm&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Wing.Chord&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - wing length [cm]; Range: 6-10cm&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Colour&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - main plumage colour (e.g. brown, grey, and black)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Sex&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - sparrow sex&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Nesting.Site&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - nesting conditions, only recorded for females (e.g. tree or shrub)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Nesting.Height&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - nest elevation above ground level, only recorded for females&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Number.of.Eggs&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - number of eggs per nest, only recorded for females&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Egg.Weight&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - mean weight of eggs per nest, only recorded for females&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Flock&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - which flock at each location each sparrow belongs to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Home.Range&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - size of home range of each flock (e.g. Small, Medium, and Large)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Predator.Presence&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - if a predator is present at a station (e.g. No or Yes)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Predator.Type&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - what kind of predator is present (e.g. Avian, Non-Avian, or None)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that the variables &lt;code&gt;Longitude&lt;/code&gt; and &lt;code&gt;Latitude&lt;/code&gt; may be used to retrieve climate data variables from a host of data sources.&lt;/p&gt;
&lt;h4 id=&#34;locations&#34;&gt;Locations&lt;/h4&gt;
&lt;p&gt;Looking at our data, we notice that it comes at distinct stations. Let&amp;rsquo;s visualise where they are:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;leaflet&amp;quot;)
Plot_df &amp;lt;- Sparrows_df[, c(&amp;quot;Longitude&amp;quot;, &amp;quot;Latitude&amp;quot;, &amp;quot;Index&amp;quot;, &amp;quot;Climate&amp;quot;, &amp;quot;Population.Status&amp;quot;)]
Plot_df &amp;lt;- unique(Plot_df)
m &amp;lt;- leaflet()
m &amp;lt;- addTiles(m)
m &amp;lt;- addMarkers(m,
  lng = Plot_df$Longitude,
  lat = Plot_df$Latitude,
  label = Plot_df$Index,
  popup = paste(Plot_df$Population.Status, Plot_df$Climate, sep = &amp;quot;;&amp;quot;)
)
m
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-{=html}&#34;&gt;&amp;lt;div class=&amp;quot;leaflet html-widget html-fill-item-overflow-hidden html-fill-item&amp;quot; id=&amp;quot;htmlwidget-9aac1c390aadeb1fd4f9&amp;quot; style=&amp;quot;width:1440px;height:768px;&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script type=&amp;quot;application/json&amp;quot; data-for=&amp;quot;htmlwidget-9aac1c390aadeb1fd4f9&amp;quot;&amp;gt;{&amp;quot;x&amp;quot;:{&amp;quot;options&amp;quot;:{&amp;quot;crs&amp;quot;:{&amp;quot;crsClass&amp;quot;:&amp;quot;L.CRS.EPSG3857&amp;quot;,&amp;quot;code&amp;quot;:null,&amp;quot;proj4def&amp;quot;:null,&amp;quot;projectedBounds&amp;quot;:null,&amp;quot;options&amp;quot;:{}}},&amp;quot;calls&amp;quot;:[{&amp;quot;method&amp;quot;:&amp;quot;addTiles&amp;quot;,&amp;quot;args&amp;quot;:[&amp;quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&amp;quot;,null,null,{&amp;quot;minZoom&amp;quot;:0,&amp;quot;maxZoom&amp;quot;:18,&amp;quot;tileSize&amp;quot;:256,&amp;quot;subdomains&amp;quot;:&amp;quot;abc&amp;quot;,&amp;quot;errorTileUrl&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;tms&amp;quot;:false,&amp;quot;noWrap&amp;quot;:false,&amp;quot;zoomOffset&amp;quot;:0,&amp;quot;zoomReverse&amp;quot;:false,&amp;quot;opacity&amp;quot;:1,&amp;quot;zIndex&amp;quot;:1,&amp;quot;detectRetina&amp;quot;:false,&amp;quot;attribution&amp;quot;:&amp;quot;&amp;amp;copy; &amp;lt;a href=\&amp;quot;https://openstreetmap.org\&amp;quot;&amp;gt;OpenStreetMap&amp;lt;\/a&amp;gt; contributors, &amp;lt;a href=\&amp;quot;https://creativecommons.org/licenses/by-sa/2.0/\&amp;quot;&amp;gt;CC-BY-SA&amp;lt;\/a&amp;gt;&amp;quot;}]},{&amp;quot;method&amp;quot;:&amp;quot;addMarkers&amp;quot;,&amp;quot;args&amp;quot;:[[60,54,-25,-21.1,70,55,31,17.25,4,10.5,-51.75],[100,-2,135,55.6,-90,-97,-92,-88.75,-53,-67,-59.17],null,null,null,{&amp;quot;interactive&amp;quot;:true,&amp;quot;draggable&amp;quot;:false,&amp;quot;keyboard&amp;quot;:true,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;zIndexOffset&amp;quot;:0,&amp;quot;opacity&amp;quot;:1,&amp;quot;riseOnHover&amp;quot;:false,&amp;quot;riseOffset&amp;quot;:250},[&amp;quot;Native;Continental&amp;quot;,&amp;quot;Native;Coastal&amp;quot;,&amp;quot;Introduced;Continental&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Semi-Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;],null,null,null,[&amp;quot;SI&amp;quot;,&amp;quot;UK&amp;quot;,&amp;quot;AU&amp;quot;,&amp;quot;RE&amp;quot;,&amp;quot;NU&amp;quot;,&amp;quot;MA&amp;quot;,&amp;quot;LO&amp;quot;,&amp;quot;BE&amp;quot;,&amp;quot;FG&amp;quot;,&amp;quot;SA&amp;quot;,&amp;quot;FI&amp;quot;],{&amp;quot;interactive&amp;quot;:false,&amp;quot;permanent&amp;quot;:false,&amp;quot;direction&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;opacity&amp;quot;:1,&amp;quot;offset&amp;quot;:[0,0],&amp;quot;textsize&amp;quot;:&amp;quot;10px&amp;quot;,&amp;quot;textOnly&amp;quot;:false,&amp;quot;className&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;sticky&amp;quot;:true},null]}],&amp;quot;limits&amp;quot;:{&amp;quot;lat&amp;quot;:[-51.75,70],&amp;quot;lng&amp;quot;:[-97,135]}},&amp;quot;evals&amp;quot;:[],&amp;quot;jsHooks&amp;quot;:[]}&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that you can zoom and drag the above map as well as click the station markers for some additional information.&lt;/p&gt;
&lt;h3 id=&#34;adding-information&#34;&gt;Adding Information&lt;/h3&gt;
&lt;p&gt;How do we get the data for this? Well, I wrote an &lt;code&gt;R&lt;/code&gt;-Package that does exactly that.&lt;/p&gt;
&lt;p&gt;First, said package needs to be installed from my GitHub repository for it. Subsequently, we need to set API Key and User number obtained at the 
&lt;a href=&#34;https://cds.climate.copernicus.eu/api-how-to&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Climate Data Store&lt;/a&gt;. I have already baked these into my material, so I don&amp;rsquo;t set them here, but include lines of code that ask you for your credentials when copy &amp;amp; pasted over:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;if (&amp;quot;KrigR&amp;quot; %in% rownames(installed.packages()) == FALSE) { # KrigR check
  Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS = &amp;quot;true&amp;quot;)
  devtools::install_github(&amp;quot;https://github.com/ErikKusch/KrigR&amp;quot;)
}
library(KrigR)
#### CDS API (needed for ERA5-Land downloads)
if (!exists(&amp;quot;API_Key&amp;quot;) | !exists(&amp;quot;API_User&amp;quot;)) { # CS API check: if CDS API credentials have not been specified elsewhere
  API_User &amp;lt;- readline(prompt = &amp;quot;Please enter your Climate Data Store API user number and hit ENTER.&amp;quot;)
  API_Key &amp;lt;- readline(prompt = &amp;quot;Please enter your Climate Data Store API key number and hit ENTER.&amp;quot;)
} # end of CDS API check

#### NUMBER OF CORES
if (!exists(&amp;quot;numberOfCores&amp;quot;)) { # Core check: if number of cores for parallel processing has not been set yet
  numberOfCores &amp;lt;- readline(prompt = paste(&amp;quot;How many cores do you want to allocate to these processes? Your machine has&amp;quot;, parallel::detectCores()))
} # end of Core check
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the package, we can download some state-of-the-art climate data. I have already prepared all of this in the data directory you downloaded earlier so this step will automatically be skipped:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;if (!file.exists(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))) {
  colnames(Plot_df)[1:3] &amp;lt;- c(&amp;quot;Lon&amp;quot;, &amp;quot;Lat&amp;quot;, &amp;quot;ID&amp;quot;) # set column names to be in line with what KrigR wants
  Points_Raw &amp;lt;- download_ERA(
    Variable = &amp;quot;2m_temperature&amp;quot;,
    DataSet = &amp;quot;era5&amp;quot;,
    DateStart = &amp;quot;1982-01-01&amp;quot;,
    DateStop = &amp;quot;2012-12-31&amp;quot;,
    TResolution = &amp;quot;month&amp;quot;,
    TStep = 1,
    Extent = Plot_df, # the point data with Lon and Lat columns
    Buffer = 0.5, # a 0.5 degree buffer should be drawn around each point
    ID = &amp;quot;ID&amp;quot;, # this is the column which holds point IDs
    API_User = API_User,
    API_Key = API_Key,
    Dir = file.path(getwd(), &amp;quot;Data&amp;quot;),
    FileName = &amp;quot;AT_Climatology.nc&amp;quot;
  )
  Points_mean &amp;lt;- calc(Points_Raw, fun = mean)
  Points_sd &amp;lt;- calc(Points_Raw, fun = sd)
  Sparrows_df$TAvg &amp;lt;- as.numeric(extract(x = Points_mean, y = Sparrows_df[, c(&amp;quot;Longitude&amp;quot;, &amp;quot;Latitude&amp;quot;)], buffer = 0.3))
  Sparrows_df$TSD &amp;lt;- as.numeric(extract(x = Points_sd, y = Sparrows_df[, c(&amp;quot;Longitude&amp;quot;, &amp;quot;Latitude&amp;quot;)], buffer = 0.3))
  saveRDS(Sparrows_df, file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))
} else {
  Sparrows_df &amp;lt;- readRDS(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have now effectively added two more variables to the data set:&lt;/p&gt;
&lt;ol start=&#34;19&#34;&gt;
&lt;li&gt;&lt;code&gt;TAvg&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - Average air temperature for a 30-year time-period&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TSD&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - Standard deviation of mean monthly air temperature for a 30-year time-period&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now we have the data set we will look at for the rest of the exercises in this seminar series. But how did we get here? Find the answer 
&lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;hypotheses&#34;&gt;Hypotheses&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s consider the following two hypotheses for our exercises for this simulated research project:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Sparrow Morphology&lt;/strong&gt; is determined by:&lt;br&gt;
A. &lt;em&gt;Climate Conditions&lt;/em&gt; with sparrows in stable, warm environments fairing better than those in colder, less stable ones.&lt;br&gt;
B. &lt;em&gt;Competition&lt;/em&gt; with sparrows in small flocks doing better than those in big flocks.&lt;br&gt;
C. &lt;em&gt;Predation&lt;/em&gt; with sparrows under pressure of predation doing worse than those without.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sites&lt;/strong&gt;  accurately represent &lt;strong&gt;sparrow morphology&lt;/strong&gt;. This may mean:&lt;br&gt;
A. &lt;em&gt;Population status&lt;/em&gt; as inferred through morphology.&lt;br&gt;
B. &lt;em&gt;Site index&lt;/em&gt; as inferred through morphology.&lt;br&gt;
C. &lt;em&gt;Climate&lt;/em&gt; as inferred through morphology.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We try to answer these over the next few sessions.&lt;/p&gt;
&lt;h2 id=&#34;sessioninfo&#34;&gt;SessionInfo&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessionInfo()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.3 (2023-03-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur ... 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] KrigR_0.1.2       terra_1.7-21      httr_1.4.5        stars_0.6-0       abind_1.4-5       fasterize_1.0.4   sf_1.0-12         lubridate_1.9.2   automap_1.1-9     doSNOW_1.0.20    
## [11] snow_0.4-4        doParallel_1.0.17 iterators_1.0.14  foreach_1.5.2     rgdal_1.6-5       raster_3.6-20     sp_1.6-0          stringr_1.5.0     keyring_1.3.1     ecmwfr_1.5.0     
## [21] ncdf4_1.21        leaflet_2.1.2    
## 
## loaded via a namespace (and not attached):
##  [1] xts_0.13.0         R.cache_0.16.0     tools_4.2.3        bslib_0.4.2        utf8_1.2.3         R6_2.5.1           KernSmooth_2.23-20 DBI_1.1.3          colorspace_2.1-0   tidyselect_1.2.0  
## [11] compiler_4.2.3     cli_3.6.0          gstat_2.1-0        bookdown_0.33      sass_0.4.5         scales_1.2.1       classInt_0.4-9     proxy_0.4-27       digest_0.6.31      rmarkdown_2.20    
## [21] R.utils_2.12.2     pkgconfig_2.0.3    htmltools_0.5.4    styler_1.9.1       fastmap_1.1.1      htmlwidgets_1.6.1  rlang_1.0.6        rstudioapi_0.14    FNN_1.1.3.2        jquerylib_0.1.4   
## [31] generics_0.1.3     zoo_1.8-11         jsonlite_1.8.4     crosstalk_1.2.0    dplyr_1.1.0        R.oo_1.25.0        magrittr_2.0.3     Rcpp_1.0.10        munsell_0.5.0      fansi_1.0.4       
## [41] lifecycle_1.0.3    R.methodsS3_1.8.2  stringi_1.7.12     yaml_2.3.7         plyr_1.8.8         grid_4.2.3         lattice_0.20-45    knitr_1.42         pillar_1.8.1       spacetime_1.2-8   
## [51] codetools_0.2-19   glue_1.6.2         evaluate_0.20      blogdown_1.16      vctrs_0.5.2        gtable_0.3.1       purrr_1.0.1        reshape_0.8.9      assertthat_0.2.1   cachem_1.0.7      
## [61] ggplot2_3.4.1      xfun_0.37          lwgeom_0.2-11      e1071_1.7-13       class_7.3-21       tibble_3.2.0       intervals_0.15.3   memoise_2.0.1      units_0.8-1        timechange_0.2.0  
## [71] ellipsis_0.3.2
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Research Project</title>
      <link>https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/</guid>
      <description>&lt;h2 id=&#34;our-resarch-project&#34;&gt;Our Resarch Project&lt;/h2&gt;
&lt;p&gt;Here (and over the next few exercises in this &amp;ldquo;course&amp;rdquo;), we are looking at a big (and entirely fictional) data base of the common house sparrow (&lt;em&gt;Passer domesticus&lt;/em&gt;). In particular, we are interested in the &lt;strong&gt;Evolution of &lt;em&gt;Passer domesticus&lt;/em&gt; in Response to Climate Change&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;I have created a large data set for this exercise which is available in a cleaned and properly handled version &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/excursions-into-biostatistics/Data.rar&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;reading-the-data-into-r&#34;&gt;Reading the Data into &lt;code&gt;R&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start by reading the data into &lt;code&gt;R&lt;/code&gt; and taking an initial look at it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sparrows_df &amp;lt;- readRDS(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowData.rds&amp;quot;))
Sparrows_df &amp;lt;- Sparrows_df[!is.na(Sparrows_df$Weight), ]
head(Sparrows_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Index Latitude Longitude     Climate Population.Status Weight Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type
## 1    SI       60       100 Continental            Native  34.05  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 2    SI       60       100 Continental            Native  34.86  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 3    SI       60       100 Continental            Native  32.34  12.66       6.64  Black Female        Shrub          35.60              1       3.21     C      Large               Yes         Avian
## 4    SI       60       100 Continental            Native  34.78  15.09       7.00  Brown Female        Shrub          47.75              0         NA     E      Large               Yes         Avian
## 5    SI       60       100 Continental            Native  35.01  13.82       6.81   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 6    SI       60       100 Continental            Native  32.36  12.67       6.64  Brown Female        Shrub          32.47              1       3.17     E      Large               Yes         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;variables&#34;&gt;Variables&lt;/h4&gt;
&lt;p&gt;When building models or trying to explain anything about our data set, we need to consider all the different variables and the information contained therein. In this data set, we have access to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Index&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - an abbreviation of &lt;code&gt;Site&lt;/code&gt; records&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Latitude&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - an identifier of where specific sparrow measurements where taken&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Longitude&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - an identifier of where specific sparrow measurements where taken&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Climate&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - local climate types that sparrows are subjected to (e.g. coastal, continental, and semi-coastal)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Population.Status&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - population status (e.g. native or introduced)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Weight&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - sparrow weight [g]; Range: 13-40g&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Height&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - sparrow height/length [cm]; Range: 10-22cm&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Wing.Chord&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - wing length [cm]; Range: 6-10cm&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Colour&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - main plumage colour (e.g. brown, grey, and black)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Sex&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - sparrow sex&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Nesting.Site&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - nesting conditions, only recorded for females (e.g. tree or shrub)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Nesting.Height&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - nest elevation above ground level, only recorded for females&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Number.of.Eggs&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - number of eggs per nest, only recorded for females&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Egg.Weight&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - mean weight of eggs per nest, only recorded for females&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Flock&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - which flock at each location each sparrow belongs to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Home.Range&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - size of home range of each flock (e.g. Small, Medium, and Large)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Predator.Presence&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - if a predator is present at a station (e.g. No or Yes)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Predator.Type&lt;/code&gt; [&lt;em&gt;Factor&lt;/em&gt;] - what kind of predator is present (e.g. Avian, Non-Avian, or None)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that the variables &lt;code&gt;Longitude&lt;/code&gt; and &lt;code&gt;Latitude&lt;/code&gt; may be used to retrieve climate data variables from a host of data sources.&lt;/p&gt;
&lt;h4 id=&#34;locations&#34;&gt;Locations&lt;/h4&gt;
&lt;p&gt;Looking at our data, we notice that it comes at distinct stations. Let&amp;rsquo;s visualise where they are:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;leaflet&amp;quot;)
Plot_df &amp;lt;- Sparrows_df[, c(&amp;quot;Longitude&amp;quot;, &amp;quot;Latitude&amp;quot;, &amp;quot;Index&amp;quot;, &amp;quot;Climate&amp;quot;, &amp;quot;Population.Status&amp;quot;)]
Plot_df &amp;lt;- unique(Plot_df)
m &amp;lt;- leaflet()
m &amp;lt;- addTiles(m)
m &amp;lt;- addMarkers(m,
  lng = Plot_df$Longitude,
  lat = Plot_df$Latitude,
  label = Plot_df$Index,
  popup = paste(Plot_df$Population.Status, Plot_df$Climate, sep = &amp;quot;;&amp;quot;)
)
m
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-{=html}&#34;&gt;&amp;lt;div class=&amp;quot;leaflet html-widget html-fill-item-overflow-hidden html-fill-item&amp;quot; id=&amp;quot;htmlwidget-198293ac646900c5a74e&amp;quot; style=&amp;quot;width:1440px;height:768px;&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script type=&amp;quot;application/json&amp;quot; data-for=&amp;quot;htmlwidget-198293ac646900c5a74e&amp;quot;&amp;gt;{&amp;quot;x&amp;quot;:{&amp;quot;options&amp;quot;:{&amp;quot;crs&amp;quot;:{&amp;quot;crsClass&amp;quot;:&amp;quot;L.CRS.EPSG3857&amp;quot;,&amp;quot;code&amp;quot;:null,&amp;quot;proj4def&amp;quot;:null,&amp;quot;projectedBounds&amp;quot;:null,&amp;quot;options&amp;quot;:{}}},&amp;quot;calls&amp;quot;:[{&amp;quot;method&amp;quot;:&amp;quot;addTiles&amp;quot;,&amp;quot;args&amp;quot;:[&amp;quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&amp;quot;,null,null,{&amp;quot;minZoom&amp;quot;:0,&amp;quot;maxZoom&amp;quot;:18,&amp;quot;tileSize&amp;quot;:256,&amp;quot;subdomains&amp;quot;:&amp;quot;abc&amp;quot;,&amp;quot;errorTileUrl&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;tms&amp;quot;:false,&amp;quot;noWrap&amp;quot;:false,&amp;quot;zoomOffset&amp;quot;:0,&amp;quot;zoomReverse&amp;quot;:false,&amp;quot;opacity&amp;quot;:1,&amp;quot;zIndex&amp;quot;:1,&amp;quot;detectRetina&amp;quot;:false,&amp;quot;attribution&amp;quot;:&amp;quot;&amp;amp;copy; &amp;lt;a href=\&amp;quot;https://openstreetmap.org\&amp;quot;&amp;gt;OpenStreetMap&amp;lt;\/a&amp;gt; contributors, &amp;lt;a href=\&amp;quot;https://creativecommons.org/licenses/by-sa/2.0/\&amp;quot;&amp;gt;CC-BY-SA&amp;lt;\/a&amp;gt;&amp;quot;}]},{&amp;quot;method&amp;quot;:&amp;quot;addMarkers&amp;quot;,&amp;quot;args&amp;quot;:[[60,54,-25,-21.1,70,55,31,17.25,4,10.5,-51.75],[100,-2,135,55.6,-90,-97,-92,-88.75,-53,-67,-59.17],null,null,null,{&amp;quot;interactive&amp;quot;:true,&amp;quot;draggable&amp;quot;:false,&amp;quot;keyboard&amp;quot;:true,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;zIndexOffset&amp;quot;:0,&amp;quot;opacity&amp;quot;:1,&amp;quot;riseOnHover&amp;quot;:false,&amp;quot;riseOffset&amp;quot;:250},[&amp;quot;Native;Continental&amp;quot;,&amp;quot;Native;Coastal&amp;quot;,&amp;quot;Introduced;Continental&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Semi-Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;,&amp;quot;Introduced;Coastal&amp;quot;],null,null,null,[&amp;quot;SI&amp;quot;,&amp;quot;UK&amp;quot;,&amp;quot;AU&amp;quot;,&amp;quot;RE&amp;quot;,&amp;quot;NU&amp;quot;,&amp;quot;MA&amp;quot;,&amp;quot;LO&amp;quot;,&amp;quot;BE&amp;quot;,&amp;quot;FG&amp;quot;,&amp;quot;SA&amp;quot;,&amp;quot;FI&amp;quot;],{&amp;quot;interactive&amp;quot;:false,&amp;quot;permanent&amp;quot;:false,&amp;quot;direction&amp;quot;:&amp;quot;auto&amp;quot;,&amp;quot;opacity&amp;quot;:1,&amp;quot;offset&amp;quot;:[0,0],&amp;quot;textsize&amp;quot;:&amp;quot;10px&amp;quot;,&amp;quot;textOnly&amp;quot;:false,&amp;quot;className&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;sticky&amp;quot;:true},null]}],&amp;quot;limits&amp;quot;:{&amp;quot;lat&amp;quot;:[-51.75,70],&amp;quot;lng&amp;quot;:[-97,135]}},&amp;quot;evals&amp;quot;:[],&amp;quot;jsHooks&amp;quot;:[]}&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that you can zoom and drag the above map as well as click the station markers for some additional information.&lt;/p&gt;
&lt;h3 id=&#34;adding-information&#34;&gt;Adding Information&lt;/h3&gt;
&lt;p&gt;How do we get the data for this? Well, I wrote an &lt;code&gt;R&lt;/code&gt;-Package that does exactly that.&lt;/p&gt;
&lt;p&gt;First, said package needs to be installed from my GitHub repository for it. Subsequently, we need to set API Key and User number obtained at the 
&lt;a href=&#34;https://cds.climate.copernicus.eu/api-how-to&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Climate Data Store&lt;/a&gt;. I have already baked these into my material, so I don&amp;rsquo;t set them here, but include lines of code that ask you for your credentials when copy &amp;amp; pasted over:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;if (&amp;quot;KrigR&amp;quot; %in% rownames(installed.packages()) == FALSE) { # KrigR check
  Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS = &amp;quot;true&amp;quot;)
  devtools::install_github(&amp;quot;https://github.com/ErikKusch/KrigR&amp;quot;)
}
library(KrigR)
#### CDS API (needed for ERA5-Land downloads)
if (!exists(&amp;quot;API_Key&amp;quot;) | !exists(&amp;quot;API_User&amp;quot;)) { # CS API check: if CDS API credentials have not been specified elsewhere
  API_User &amp;lt;- readline(prompt = &amp;quot;Please enter your Climate Data Store API user number and hit ENTER.&amp;quot;)
  API_Key &amp;lt;- readline(prompt = &amp;quot;Please enter your Climate Data Store API key number and hit ENTER.&amp;quot;)
} # end of CDS API check

#### NUMBER OF CORES
if (!exists(&amp;quot;numberOfCores&amp;quot;)) { # Core check: if number of cores for parallel processing has not been set yet
  numberOfCores &amp;lt;- readline(prompt = paste(&amp;quot;How many cores do you want to allocate to these processes? Your machine has&amp;quot;, parallel::detectCores()))
} # end of Core check
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the package, we can download some state-of-the-art climate data. I have already prepared all of this in the data directory you downloaded earlier so this step will automatically be skipped:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;if (!file.exists(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))) {
  colnames(Plot_df)[1:3] &amp;lt;- c(&amp;quot;Lon&amp;quot;, &amp;quot;Lat&amp;quot;, &amp;quot;ID&amp;quot;) # set column names to be in line with what KrigR wants
  Points_Raw &amp;lt;- download_ERA(
    Variable = &amp;quot;2m_temperature&amp;quot;,
    DataSet = &amp;quot;era5&amp;quot;,
    DateStart = &amp;quot;1982-01-01&amp;quot;,
    DateStop = &amp;quot;2012-12-31&amp;quot;,
    TResolution = &amp;quot;month&amp;quot;,
    TStep = 1,
    Extent = Plot_df, # the point data with Lon and Lat columns
    Buffer = 0.5, # a 0.5 degree buffer should be drawn around each point
    ID = &amp;quot;ID&amp;quot;, # this is the column which holds point IDs
    API_User = API_User,
    API_Key = API_Key,
    Dir = file.path(getwd(), &amp;quot;Data&amp;quot;),
    FileName = &amp;quot;AT_Climatology.nc&amp;quot;
  )
  Points_mean &amp;lt;- calc(Points_Raw, fun = mean)
  Points_sd &amp;lt;- calc(Points_Raw, fun = sd)
  Sparrows_df$TAvg &amp;lt;- as.numeric(extract(x = Points_mean, y = Sparrows_df[, c(&amp;quot;Longitude&amp;quot;, &amp;quot;Latitude&amp;quot;)], buffer = 0.3))
  Sparrows_df$TSD &amp;lt;- as.numeric(extract(x = Points_sd, y = Sparrows_df[, c(&amp;quot;Longitude&amp;quot;, &amp;quot;Latitude&amp;quot;)], buffer = 0.3))
  saveRDS(Sparrows_df, file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))
} else {
  Sparrows_df &amp;lt;- readRDS(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have now effectively added two more variables to the data set:&lt;/p&gt;
&lt;ol start=&#34;19&#34;&gt;
&lt;li&gt;&lt;code&gt;TAvg&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - Average air temperature for a 30-year time-period&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TSD&lt;/code&gt; [&lt;em&gt;Numeric&lt;/em&gt;] - Standard deviation of mean monthly air temperature for a 30-year time-period&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now we have the data set we will look at for the rest of the exercises in this seminar series. But how did we get here? Find the answer &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;hypotheses&#34;&gt;Hypotheses&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s consider the following two hypotheses for our exercises for this simulated research project:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Sparrow Morphology&lt;/strong&gt; is determined by:&lt;br&gt;
A. &lt;em&gt;Climate Conditions&lt;/em&gt; with sparrows in stable, warm environments fairing better than those in colder, less stable ones.&lt;br&gt;
B. &lt;em&gt;Competition&lt;/em&gt; with sparrows in small flocks doing better than those in big flocks.&lt;br&gt;
C. &lt;em&gt;Predation&lt;/em&gt; with sparrows under pressure of predation doing worse than those without.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sites&lt;/strong&gt;  accurately represent &lt;strong&gt;sparrow morphology&lt;/strong&gt;. This may mean:&lt;br&gt;
A. &lt;em&gt;Population status&lt;/em&gt; as inferred through morphology.&lt;br&gt;
B. &lt;em&gt;Site index&lt;/em&gt; as inferred through morphology.&lt;br&gt;
C. &lt;em&gt;Climate&lt;/em&gt; as inferred through morphology.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We try to answer these over the next few sessions.&lt;/p&gt;
&lt;h2 id=&#34;sessioninfo&#34;&gt;SessionInfo&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessionInfo()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.3 (2023-03-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur ... 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] KrigR_0.1.2       terra_1.7-21      httr_1.4.5        stars_0.6-0       abind_1.4-5       fasterize_1.0.4   sf_1.0-12         lubridate_1.9.2   automap_1.1-9     doSNOW_1.0.20    
## [11] snow_0.4-4        doParallel_1.0.17 iterators_1.0.14  foreach_1.5.2     rgdal_1.6-5       raster_3.6-20     sp_1.6-0          stringr_1.5.0     keyring_1.3.1     ecmwfr_1.5.0     
## [21] ncdf4_1.21        leaflet_2.1.2    
## 
## loaded via a namespace (and not attached):
##  [1] xts_0.13.0         R.cache_0.16.0     tools_4.2.3        bslib_0.4.2        utf8_1.2.3         R6_2.5.1           KernSmooth_2.23-20 DBI_1.1.3          colorspace_2.1-0   tidyselect_1.2.0  
## [11] compiler_4.2.3     cli_3.6.0          gstat_2.1-0        bookdown_0.33      sass_0.4.5         scales_1.2.1       classInt_0.4-9     proxy_0.4-27       digest_0.6.31      rmarkdown_2.20    
## [21] R.utils_2.12.2     pkgconfig_2.0.3    htmltools_0.5.4    styler_1.9.1       fastmap_1.1.1      htmlwidgets_1.6.1  rlang_1.0.6        rstudioapi_0.14    FNN_1.1.3.2        jquerylib_0.1.4   
## [31] generics_0.1.3     zoo_1.8-11         jsonlite_1.8.4     crosstalk_1.2.0    dplyr_1.1.0        R.oo_1.25.0        magrittr_2.0.3     Rcpp_1.0.10        munsell_0.5.0      fansi_1.0.4       
## [41] lifecycle_1.0.3    R.methodsS3_1.8.2  stringi_1.7.12     yaml_2.3.7         plyr_1.8.8         grid_4.2.3         lattice_0.20-45    knitr_1.42         pillar_1.8.1       spacetime_1.2-8   
## [51] codetools_0.2-19   glue_1.6.2         evaluate_0.20      blogdown_1.16      vctrs_0.5.2        gtable_0.3.1       purrr_1.0.1        reshape_0.8.9      assertthat_0.2.1   cachem_1.0.7      
## [61] ggplot2_3.4.1      xfun_0.37          lwgeom_0.2-11      e1071_1.7-13       class_7.3-21       tibble_3.2.0       intervals_0.15.3   memoise_2.0.1      units_0.8-1        timechange_0.2.0  
## [71] ellipsis_0.3.2
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Descriptive Statistics</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/descriptive-statistics/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/descriptive-statistics/</guid>
      <description>&lt;h1 id=&#34;theory&#34;&gt;Theory&lt;/h1&gt;
&lt;p&gt;These are the solutions to the exercises contained within the handout to Descriptive Statistics which walks you through the basics of descriptive statistics and its parameters. The analyses presented here are using data from the &lt;code&gt;StarWars&lt;/code&gt; data set supplied through the &lt;code&gt;dplyr&lt;/code&gt; package that have been saved as a .csv file. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/04---Descriptive-Statistics_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/DescriptiveData.csv&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;packages&#34;&gt;Packages&lt;/h2&gt;
&lt;p&gt;As you will remember from our lecture slides, the calculation of the mode in &lt;code&gt;R&lt;/code&gt; can either be achieved through some intense coding or simply by using the &lt;code&gt;mlv(..., method=&amp;quot;mfv&amp;quot;)&lt;/code&gt; function contained within the &lt;code&gt;modeest&lt;/code&gt; package (unfortunately, this package is out of date and can sometimes be challenging to install).&lt;/p&gt;
&lt;p&gt;Conclusively, it is now time for you to get familiar with how packages work in &lt;code&gt;R&lt;/code&gt;. Packages are the way by which &lt;code&gt;R&lt;/code&gt; is supplied with user-created and moderator-mediated functionality that exceeds the base applicability of &lt;code&gt;R&lt;/code&gt;. Many things you will want to accomplish in more advanced statistics is impossible without such packages and even basic tasks such as data visualisation (dealt with in our next seminar) are reliant on &lt;code&gt;R&lt;/code&gt; packages.&lt;/p&gt;
&lt;p&gt;If you want to get a package and its functions into &lt;code&gt;R&lt;/code&gt; there are two ways we will discuss in the following. In general, it pays to load all packages at the beginning of a coding document before any actual analyses happen (in the preamble) so you get a good overview of what the program is calling upon.&lt;/p&gt;
&lt;h3 id=&#34;basic-preamble&#34;&gt;Basic Preamble&lt;/h3&gt;
&lt;p&gt;This is the most basic version of getting packages into &lt;code&gt;R&lt;/code&gt; and is widely practised and taught. Unsurprisingly, I am not a big fan of it.&lt;/p&gt;
&lt;p&gt;First, you use function &lt;code&gt;install.packages()&lt;/code&gt; to download the desired package off dedicated servers (usually CRAN-mirrors) to your machine where it is then unpacked into a library (a folder that&amp;rsquo;s located in your documents section by default). Secondly, you need to invoke the &lt;code&gt;library()&lt;/code&gt; function to load the &lt;code&gt;R&lt;/code&gt; package you need into your active &lt;code&gt;R&lt;/code&gt; session. In our case of the package &lt;code&gt;modeest&lt;/code&gt; it would look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;modeest&amp;quot;)
library(modeest)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason I am not overly fond of this procedure is that it is clunky, can break easily through spelling mistakes and starts cluttering your preamble super fast if the analyses you are wanting to perform require excessive amounts of packages. Additionally, when you are some place with a bad internet connection you might not want to re-download packages that are already contained on your hard drive.&lt;/p&gt;
&lt;h3 id=&#34;advanced-preamble&#34;&gt;Advanced Preamble&lt;/h3&gt;
&lt;p&gt;There is a myriad of different preamble styles (just as there are tons of different, personalised coding styles). I am left with presenting my preamble of choice here but I do not claim that this is the most sophisticated one out there.&lt;/p&gt;
&lt;p&gt;The way this preamble works is that it is structured around a user-defined function (something we will touch on later in our seminar series) which first checks whether a package is already downloaded and then installs (if necessary) and/or loads it into &lt;code&gt;R&lt;/code&gt;. This function is called &lt;code&gt;install.load.package()&lt;/code&gt; and you can see its specification down below (don&amp;rsquo;t worry if it doesn&amp;rsquo;t make sense to you yet - it is not supposed to at this point). Unfortunately, it can only ever be applied to one package at a time and so we need a workaround to make it work on multiple packages at once. This can be achieved by establishing a vector of all desired package names (&lt;code&gt;package_vec&lt;/code&gt;) and then applying (&lt;code&gt;sapply()&lt;/code&gt;) the &lt;code&gt;install.load.package()&lt;/code&gt; function to every item of the package name vector iteratively as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
    if (!require(x, character.only = TRUE)) 
        install.packages(x)
    require(x, character.only = TRUE)
}
# packages to load/install if necessary
package_vec &amp;lt;- c(&amp;quot;modeest&amp;quot;)
# applying function install.load.package to all packages specified in package_vec
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: modeest
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## modeest 
##    TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why do I prefer this? Firstly, it is way shorter than the basic method when dealing with many packages (which you will get into fast, I promise), reduces the chance for typos by 50% and does not override already installed packages hence speeding up your processing time.&lt;/p&gt;
&lt;h2 id=&#34;loading-the-excel-data-into-r&#34;&gt;Loading the Excel data into &lt;code&gt;R&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Our data is located in the &lt;code&gt;Data&lt;/code&gt; folder and is called &lt;code&gt;DescriptiveData.csv&lt;/code&gt;. Since it is a .csv file, we can simply use the &lt;code&gt;R&lt;/code&gt; in-built function &lt;code&gt;read.csv()&lt;/code&gt; to load the data by combining the former two identifiers into one long string with a backslash separating the two (the backslash indicates a step down in the folder hierarchy). Given this argument, &lt;code&gt;read.csv()&lt;/code&gt; will produce an object of type &lt;code&gt;data.frame&lt;/code&gt; in &lt;code&gt;R&lt;/code&gt; which we want to keep in our environment and hence need to assign a name to. In our case, let that name be &lt;code&gt;Data_df&lt;/code&gt; (I recommend using endings to your data object names that indicate their type for easier coding without constant type checking):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- read.csv(&amp;quot;Data/DescriptiveData.csv&amp;quot;)  # load data file from Data folder
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;whats-contained-within-our-data&#34;&gt;What&amp;rsquo;s contained within our data?&lt;/h2&gt;
&lt;p&gt;Now that our data set is finally loaded into &lt;code&gt;R&lt;/code&gt;, we can finally get to trying to make sense of it. Usually, this shouldn&amp;rsquo;t ever be something one has to do in &lt;code&gt;R&lt;/code&gt; but should be manageable through a project-/data-specific README file (we will cover this in our seminar on hypotheses testing and project planning) but for now we are stuck with pure exploration of our data set. Get your goggles on and let&amp;rsquo;s dive in!&lt;/p&gt;
&lt;p&gt;Firstly, it always pays to asses the basic attributes of any data object (remember the Introduction to &lt;code&gt;R&lt;/code&gt; seminar):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Name&lt;/em&gt; - we know the name (it is &lt;code&gt;Data_df&lt;/code&gt;) since we named it that&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Type&lt;/em&gt; - we already know that it is a &lt;code&gt;data.frame&lt;/code&gt; because we created it using the &lt;code&gt;read.csv&lt;/code&gt; function&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Mode&lt;/em&gt; - this is an interesting one as it means having to subset our data frame&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Dimensions&lt;/em&gt; - a crucial information about how many observations and variables are contained within our data set&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dimensions&#34;&gt;Dimensions&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start with the &lt;em&gt;dimensions&lt;/em&gt; because these will tell us how many &lt;em&gt;modes&lt;/em&gt; (these are object attribute modes and not descriptive parameter modes) to asses:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 87  8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the &lt;code&gt;dim()&lt;/code&gt; function, we arrive at the conclusion that our &lt;code&gt;Data_df&lt;/code&gt; contains 87 rows and 8 columns. Since data frames are usually ordered as observations $\times$ variables, we can conclude that we have 87 observations and 8 variables at our hands.&lt;br&gt;
You can arrive at the same point by using the function &lt;code&gt;View()&lt;/code&gt; in &lt;code&gt;R&lt;/code&gt;. I&amp;rsquo;m not showing this here because it does not translate well to paper and would make whoever chooses to print this waste paper.&lt;/p&gt;
&lt;h3 id=&#34;modes&#34;&gt;Modes&lt;/h3&gt;
&lt;p&gt;Now it&amp;rsquo;s time to get a hang of the &lt;em&gt;modes&lt;/em&gt; of the variable records within our data set. To do so, we have two choices, we can either subset the data frame by columns and apply the &lt;code&gt;class()&lt;/code&gt; function to each column subset or simply apply the &lt;code&gt;str()&lt;/code&gt; function to the data frame object. The reason &lt;code&gt;str()&lt;/code&gt; may be favourable in this case is due to the fact that &lt;code&gt;str()&lt;/code&gt; automatically breaks down the structure of &lt;code&gt;R&lt;/code&gt;-internal objects and hence saves us the sub-setting:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	87 obs. of  8 variables:
##  $ name      : chr  &amp;quot;Luke Skywalker&amp;quot; &amp;quot;C-3PO&amp;quot; &amp;quot;R2-D2&amp;quot; &amp;quot;Darth Vader&amp;quot; ...
##  $ height    : int  172 167 96 202 150 178 165 97 183 182 ...
##  $ mass      : num  77 75 32 136 49 120 75 32 84 77 ...
##  $ hair_color: chr  &amp;quot;blond&amp;quot; &amp;quot;&amp;quot; &amp;quot;&amp;quot; &amp;quot;none&amp;quot; ...
##  $ skin_color: chr  &amp;quot;fair&amp;quot; &amp;quot;gold&amp;quot; &amp;quot;white, blue&amp;quot; &amp;quot;white&amp;quot; ...
##  $ eye_color : chr  &amp;quot;blue&amp;quot; &amp;quot;yellow&amp;quot; &amp;quot;red&amp;quot; &amp;quot;yellow&amp;quot; ...
##  $ birth_year: num  19 112 33 41.9 19 52 47 NA 24 57 ...
##  $ gender    : chr  &amp;quot;male&amp;quot; &amp;quot;&amp;quot; &amp;quot;&amp;quot; &amp;quot;male&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, our data frame knows the 8 variables of name, height, mass, hair_color, skin_color, eye_color, birth_year, gender which range from &lt;code&gt;integer&lt;/code&gt; to &lt;code&gt;numeric&lt;/code&gt; and &lt;code&gt;factor&lt;/code&gt; modes.&lt;/p&gt;
&lt;h3 id=&#34;data-content&#34;&gt;Data Content&lt;/h3&gt;
&lt;p&gt;So what does our data actually tell us? Answering this question usually comes down to some analyses but for now we are only really interested in what kind of information our data frame is storing.&lt;/p&gt;
&lt;p&gt;Again, this would be easiest to asses using a README file or the &lt;code&gt;View()&lt;/code&gt; function in &lt;code&gt;R&lt;/code&gt;. However, for the sake of brevity we can make due with the following to commands which present the user with the first and last five rows of any respective data frame:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             name height mass  hair_color  skin_color eye_color birth_year
## 1 Luke Skywalker    172   77       blond        fair      blue       19.0
## 2          C-3PO    167   75                    gold    yellow      112.0
## 3          R2-D2     96   32             white, blue       red       33.0
## 4    Darth Vader    202  136        none       white    yellow       41.9
## 5    Leia Organa    150   49       brown       light     brown       19.0
## 6      Owen Lars    178  120 brown, grey       light      blue       52.0
##   gender
## 1   male
## 2       
## 3       
## 4   male
## 5 female
## 6   male
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tail(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              name height mass hair_color skin_color eye_color birth_year gender
## 82           Finn     NA   NA      black       dark      dark         NA   male
## 83            Rey     NA   NA      brown      light     hazel         NA female
## 84    Poe Dameron     NA   NA      brown      light     brown         NA   male
## 85            BB8     NA   NA       none       none     black         NA   none
## 86 Captain Phasma     NA   NA    unknown    unknown   unknown         NA female
## 87  PadmÃ© Amidala    165   45      brown      light     brown         46 female
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The avid reader will surely have picked up on the fact that all the records in the &lt;code&gt;name&lt;/code&gt; column of &lt;code&gt;Data_df&lt;/code&gt; belong to characters from the Star Wars universe. In fact, this data set is a modified version of the &lt;code&gt;StarWars&lt;/code&gt; data set supplied by the &lt;code&gt;dplyr&lt;/code&gt; package and contains information of many of the important cast members of the Star Wars movie universe.&lt;/p&gt;
&lt;h2 id=&#34;parameters-of-descriptive-statistics&#34;&gt;Parameters of descriptive statistics&lt;/h2&gt;
&lt;h3 id=&#34;names&#34;&gt;Names&lt;/h3&gt;
&lt;p&gt;As it turns out (and should&amp;rsquo;ve been obvious from the onset if we&amp;rsquo;re honest), every major character in the cinematic Star Wars Universe has a unique name to themselves. Conclusively, the calculation of any parameters of descriptive statistics makes no sense with the names of our characters for the two following reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The name variable is of mode character/factor and only allows for the calculation of the mode&lt;/li&gt;
&lt;li&gt;Since every name only appears once, there is no mode&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As long as the calculation of descriptive parameters of the &lt;code&gt;name&lt;/code&gt; variable of our data set is concerned, Admiral Ackbar said it best: &amp;ldquo;It&amp;rsquo;s a trap&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;height&#34;&gt;Height&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s get started on figuring out some parameters of descriptive statistics for the &lt;code&gt;height&lt;/code&gt; variable of our Star Wars characters.&lt;/p&gt;
&lt;h4 id=&#34;subsetting&#34;&gt;Subsetting&lt;/h4&gt;
&lt;p&gt;First, we need to extract the data in question from our big data frame object. This can be achieved by indexing through the column name as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Height &amp;lt;- Data_df$height
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;location-parameters&#34;&gt;Location Parameters&lt;/h4&gt;
&lt;p&gt;Now, with our &lt;code&gt;Height&lt;/code&gt; vector being the numeric height records of the Star Wars characters in our data set, we are primed to calculate location parameters as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mean &amp;lt;- mean(Height, na.rm = TRUE)
median &amp;lt;- median(Height, na.rm = TRUE)
mode &amp;lt;- mlv(na.omit(Height), method = &amp;quot;mfv&amp;quot;)
min &amp;lt;- min(Height, na.rm = TRUE)
max &amp;lt;- max(Height, na.rm = TRUE)
range &amp;lt;- max - min

# Combining all location parameters into one vector for easier viewing
LocPars_vec &amp;lt;- c(mean, median, mode, min, max, range)
names(LocPars_vec) &amp;lt;- c(&amp;quot;mean&amp;quot;, &amp;quot;median&amp;quot;, &amp;quot;mode&amp;quot;, &amp;quot;minimum&amp;quot;, &amp;quot;maximum&amp;quot;, &amp;quot;range&amp;quot;)
LocPars_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mean  median    mode minimum maximum   range 
## 174.358 180.000 183.000  66.000 264.000 198.000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can clearly see, there is a big range in the heights of our respective Star Wars characters with mean and median being fairly disjunct due to the outliers in height on especially either end.&lt;/p&gt;
&lt;h4 id=&#34;distribution-parameters&#34;&gt;Distribution Parameters&lt;/h4&gt;
&lt;p&gt;Now that we are aware of the location parameters of the Star Wars height records, we can move on to the distribution parameters/parameters of spread. Those can be calculated in &lt;code&gt;R&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;var &amp;lt;- var(Height, na.rm = TRUE)
sd &amp;lt;- sd(Height, na.rm = TRUE)
quantiles &amp;lt;- quantile(Height, na.rm = TRUE)

# Combining all location parameters into one vector for easier viewing
DisPars_vec &amp;lt;- c(var, sd, quantiles)
names(DisPars_vec) &amp;lt;- c(&amp;quot;var&amp;quot;, &amp;quot;sd&amp;quot;, &amp;quot;0%&amp;quot;, &amp;quot;25%&amp;quot;, &amp;quot;50%&amp;quot;, &amp;quot;75%&amp;quot;, &amp;quot;100%&amp;quot;)
DisPars_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        var         sd         0%        25%        50%        75%       100% 
## 1208.98272   34.77043   66.00000  167.00000  180.00000  191.00000  264.00000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how some of the quantiles (actually quartiles in this case) link up with some of the parameters of central tendency.&lt;/p&gt;
&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;
&lt;p&gt;Just to round this off, have a look at what the &lt;code&gt;summary()&lt;/code&gt; function in &lt;code&gt;R&lt;/code&gt; supplies you with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary &amp;lt;- summary(na.omit(Height))
summary
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    66.0   167.0   180.0   174.4   191.0   264.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a nice assortment of location and dispersion parameters.&lt;/p&gt;
&lt;h3 id=&#34;mass&#34;&gt;Mass&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s focus on the weight of our Star Wars characters.&lt;/p&gt;
&lt;h4 id=&#34;subsetting-1&#34;&gt;Subsetting&lt;/h4&gt;
&lt;p&gt;Again, we need to extract our data from the data frame. For the sake of brevity, I will refrain from showing you the rest of the analysis and only present its results to save some space.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Mass &amp;lt;- Data_df$mass
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;location-parameters-1&#34;&gt;Location Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##       mean     median       mode    minimum    maximum      range 
##   97.31186   79.00000   80.00000   15.00000 1358.00000 1343.00000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, there is a huge range in weight records of Star Wars characters and especially the outlier on the upper end (1358kg) push the mean towards the upper end of the weight range and away from the median. We&amp;rsquo;ve got Jabba Desilijic Tiure to thank for that.&lt;/p&gt;
&lt;h4 id=&#34;distribution-parameters-1&#34;&gt;Distribution Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##        var         sd         0%        25%        50%        75%       100% 
## 28715.7300   169.4572    15.0000    55.6000    79.0000    84.5000  1358.0000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, the wide range of weight records also prompts a large variance and standard deviation.&lt;/p&gt;
&lt;h3 id=&#34;hair-color&#34;&gt;Hair Color&lt;/h3&gt;
&lt;p&gt;Hair colour in our data set is saved in column 4 of our data set and so when sub-setting the data frame to obtain information about a characters hair colour, instead of calling on &lt;code&gt;Data_df$hair_color&lt;/code&gt; we can also do so as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HCs &amp;lt;- Data_df[, 4]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, hair colour is not a &lt;code&gt;numeric&lt;/code&gt; variable and much better represent by being of mode &lt;code&gt;factor&lt;/code&gt;. Therefore, we are unable to obtain most parameters of descriptive statistics but we can show a frequency count as follows which allows for the calculation of the mode:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(HCs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## HCs
##                      auburn  auburn, grey auburn, white         black 
##             5             1             1             1            13 
##         blond        blonde         brown   brown, grey          grey 
##             3             1            18             1             1 
##          none       unknown         white 
##            37             1             4
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;eye-colour&#34;&gt;Eye Colour&lt;/h3&gt;
&lt;p&gt;Eye colour is another &lt;code&gt;factor&lt;/code&gt; mode variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ECs &amp;lt;- Data_df$eye_color
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can only calculate the mode by looking for the maximum in our &lt;code&gt;table()&lt;/code&gt; output:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(ECs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ECs
##         black          blue     blue-gray         brown          dark 
##            10            19             1            21             1 
##          gold green, yellow         hazel        orange          pink 
##             1             1             3             8             1 
##           red     red, blue       unknown         white        yellow 
##             5             1             3             1            11
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;birth-year&#34;&gt;Birth Year&lt;/h3&gt;
&lt;h4 id=&#34;subsetting-2&#34;&gt;Subsetting&lt;/h4&gt;
&lt;p&gt;As another &lt;code&gt;numeric&lt;/code&gt; variable, birth year allows for the calculation of the full range of parameters of descriptive statistics:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;BY &amp;lt;- Data_df$birth_year
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Keep in mind that StarWars operates on a different time reference scale than we do.&lt;/p&gt;
&lt;h4 id=&#34;location-parameters-2&#34;&gt;Location Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##      mean    median      mode   minimum   maximum     range 
##  87.56512  52.00000  19.00000   8.00000 896.00000 888.00000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, there is a big disparity here between mean and median which stems from extreme outliers on both ends of the age spectrum (Yoda and Wicket Systri Warrick, respectively).&lt;/p&gt;
&lt;h4 id=&#34;distribution-parameters-2&#34;&gt;Distribution Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##        var         sd         0%        25%        50%        75%       100% 
## 23929.4414   154.6914     8.0000    35.0000    52.0000    72.0000   896.0000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unsurprisingly, there is a big variance and standard deviation for the observed birth year/age records.&lt;/p&gt;
&lt;h3 id=&#34;gender&#34;&gt;Gender&lt;/h3&gt;
&lt;p&gt;Gender is another &lt;code&gt;factor&lt;/code&gt; mode variable (obviously):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Gender &amp;lt;- Data_df$gender
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can, again, only judge the mode of our data from the output of the &lt;code&gt;table()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Gender)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gender
##                      female hermaphrodite          male          none 
##             3            19             1            62             2
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Descriptive Statistics</title>
      <link>https://www.erikkusch.com/courses/biostat101/descriptive-statistics/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/descriptive-statistics/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are the solutions to the exercises contained within the handout to Descriptive Statistics which walks you through the basics of descriptive statistics and its parameters. The analyses presented here are using data from the &lt;code&gt;StarWars&lt;/code&gt; data set supplied through the &lt;code&gt;dplyr&lt;/code&gt; package that have been saved as a .csv file. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions. I have prepared some slides for this session:
&lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/04---Descriptive-Statistics_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/04---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/DescriptiveData.csv&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;. Do not worry about downloading it for now.&lt;/p&gt;
&lt;h2 id=&#34;packages&#34;&gt;Packages&lt;/h2&gt;
&lt;p&gt;As you will remember from our lecture slides, the calculation of the mode in &lt;code&gt;R&lt;/code&gt; can either be achieved through some intense coding or simply by using the &lt;code&gt;mlv(..., method=&amp;quot;mfv&amp;quot;)&lt;/code&gt; function contained within the &lt;code&gt;modeest&lt;/code&gt; package (unfortunately, this package is out of date and can sometimes be challenging to install).&lt;/p&gt;
&lt;p&gt;Conclusively, it is now time for you to get familiar with how packages work in &lt;code&gt;R&lt;/code&gt;. Packages are the way by which &lt;code&gt;R&lt;/code&gt; is supplied with user-created and moderator-mediated functionality that exceeds the base applicability of &lt;code&gt;R&lt;/code&gt;. Many things you will want to accomplish in more advanced statistics is impossible without such packages and even basic tasks such as data visualisation (dealt with in our next seminar) are reliant on &lt;code&gt;R&lt;/code&gt; packages.&lt;/p&gt;
&lt;p&gt;If you want to get a package and its functions into &lt;code&gt;R&lt;/code&gt; there are two ways we will discuss in the following. In general, it pays to load all packages at the beginning of a coding document before any actual analyses happen (in the preamble) so you get a good overview of what the program is calling upon.&lt;/p&gt;
&lt;h3 id=&#34;basic-preamble&#34;&gt;Basic Preamble&lt;/h3&gt;
&lt;p&gt;This is the most basic version of getting packages into &lt;code&gt;R&lt;/code&gt; and is widely practised and taught. Unsurprisingly, I am not a big fan of it.&lt;/p&gt;
&lt;p&gt;First, you use function &lt;code&gt;install.packages()&lt;/code&gt; to download the desired package off dedicated servers (usually CRAN-mirrors) to your machine where it is then unpacked into a library (a folder that&amp;rsquo;s located in your documents section by default). Secondly, you need to invoke the &lt;code&gt;library()&lt;/code&gt; function to load the &lt;code&gt;R&lt;/code&gt; package you need into your active &lt;code&gt;R&lt;/code&gt; session. In our case of the package &lt;code&gt;modeest&lt;/code&gt; it would look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;modeest&amp;quot;)
library(modeest)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason I am not overly fond of this procedure is that it is clunky, can break easily through spelling mistakes and starts cluttering your preamble super fast if the analyses you are wanting to perform require excessive amounts of packages. Additionally, when you are some place with a bad internet connection you might not want to re-download packages that are already contained on your hard drive.&lt;/p&gt;
&lt;h3 id=&#34;advanced-preamble&#34;&gt;Advanced Preamble&lt;/h3&gt;
&lt;p&gt;There is a myriad of different preamble styles (just as there are tons of different, personalised coding styles). I am left with presenting my preamble of choice here but I do not claim that this is the most sophisticated one out there.&lt;/p&gt;
&lt;p&gt;The way this preamble works is that it is structured around a user-defined function (something we will touch on later in our seminar series) which first checks whether a package is already downloaded and then installs (if necessary) and/or loads it into &lt;code&gt;R&lt;/code&gt;. This function is called &lt;code&gt;install.load.package()&lt;/code&gt; and you can see its specification down below (don&amp;rsquo;t worry if it doesn&amp;rsquo;t make sense to you yet - it is not supposed to at this point). Unfortunately, it can only ever be applied to one package at a time and so we need a workaround to make it work on multiple packages at once. This can be achieved by establishing a vector of all desired package names (&lt;code&gt;package_vec&lt;/code&gt;) and then applying (&lt;code&gt;sapply()&lt;/code&gt;) the &lt;code&gt;install.load.package()&lt;/code&gt; function to every item of the package name vector iteratively as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
    if (!require(x, character.only = TRUE))
        install.packages(x)
    require(x, character.only = TRUE)
}
# packages to load/install if necessary
package_vec &amp;lt;- c(&amp;quot;modeest&amp;quot;)
# applying function install.load.package to all packages specified in
# package_vec
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: modeest
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## modeest 
##    TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why do I prefer this? Firstly, it is way shorter than the basic method when dealing with many packages (which you will get into fast, I promise), reduces the chance for typos by 50% and does not override already installed packages hence speeding up your processing time.&lt;/p&gt;
&lt;h2 id=&#34;loading-the-excel-data-into-r&#34;&gt;Loading the Excel data into &lt;code&gt;R&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Our data is located in the &lt;code&gt;Data&lt;/code&gt; folder and is called &lt;code&gt;DescriptiveData.csv&lt;/code&gt;. Since it is a .csv file, we can simply use the &lt;code&gt;R&lt;/code&gt; in-built function &lt;code&gt;read.csv()&lt;/code&gt; to load the data by combining the former two identifiers into one long string with a backslash separating the two (the backslash indicates a step down in the folder hierarchy). Given this argument, &lt;code&gt;read.csv()&lt;/code&gt; will produce an object of type &lt;code&gt;data.frame&lt;/code&gt; in &lt;code&gt;R&lt;/code&gt; which we want to keep in our environment and hence need to assign a name to. In our case, let that name be &lt;code&gt;Data_df&lt;/code&gt; (I recommend using endings to your data object names that indicate their type for easier coding without constant type checking):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Data_df &amp;lt;- read.csv(&#39;Data/DescriptiveData.csv&#39;) # load data file from Data
# folder if you downloaded the data as a .csv alternatively, read the csv
# directly from the url
Data_df &amp;lt;- read.csv(&amp;quot;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/DescriptiveData.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;whats-contained-within-our-data&#34;&gt;What&amp;rsquo;s contained within our data?&lt;/h2&gt;
&lt;p&gt;Now that our data set is finally loaded into &lt;code&gt;R&lt;/code&gt;, we can finally get to trying to make sense of it. Usually, this shouldn&amp;rsquo;t ever be something one has to do in &lt;code&gt;R&lt;/code&gt; but should be manageable through a project-/data-specific README file (we will cover this in our seminar on hypotheses testing and project planning) but for now we are stuck with pure exploration of our data set. Get your goggles on and let&amp;rsquo;s dive in!&lt;/p&gt;
&lt;p&gt;Firstly, it always pays to asses the basic attributes of any data object (remember the Introduction to &lt;code&gt;R&lt;/code&gt; seminar):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Name&lt;/em&gt; - we know the name (it is &lt;code&gt;Data_df&lt;/code&gt;) since we named it that&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Type&lt;/em&gt; - we already know that it is a &lt;code&gt;data.frame&lt;/code&gt; because we created it using the &lt;code&gt;read.csv&lt;/code&gt; function&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Mode&lt;/em&gt; - this is an interesting one as it means having to subset our data frame&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Dimensions&lt;/em&gt; - a crucial information about how many observations and variables are contained within our data set&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dimensions&#34;&gt;Dimensions&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start with the &lt;em&gt;dimensions&lt;/em&gt; because these will tell us how many &lt;em&gt;modes&lt;/em&gt; (these are object attribute modes and not descriptive parameter modes) to asses:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 87  8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the &lt;code&gt;dim()&lt;/code&gt; function, we arrive at the conclusion that our &lt;code&gt;Data_df&lt;/code&gt; contains 87 rows and 8 columns. Since data frames are usually ordered as observations $\times$ variables, we can conclude that we have 87 observations and 8 variables at our hands.&lt;br&gt;
You can arrive at the same point by using the function &lt;code&gt;View()&lt;/code&gt; in &lt;code&gt;R&lt;/code&gt;. I&amp;rsquo;m not showing this here because it does not translate well to paper and would make whoever chooses to print this waste paper.&lt;/p&gt;
&lt;h3 id=&#34;modes&#34;&gt;Modes&lt;/h3&gt;
&lt;p&gt;Now it&amp;rsquo;s time to get a hang of the &lt;em&gt;modes&lt;/em&gt; of the variable records within our data set. To do so, we have two choices, we can either subset the data frame by columns and apply the &lt;code&gt;class()&lt;/code&gt; function to each column subset or simply apply the &lt;code&gt;str()&lt;/code&gt; function to the data frame object. The reason &lt;code&gt;str()&lt;/code&gt; may be favourable in this case is due to the fact that &lt;code&gt;str()&lt;/code&gt; automatically breaks down the structure of &lt;code&gt;R&lt;/code&gt;-internal objects and hence saves us the sub-setting:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	87 obs. of  8 variables:
##  $ name      : chr  &amp;quot;Luke Skywalker&amp;quot; &amp;quot;C-3PO&amp;quot; &amp;quot;R2-D2&amp;quot; &amp;quot;Darth Vader&amp;quot; ...
##  $ height    : int  172 167 96 202 150 178 165 97 183 182 ...
##  $ mass      : num  77 75 32 136 49 120 75 32 84 77 ...
##  $ hair_color: chr  &amp;quot;blond&amp;quot; &amp;quot;&amp;quot; &amp;quot;&amp;quot; &amp;quot;none&amp;quot; ...
##  $ skin_color: chr  &amp;quot;fair&amp;quot; &amp;quot;gold&amp;quot; &amp;quot;white, blue&amp;quot; &amp;quot;white&amp;quot; ...
##  $ eye_color : chr  &amp;quot;blue&amp;quot; &amp;quot;yellow&amp;quot; &amp;quot;red&amp;quot; &amp;quot;yellow&amp;quot; ...
##  $ birth_year: num  19 112 33 41.9 19 52 47 NA 24 57 ...
##  $ gender    : chr  &amp;quot;male&amp;quot; &amp;quot;&amp;quot; &amp;quot;&amp;quot; &amp;quot;male&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, our data frame knows the 8 variables of name, height, mass, hair_color, skin_color, eye_color, birth_year, gender which range from &lt;code&gt;integer&lt;/code&gt; to &lt;code&gt;numeric&lt;/code&gt; and &lt;code&gt;factor&lt;/code&gt; modes.&lt;/p&gt;
&lt;h3 id=&#34;data-content&#34;&gt;Data Content&lt;/h3&gt;
&lt;p&gt;So what does our data actually tell us? Answering this question usually comes down to some analyses but for now we are only really interested in what kind of information our data frame is storing.&lt;/p&gt;
&lt;p&gt;Again, this would be easiest to asses using a README file or the &lt;code&gt;View()&lt;/code&gt; function in &lt;code&gt;R&lt;/code&gt;. However, for the sake of brevity we can make due with the following to commands which present the user with the first and last five rows of any respective data frame:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             name height mass  hair_color  skin_color eye_color birth_year
## 1 Luke Skywalker    172   77       blond        fair      blue       19.0
## 2          C-3PO    167   75                    gold    yellow      112.0
## 3          R2-D2     96   32             white, blue       red       33.0
## 4    Darth Vader    202  136        none       white    yellow       41.9
## 5    Leia Organa    150   49       brown       light     brown       19.0
## 6      Owen Lars    178  120 brown, grey       light      blue       52.0
##   gender
## 1   male
## 2       
## 3       
## 4   male
## 5 female
## 6   male
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tail(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                name height mass hair_color skin_color eye_color birth_year
## 82             Finn     NA   NA      black       dark      dark         NA
## 83              Rey     NA   NA      brown      light     hazel         NA
## 84      Poe Dameron     NA   NA      brown      light     brown         NA
## 85              BB8     NA   NA       none       none     black         NA
## 86   Captain Phasma     NA   NA    unknown    unknown   unknown         NA
## 87 Padm\xe9 Amidala    165   45      brown      light     brown         46
##    gender
## 82   male
## 83 female
## 84   male
## 85   none
## 86 female
## 87 female
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The avid reader will surely have picked up on the fact that all the records in the &lt;code&gt;name&lt;/code&gt; column of &lt;code&gt;Data_df&lt;/code&gt; belong to characters from the Star Wars universe. In fact, this data set is a modified version of the &lt;code&gt;StarWars&lt;/code&gt; data set supplied by the &lt;code&gt;dplyr&lt;/code&gt; package and contains information of many of the important cast members of the Star Wars movie universe.&lt;/p&gt;
&lt;h2 id=&#34;parameters-of-descriptive-statistics&#34;&gt;Parameters of descriptive statistics&lt;/h2&gt;
&lt;h3 id=&#34;names&#34;&gt;Names&lt;/h3&gt;
&lt;p&gt;As it turns out (and should&amp;rsquo;ve been obvious from the onset if we&amp;rsquo;re honest), every major character in the cinematic Star Wars Universe has a unique name to themselves. Conclusively, the calculation of any parameters of descriptive statistics makes no sense with the names of our characters for the two following reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The name variable is of mode character/factor and only allows for the calculation of the mode&lt;/li&gt;
&lt;li&gt;Since every name only appears once, there is no mode&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As long as the calculation of descriptive parameters of the &lt;code&gt;name&lt;/code&gt; variable of our data set is concerned, Admiral Ackbar said it best: &amp;ldquo;It&amp;rsquo;s a trap&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;height&#34;&gt;Height&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s get started on figuring out some parameters of descriptive statistics for the &lt;code&gt;height&lt;/code&gt; variable of our Star Wars characters.&lt;/p&gt;
&lt;h4 id=&#34;subsetting&#34;&gt;Subsetting&lt;/h4&gt;
&lt;p&gt;First, we need to extract the data in question from our big data frame object. This can be achieved by indexing through the column name as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Height &amp;lt;- Data_df$height
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;location-parameters&#34;&gt;Location Parameters&lt;/h4&gt;
&lt;p&gt;Now, with our &lt;code&gt;Height&lt;/code&gt; vector being the numeric height records of the Star Wars characters in our data set, we are primed to calculate location parameters as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mean &amp;lt;- mean(Height, na.rm = TRUE)
median &amp;lt;- median(Height, na.rm = TRUE)
mode &amp;lt;- mlv(na.omit(Height), method = &amp;quot;mfv&amp;quot;)
min &amp;lt;- min(Height, na.rm = TRUE)
max &amp;lt;- max(Height, na.rm = TRUE)
range &amp;lt;- max - min

# Combining all location parameters into one vector for easier viewing
LocPars_vec &amp;lt;- c(mean, median, mode, min, max, range)
names(LocPars_vec) &amp;lt;- c(&amp;quot;mean&amp;quot;, &amp;quot;median&amp;quot;, &amp;quot;mode&amp;quot;, &amp;quot;minimum&amp;quot;, &amp;quot;maximum&amp;quot;, &amp;quot;range&amp;quot;)
LocPars_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mean  median    mode minimum maximum   range 
## 174.358 180.000 183.000  66.000 264.000 198.000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can clearly see, there is a big range in the heights of our respective Star Wars characters with mean and median being fairly disjunct due to the outliers in height on especially either end.&lt;/p&gt;
&lt;h4 id=&#34;distribution-parameters&#34;&gt;Distribution Parameters&lt;/h4&gt;
&lt;p&gt;Now that we are aware of the location parameters of the Star Wars height records, we can move on to the distribution parameters/parameters of spread. Those can be calculated in &lt;code&gt;R&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;var &amp;lt;- var(Height, na.rm = TRUE)
sd &amp;lt;- sd(Height, na.rm = TRUE)
quantiles &amp;lt;- quantile(Height, na.rm = TRUE)

# Combining all location parameters into one vector for easier viewing
DisPars_vec &amp;lt;- c(var, sd, quantiles)
names(DisPars_vec) &amp;lt;- c(&amp;quot;var&amp;quot;, &amp;quot;sd&amp;quot;, &amp;quot;0%&amp;quot;, &amp;quot;25%&amp;quot;, &amp;quot;50%&amp;quot;, &amp;quot;75%&amp;quot;, &amp;quot;100%&amp;quot;)
DisPars_vec
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        var         sd         0%        25%        50%        75%       100% 
## 1208.98272   34.77043   66.00000  167.00000  180.00000  191.00000  264.00000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how some of the quantiles (actually quartiles in this case) link up with some of the parameters of central tendency.&lt;/p&gt;
&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;
&lt;p&gt;Just to round this off, have a look at what the &lt;code&gt;summary()&lt;/code&gt; function in &lt;code&gt;R&lt;/code&gt; supplies you with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary &amp;lt;- summary(na.omit(Height))
summary
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    66.0   167.0   180.0   174.4   191.0   264.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a nice assortment of location and dispersion parameters.&lt;/p&gt;
&lt;h3 id=&#34;mass&#34;&gt;Mass&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s focus on the weight of our Star Wars characters.&lt;/p&gt;
&lt;h4 id=&#34;subsetting-1&#34;&gt;Subsetting&lt;/h4&gt;
&lt;p&gt;Again, we need to extract our data from the data frame. For the sake of brevity, I will refrain from showing you the rest of the analysis and only present its results to save some space.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Mass &amp;lt;- Data_df$mass
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;location-parameters-1&#34;&gt;Location Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##       mean     median       mode    minimum    maximum      range 
##   97.31186   79.00000   80.00000   15.00000 1358.00000 1343.00000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, there is a huge range in weight records of Star Wars characters and especially the outlier on the upper end (1358kg) push the mean towards the upper end of the weight range and away from the median. We&amp;rsquo;ve got Jabba Desilijic Tiure to thank for that.&lt;/p&gt;
&lt;h4 id=&#34;distribution-parameters-1&#34;&gt;Distribution Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##        var         sd         0%        25%        50%        75%       100% 
## 28715.7300   169.4572    15.0000    55.6000    79.0000    84.5000  1358.0000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, the wide range of weight records also prompts a large variance and standard deviation.&lt;/p&gt;
&lt;h3 id=&#34;hair-color&#34;&gt;Hair Color&lt;/h3&gt;
&lt;p&gt;Hair colour in our data set is saved in column 4 of our data set and so when sub-setting the data frame to obtain information about a characters hair colour, instead of calling on &lt;code&gt;Data_df$hair_color&lt;/code&gt; we can also do so as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HCs &amp;lt;- Data_df[, 4]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, hair colour is not a &lt;code&gt;numeric&lt;/code&gt; variable and much better represent by being of mode &lt;code&gt;factor&lt;/code&gt;. Therefore, we are unable to obtain most parameters of descriptive statistics but we can show a frequency count as follows which allows for the calculation of the mode:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(HCs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## HCs
##                      auburn  auburn, grey auburn, white         black 
##             5             1             1             1            13 
##         blond        blonde         brown   brown, grey          grey 
##             3             1            18             1             1 
##          none       unknown         white 
##            37             1             4
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;eye-colour&#34;&gt;Eye Colour&lt;/h3&gt;
&lt;p&gt;Eye colour is another &lt;code&gt;factor&lt;/code&gt; mode variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ECs &amp;lt;- Data_df$eye_color
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can only calculate the mode by looking for the maximum in our &lt;code&gt;table()&lt;/code&gt; output:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(ECs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ECs
##         black          blue     blue-gray         brown          dark 
##            10            19             1            21             1 
##          gold green, yellow         hazel        orange          pink 
##             1             1             3             8             1 
##           red     red, blue       unknown         white        yellow 
##             5             1             3             1            11
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;birth-year&#34;&gt;Birth Year&lt;/h3&gt;
&lt;h4 id=&#34;subsetting-2&#34;&gt;Subsetting&lt;/h4&gt;
&lt;p&gt;As another &lt;code&gt;numeric&lt;/code&gt; variable, birth year allows for the calculation of the full range of parameters of descriptive statistics:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;BY &amp;lt;- Data_df$birth_year
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Keep in mind that StarWars operates on a different time reference scale than we do.&lt;/p&gt;
&lt;h4 id=&#34;location-parameters-2&#34;&gt;Location Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##      mean    median      mode   minimum   maximum     range 
##  87.56512  52.00000  19.00000   8.00000 896.00000 888.00000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, there is a big disparity here between mean and median which stems from extreme outliers on both ends of the age spectrum (Yoda and Wicket Systri Warrick, respectively).&lt;/p&gt;
&lt;h4 id=&#34;distribution-parameters-2&#34;&gt;Distribution Parameters&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;##        var         sd         0%        25%        50%        75%       100% 
## 23929.4414   154.6914     8.0000    35.0000    52.0000    72.0000   896.0000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unsurprisingly, there is a big variance and standard deviation for the observed birth year/age records.&lt;/p&gt;
&lt;h3 id=&#34;gender&#34;&gt;Gender&lt;/h3&gt;
&lt;p&gt;Gender is another &lt;code&gt;factor&lt;/code&gt; mode variable (obviously):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Gender &amp;lt;- Data_df$gender
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can, again, only judge the mode of our data from the output of the &lt;code&gt;table()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Gender)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Gender
##                      female hermaphrodite          male          none 
##             3            19             1            62             2
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Data Handling and Data Assumptions</title>
      <link>https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/Excursions-into-Biostatistics/Data-Handling-and-Assumptions---Making-the-Most-of-Your-Data.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;exercise&#34;&gt;Exercise&lt;/h2&gt;
&lt;p&gt;First, imagine we have been out and about collecting samples for our sparrow populations. You can find the data came home with after our field work season &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/excursions-into-biostatistics/Data.rar&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;. This data set contains errors/mis-specified data entry and other slip-ups that can happen as a part of data collection exercises. We need to fix that.&lt;/p&gt;
&lt;h3 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h3&gt;
&lt;p&gt;The following three sections are what I consider to be &lt;em&gt;essential&lt;/em&gt; parts of the preamble to any &lt;code&gt;R&lt;/code&gt;-based analysis. I highly recommend clearly indicating these bits in your code.&lt;/p&gt;
&lt;p&gt;More often than not, you will use variations of these code chunks whether you are working on data handling, data exploration or full-fledged statistical analyses.&lt;/p&gt;
&lt;h3 id=&#34;necessary-steps-for-reproducibility&#34;&gt;Necessary Steps For Reproducibility&lt;/h3&gt;
&lt;p&gt;Reproducibility is the be-all and end-all of any statistical analysis, particularly in light of the peer-review process in life sciences.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list = ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep = &amp;quot;/&amp;quot;) # soft-coding our data directory
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you get into highly complex statistical analyses, you may wish to break up chunks of your analysis into separate documents. To ensure that remnants of an earlier analysis or analysis chunk do not influence the results of your current analysis, you may wish to &lt;em&gt;empty&lt;/em&gt; &lt;code&gt;R&lt;/code&gt;&amp;rsquo;s cache (&lt;em&gt;Environment&lt;/em&gt;) before attempting a new analysis. This is achieved via the command &lt;code&gt;rm(list=ls())&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, you &lt;em&gt;need&lt;/em&gt; to remember the importance of &lt;em&gt;soft-coding&lt;/em&gt; for the sake of reproducibility. One of the worst offences to the peer-review process in &lt;code&gt;R&lt;/code&gt;-based statistics is the erroneous hard-coding of the working directory. The &lt;code&gt;getwd()&lt;/code&gt; function shown above solves this exact problem. However, for this workaround to function properly you need to open the code document of interest by double-clicking it within its containing folder.&lt;/p&gt;
&lt;p&gt;When using the &lt;code&gt;xlsx&lt;/code&gt; package or any &lt;em&gt;Excel&lt;/em&gt;-reliant process via &lt;code&gt;R&lt;/code&gt;, your code will automatically run a Java process in the background. By default the Java engine is limited as far as RAM allocation goes and tends to fail when faced with enormous data sets. The workaround &lt;code&gt;options(java.parameters = &amp;quot;-Xmx8g&amp;quot;)&lt;/code&gt; gets rid of this issue by allocation 8 GBs of RAM to Java.&lt;/p&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Packages are &lt;code&gt;R&lt;/code&gt;&amp;rsquo;s way of giving you access to a seemingly infinite repository of functions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x)
  }
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(
  &amp;quot;dplyr&amp;quot; # we need this package to fix the most common data errors
)
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dplyr 
##  TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the above function is way more sophisticated than the usual &lt;code&gt;install.packages()&lt;/code&gt; + &lt;code&gt;library()&lt;/code&gt; approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.&lt;/p&gt;
&lt;h3 id=&#34;loading-the-data&#34;&gt;Loading The Data&lt;/h3&gt;
&lt;p&gt;Loading data is crucial to any analysis in &lt;code&gt;R&lt;/code&gt;. Period.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;R&lt;/code&gt; offers a plethora of approaches to data loading and you will usually be taught the &lt;code&gt;read.table()&lt;/code&gt; command in basic biostatistics courses. However, I have found to prefer the functionality provided by the &lt;code&gt;xlsx&lt;/code&gt; package since most data recording is taking place in Excel. As this package is dependant on the installation of Java and &lt;code&gt;RJava&lt;/code&gt;, we will settle on the base &lt;code&gt;R&lt;/code&gt; function &lt;code&gt;read.csv()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- read.csv(file = paste(Dir.Data, &amp;quot;/SparrowData.csv&amp;quot;, sep = &amp;quot;&amp;quot;), header = TRUE)
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another trick to have up your sleeve (if your RAM enables you to act on it) is to duplicate your initial data onto a new object once loaded into &lt;code&gt;R&lt;/code&gt;. This will enable you to easily remedy mistakes in data treatment without having to reload your initial data set from the data file.&lt;/p&gt;
&lt;h2 id=&#34;inspecting-the-data&#34;&gt;Inspecting The Data&lt;/h2&gt;
&lt;p&gt;Once the data is loaded into &lt;code&gt;R&lt;/code&gt;, you &lt;em&gt;need to inspect&lt;/em&gt; it to make sure it is ready for use.&lt;/p&gt;
&lt;h3 id=&#34;assessing-a-data-frame-in-r&#34;&gt;Assessing A Data Frame in &lt;code&gt;R&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Most, if not all, data you will ever load into &lt;code&gt;R&lt;/code&gt; will be stored as a &lt;code&gt;data.frame&lt;/code&gt; within &lt;code&gt;R&lt;/code&gt;. Some of the most important functions for inspecting data frames (&amp;ldquo;df&amp;rdquo; in the following) in base &lt;code&gt;R&lt;/code&gt; are the following four:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dim(df)&lt;/code&gt; returns the dimensions (Rows x Columns)of the data frame&lt;/li&gt;
&lt;li&gt;&lt;code&gt;head(df)&lt;/code&gt; returns the first 6 rows of the data frame by default (here changed to 4)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tail(df)&lt;/code&gt; returns the last 6 rows of the data frame by default (here changed to 4)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;View(df)&lt;/code&gt; opens nearly any &lt;code&gt;R&lt;/code&gt; object in a separate tab for further inspection. Since we are dealing with an enormous data set here, I will exclude this function for now to save you from printing unnecessary pages.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1068   21
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(Data_df, n = 4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X    Site Index Latitude Longitude     Climate Population.Status Weight Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size
## 1 1 Siberia    SI       60       100 Continental            Native  34,05  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large         16
## 2 2 Siberia    SI       60       100 Continental            Native  34,86  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large         16
## 3 3 Siberia    SI       60       100 Continental            Native  32,34  12.66       6.64  Black Female        Shrub           35.6              1       3.21     C      Large         14
## 4 4 Siberia    SI       60       100 Continental            Native  34,78  15.09       7.00  Brown Female        Shrub          47.75              0         NA     E      Large         10
##   Predator.Presence Predator.Type
## 1               Yes         Avian
## 2               Yes         Avian
## 3               Yes         Avian
## 4               Yes         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tail(Data_df, n = 4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         X           Site Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour  Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size
## 1065 1065 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced  34.25  15.26       7.04   Grey Male                                                           A      Large         19
## 1066 1066 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced  31.76  12.78       6.67   Grey Male                                                           A      Large         19
## 1067 1067 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced  31.48  12.49       6.63  Black Male                                                           C      Large         18
## 1068 1068 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced  31.94  12.96       6.70   Grey Male                                                           A      Large         19
##      Predator.Presence Predator.Type
## 1065               Yes         Avian
## 1066               Yes         Avian
## 1067               Yes         Avian
## 1068               Yes         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When having an initial look at the results of &lt;code&gt;head(Data_df)&lt;/code&gt; and &lt;code&gt;tail(Data_df)&lt;/code&gt; we can spot two important things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NA&lt;/code&gt;s in head and tail of our data set are stored differently. This is a common problem with biological data sets and we will deal with this issue extensively in the next few sections of this document.&lt;/li&gt;
&lt;li&gt;Due to our data loading procedure we ended up with a redundant first column that is simply showing the respective row numbers. However, this is unnecessary in &lt;code&gt;R&lt;/code&gt; and so we can delete this column as seen below.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df[, -1] # eliminating the erroneous first column as it is redundant
dim(Data_df) # checking if the elimination went right
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1068   20
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-summary-function&#34;&gt;The &lt;code&gt;Summary()&lt;/code&gt; Function&lt;/h3&gt;
&lt;p&gt;As already stated in our seminar series, the &lt;code&gt;summary()&lt;/code&gt; function is &lt;em&gt;invaluable&lt;/em&gt; to data exploration and data inspection. However, it is only partially applicable as it will not work flawlessly on every class of data. Examples of this are shown below.&lt;/p&gt;
&lt;p&gt;The weight data contained within our data frame should be numeric and thus pose no issue to the &lt;code&gt;summary()&lt;/code&gt; function. However, as shown in the next section, it is currently of type character which leads the &lt;code&gt;summary()&lt;/code&gt; function to work improperly.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The height data within our data set, on the other hand, is stored correctly as class numeric. Thus the &lt;code&gt;summary()&lt;/code&gt; function performs flawlessly.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.35   13.52   14.52   15.39   16.22  135.40
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Making data inspection more easy, one may which to automate the use of the &lt;code&gt;summary()&lt;/code&gt; function. However, this only makes sense, when every data column is presenting data in the correct class type. Therefore, we will first fix the column classes and then use the &lt;code&gt;summary()&lt;/code&gt; command.&lt;/p&gt;
&lt;h2 id=&#34;data-cleaning-workflow&#34;&gt;Data Cleaning Workflow&lt;/h2&gt;
&lt;h3 id=&#34;identifying-problems&#34;&gt;Identifying Problems&lt;/h3&gt;
&lt;p&gt;Indentifying most problems in any data set you may ever encounter comes down to mostly two manifestations of inadequate data entry or handling:&lt;/p&gt;
&lt;p&gt;**1. Types/Classes  **&lt;br&gt;
Before even opening a data set, we should know what kind of data classes we expect for every variable (for example, height records as a &lt;code&gt;factor&lt;/code&gt; don&amp;rsquo;t make much sense). Problems with data/variable classes can have lasting influence on your analyses and so we need to test the class for each variable (column) individually. Before we alter any column classes, we will first need to identify columns whose classes need fixing. Doing so is as easy applying the &lt;code&gt;class()&lt;/code&gt; function to the data contained within every column of our data frame separately.&lt;br&gt;
&lt;code&gt;R&lt;/code&gt; offers multiple functions for this but I find the &lt;code&gt;lapply()&lt;/code&gt; function to perform flawlessly as shown below. Since &lt;code&gt;lapply()&lt;/code&gt; returns a &lt;code&gt;list&lt;/code&gt; of class identifiers and these don&amp;rsquo;t translate well to paper, I have opted to transform the list into a named character vector using the &lt;code&gt;unlist()&lt;/code&gt; command. One could also use the &lt;code&gt;str()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unlist(lapply(Data_df, class))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Site             Index          Latitude         Longitude           Climate Population.Status            Weight            Height        Wing.Chord            Colour               Sex 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;         &amp;quot;numeric&amp;quot;         &amp;quot;numeric&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;         &amp;quot;numeric&amp;quot;         &amp;quot;numeric&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot; 
##      Nesting.Site    Nesting.Height    Number.of.Eggs        Egg.Weight             Flock        Home.Range        Flock.Size Predator.Presence     Predator.Type 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;         &amp;quot;integer&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For further inspection, one may want to combine the information obtained by using the &lt;code&gt;class()&lt;/code&gt; function with either the &lt;code&gt;summary()&lt;/code&gt; function (for all non-numeric records) or the &lt;code&gt;hist&lt;/code&gt; function (particularly useful for numeric records).&lt;/p&gt;
&lt;p&gt;**2. Contents/Values  **&lt;br&gt;
Typos and the like will always lead to some data that simply doesn&amp;rsquo;t make sense given the context of your project. Sometimes, errors like these are salvageable but doing so can be a very difficult process. Before we alter any column contents, we will first need to identify columns whose contents need fixing, however. Doing so is as easy applying an automated version of &lt;code&gt;summary()&lt;/code&gt; to the data contained within every column of our data frame separately after having fixed possibly erroneous data classes.&lt;/p&gt;
&lt;h3 id=&#34;fixing-the-problems&#34;&gt;Fixing The Problems&lt;/h3&gt;
&lt;p&gt;Fixing the problems in our data sets always comes down to altering data classes, altering faulty values or removing them entirely.&lt;br&gt;
To make sure we fix all problems, we may often wish to enlist the &lt;code&gt;summary()&lt;/code&gt; function as well as the &lt;code&gt;hist()&lt;/code&gt; function for data inspection and visualisation.&lt;/p&gt;
&lt;p&gt;Before we alter any column contents, we will first need to identify columns whose contents need fixing.&lt;/p&gt;
&lt;!-- Doing so is as easy applying an automated version of `summary()` to the data contained within every column of our data frame separately which is now possible since we have fixed the column types.   --&gt;
&lt;!-- The code below does exactly that: --&gt;
&lt;!-- ```{r ColContProblems} --&gt;
&lt;!-- for(i in 1:dim(Data_df)[2]){ --&gt;
&lt;!--   print(colnames(Data_df)[i]) --&gt;
&lt;!--   print(summary(Data_df[,i])) --&gt;
&lt;!--   print(&#34;------------------------------------------------------&#34;) --&gt;
&lt;!-- } --&gt;
&lt;!-- ``` --&gt;
&lt;!-- There are some glaring issues her which we will address in the following sections. --&gt;
&lt;h2 id=&#34;our-data&#34;&gt;Our Data&lt;/h2&gt;
&lt;h3 id=&#34;site&#34;&gt;Site&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (only 11 possible values)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-1&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Site records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;index&#34;&gt;Index&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (only 11 possible values)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-2&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Index records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Index)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Index)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to. Pay attention that thes shortened index numbers lign up with the numbers of site records!&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-1&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;p&gt;\newpage&lt;/p&gt;
&lt;h3 id=&#34;latitude&#34;&gt;Latitude&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (Latitude is inherently continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-3&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Latitude records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Latitude)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Latitude) # use this instead of summary due to station-dependency here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -51.75    -25  -21.1      4   10.5  17.25     31     54     55     60     70 
##     69     88     95    250    114    105     81     68     68     66     64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-2&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;longitude&#34;&gt;Longitude&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (Longitude is inherently continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-4&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Longitude records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Longitude)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Longitude) # use this instead of summary due to station-dependency here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    -97    -92    -90 -88.75    -67 -59.17    -53     -2   55.6    100    135 
##     68     81     64    105    114     69    250     68     95     66     88
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-3&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;climate&#34;&gt;Climate&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: coastal, semi-coastal, continental)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-5&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Climate records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-4&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;population-status&#34;&gt;Population Status&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: native, introduced)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-6&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Population Status records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Population.Status)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Population.Status)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-5&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;weight&#34;&gt;Weight&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (weight is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-7&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Weight records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously, something is wrong.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-6&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;As seen above, weight records are currently stored as character which they shouldn&amp;rsquo;t. So how do we fix this?&lt;/p&gt;
&lt;p&gt;Firstly, let&amp;rsquo;s try an intuitive &lt;code&gt;as.numeric()&lt;/code&gt; approach which attempts to convert all values contained within a vector into numeric records.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(Data_df_base$Weight)
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   26.34   30.38   29.40   31.87  420.00      66
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, this didn&amp;rsquo;t do the trick since weight data values (recorded in g) below 13 and above 40 are highly unlikely for &lt;em&gt;Passer domesticus&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Sometimes, the &lt;code&gt;as.numeric()&lt;/code&gt; can be made more powerful by handing it data of class &lt;code&gt;character&lt;/code&gt;. To do so, simply combine &lt;code&gt;as.numeric()&lt;/code&gt; with &lt;code&gt;as.character()&lt;/code&gt; as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(as.character(Data_df_base$Weight))
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   26.34   30.38   29.40   31.87  420.00      66
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That still didn&amp;rsquo;t resolve our problem. Weight measurements were taken for all study organisms and so there shouldn&amp;rsquo;t be any &lt;code&gt;NA&lt;/code&gt;s and yet we find 66.&lt;/p&gt;
&lt;p&gt;Interestingly enough this is the exact same number as observations available for Siberia. A closer look at the data frame shows us that weight data for Siberia has been recorded with commas as decimal delimiters whilst the rest of the data set utilises dots.&lt;/p&gt;
&lt;p&gt;Fixing this is not necessarily difficult but it is an erroneous issue for data handling which comes up often and is easy to avoid. Getting rid of the flaws is as simple as using the &lt;code&gt;gsub()&lt;/code&gt; function contained within the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(gsub(pattern = &amp;quot;,&amp;quot;, replacement = &amp;quot;.&amp;quot;, x = Data_df_base$Weight))
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   19.38   27.90   30.63   29.69   32.24  420.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is one data record left hat exceeds the biologically viable span for body weight records of &lt;em&gt;Passer domesticus&lt;/em&gt;. This data record holds the value 420. Since this is unlikely to be a simple mistake of placing the decimal delimiter in the wrong place (both 4.2 and 42 grams are also not feasible weight records for house sparrows), we have to delete the weight data record in question:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight[which(Data_df_base$Weight == 420)] &amp;lt;- NA
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   27.89   30.63   29.33   32.23   36.66       1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(Data_df$Weight, breaks = 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;4_Data-Handling-and-Assumptions---Making-the-Most-of-Your-Data_files/figure-html/ColContWeight-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;height&#34;&gt;Height&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (height is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-8&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Height records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.35   13.52   14.52   15.39   16.22  135.40
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, some of our data don&amp;rsquo;t behave the way the should (a 135.4 or  1.35 cm tall sparrow are just absurd).&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-7&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Height (or &amp;ldquo;Length&amp;rdquo;) records of &lt;em&gt;Passer domesticus&lt;/em&gt; should fall roughly between 10cm and 22cm. Looking at the data which exceed these thresholds, it is apparent that these are generated simply through misplaced decimal delimiters. So we fix them as follows and use a histogram to check if it worked.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;lt; 10)] # decimal point placed wrong here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.350 1.446
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;lt; 10)] &amp;lt;- Data_df$Height[which(Data_df$Height &amp;lt; 10)] * 10 # FIXED IT!
Data_df$Height[which(Data_df$Height &amp;gt; 22)] # decimal point placed wrong here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 126.7 135.4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;gt; 22)] &amp;lt;- Data_df$Height[which(Data_df$Height &amp;gt; 22)] / 10 # FIXED IT!
summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   11.09   13.52   14.51   15.20   16.20   21.68
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(Data_df$Height, breaks = 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;4_Data-Handling-and-Assumptions---Making-the-Most-of-Your-Data_files/figure-html/ColContHeight-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;wing-chord&#34;&gt;Wing Chord&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (wing chord is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-9&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Wing Chord records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   6.410   6.840   7.050   7.337   7.400   9.000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-8&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;colour&#34;&gt;Colour&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: black, grey, brown)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-10&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Colour records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some of the colour records are very odd.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-9&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;The colour records &amp;ldquo;Bright black&amp;rdquo; and &amp;ldquo;Grey with black spots&amp;rdquo; should be &amp;ldquo;Grey&amp;rdquo;. Someone clearly got too eager on the assignment of colours here. The fix is as easy as identifying the data records which are &amp;ldquo;too precise&amp;rdquo; and overwrite them with the correct assignment:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Colour[which(Data_df$Colour == &amp;quot;Bright black&amp;quot;)] &amp;lt;- &amp;quot;Grey&amp;quot;
Data_df$Colour[which(Data_df$Colour == &amp;quot;Grey with black spots&amp;quot;)] &amp;lt;- &amp;quot;Grey&amp;quot;
Data_df$Colour &amp;lt;- droplevels(factor(Data_df$Colour)) # drop unused factor levels
summary(Data_df$Colour) # FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Black Brown  Grey 
##   356   298   414
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;sex&#34;&gt;Sex&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: male and female)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-11&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Climate records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-10&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;nesting-site&#34;&gt;Nesting Site&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: shrub and tree)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-12&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Nesting Site records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;fixing-problems-11&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;One individual is recording to be nesting on the ground. This is something house sparrows don&amp;rsquo;t do. Therefore, we have to assume that this individual is not even a &lt;em&gt;Passer domesticus&lt;/em&gt; to begin with.&lt;/p&gt;
&lt;p&gt;The only way to solve this is to remove all observations pertaining to this individual:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df[-which(Data_df$Nesting.Site == &amp;quot;Ground&amp;quot;), ]
summary(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We just deleted a data record. This affects the flock size of the flock it belongs to (basically, this column contains hard-coded values) which we are going to deal with later.&lt;br&gt;
Still, there are manually entered &lt;code&gt;NA&lt;/code&gt; records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The nesting site for a data record where sex reads &amp;ldquo;Male&amp;rdquo; has to be &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Nesting.Site[which(Data_df$Sex == &amp;quot;Male&amp;quot;)] &amp;lt;- NA
Data_df$Nesting.Site &amp;lt;- droplevels(factor(Data_df$Nesting.Site)) # drop unused factor levels
summary(Data_df$Nesting.Site) # FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Shrub  Tree  NA&#39;s 
##   292   231   544
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;nesting-height&#34;&gt;Nesting Height&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (continuous records in two clusters corresponding to shrubs and trees)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-13&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Nesting Height records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are obviously some issues here.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-12&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Nesting height is a clear example of a variable that should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet our data frame currently stores them as character.&lt;/p&gt;
&lt;p&gt;Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Nesting.Height))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   11.78   42.34   64.85  480.59  951.38 1950.86     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly, something went horribly wrong here. When taking a closer look, the number of 1s is artificially inflated. This is due to the &lt;code&gt;NA&lt;/code&gt;s contained within the data set. These are currently stored as characters since they have been entered into the Excel sheet itself. The &lt;code&gt;as.numeric()&lt;/code&gt; function transforms these into 1s.&lt;/p&gt;
&lt;p&gt;One way of circumventing this issue is to combine the &lt;code&gt;as.numeric()&lt;/code&gt; function with the &lt;code&gt;as.character()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Nesting.Height &amp;lt;- as.numeric(as.character(Data_df$Nesting.Height))
summary(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   11.78   42.34   64.85  480.59  951.38 1950.86     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This quite clearly fixed our problems.&lt;/p&gt;
&lt;!-- As can be seen in the histograms below there are now far less erroneously small values. --&gt;
&lt;!-- ```{r plottingpanesNestingHeight, fig.height=2.75} --&gt;
&lt;!-- par(mfrow=c(1,2)) # plotting panes as 1 by 2 --&gt;
&lt;!-- hist(as.numeric(Data_df_base$Nesting.Height), main = &#34;Numeric(Data)&#34;, breaks = 100) --&gt;
&lt;!-- hist(as.numeric(as.character(Data_df_base$Nesting.Height)), main = &#34;Numeric(Character(Data))&#34;, breaks = 100) --&gt;
&lt;!-- ``` --&gt;
&lt;h3 id=&#34;number-of-eggs&#34;&gt;Number of Eggs&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (no a priori knowledge of levels)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-14&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Number of Eggs records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One very out of the ordinary record is to be seen.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-13&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Number of eggs is another variable which should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet is currently stored as character.&lt;/p&gt;
&lt;p&gt;Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Number.of.Eggs))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   2.000   3.000   3.746   4.000  10.000     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, this didn&amp;rsquo;t do the trick. The number of 1s might be inflated and we expect exactly 544 (number of males) &lt;code&gt;NA&lt;/code&gt;s since number of eggs have only been recorded for female house sparrows.&lt;/p&gt;
&lt;p&gt;We already know that improperly stored &lt;code&gt;NA&lt;/code&gt; records are prone to causing an inflation of data records of value 1. We also remember that head and tail of our data frame hold different types of &lt;code&gt;NA&lt;/code&gt; records. Let&amp;rsquo;s find out who entered &lt;code&gt;NA&lt;/code&gt;s correctly:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Site[which(is.na(Data_df$Egg.Weight))])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code above identifies the sites at which proper &lt;code&gt;NA&lt;/code&gt; recording has been done. The Falkland Isle team did it right (&lt;code&gt;NA&lt;/code&gt; fields in Excel were left blank). Fixing this is actually a bit more challenging and so we do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make everything into characters
Data_df$Number.of.Eggs &amp;lt;- as.character(Data_df$Number.of.Eggs)
# writing character NA onto actual NAs
Data_df$Number.of.Eggs[which(is.na(Data_df$Number.of.Eggs))] &amp;lt;- &amp;quot;  NA&amp;quot;
# make all character NAs into proper NAs
Data_df$Number.of.Eggs[Data_df$Number.of.Eggs == &amp;quot;  NA&amp;quot;] &amp;lt;- NA
# make everything numeric
Data_df$Number.of.Eggs &amp;lt;- as.numeric(as.character(Data_df$Number.of.Eggs))
summary(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   2.000   3.000   3.746   4.000  10.000     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We did it!&lt;/p&gt;
&lt;h3 id=&#34;egg-weight&#34;&gt;Egg Weight&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (another weight measurement that needs to be continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-15&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Egg Weight records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;fixing-problems-14&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Egg weight should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet is currently stored as character. Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Egg.Weight))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.580   2.340   2.670   2.619   2.890   3.590     590
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Something is wrong here. Not enough &lt;code&gt;NA&lt;/code&gt;s are recorded. We expect exactly 590 &lt;code&gt;NA&lt;/code&gt;s (Number of males + Number of Females with zero eggs). Additionally, there are way too many 1s.
Our problem, again, lies with the way the &lt;code&gt;NA&lt;/code&gt;s have been entered into the data set from the beginning and so we use the following fix again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make everything into characters
Data_df$Egg.Weight &amp;lt;- as.character(Data_df$Egg.Weight)
# writing character NA onto actual NAs
Data_df$Egg.Weight[which(is.na(Data_df$Egg.Weight))] &amp;lt;- &amp;quot;  NA&amp;quot;
# make all character NAs into proper NAs
Data_df$Egg.Weight[Data_df$Egg.Weight == &amp;quot;  NA&amp;quot;] &amp;lt;- NA
# make everything numeric
Data_df$Egg.Weight &amp;lt;- as.numeric(as.character(Data_df$Egg.Weight))
summary(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.580   2.340   2.670   2.619   2.890   3.590     590
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;flock&#34;&gt;Flock&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (each sparrow was assigned to one particular flock)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-16&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Flock records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Flock)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Flock)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-15&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;home-range&#34;&gt;Home Range&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: small, medium, large)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-17&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Home Range records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Home.Range)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Home.Range)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-16&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;flock-size&#34;&gt;Flock Size&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (continuous measurement of how many sparrows are in each flock - measured as integers)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-18&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Flock Size records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Flock.Size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Flock.Size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    7.00   16.00   19.00   25.81   31.00   58.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-17&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;predator-presence&#34;&gt;Predator Presence&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: yes and no)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-19&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Predator Presence records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-18&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;predator-type&#34;&gt;Predator Type&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: Avian, Non-Avian, and &lt;code&gt;NA&lt;/code&gt;)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-20&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Predator Type records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Something doesn&amp;rsquo;t sit well here.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-19&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Someone got overly eager when recording Predator Type and specified the presence of a hawk instead of taking down &amp;ldquo;Avian&amp;rdquo;. We fix this as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Predator.Type[which(Data_df$Predator.Type == &amp;quot;Hawk&amp;quot;)] &amp;lt;- &amp;quot;Avian&amp;quot;
summary(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This fixed it  but there are still manually entered &lt;code&gt;NA&lt;/code&gt; records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The predator type for a data record where predator presence reads &amp;ldquo;No&amp;rdquo; has to be &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Predator.Type[which(Data_df$Predator.Presence == &amp;quot;No&amp;quot;)] &amp;lt;- NA
Data_df$Predator.Type &amp;lt;- droplevels(factor(Data_df$Predator.Type)) # drop unused factor levels
summary(Data_df$Predator.Type) # FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Avian Non-Avian      NA&#39;s 
##       490       220       357
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;redundant-data&#34;&gt;Redundant Data&lt;/h3&gt;
&lt;p&gt;Our data contains redundant columns (i.e.: columns whose data is present in another column already). These are (1) Flock Size (data contained in Flock column) and (2) Site (data contained in Index column). The fix to this is as easy as removing the columns in question.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- within(Data_df, rm(Flock.Size, Site))
dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1067   18
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fixed it!&lt;/p&gt;
&lt;p&gt;By doing so, we have gotten rid of our flock size problem stemming from the deletion of a data record. You could also argue that the columns &lt;code&gt;Site&lt;/code&gt; and &lt;code&gt;Index&lt;/code&gt; are redundant. We could arguably keep both for quality-of-life when interpreting our results (make use of &lt;code&gt;Sites&lt;/code&gt;) and coding (make use of &lt;code&gt;Index&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;saving-the-fixed-data-set&#34;&gt;Saving The Fixed Data Set&lt;/h2&gt;
&lt;p&gt;We fixed out entire data set! The data set is now ready for use.&lt;/p&gt;
&lt;p&gt;Keep in mind that the data set I provided you with was relatively clean and real-world messy data sets can be far more difficult to clean up.&lt;/p&gt;
&lt;p&gt;Before going forth, we need to save it. &lt;strong&gt;Attention:&lt;/strong&gt; don&amp;rsquo;t overwrite your initial data file!&lt;/p&gt;
&lt;h3 id=&#34;final-check&#34;&gt;Final Check&lt;/h3&gt;
&lt;p&gt;Before exporting you may want to ensure that everything is in order and do a final round of data inspection. This can be achieved by running the automated &lt;code&gt;summary()&lt;/code&gt; command from earlier again as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;for (i in 1:dim(Data_df)[2]) {
  print(colnames(Data_df)[i])
  print(summary(Data_df[, i]))
  print(&amp;quot;------------------------------------------------------&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Index&amp;quot;
##    Length     Class      Mode 
##      1067 character character 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Latitude&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -51.75    4.00   10.50   13.63   31.00   70.00 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Longitude&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -97.00  -88.75  -53.00  -28.47   -2.00  135.00 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Climate&amp;quot;
##    Length     Class      Mode 
##      1067 character character 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Population.Status&amp;quot;
##    Length     Class      Mode 
##      1067 character character 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Weight&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   27.87   30.61   29.32   32.24   36.66       1 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Height&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   11.09   13.52   14.51   15.20   16.20   21.68 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Wing.Chord&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   6.410   6.840   7.050   7.337   7.400   9.000 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Colour&amp;quot;
## Black Brown  Grey 
##   356   298   413 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Sex&amp;quot;
##    Length     Class      Mode 
##      1067 character character 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Nesting.Site&amp;quot;
## Shrub  Tree  NA&#39;s 
##   292   231   544 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Nesting.Height&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   11.78   42.34   64.85  480.59  951.38 1950.86     544 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Number.of.Eggs&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   2.000   3.000   3.746   4.000  10.000     544 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Egg.Weight&amp;quot;
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.580   2.340   2.670   2.619   2.890   3.590     590 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Flock&amp;quot;
##    Length     Class      Mode 
##      1067 character character 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Home.Range&amp;quot;
##    Length     Class      Mode 
##      1067 character character 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Predator.Presence&amp;quot;
##    Length     Class      Mode 
##      1067 character character 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
## [1] &amp;quot;Predator.Type&amp;quot;
##     Avian Non-Avian      NA&#39;s 
##       490       220       357 
## [1] &amp;quot;------------------------------------------------------&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Everything checks out. Let&amp;rsquo;s save our final data frame.&lt;/p&gt;
&lt;h3 id=&#34;exporting-the-altered-data&#34;&gt;Exporting The Altered Data&lt;/h3&gt;
&lt;p&gt;Since Excel is readily available for viewing data outside of R, I like to save my final data set in excel format as can be seen below. Additionally, I recommend saving your final data frame as an RDS file. These are &lt;code&gt;R&lt;/code&gt; specific data files which you will not be able to alter outside of &lt;code&gt;R&lt;/code&gt; thus saving yourself from accidentally changing records when only trying to view your data. On top of that, RDS files take up less space than either Excel or TXT files do.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# saving in excel sheet
write.csv(Data_df, file = paste(Dir.Data, &amp;quot;/SparrowData_FIXED.csv&amp;quot;, sep=&amp;quot;&amp;quot;))
# saving as R data frame object
saveRDS(Data_df, file = paste(Dir.Data, &amp;quot;/SparrowData.rds&amp;quot;, sep=&amp;quot;&amp;quot;)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sessioninfo&#34;&gt;SessionInfo&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessionInfo()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.3 (2023-03-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur ... 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] dplyr_1.1.0
## 
## loaded via a namespace (and not attached):
##  [1] bslib_0.4.2       compiler_4.2.3    pillar_1.8.1      jquerylib_0.1.4   highr_0.10        R.methodsS3_1.8.2 R.utils_2.12.2    tools_4.2.3       digest_0.6.31     jsonlite_1.8.4   
## [11] evaluate_0.20     lifecycle_1.0.3   tibble_3.2.0      R.cache_0.16.0    pkgconfig_2.0.3   rlang_1.0.6       cli_3.6.0         rstudioapi_0.14   yaml_2.3.7        blogdown_1.16    
## [21] xfun_0.37         fastmap_1.1.1     styler_1.9.1      knitr_1.42        generics_0.1.3    vctrs_0.5.2       sass_0.4.5        tidyselect_1.2.0  glue_1.6.2        R6_2.5.1         
## [31] fansi_1.0.4       rmarkdown_2.20    bookdown_0.33     purrr_1.0.1       magrittr_2.0.3    htmltools_0.5.4   utf8_1.2.3        cachem_1.0.7      R.oo_1.25.0
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Data Visualisation</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/data-visualisation/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/data-visualisation/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are the solutions to the exercises contained within the handout to Data Visualisation which walks you through the basics of data visualisation in &lt;code&gt;R&lt;/code&gt;using &lt;code&gt;ggplot2&lt;/code&gt;. The plots presented here are using data from the &lt;code&gt;iris&lt;/code&gt; data set supplied through the &lt;code&gt;datasets&lt;/code&gt; package. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/05---Data-Visualisation_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;This practical makes use of R-internal data so you don&amp;rsquo;t need to download anything extra today.&lt;/p&gt;
&lt;h2 id=&#34;packages&#34;&gt;Packages&lt;/h2&gt;
&lt;p&gt;Recall the exercise that went along with the last seminar (Descriptive Statistics) where we learnt the difference between a basic and advanced preamble for package loading in &lt;code&gt;R&lt;/code&gt;. Here (and in future exercises) I will only supply you with the advanced version of the preamble.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s load the &lt;code&gt;ggplot2&lt;/code&gt; package into our &lt;code&gt;R&lt;/code&gt; session so we&amp;rsquo;ll be able to use its functionality for data visualisation as well as the &lt;code&gt;datasets&lt;/code&gt; package to get the &lt;code&gt;iris&lt;/code&gt; data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
# packages to load/install if necessary
package_vec &amp;lt;- c(&amp;quot;ggplot2&amp;quot;, &amp;quot;datasets&amp;quot;)
# applying function install.load.package to all packages specified in package_vec
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  ggplot2 datasets 
##     TRUE     TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;loading-r-internal-data-sets-iris&#34;&gt;Loading &lt;code&gt;R&lt;/code&gt;-internal data sets (&lt;code&gt;iris&lt;/code&gt;)&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;iris&lt;/code&gt; data set is included in the &lt;code&gt;datasets&lt;/code&gt; package in &lt;code&gt;R&lt;/code&gt;. An &lt;code&gt;R&lt;/code&gt;-internal data set is loaded through the command &lt;code&gt;data()&lt;/code&gt;. Take note that you do not have to assign this command&amp;rsquo;s output to a new object (via &lt;code&gt;&amp;lt;-&lt;/code&gt;). Instead, the dataset is loaded to your current environment by its name (iris, in this case). Keep in mind that this &lt;strong&gt;can override&lt;/strong&gt; objects of the same name that are already present in your current session of &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(&amp;quot;iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;inspect-the-data-set&#34;&gt;Inspect the data set&lt;/h2&gt;
&lt;p&gt;Since we know that &lt;code&gt;iris&lt;/code&gt; is a dataset, we can be reasonably sure that this object will be complex enough to warrant using the &lt;code&gt;str()&lt;/code&gt; function for inspection:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(iris)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &amp;quot;setosa&amp;quot;,&amp;quot;versicolor&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;iris&lt;/code&gt; dataset contains four measurements (&lt;code&gt;Sepal.Length&lt;/code&gt;, &lt;code&gt;Sepal.Width&lt;/code&gt;, &lt;code&gt;Petal.Length&lt;/code&gt;, &lt;code&gt;Petal.Width&lt;/code&gt;) for 150 flowers representing three species of iris (&lt;em&gt;Iris setosa&lt;/em&gt;, &lt;em&gt;versicolor&lt;/em&gt; and &lt;em&gt;virginica&lt;/em&gt;).&lt;/p&gt;
&lt;h2 id=&#34;boxplot-of-petallength-by-species&#34;&gt;&lt;strong&gt;Boxplot&lt;/strong&gt; of &lt;code&gt;Petal.Length&lt;/code&gt; by &lt;code&gt;Species&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Species, y=Petal.Length) # aesthetics
       ) + geom_boxplot() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Length of three different species of Iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise1-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;THis boxplot shows us exactly how the distributions of petal length measurements of our three species of Iris are differing from one another. Despite the obvious trend in the data, &lt;strong&gt;be sure not to report results through figures alone!&lt;/strong&gt; We will find out how to test whether the pattern we can observe here holds up to scrutiny at a later point in time of our seminars.&lt;/p&gt;
&lt;h2 id=&#34;scatterplot-of-petallength-and-petalwidth&#34;&gt;&lt;strong&gt;Scatterplot&lt;/strong&gt; of &lt;code&gt;Petal.Length&lt;/code&gt; and &lt;code&gt;Petal.Width&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Petal.Width, y=Petal.Length) # aesthetics
       ) + geom_point() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;scatterplot-of-petallength-and-petalwidth-grouped-by-species&#34;&gt;&lt;strong&gt;Scatterplot&lt;/strong&gt; of &lt;code&gt;Petal.Length&lt;/code&gt; and &lt;code&gt;Petal.Width&lt;/code&gt; grouped by &lt;code&gt;Species&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Petal.Width, y=Petal.Length, colour = Species) # aesthetics
       ) + geom_point() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;) + 
  theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside
  scale_color_discrete(name=&amp;quot;Iris Species&amp;quot;)  # Change legend title
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise3-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;relationship-of-sepallength-and-sepalwidth&#34;&gt;Relationship of &lt;code&gt;Sepal.Length&lt;/code&gt; and &lt;code&gt;Sepal.Width&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Sepal.Width, y=Sepal.Length) # aesthetics
       ) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;relationship-of-sepallength-and-sepalwidth-grouped-by-species&#34;&gt;Relationship of &lt;code&gt;Sepal.Length&lt;/code&gt; and &lt;code&gt;Sepal.Width&lt;/code&gt; (grouped by &lt;code&gt;Species&lt;/code&gt;)&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Sepal.Width, y=Sepal.Length, colour = Species) # aesthetics
       ) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;) + 
  theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside
  scale_color_discrete(name=&amp;quot;Iris Species&amp;quot;)  # Change legend title
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise5-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Visualisation</title>
      <link>https://www.erikkusch.com/courses/biostat101/data-visualisation/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/data-visualisation/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are the solutions to the exercises contained within the handout to Data Visualisation which walks you through the basics of data visualisation in &lt;code&gt;R&lt;/code&gt; using &lt;code&gt;ggplot2&lt;/code&gt;. The plots presented here are using data from the &lt;code&gt;iris&lt;/code&gt; data set supplied through the &lt;code&gt;datasets&lt;/code&gt; package. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions. I have prepared some slides for this session: &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/05---Data-Visualisation_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/05---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;This practical makes use of R-internal data so you don&amp;rsquo;t need to download anything extra today.&lt;/p&gt;
&lt;h2 id=&#34;packages&#34;&gt;Packages&lt;/h2&gt;
&lt;p&gt;Recall the exercise that went along with the last seminar (Descriptive Statistics) where we learnt the difference between a basic and advanced preamble for package loading in &lt;code&gt;R&lt;/code&gt;. Here (and in future exercises) I will only supply you with the advanced version of the preamble.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s load the &lt;code&gt;ggplot2&lt;/code&gt; package into our &lt;code&gt;R&lt;/code&gt; session so we&amp;rsquo;ll be able to use its functionality for data visualisation as well as the &lt;code&gt;datasets&lt;/code&gt; package to get the &lt;code&gt;iris&lt;/code&gt; data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
# packages to load/install if necessary
package_vec &amp;lt;- c(&amp;quot;ggplot2&amp;quot;, &amp;quot;datasets&amp;quot;)
# applying function install.load.package to all packages specified in package_vec
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  ggplot2 datasets 
##     TRUE     TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;loading-r-internal-data-sets-iris&#34;&gt;Loading &lt;code&gt;R&lt;/code&gt;-internal data sets (&lt;code&gt;iris&lt;/code&gt;)&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;iris&lt;/code&gt; data set is included in the &lt;code&gt;datasets&lt;/code&gt; package in &lt;code&gt;R&lt;/code&gt;. An &lt;code&gt;R&lt;/code&gt;-internal data set is loaded through the command &lt;code&gt;data()&lt;/code&gt;. Take note that you do not have to assign this command&amp;rsquo;s output to a new object (via &lt;code&gt;&amp;lt;-&lt;/code&gt;). Instead, the dataset is loaded to your current environment by its name (iris, in this case). Keep in mind that this &lt;strong&gt;can override&lt;/strong&gt; objects of the same name that are already present in your current session of &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(&amp;quot;iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;inspect-the-data-set&#34;&gt;Inspect the data set&lt;/h2&gt;
&lt;p&gt;Since we know that &lt;code&gt;iris&lt;/code&gt; is a dataset, we can be reasonably sure that this object will be complex enough to warrant using the &lt;code&gt;str()&lt;/code&gt; function for inspection:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(iris)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &amp;quot;setosa&amp;quot;,&amp;quot;versicolor&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;iris&lt;/code&gt; dataset contains four measurements (&lt;code&gt;Sepal.Length&lt;/code&gt;, &lt;code&gt;Sepal.Width&lt;/code&gt;, &lt;code&gt;Petal.Length&lt;/code&gt;, &lt;code&gt;Petal.Width&lt;/code&gt;) for 150 flowers representing three species of iris (&lt;em&gt;Iris setosa&lt;/em&gt;, &lt;em&gt;versicolor&lt;/em&gt; and &lt;em&gt;virginica&lt;/em&gt;).&lt;/p&gt;
&lt;h2 id=&#34;boxplot-of-petallength-by-species&#34;&gt;&lt;strong&gt;Boxplot&lt;/strong&gt; of &lt;code&gt;Petal.Length&lt;/code&gt; by &lt;code&gt;Species&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Species, y=Petal.Length) # aesthetics
       ) + geom_boxplot() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Length of three different species of Iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise1-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;THis boxplot shows us exactly how the distributions of petal length measurements of our three species of Iris are differing from one another. Despite the obvious trend in the data, &lt;strong&gt;be sure not to report results through figures alone!&lt;/strong&gt; We will find out how to test whether the pattern we can observe here holds up to scrutiny at a later point in time of our seminars.&lt;/p&gt;
&lt;h2 id=&#34;scatterplot-of-petallength-and-petalwidth&#34;&gt;&lt;strong&gt;Scatterplot&lt;/strong&gt; of &lt;code&gt;Petal.Length&lt;/code&gt; and &lt;code&gt;Petal.Width&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Petal.Width, y=Petal.Length) # aesthetics
       ) + geom_point() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;scatterplot-of-petallength-and-petalwidth-grouped-by-species&#34;&gt;&lt;strong&gt;Scatterplot&lt;/strong&gt; of &lt;code&gt;Petal.Length&lt;/code&gt; and &lt;code&gt;Petal.Width&lt;/code&gt; grouped by &lt;code&gt;Species&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Petal.Width, y=Petal.Length, colour = Species) # aesthetics
       ) + geom_point() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;) + 
  theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside
  scale_color_discrete(name=&amp;quot;Iris Species&amp;quot;)  # Change legend title
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise3-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;relationship-of-sepallength-and-sepalwidth&#34;&gt;Relationship of &lt;code&gt;Sepal.Length&lt;/code&gt; and &lt;code&gt;Sepal.Width&lt;/code&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Sepal.Width, y=Sepal.Length) # aesthetics
       ) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;relationship-of-sepallength-and-sepalwidth-grouped-by-species&#34;&gt;Relationship of &lt;code&gt;Sepal.Length&lt;/code&gt; and &lt;code&gt;Sepal.Width&lt;/code&gt; (grouped by &lt;code&gt;Species&lt;/code&gt;)&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(iris, # the data set
       aes(x=Sepal.Width, y=Sepal.Length, colour = Species) # aesthetics
       ) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot
  theme_bw() + labs(title=&amp;quot;Petal Width and Petal Length of three different species of Iris&amp;quot;) + 
  theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside
  scale_color_discrete(name=&amp;quot;Iris Species&amp;quot;)  # Change legend title
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;05---Data-Visualisation_files/figure-html/PlottingExercise5-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Classifications</title>
      <link>https://www.erikkusch.com/courses/excursions-into-biostatistics/classifications-order-from-chaos/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/excursions-into-biostatistics/classifications-order-from-chaos/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/Excursions-into-Biostatistics/Classifications---Order-from-Chaos.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;our-resarch-project&#34;&gt;Our Resarch Project&lt;/h2&gt;
&lt;p&gt;Today, we are looking at a big (and entirely fictional) data base of the common house sparrow (&lt;em&gt;Passer domesticus&lt;/em&gt;). In particular, we are interested in the &lt;strong&gt;Evolution of &lt;em&gt;Passer domesticus&lt;/em&gt; in Response to Climate Change&lt;/strong&gt; which was previously explained &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;I have created a large data set for this exercise which is available &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/excursions-into-biostatistics/Data.rar&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt; and we previously cleaned up so that is now usable &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;reading-the-data-into-r&#34;&gt;Reading the Data into &lt;code&gt;R&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start by reading the data into &lt;code&gt;R&lt;/code&gt; and taking an initial look at it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sparrows_df &amp;lt;- readRDS(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))
head(Sparrows_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Index Latitude Longitude     Climate Population.Status Weight Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type
## 1    SI       60       100 Continental            Native  34.05  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 2    SI       60       100 Continental            Native  34.86  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 3    SI       60       100 Continental            Native  32.34  12.66       6.64  Black Female        Shrub          35.60              1       3.21     C      Large               Yes         Avian
## 4    SI       60       100 Continental            Native  34.78  15.09       7.00  Brown Female        Shrub          47.75              0         NA     E      Large               Yes         Avian
## 5    SI       60       100 Continental            Native  35.01  13.82       6.81   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 6    SI       60       100 Continental            Native  32.36  12.67       6.64  Brown Female        Shrub          32.47              1       3.17     E      Large               Yes         Avian
##       TAvg      TSD
## 1 269.9596 15.71819
## 2 269.9596 15.71819
## 3 269.9596 15.71819
## 4 269.9596 15.71819
## 5 269.9596 15.71819
## 6 269.9596 15.71819
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;hypotheses&#34;&gt;Hypotheses&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s remember our hypotheses:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Sparrow Morphology&lt;/strong&gt; is determined by:&lt;br&gt;
A. &lt;em&gt;Climate Conditions&lt;/em&gt; with sparrows in stable, warm environments fairing better than those in colder, less stable ones.&lt;br&gt;
B. &lt;em&gt;Competition&lt;/em&gt; with sparrows in small flocks doing better than those in big flocks.&lt;br&gt;
C. &lt;em&gt;Predation&lt;/em&gt; with sparrows under pressure of predation doing worse than those without.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sites&lt;/strong&gt;  accurately represent &lt;strong&gt;sparrow morphology&lt;/strong&gt;. This may mean:&lt;br&gt;
A. &lt;em&gt;Population status&lt;/em&gt; as inferred through morphology.&lt;br&gt;
B. &lt;em&gt;Site index&lt;/em&gt; as inferred through morphology.&lt;br&gt;
C. &lt;em&gt;Climate&lt;/em&gt; as inferred through morphology.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Quite obviously, &lt;strong&gt;hypothesis 2&lt;/strong&gt; is the only one lending itself well to classification exercises. In fact, what we want to answer is the question: &lt;em&gt;&amp;ldquo;Can we successfully classify populations at different sites according to their morphological expressions?&amp;quot;&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;r-environment&#34;&gt;&lt;code&gt;R&lt;/code&gt; Environment&lt;/h2&gt;
&lt;p&gt;For this exercise, we will need the following packages:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;)
  }
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(
  &amp;quot;ggplot2&amp;quot;, # for visualisation
  &amp;quot;mclust&amp;quot;, # for k-means clustering,
  &amp;quot;vegan&amp;quot;, # for distance matrices in hierarchical clustering
  &amp;quot;rpart&amp;quot;, # for decision trees
  &amp;quot;rpart.plot&amp;quot;, # for plotting decision trees
  &amp;quot;randomForest&amp;quot;, # for randomForest classifier
  &amp;quot;car&amp;quot;, # check multicollinearity
  &amp;quot;MASS&amp;quot; # for ordinal logistic regression
)
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      ggplot2       mclust        vegan        rpart   rpart.plot randomForest          car         MASS 
##         TRUE         TRUE         TRUE         TRUE         TRUE         TRUE         TRUE         TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the above function is way more sophisticated than the usual &lt;code&gt;install.packages()&lt;/code&gt; &amp;amp; &lt;code&gt;library()&lt;/code&gt; approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.&lt;/p&gt;
&lt;h2 id=&#34;logistic-regression&#34;&gt;Logistic Regression&lt;/h2&gt;
&lt;p&gt;Remember the &lt;strong&gt;Assumptions of Logistic Regression&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Absence of influential outliers&lt;/li&gt;
&lt;li&gt;Absence of multi-collinearity&lt;/li&gt;
&lt;li&gt;Predictor Variables and log odds are related in a linear fashion&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;binary-logistic-regression&#34;&gt;Binary Logistic Regression&lt;/h3&gt;
&lt;p&gt;Binary Logistic regression only accommodates binary outcomes. This leaves only one of our hypotheses open for investigation - &lt;strong&gt;2.A.&lt;/strong&gt; &lt;em&gt;Population Status&lt;/em&gt; - since this is the only response variable boasting two levels.&lt;/p&gt;
&lt;p&gt;To reduce the effect of as many confounding variables as possible, I reduce the data set to just those observations belonging to our station in Siberia and Manitoba. Both are located at very similar latitudes. They really only differ in their climate condition and the population status:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;LogReg_df &amp;lt;- Sparrows_df[Sparrows_df$Index == &amp;quot;MA&amp;quot; | Sparrows_df$Index == &amp;quot;SI&amp;quot;, c(&amp;quot;Population.Status&amp;quot;, &amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;)]
LogReg_df$PS &amp;lt;- as.numeric(LogReg_df$Population.Status) - 1 # make climate numeric for model
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;initial-model--collinearity&#34;&gt;Initial Model &amp;amp; Collinearity&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start with the biggest model we can build here and then assess if our assumptions are met:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_LogReg_mod &amp;lt;- glm(PS ~ Weight + Height + Wing.Chord,
  data = LogReg_df,
  family = binomial(link = &amp;quot;logit&amp;quot;),
)
summary(H2_LogReg_mod)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = PS ~ Weight + Height + Wing.Chord, family = binomial(link = &amp;quot;logit&amp;quot;), 
##     data = LogReg_df)
## 
## Deviance Residuals: 
##        Min          1Q      Median          3Q         Max  
## -2.657e-05  -2.110e-08  -2.110e-08   2.110e-08   2.855e-05  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&amp;gt;|z|)
## (Intercept)  1.557e+03  3.312e+07   0.000    1.000
## Weight       7.242e+01  3.735e+04   0.002    0.998
## Height       2.153e+01  1.061e+06   0.000    1.000
## Wing.Chord  -6.247e+02  6.928e+06   0.000    1.000
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1.8437e+02  on 132  degrees of freedom
## Residual deviance: 6.8926e-09  on 129  degrees of freedom
## AIC: 8
## 
## Number of Fisher Scoring iterations: 25
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well&amp;hellip; nothing here is significant. Let&amp;rsquo;s see what the culprit might be. With morphological traits, you are often looking at a whole set of collinearity, so let&amp;rsquo;s start by investigating that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vif(H2_LogReg_mod)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Weight      Height  Wing.Chord 
##    9.409985 6550.394451 6342.683550
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A Variance Inflation Factor (VIF) value of $\geq5-10$ is seen as identifying problematic collinearity. Quite obviously, this is the case. We need to throw away some predictors. I only want to keep &lt;code&gt;Weight&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;weight-model-and-further-assumptions&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; Model and Further Assumptions&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s run a simplified model that just used &lt;code&gt;Weight&lt;/code&gt; as a predictor:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_LogReg_mod &amp;lt;- glm(PS ~ Weight,
  data = LogReg_df,
  family = binomial(link = &amp;quot;logit&amp;quot;)
)
summary(H2_LogReg_mod)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = PS ~ Weight, family = binomial(link = &amp;quot;logit&amp;quot;), 
##     data = LogReg_df)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1980  -0.5331  -0.1235   0.5419   1.9067  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept) -46.3244     7.8319  -5.915 3.32e-09 ***
## Weight        1.4052     0.2374   5.920 3.23e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 184.37  on 132  degrees of freedom
## Residual deviance: 105.08  on 131  degrees of freedom
## AIC: 109.08
## 
## Number of Fisher Scoring iterations: 5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A significant effect, huzzah! We still need to test for our assumptions, however. Checking for &lt;strong&gt;multicollinearity&lt;/strong&gt; makes no sense since we only use one predictor, so we can skip that.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Linear Relationship&lt;/strong&gt; between predictor(s) and log-odds of the output can be assessed as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;probabilities &amp;lt;- predict(H2_LogReg_mod, type = &amp;quot;response&amp;quot;) # predict model response on original data
LogReg_df$Probs &amp;lt;- probabilities # safe probabilities to data frame
LogReg_df$LogOdds &amp;lt;- log(probabilities / (1 - probabilities)) # calculate log-odds
## Plot Log-Odds vs. Predictor
ggplot(data = LogReg_df, aes(x = Weight, y = LogOdds)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = TRUE) +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That is clearly linear relationship!&lt;/p&gt;
&lt;p&gt;Moving on to our final assumption, we want to assess whether there are influential &lt;strong&gt;Outliers&lt;/strong&gt;. For this, we want to look at the &lt;em&gt;Cook&amp;rsquo;s distance&lt;/em&gt; as well as the &lt;em&gt;standardised residuals&lt;/em&gt; per observation:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Cook&#39;s distance
plot(H2_LogReg_mod, which = 4, id.n = 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Standardises Residuals
Outlier_df &amp;lt;- data.frame(
  Residuals = resid(H2_LogReg_mod),
  Index = 1:nrow(LogReg_df),
  Outcome = factor(LogReg_df$PS)
)
Outlier_df$Std.Resid &amp;lt;- scale(Outlier_df$Residuals)
# Plot Residuals
ggplot(Outlier_df, aes(Outcome, Std.Resid)) +
  geom_boxplot() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;1440&#34; /&gt;
Both of these plots do not highlight any worrying influential outliers. An influential outliers would manifest with a prominent standardises residual ($|Std.Resid|\sim3$)/Cook&amp;rsquo;s distance.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s finally plot what the model predicts:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = LogReg_df, aes(x = Weight, y = LogReg_df$PS)) +
  geom_point() +
  theme_bw() +
  geom_smooth(
    data = LogReg_df, aes(x = Weight, y = Probs),
    method = &amp;quot;glm&amp;quot;,
    method.args = list(family = &amp;quot;binomial&amp;quot;),
    se = TRUE
  ) +
  labs(y = &amp;quot;Introduced Population&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;ordinal-logistic-regression&#34;&gt;Ordinal Logistic Regression&lt;/h3&gt;
&lt;p&gt;Ordinal Logistic regression allows for multiple levels of the response variable so long as they are on an ordinal scale. Here, we could test all of our above hypotheses. However, I&amp;rsquo;d like to stick with &lt;strong&gt;2.C.&lt;/strong&gt; &lt;em&gt;Climate&lt;/em&gt; for this example.&lt;/p&gt;
&lt;p&gt;Again, to reduce the effect of as many confounding variables as possible, I reduce the data set to just those observations belonging to our station in Siberia, Manitoba, and also the United Kingdom this time. All three are located at very similar latitudes. They really only differ in their climate condition and the population status:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;LogReg_df &amp;lt;- Sparrows_df[Sparrows_df$Index == &amp;quot;UK&amp;quot; | Sparrows_df$Index == &amp;quot;MA&amp;quot; | Sparrows_df$Index == &amp;quot;SI&amp;quot;, c(&amp;quot;Climate&amp;quot;, &amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;)]
LogReg_df$CL &amp;lt;- factor(as.numeric(LogReg_df$Climate) - 1) # make climate factored numeric for model
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;initial-model--collinearity-1&#34;&gt;Initial Model &amp;amp; Collinearity&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start with the biggest model we can build here and then assess if our assumptions are met:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_LogReg_mod &amp;lt;- polr(CL ~ Weight + Height + Wing.Chord,
  data = LogReg_df,
  Hess = TRUE
)
summary_table &amp;lt;- coef(summary(H2_LogReg_mod))
pval &amp;lt;- pnorm(abs(summary_table[, &amp;quot;t value&amp;quot;]), lower.tail = FALSE) * 2
summary_table &amp;lt;- cbind(summary_table, &amp;quot;p value&amp;quot; = round(pval, 6))
summary_table
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   Value Std. Error      t value p value
## Weight       -0.4595719 0.09750018    -4.713549   2e-06
## Height       25.0808034 0.19522606   128.470573   0e+00
## Wing.Chord -164.1103857 0.51246129  -320.239573   0e+00
## 0|1        -788.2133893 0.11008589 -7159.985419   0e+00
## 1|2        -786.8019284 0.18747890 -4196.749302   0e+00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well&amp;hellip; a lot here is significant. We identified &lt;strong&gt;multicollinearity&lt;/strong&gt; as a problem earlier. Let&amp;rsquo;s investigate that again:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vif(H2_LogReg_mod)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Weight     Height Wing.Chord 
##   431.6796   294.6353   536.5452
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Horrible!. A Variance Inflation Factor (VIF) value of $\geq5-10$ is seen as identifying problematic collinearity. Quite obviously, this is the case. We need to throw away some predictors. I only want to keep &lt;code&gt;Weight&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;weight-model-and-further-assumptions-1&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; Model and Further Assumptions&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s run a simplified model that just used &lt;code&gt;Weight&lt;/code&gt; as a predictor:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_LogReg_mod &amp;lt;- polr(CL ~ Weight,
  data = LogReg_df,
  Hess = TRUE
)
summary_table &amp;lt;- coef(summary(H2_LogReg_mod))
pval &amp;lt;- pnorm(abs(summary_table[, &amp;quot;t value&amp;quot;]), lower.tail = FALSE) * 2
summary_table &amp;lt;- cbind(summary_table, &amp;quot;p value&amp;quot; = round(pval, 6))
summary_table
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               Value Std. Error      t value  p value
## Weight -0.020768177  0.0761669 -0.272666718 0.785109
## 0|1    -1.354848455  2.5131706 -0.539099272 0.589818
## 1|2     0.009549511  2.5112093  0.003802754 0.996966
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well&amp;hellip; this model doesn&amp;rsquo;t help us at all in understanding climate through morphology of our sparrows. Let&amp;rsquo;s abandon this and move on to classification methods which are much better suited to this task.&lt;/p&gt;
&lt;h2 id=&#34;k-means-clustering&#34;&gt;K-Means Clustering&lt;/h2&gt;
&lt;p&gt;K-Means clustering is incredibly potent in identifying a number of appropriate clusters, their attributes, and sort observations into appropriate clusters.&lt;/p&gt;
&lt;h3 id=&#34;population-status-classifier&#34;&gt;Population Status Classifier&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start with understanding population status through morphological traits:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Population.Status&amp;quot;)]
H2_PS_mclust &amp;lt;- Mclust(Morph_df[-4], G = length(unique(Morph_df[, 4])))
plot(H2_PS_mclust, what = &amp;quot;uncertainty&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we can see, K-means clustering is able to really neatly identify two groups in our data. But do they actually belong do the right groups of &lt;code&gt;Population.Status&lt;/code&gt;? We&amp;rsquo;ll find out in &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/&#34; target=&#34;_blank&#34;&gt; Model Selection and Validation&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;site-classifier&#34;&gt;Site Classifier&lt;/h3&gt;
&lt;p&gt;On to our site index classification. Running the k-means clustering algorithm returns:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Index&amp;quot;)]
H2_Index_mclust &amp;lt;- Mclust(Morph_df[-4], G = length(unique(Morph_df[, 4])))
plot(H2_Index_mclust, what = &amp;quot;uncertainty&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s a pretty bad classification. I would not place trust in these clusters seeing how much they overlap.&lt;/p&gt;
&lt;h3 id=&#34;climate-classifier&#34;&gt;Climate Classifier&lt;/h3&gt;
&lt;p&gt;Lastly, turning to our climate classification using k-means classification:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Climate&amp;quot;)]
H2_Climate_mclust &amp;lt;- Mclust(Morph_df[-4], G = length(unique(Morph_df[, 4])))
plot(H2_Climate_mclust, what = &amp;quot;uncertainty&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;1440&#34; /&gt;
These clusters are decent although there is quite a bit of overlap between the blue and red cluster.&lt;/p&gt;
&lt;h3 id=&#34;optimal-model&#34;&gt;Optimal Model&lt;/h3&gt;
&lt;p&gt;K-means clustering is also able to identify the most &amp;ldquo;appropriate&amp;rdquo; number of clusters given the data and uncertainty of classification:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;)]
dataBIC &amp;lt;- mclustBIC(Morph_df)
summary(dataBIC) # show summary of top-ranking models
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Best BIC values:
##             VVV,7     EVV,7     EVV,8
## BIC      63.39237 -304.1895 -336.0531
## BIC diff  0.00000 -367.5819 -399.4455
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(dataBIC)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;G &amp;lt;- as.numeric(strsplit(names(summary(dataBIC))[1], &amp;quot;,&amp;quot;)[[1]][2])
H2_Opt_mclust &amp;lt;- Mclust(Morph_df, # data for the cluster model
  G = G # BIC index for model to be built
)
H2_Opt_mclust[[&amp;quot;parameters&amp;quot;]][[&amp;quot;mean&amp;quot;]] # mean values of clusters
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 [,1]      [,2]     [,3]      [,4]      [,5]      [,6]      [,7]
## Weight     34.830000 32.677280 33.63023 31.354892 30.146417 22.585240 22.796014
## Height     13.641765 13.570427 14.20721 14.317070 14.085826 18.847550 19.036621
## Wing.Chord  6.787059  6.780954  6.99186  7.044881  6.965047  8.576106  8.609035
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(H2_Opt_mclust, what = &amp;quot;uncertainty&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-17-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here, K-means clustering would have us settle on 7 clusters. That does not coincide with anything we could really test for at this point. COnclusively, this model goes into the category of &amp;ldquo;Nice to have, but ultimately useless here&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;summary-of-k-means-clustering&#34;&gt;Summary of K-Means Clustering&lt;/h3&gt;
&lt;p&gt;So what do we take from this? Well&amp;hellip; Population status was well explained all morphological traits and so would in turn also do a good job of being a proxy for the other when doing mixed regression models, for example. Hence, we might want to include this variable in future &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/regressions-correlations-for-the-advanced/&#34; target=&#34;_blank&#34;&gt; Regression Models&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;hierarchical-clustering&#34;&gt;Hierarchical Clustering&lt;/h2&gt;
&lt;p&gt;Moving on to hierarchical clustering, we luckily only need to create a few trees to start with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;)] # selecting morphology data
dist_mat &amp;lt;- dist(Morph_df) # distance matrix
## Hierarchical clustering using different linkages
H2_Hierachical_clas1 &amp;lt;- hclust(dist_mat, method = &amp;quot;complete&amp;quot;)
H2_Hierachical_clas2 &amp;lt;- hclust(dist_mat, method = &amp;quot;single&amp;quot;)
H2_Hierachical_clas3 &amp;lt;- hclust(dist_mat, method = &amp;quot;average&amp;quot;)
## Plotting Hierarchies
par(mfrow = c(1, 3))
plot(H2_Hierachical_clas1, main = &amp;quot;complete&amp;quot;)
plot(H2_Hierachical_clas2, main = &amp;quot;single&amp;quot;)
plot(H2_Hierachical_clas3, main = &amp;quot;average&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here, you can see that the type of linkage employed by your hierarchical approach is very important as to how the hierarchy ends up looking like. For now, we run with all of them.&lt;/p&gt;
&lt;h3 id=&#34;population-status-classifier-1&#34;&gt;Population Status Classifier&lt;/h3&gt;
&lt;p&gt;For our population status classifier, let&amp;rsquo;s obtain our data and cluster number we are after:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Population.Status&amp;quot;)]
G &amp;lt;- length(unique(Morph_df[, 4]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can look at how well our different Hierarchies fair at explaining these categories when cut at the point where the same number of categories is present in the tree:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas1, k = G) # cut tree
table(clusterCut, Morph_df$Population.Status) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut Introduced Native
##          1        682    134
##          2        250      0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas2, k = G) # cut tree
table(clusterCut, Morph_df$Population.Status) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut Introduced Native
##          1        682    134
##          2        250      0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas3, k = G) # cut tree
table(clusterCut, Morph_df$Population.Status) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut Introduced Native
##          1        682    134
##          2        250      0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interestingly enough, no matter the linkage, all of these approaches get Introduced and Native populations confused in the first group, but not the second.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at the decisions that we could make when following a decision tree for this example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_PS_decision &amp;lt;- rpart(Population.Status ~ ., data = Morph_df)
rpart.plot(H2_PS_decision)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Following this decision tree we first ask &lt;em&gt;&amp;ldquo;Is our sparrow lighter than 35g?&amp;quot;&lt;/em&gt;. If the answer is yes, we move to the left and ask the question &lt;em&gt;&amp;ldquo;Is the wing span of our sparrow greater/equal than 6.9cm?&amp;quot;&lt;/em&gt;. If the answer is yes, we move to the left and assign this sparrow to an introduced population status. 62% of all observations are in this node and to 2% we believe that this node might actually be a Native node. All other nodes are explained accordingly. More about their interpretation can be found in this 
&lt;a href=&#34;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=&amp;amp;ved=2ahUKEwizk67jmJDvAhUnMuwKHbaiD90QFjAAegQIARAD&amp;amp;url=http%3A%2F%2Fwww.milbo.org%2Frpart-plot%2Fprp.pdf&amp;amp;usg=AOvVaw2DpMfeZC2yVdRaYZBXBA8K&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Manual&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;site-classifier-1&#34;&gt;Site Classifier&lt;/h3&gt;
&lt;p&gt;Moving on to the site index classifier, we need our data and number of clusters:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Index&amp;quot;)]
G &amp;lt;- length(unique(Morph_df[, 4]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at our different outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas1, k = G) # cut tree
table(clusterCut, Morph_df$Index) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut  AU  BE  FG  FI  LO  MA  NU  RE  SA  SI  UK
##         1   24   0   0  21   0  15  17   0   0  22  13
##         2   17   0   0   5   3   7   6   0   0  31   5
##         3   19   0   0  29  12  22  21   0   0  13  25
##         4   24  26   0   2  33   5   7  32  16   0  12
##         5    3   0   0  12   4  18  13   0   0   0  13
##         6    0  60   0   0  20   0   0  49  77   0   0
##         7    0  19   0   0   9   0   0  14  21   0   0
##         8    0   0  80   0   0   0   0   0   0   0   0
##         9    0   0 138   0   0   0   0   0   0   0   0
##         10   0   0  16   0   0   0   0   0   0   0   0
##         11   0   0  16   0   0   0   0   0   0   0   0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas2, k = G) # cut tree
table(clusterCut, Morph_df$Index) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut  AU  BE  FG  FI  LO  MA  NU  RE  SA  SI  UK
##         1    0   0   0   0   0   0   0   0   0  28   0
##         2   87 102   0  69  80  67  64  95 112  32  68
##         3    0   0   0   0   0   0   0   0   0   4   0
##         4    0   0   0   0   0   0   0   0   0   2   0
##         5    0   0   0   0   1   0   0   0   0   0   0
##         6    0   1   0   0   0   0   0   0   0   0   0
##         7    0   2   0   0   0   0   0   0   0   0   0
##         8    0   0 122   0   0   0   0   0   0   0   0
##         9    0   0 126   0   0   0   0   0   0   0   0
##         10   0   0   2   0   0   0   0   0   0   0   0
##         11   0   0   0   0   0   0   0   0   2   0   0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas3, k = G) # cut tree
table(clusterCut, Morph_df$Index) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut  AU  BE  FG  FI  LO  MA  NU  RE  SA  SI  UK
##         1   44   0   0  15  14  15  22   0   0  45  19
##         2   42  31   0  50  50  49  40  27   0  12  44
##         3    1   0   0   0   0   0   0   0   0   5   0
##         4    0   0   0   0   0   0   0   0   0   4   0
##         5    0   6   0   4   9   3   2   1   0   0   5
##         6    0  34   0   0   0   0   0  35  81   0   0
##         7    0  21   0   0   8   0   0  27  23   0   0
##         8    0  13   0   0   0   0   0   5  10   0   0
##         9    0   0 106   0   0   0   0   0   0   0   0
##         10   0   0 134   0   0   0   0   0   0   0   0
##         11   0   0  10   0   0   0   0   0   0   0   0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now see clearly how different linkages have a major impact in determining how our hierarchy groups different observations. I won&amp;rsquo;t go into interpretations here to save time and energy since these outputs are so busy.&lt;/p&gt;
&lt;p&gt;Our decision tree is also excrutiatingly busy:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_Index_decision &amp;lt;- rpart(Index ~ ., data = Morph_df)
rpart.plot(H2_Index_decision)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;climate-classifier-1&#34;&gt;Climate Classifier&lt;/h3&gt;
&lt;p&gt;Back over to our climate classifier:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Morph_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Climate&amp;quot;)]
G &amp;lt;- length(unique(Morph_df[, 4]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s look at how the different linkages impact our results:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas1, k = G) # cut tree
table(clusterCut, Morph_df$Climate) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut Coastal Continental Semi-Coastal
##          1     577         105           60
##          2      19          48            7
##          3     250           0            0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas2, k = G) # cut tree
table(clusterCut, Morph_df$Climate) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut Coastal Continental Semi-Coastal
##          1     595         153           67
##          2       1           0            0
##          3     250           0            0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusterCut &amp;lt;- cutree(H2_Hierachical_clas3, k = G) # cut tree
table(clusterCut, Morph_df$Climate) # assess fit
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
## clusterCut Coastal Continental Semi-Coastal
##          1     596         153           67
##          2     240           0            0
##          3      10           0            0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of our linkage types have problems discerning Coastal types. I wager that is because of a ton of confounding effects which drive morphological traits in addition to climate types.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s another look at a decision tree:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_Climate_decision &amp;lt;- rpart(Climate ~ ., data = Morph_df)
rpart.plot(H2_Climate_decision)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;summary-of-hierarchical-clustering&#34;&gt;Summary of Hierarchical Clustering&lt;/h3&gt;
&lt;p&gt;We have seen that site indices may hold some explanatory power regarding sparrow morphology, but the picture is very complex. We may want to keep them in mind as random effects for future models (don&amp;rsquo;t worry if that doesn&amp;rsquo;t mean much to you yet).&lt;/p&gt;
&lt;h2 id=&#34;random-forest&#34;&gt;Random Forest&lt;/h2&gt;
&lt;p&gt;Random Forests are one of the most powerful classification methods and I love them. They are incredibly powerful, accurate, and easy to use. Unfortunately, they are black-box algorithms (you don&amp;rsquo;t know what&amp;rsquo;s happening in them exactly in numerical terms) and they require observed outcomes. That&amp;rsquo;s not a problem for us with this research project!&lt;/p&gt;
&lt;h3 id=&#34;population-status-classifier-2&#34;&gt;Population Status Classifier&lt;/h3&gt;
&lt;p&gt;Running our random for model for population statuses:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(42) # set seed because the process is random
H2_PS_RF &amp;lt;- tuneRF(
  x = Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;)], # variables which to use for clustering
  y = Sparrows_df$Population.Status, # correct cluster assignment
  strata = Sparrows_df$Population.Status, # stratified sampling
  doBest = TRUE, # run the best overall tree
  ntreeTry = 20000, # consider this number of trees
  improve = 0.0000001, # improvement if this is exceeded
  trace = FALSE, plot = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -0.08235294 1e-07
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Works perfectly.&lt;/p&gt;
&lt;p&gt;Random forests give us access to &lt;em&gt;confusion matrices&lt;/em&gt; which tell us about classification accuracy:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_PS_RF[[&amp;quot;confusion&amp;quot;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Introduced Native class.error
## Introduced        902     30  0.03218884
## Native             55     79  0.41044776
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Evidently, we are good at predicting Introduced population status, but Native population status is almost as random as a coin toss.&lt;/p&gt;
&lt;p&gt;Which variables give us the most information when establishing these groups?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;varImpPlot(H2_PS_RF)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-30-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Well look who it is. &lt;code&gt;Weight&lt;/code&gt; comes out as the most important variable once again!&lt;/p&gt;
&lt;h3 id=&#34;site-classifier-2&#34;&gt;Site Classifier&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s run a random forest analysis for our site indices:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(42) # set seed because the process is random
H2_Index_RF &amp;lt;- tuneRF(
  x = Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;)], # variables which to use for clustering
  y = Sparrows_df$Index, # correct cluster assignment
  strata = Sparrows_df$Index, # stratified sampling
  doBest = TRUE, # run the best overall tree
  ntreeTry = 20000, # consider this number of trees
  improve = 0.0000001, # improvement if this is exceeded
  trace = FALSE, plot = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.01630435 1e-07 
## 0 1e-07
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_Index_RF[[&amp;quot;confusion&amp;quot;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    AU  BE  FG FI LO MA NU RE  SA SI UK class.error
## AU 77   0   0  2  8  0  0  0   0  0  0  0.11494253
## BE  0 102   0  0  0  0  0  0   3  0  0  0.02857143
## FG  0   0 250  0  0  0  0  0   0  0  0  0.00000000
## FI  0   0   0 33  0 21  0  0   0  0 15  0.52173913
## LO  9   0   0  0 69  0  0  2   0  0  1  0.14814815
## MA  0   0   0 17  0 26  2  0   0  0 22  0.61194030
## NU  0   0   0  0  0  7 44  0   0  7  6  0.31250000
## RE  0   4   0  0  3  0  0 87   1  0  0  0.08421053
## SA  0   5   0  0  0  0  0  0 109  0  0  0.04385965
## SI  0   0   0  0  0  1  7  0   0 58  0  0.12121212
## UK  0   0   0 14  0 25  1  0   0  0 28  0.58823529
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;varImpPlot(H2_Index_RF)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Except for Manitoba and the UK (which are often mistaken for each other), morphology (and mostly &lt;code&gt;Weight&lt;/code&gt;) explains station indices quite adequately.&lt;/p&gt;
&lt;h3 id=&#34;climate-classifier-2&#34;&gt;Climate Classifier&lt;/h3&gt;
&lt;p&gt;Lastly, we turn to our climate classifier again:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(42) # set seed because the process is random
H2_Climate_RF &amp;lt;- tuneRF(
  x = Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;)], # variables which to use for clustering
  y = Sparrows_df$Climate, # correct cluster assignment
  strata = Sparrows_df$Climate, # stratified sampling
  doBest = TRUE, # run the best overall tree
  ntreeTry = 20000, # consider this number of trees
  improve = 0.0000001, # improvement if this is exceeded
  trace = FALSE, plot = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.05172414 1e-07 
## -0.02727273 1e-07
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H2_Climate_RF[[&amp;quot;confusion&amp;quot;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Coastal Continental Semi-Coastal class.error
## Coastal          797          16           33  0.05791962
## Continental       15         137            1  0.10457516
## Semi-Coastal      47           0           20  0.70149254
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;varImpPlot(H2_Climate_RF)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;5_Classifications---Order-from-Chaos_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Oof. We get semi-coastal habitats almost completely wrong. The other climate conditions are explained well through morphology, though.&lt;/p&gt;
&lt;h2 id=&#34;final-models&#34;&gt;Final Models&lt;/h2&gt;
&lt;p&gt;In our upcoming &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/&#34; target=&#34;_blank&#34;&gt; Model Selection and Validation&lt;/a&gt; Session, we will look into how to compare and validate models. We now need to select some models we have created here today and want to carry forward to said session.&lt;/p&gt;
&lt;p&gt;Personally, I am quite enamoured with our models &lt;code&gt;H2_PS_mclust&lt;/code&gt; (k-means clustering of population status), &lt;code&gt;H2_PS_RF&lt;/code&gt; (random forest of population status), and &lt;code&gt;H2_Index_RF&lt;/code&gt; (random forest of site indices). Let&amp;rsquo;s save these as a separate object ready to be loaded into our &lt;code&gt;R&lt;/code&gt; environment in the coming session:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;save(H2_PS_mclust, H2_PS_RF, H2_Index_RF, file = file.path(&amp;quot;Data&amp;quot;, &amp;quot;H2_Models.RData&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sessioninfo&#34;&gt;SessionInfo&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessionInfo()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.3 (2023-03-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur ... 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] MASS_7.3-58.2        car_3.1-1            carData_3.0-5        randomForest_4.7-1.1 rpart.plot_3.1.1     rpart_4.1.19         vegan_2.6-4          lattice_0.20-45      permute_0.9-7       
## [10] mclust_6.0.0         ggplot2_3.4.1       
## 
## loaded via a namespace (and not attached):
##  [1] styler_1.9.1      tidyselect_1.2.0  xfun_0.37         bslib_0.4.2       purrr_1.0.1       splines_4.2.3     colorspace_2.1-0  vctrs_0.5.2       generics_0.1.3    htmltools_0.5.4  
## [11] yaml_2.3.7        mgcv_1.8-42       utf8_1.2.3        rlang_1.0.6       R.oo_1.25.0       jquerylib_0.1.4   pillar_1.8.1      glue_1.6.2        withr_2.5.0       R.utils_2.12.2   
## [21] R.cache_0.16.0    lifecycle_1.0.3   munsell_0.5.0     blogdown_1.16     gtable_0.3.1      R.methodsS3_1.8.2 evaluate_0.20     labeling_0.4.2    knitr_1.42        fastmap_1.1.1    
## [31] parallel_4.2.3    fansi_1.0.4       highr_0.10        scales_1.2.1      cachem_1.0.7      jsonlite_1.8.4    abind_1.4-5       farver_2.1.1      digest_0.6.31     bookdown_0.33    
## [41] dplyr_1.1.0       grid_4.2.3        cli_3.6.0         tools_4.2.3       magrittr_2.0.3    sass_0.4.5        tibble_3.2.0      cluster_2.1.4     pkgconfig_2.0.3   Matrix_1.5-3     
## [51] rmarkdown_2.20    rstudioapi_0.14   R6_2.5.1          nlme_3.1-162      compiler_4.2.3
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Regressions</title>
      <link>https://www.erikkusch.com/courses/excursions-into-biostatistics/regressions-correlations-for-the-advanced/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/excursions-into-biostatistics/regressions-correlations-for-the-advanced/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/Excursions-into-Biostatistics/Regressions---Correlations-for-the-Advanced.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;our-resarch-project&#34;&gt;Our Resarch Project&lt;/h2&gt;
&lt;p&gt;Today, we are looking at a big (and entirely fictional) data base of the common house sparrow (&lt;em&gt;Passer domesticus&lt;/em&gt;). In particular, we are interested in the &lt;strong&gt;Evolution of &lt;em&gt;Passer domesticus&lt;/em&gt; in Response to Climate Change&lt;/strong&gt; which was previously explained &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;I have created a large data set for this exercise which is available &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/excursions-into-biostatistics/Data.rar&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt; and we previously cleaned up so that is now usable &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;reading-the-data-into-r&#34;&gt;Reading the Data into &lt;code&gt;R&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start by reading the data into &lt;code&gt;R&lt;/code&gt; and taking an initial look at it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sparrows_df &amp;lt;- readRDS(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))
head(Sparrows_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Index Latitude Longitude     Climate Population.Status Weight Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type
## 1    SI       60       100 Continental            Native  34.05  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 2    SI       60       100 Continental            Native  34.86  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 3    SI       60       100 Continental            Native  32.34  12.66       6.64  Black Female        Shrub          35.60              1       3.21     C      Large               Yes         Avian
## 4    SI       60       100 Continental            Native  34.78  15.09       7.00  Brown Female        Shrub          47.75              0         NA     E      Large               Yes         Avian
## 5    SI       60       100 Continental            Native  35.01  13.82       6.81   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 6    SI       60       100 Continental            Native  32.36  12.67       6.64  Brown Female        Shrub          32.47              1       3.17     E      Large               Yes         Avian
##       TAvg      TSD
## 1 269.9596 15.71819
## 2 269.9596 15.71819
## 3 269.9596 15.71819
## 4 269.9596 15.71819
## 5 269.9596 15.71819
## 6 269.9596 15.71819
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;hypotheses&#34;&gt;Hypotheses&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s remember our hypotheses:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Sparrow Morphology&lt;/strong&gt; is determined by:&lt;br&gt;
A. &lt;em&gt;Climate Conditions&lt;/em&gt; with sparrows in stable, warm environments fairing better than those in colder, less stable ones.&lt;br&gt;
B. &lt;em&gt;Competition&lt;/em&gt; with sparrows in small flocks doing better than those in big flocks.&lt;br&gt;
C. &lt;em&gt;Predation&lt;/em&gt; with sparrows under pressure of predation doing worse than those without.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sites&lt;/strong&gt;  accurately represent &lt;strong&gt;sparrow morphology&lt;/strong&gt;. This may mean:&lt;br&gt;
A. &lt;em&gt;Population status&lt;/em&gt; as inferred through morphology.&lt;br&gt;
B. &lt;em&gt;Site index&lt;/em&gt; as inferred through morphology.&lt;br&gt;
C. &lt;em&gt;Climate&lt;/em&gt; as inferred through morphology.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Quite obviously, &lt;strong&gt;hypothesis 1&lt;/strong&gt; is the only one lending itself well to regression exercises. Since we have three variables that describe sparrow morphology (&lt;code&gt;Weight&lt;/code&gt;, &lt;code&gt;Height&lt;/code&gt;, &lt;code&gt;Wing.Chord&lt;/code&gt;) and multi-response-variable models are definitely above the pay-grade of this material, we need to select one of our morphology variables as our response variable here. Remembering the &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/classifications-order-from-chaos/&#34; target=&#34;_blank&#34;&gt; Classification exercise&lt;/a&gt;, we recall that &lt;code&gt;Weight&lt;/code&gt; was the most informative morphological trait so far. Hence, we stick with this one for these exercises.&lt;/p&gt;
&lt;h2 id=&#34;r-environment&#34;&gt;&lt;code&gt;R&lt;/code&gt; Environment&lt;/h2&gt;
&lt;p&gt;For this exercise, we will need the following packages:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;)
  }
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(
  &amp;quot;ggplot2&amp;quot;, # for visualisation
  &amp;quot;nlme&amp;quot;, # for mixed effect models
  &amp;quot;HLMdiag&amp;quot; # for leverage of mixed effect models
)
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ggplot2    nlme HLMdiag 
##    TRUE    TRUE    TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the above function is way more sophisticated than the usual &lt;code&gt;install.packages()&lt;/code&gt; &amp;amp; &lt;code&gt;library()&lt;/code&gt; approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.&lt;/p&gt;
&lt;h2 id=&#34;linear-regression&#34;&gt;Linear Regression&lt;/h2&gt;
&lt;p&gt;Remember the &lt;strong&gt;Assumptions of Linear Regression&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Variable values follow homoscedasticity (equal variance across entire data range)&lt;/li&gt;
&lt;li&gt;Residuals follow normal distribution (normality)&lt;/li&gt;
&lt;li&gt;Absence of influential outliers&lt;/li&gt;
&lt;li&gt;Response and Predictor are related in a linear fashion&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;climate-conditions&#34;&gt;Climate Conditions&lt;/h3&gt;
&lt;h4 id=&#34;weight-as-a-result-of-average-temperature-tavg&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of average temperature (&lt;code&gt;TAvg&lt;/code&gt;)&lt;/h4&gt;
&lt;p&gt;Before we begin, let&amp;rsquo;s plot the data we want to model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Sparrows_df, aes(y = Weight, x = TAvg)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;) +
  geom_point() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;1440&#34; /&gt;
I have an inkling that we might run into some issues here, but let&amp;rsquo;s continue for now:&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s build the actual model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_ClimateTavg &amp;lt;- lm(Weight ~ TAvg, data = Sparrows_df)
par(mfrow = c(2, 2))
plot(H1_ClimateTavg)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;1440&#34; /&gt;
While the meeting of most of the assumptions here might be debatable, we certainly cannot accept a linear model with residuals this non-normal distributed. Sow hat do we? We try to remove as many confounding effects as possible!&lt;/p&gt;
&lt;p&gt;Remember the plot-locations, climates, and population statues in the data set (go back &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt; if necessary). How about we look exclusively at stations in the Americas which are all housing introduced sparrow populations and almost exclusively lie in coastal habitats? I&amp;rsquo;ll remove all non-coastal climate sites and only consider the central and North America here. Let&amp;rsquo;s do that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# everything west of -7Â° is on the Americas
# every that&#39;s coastal climate type is retained
# everything north of 11Â° is central and north America
CentralNorthAm_df &amp;lt;- Sparrows_df[Sparrows_df$Longitude &amp;lt; -7 &amp;amp; Sparrows_df$Climate == &amp;quot;Coastal&amp;quot; &amp;amp; Sparrows_df$Latitude &amp;gt; 11, ]
ggplot(data = CentralNorthAm_df, aes(y = Weight, x = TAvg)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;) +
  geom_point() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_ClimateTavg &amp;lt;- lm(Weight ~ TAvg, data = CentralNorthAm_df)
par(mfrow = c(2, 2))
plot(H1_ClimateTavg)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;1440&#34; /&gt;
This looks sensible to me! The scatterplot shows that sparrows are lighter in warmer areas which makes sense to me.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_ClimateTavg)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ TAvg, data = CentralNorthAm_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.1440 -1.0861  0.0219  0.9823  3.9743 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 45.167990   1.618752  27.903  &amp;lt; 2e-16 ***
## TAvg        -0.049501   0.005635  -8.785 2.63e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.404 on 248 degrees of freedom
## Multiple R-squared:  0.2373,	Adjusted R-squared:  0.2343 
## F-statistic: 77.18 on 1 and 248 DF,  p-value: 2.633e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our model estimates show the same pattern.&lt;/p&gt;
&lt;h4 id=&#34;weight-as-a-result-of-temperature-variability-tsd&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of temperature variability (&lt;code&gt;TSD&lt;/code&gt;)&lt;/h4&gt;
&lt;p&gt;I&amp;rsquo;ll continue with my North American, coastal subset here:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# everything west of -7Â° is on the Americas
# every that&#39;s coastal climate type is retained
# everything north of 11Â° is central and north America
CentralNorthAm_df &amp;lt;- Sparrows_df[Sparrows_df$Longitude &amp;lt; -7 &amp;amp; Sparrows_df$Climate == &amp;quot;Coastal&amp;quot; &amp;amp; Sparrows_df$Latitude &amp;gt; 11, ]
ggplot(data = CentralNorthAm_df, aes(y = Weight, x = TSD)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;) +
  geom_point() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_ClimateTSD &amp;lt;- lm(Weight ~ TSD, data = CentralNorthAm_df)
par(mfrow = c(2, 2))
plot(H1_ClimateTSD)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_ClimateTSD)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ TSD, data = CentralNorthAm_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.7978 -1.0053  0.0002  1.0042  3.5648 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 29.61266    0.14922  198.45   &amp;lt;2e-16 ***
## TSD          0.22680    0.02069   10.96   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.319 on 248 degrees of freedom
## Multiple R-squared:  0.3263,	Adjusted R-squared:  0.3236 
## F-statistic: 120.1 on 1 and 248 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again all assumptions are met and the model itself is very intuitive: The more variable the climate, the heavier the sparrows.&lt;/p&gt;
&lt;h4 id=&#34;weight-as-a-result-of-both-temperature-mean-tavg-and-temperature-variability-tsd&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of both temperature mean (&lt;code&gt;TAvg&lt;/code&gt;) and temperature variability (&lt;code&gt;TSD&lt;/code&gt;)&lt;/h4&gt;
&lt;p&gt;Naturally, we continue with the same subset of the data as before:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# everything west of -7Â° is on the Americas
# every that&#39;s coastal climate type is retained
# everything north of 11Â° is central and north America
CentralNorthAm_df &amp;lt;- Sparrows_df[Sparrows_df$Longitude &amp;lt; -7 &amp;amp; Sparrows_df$Climate == &amp;quot;Coastal&amp;quot; &amp;amp; Sparrows_df$Latitude &amp;gt; 11, ]
H1_ClimateCont &amp;lt;- lm(Weight ~ TAvg + TSD, data = CentralNorthAm_df)
par(mfrow = c(2, 2))
plot(H1_ClimateCont)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_ClimateCont)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ TAvg + TSD, data = CentralNorthAm_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6593 -1.0263  0.0272  0.9207  3.2359 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 16.59866    4.68943   3.540 0.000479 ***
## TAvg         0.04215    0.01518   2.777 0.005915 ** 
## TSD          0.38142    0.05931   6.431 6.52e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.302 on 247 degrees of freedom
## Multiple R-squared:  0.3467,	Adjusted R-squared:  0.3414 
## F-statistic: 65.54 on 2 and 247 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interestingly, average temperature has a different (and weaker) effect now than when investigated in isolation. Variability of temperature has become even more important (i.e. stronger effect). So which model should we use? That&amp;rsquo;s exactly what we&amp;rsquo;ll investigate in our session on &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/&#34; target=&#34;_blank&#34;&gt; Model Selection and Validation&lt;/a&gt;!&lt;/p&gt;
&lt;h3 id=&#34;competition&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;Next, we build models which aim to explain sparrow &lt;code&gt;Weight&lt;/code&gt; through variables pertaining to competition. To do so, I first calculate the size for each flock at each site and append these to each bird:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;FlockSizes &amp;lt;- with(Sparrows_df, table(Flock, Index))
Sparrows_df$Flock.Size &amp;lt;- NA
for (Flock_Iter in rownames(FlockSizes)) { # loop over flocks
  for (Site_Iter in colnames(FlockSizes)) { # loop over sites
    Positions &amp;lt;- Sparrows_df$Index == Site_Iter &amp;amp; Sparrows_df$Flock == Flock_Iter
    Sparrows_df$Flock.Size[Positions] &amp;lt;- FlockSizes[Flock_Iter, Site_Iter]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that done, we can now build our models up again like we did with the climate data before.&lt;/p&gt;
&lt;h4 id=&#34;weight-as-a-result-of-home-range-size-homerange&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of Home Range size (&lt;code&gt;Home.Range&lt;/code&gt;)&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Sparrows_df, aes(x = Home.Range, y = Weight)) +
  geom_boxplot() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_CompetitionHR &amp;lt;- lm(Weight ~ Home.Range, data = Sparrows_df)
par(mfrow = c(2, 2))
plot(H1_CompetitionHR)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;1440&#34; /&gt;
Nope. Those residuals have me nope out. We won&amp;rsquo;t use this model.&lt;/p&gt;
&lt;h4 id=&#34;weight-as-a-result-of-flock-size-size-flocksize&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of Flock Size size (&lt;code&gt;Flock.Size&lt;/code&gt;)&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Sparrows_df, aes(x = Flock.Size, y = Weight)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;) +
  geom_point() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_CompetitionFS &amp;lt;- lm(Weight ~ Flock.Size, data = Sparrows_df)
par(mfrow = c(2, 2))
plot(H1_CompetitionFS)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-11-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_CompetitionFS)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Flock.Size, data = Sparrows_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.7421 -1.2163  0.0961  1.2823  4.7176 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 35.456378   0.114500   309.7   &amp;lt;2e-16 ***
## Flock.Size  -0.237908   0.003831   -62.1   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.893 on 1064 degrees of freedom
## Multiple R-squared:  0.7838,	Adjusted R-squared:  0.7836 
## F-statistic:  3857 on 1 and 1064 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that&amp;rsquo;s a neat model! Not only do the diagnostics plot look spot-on (not showing these here), the relationship is strong and clear to see - the bigger the flock, the lighter the sparrow.&lt;/p&gt;
&lt;h4 id=&#34;weight-as-a-result-of-home-range-size-homerange-and-flock-size-size-flocksize&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of Home Range size (&lt;code&gt;Home.Range&lt;/code&gt;) and Flock Size size (&lt;code&gt;Flock.Size&lt;/code&gt;)&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Sparrows_df, aes(x = Flock.Size, y = Weight, col = Home.Range)) +
  geom_point() +
  stat_smooth(method = &amp;quot;lm&amp;quot;) +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_CompetitionFULL &amp;lt;- lm(Weight ~ Home.Range * Flock.Size, data = Sparrows_df)
par(mfrow = c(2, 2))
plot(H1_CompetitionFULL)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-12-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_CompetitionFULL)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Home.Range * Flock.Size, data = Sparrows_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.5599 -1.2261  0.0427  1.2806  4.5553 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                 33.29279    0.31986 104.086  &amp;lt; 2e-16 ***
## Home.RangeMedium             0.29700    0.89288   0.333    0.739    
## Home.RangeSmall              1.88176    0.35265   5.336 1.16e-07 ***
## Flock.Size                  -0.07337    0.01848  -3.970 7.66e-05 ***
## Home.RangeMedium:Flock.Size -0.03363    0.05787  -0.581    0.561    
## Home.RangeSmall:Flock.Size  -0.16211    0.01896  -8.548  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.8 on 1060 degrees of freedom
## Multiple R-squared:  0.8051,	Adjusted R-squared:  0.8042 
## F-statistic:   876 on 5 and 1060 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that our model is unsure of what to do with the home ranges when it comes to medium-sized ranges. The scatterplot shows that is is probably due to us not having a lot of samples for medium-sized home-ranges. Aside from that, our model meets all assumptions and produces quite intuitive parameter estimates.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;Next, we look at sparrow &lt;code&gt;Weight&lt;/code&gt; through the lens of predation. To do so, we need to recode all &lt;code&gt;NA&lt;/code&gt;s in the &lt;code&gt;Predator.Type&lt;/code&gt; variable into something else for our models ro tun properly. I chose &lt;code&gt;&amp;quot;None&amp;quot;&lt;/code&gt; here to indicate that there is no predation-pressure at these sites:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(Sparrows_df$Predator.Type) &amp;lt;- c(levels(Sparrows_df$Predator.Type), &amp;quot;None&amp;quot;)
Sparrows_df$Predator.Type[is.na(Sparrows_df$Predator.Type)] &amp;lt;- &amp;quot;None&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that taken care of, we again build our models one-by-one.&lt;/p&gt;
&lt;p&gt;Again, because of issues with normality of residuals, we default to our three sites across Central and North America, which are of coastal climate:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# everything west of -7Â° is on the Americas
# every that&#39;s coastal climate type is retained
# everything north of 11Â° is central and north America
CentralNorthAm_df &amp;lt;- Sparrows_df[Sparrows_df$Longitude &amp;lt; -7 &amp;amp; Sparrows_df$Climate == &amp;quot;Coastal&amp;quot; &amp;amp; Sparrows_df$Latitude &amp;gt; 11, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;weight-as-a-result-of-predatorpresence&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of &lt;code&gt;Predator.Presence&lt;/code&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = CentralNorthAm_df, aes(x = Predator.Presence, y = Weight)) +
  geom_boxplot() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_PredationPresence &amp;lt;- lm(Weight ~ Predator.Presence, data = CentralNorthAm_df)
par(mfrow = c(2, 2))
plot(H1_PredationPresence)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-15-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_PredationPresence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Predator.Presence, data = CentralNorthAm_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5051 -1.0701 -0.0396  1.0749  4.2549 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)           31.4141     0.1752 179.261  &amp;lt; 2e-16 ***
## Predator.PresenceYes  -0.6589     0.2131  -3.092  0.00222 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.577 on 248 degrees of freedom
## Multiple R-squared:  0.03711,	Adjusted R-squared:  0.03323 
## F-statistic: 9.557 on 1 and 248 DF,  p-value: 0.002219
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to our model, sparrows under pressure of predation are lighter than those which aren&amp;rsquo;t. Does that make sense? Intuitively, yes, but I would argue that there are too many confounding variable here to be sure.&lt;/p&gt;
&lt;h4 id=&#34;weight-as-a-result-of-predatortype&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of &lt;code&gt;Predator.Type&lt;/code&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = CentralNorthAm_df, aes(x = Predator.Type, y = Weight)) +
  geom_boxplot() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_PredationType &amp;lt;- lm(Weight ~ Predator.Type, data = CentralNorthAm_df)
par(mfrow = c(2, 2))
plot(H1_PredationType)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-16-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_PredationType)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Predator.Type, data = CentralNorthAm_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6593 -1.0263  0.0272  0.9207  3.2359 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)             29.9093     0.1270 235.439  &amp;lt; 2e-16 ***
## Predator.TypeNon-Avian   2.2335     0.2064  10.819  &amp;lt; 2e-16 ***
## Predator.TypeNone        1.5047     0.1925   7.817 1.56e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.302 on 247 degrees of freedom
## Multiple R-squared:  0.3467,	Adjusted R-squared:  0.3414 
## F-statistic: 65.54 on 2 and 247 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OK. This clearly shows that there are either some confounds present or that our data shows something very counter-intuitive. Sparrows under nor predation are lighter than sparrows under non-avian predation? That makes no sense to me.&lt;/p&gt;
&lt;h4 id=&#34;weight-as-a-result-of-predatorpresence-and-predatortype&#34;&gt;&lt;code&gt;Weight&lt;/code&gt; as a result of &lt;code&gt;Predator.Presence&lt;/code&gt; and &lt;code&gt;Predator.Type&lt;/code&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = CentralNorthAm_df, aes(x = Predator.Presence, y = Weight, fill = Predator.Type)) +
  geom_boxplot() +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_PredationFULL &amp;lt;- lm(Weight ~ Predator.Presence + Predator.Type, data = Sparrows_df)
par(mfrow = c(2, 2))
plot(H1_PredationFULL)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-17-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_PredationFULL)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Predator.Presence + Predator.Type, data = Sparrows_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.6635 -2.2987 -0.0844  1.9563  9.6165 
## 
## Coefficients: (1 not defined because of singularities)
##                        Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)             30.6145     0.1816  168.60   &amp;lt;2e-16 ***
## Predator.PresenceYes    -3.5709     0.2387  -14.96   &amp;lt;2e-16 ***
## Predator.TypeNon-Avian   5.2809     0.2789   18.94   &amp;lt;2e-16 ***
## Predator.TypeNone            NA         NA      NA       NA    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.431 on 1063 degrees of freedom
## Multiple R-squared:  0.2901,	Adjusted R-squared:  0.2888 
## F-statistic: 217.2 on 2 and 1063 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those residuals don&amp;rsquo;t look good, but that&amp;rsquo;s not what I am after with this model. Immediately, we should notice that our model returns &lt;code&gt;NA&lt;/code&gt; for the parameter estimate of &lt;code&gt;Predator.TypeNone&lt;/code&gt;. Why does that happen? Because &lt;code&gt;Predator.TypeNone&lt;/code&gt; coincides with &lt;code&gt;Predator.PresenceNo&lt;/code&gt; (the &lt;code&gt;Intercept&lt;/code&gt;) of this model and so does not provide any additional information. In fact, &lt;code&gt;Predator.Type&lt;/code&gt; offers all the information of &lt;code&gt;Predator.Presence&lt;/code&gt; and then some! Consequently, including both in a model does not make sense and we can immediately disqualify this model.&lt;/p&gt;
&lt;h3 id=&#34;null--full-model&#34;&gt;Null &amp;amp; Full Model&lt;/h3&gt;
&lt;p&gt;For some comparison further down the line, we need a null model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Null_Sparrows &amp;lt;- lm(Weight ~ 1, data = Sparrows_df)
H1_Null_CNA &amp;lt;- lm(Weight ~ 1, data = CentralNorthAm_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our full model contains all of our aforementioned variables/parameters to the best of our knowledge/intuition at this point. We will get to making this model better later. Don&amp;rsquo;t worry:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_FULL_Sparrows &amp;lt;- lm(Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + Predator.Type, data = Sparrows_df)
par(mfrow = c(2, 2))
plot(H1_FULL_Sparrows)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_FULL_Sparrows)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + 
##     Predator.Type, data = Sparrows_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.2164 -1.0436  0.0939  1.0495  4.7403 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                 43.65271    4.09482  10.660  &amp;lt; 2e-16 ***
## ClimateContinental           2.28851    0.31524   7.259 7.53e-13 ***
## ClimateSemi-Coastal         -0.79097    0.30663  -2.580  0.01003 *  
## TAvg                        -0.04252    0.01402  -3.034  0.00247 ** 
## TSD                          0.01431    0.04032   0.355  0.72272    
## Home.RangeMedium             1.63110    0.85370   1.911  0.05632 .  
## Home.RangeSmall              2.36146    0.41639   5.671 1.83e-08 ***
## Flock.Size                  -0.03445    0.01896  -1.817  0.06955 .  
## Predator.TypeNon-Avian       0.24253    0.16673   1.455  0.14605    
## Predator.TypeNone            0.75123    0.17268   4.350 1.49e-05 ***
## Home.RangeMedium:Flock.Size -0.10115    0.05614  -1.802  0.07186 .  
## Home.RangeSmall:Flock.Size  -0.16452    0.01990  -8.267 4.09e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.605 on 1054 degrees of freedom
## Multiple R-squared:  0.846,	Adjusted R-squared:  0.8444 
## F-statistic: 526.6 on 11 and 1054 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Already at this point, it is interesting to point out how some previously non-significant effects drop out while other become significant due to the inclusion of all parameters in one model.&lt;/p&gt;
&lt;p&gt;Now we also need a full model for our Central-/North-America data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_FULL_CNA &amp;lt;- lm(Weight ~ TAvg + TSD + Home.Range * Flock.Size + Predator.Type, data = CentralNorthAm_df)
par(mfrow = c(2, 2))
plot(H1_FULL_CNA)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_FULL_CNA)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ TAvg + TSD + Home.Range * Flock.Size + 
##     Predator.Type, data = CentralNorthAm_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6979 -0.9364 -0.0501  1.0483  3.3590 
## 
## Coefficients: (2 not defined because of singularities)
##                             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                 14.18473    6.20215   2.287   0.0231 *  
## TAvg                         0.05336    0.02038   2.618   0.0094 ** 
## TSD                          0.39853    0.07842   5.082 7.48e-07 ***
## Home.RangeMedium            -3.83588    1.99164  -1.926   0.0553 .  
## Home.RangeSmall             -1.50681    1.03368  -1.458   0.1462    
## Flock.Size                  -0.07581    0.05850  -1.296   0.1963    
## Predator.TypeNon-Avian            NA         NA      NA       NA    
## Predator.TypeNone                 NA         NA      NA       NA    
## Home.RangeMedium:Flock.Size  0.29821    0.13273   2.247   0.0256 *  
## Home.RangeSmall:Flock.Size   0.10097    0.06212   1.625   0.1054    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.285 on 242 degrees of freedom
## Multiple R-squared:  0.3765,	Adjusted R-squared:  0.3585 
## F-statistic: 20.88 on 7 and 242 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;summary-of-linear-regression&#34;&gt;Summary of Linear Regression&lt;/h3&gt;
&lt;p&gt;To streamline the next few steps of our exercise on &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/&#34; target=&#34;_blank&#34;&gt; Model Selection and Validation&lt;/a&gt;, we combine all of our models into a &lt;code&gt;list&lt;/code&gt; object for now:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_ModelSparrows_ls &amp;lt;- list(
  H1_Null_Sparrows,
  H1_CompetitionFS,
  H1_CompetitionFULL,
  H1_FULL_Sparrows
)
names(H1_ModelSparrows_ls) &amp;lt;- c(
  &amp;quot;Null&amp;quot;,
  &amp;quot;Comp_Flock.Size&amp;quot;, &amp;quot;Comp_Full&amp;quot;,
  &amp;quot;Full&amp;quot;
)
H1_ModelCNA_ls &amp;lt;- list(
  H1_Null_CNA,
  H1_ClimateTavg,
  H1_ClimateTSD,
  H1_ClimateCont,
  H1_PredationPresence,
  H1_PredationType,
  H1_FULL_CNA
)
names(H1_ModelCNA_ls) &amp;lt;- c(
  &amp;quot;Null&amp;quot;,
  &amp;quot;Clim_TAvg&amp;quot;, &amp;quot;Clim_TSD&amp;quot;, &amp;quot;Clim_Full&amp;quot;,
  &amp;quot;Pred_Pres&amp;quot;, &amp;quot;Pred_Type&amp;quot;,
  &amp;quot;Full&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;mixed-effect-models&#34;&gt;Mixed Effect Models&lt;/h2&gt;
&lt;p&gt;Remember the &lt;strong&gt;Assumptions of Mixed Effect Models&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Variable values follow homoscedasticity (equal variance across entire data range)&lt;/li&gt;
&lt;li&gt;Residuals follow normal distribution (normality)&lt;/li&gt;
&lt;li&gt;Absence of influential outliers&lt;/li&gt;
&lt;li&gt;Response and Predictor are related in a linear fashion&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;climate-conditions-1&#34;&gt;Climate Conditions&lt;/h3&gt;
&lt;p&gt;Here, I create a mixed effect model that is accounting predicting &lt;code&gt;Weight&lt;/code&gt; with a combination &lt;code&gt;TAvg&lt;/code&gt; and &lt;code&gt;TSD&lt;/code&gt; while accounting for random intercepts of &lt;code&gt;Index&lt;/code&gt; and &lt;code&gt;Population.Status&lt;/code&gt;. As we learned in our exercise on &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/classifications-order-from-chaos/&#34; target=&#34;_blank&#34;&gt; Classifications&lt;/a&gt;, these two are probably important in controlling for some morphology effects in &lt;code&gt;Weight&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I create such a model for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;strong&gt;entire sparrow data data set&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Only the &lt;strong&gt;Central-/North-America sparrows&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;to make models comparable to our previous basic, linear models.&lt;/p&gt;
&lt;h4 id=&#34;global-model&#34;&gt;Global Model&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Climate_ME_Sparrows &amp;lt;- lme(Weight ~ TAvg + TSD,
  random = list(
    Population.Status = ~1,
    Index = ~1
  ),
  data = Sparrows_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Climate_ME_Sparrows), resid(H1_Climate_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Climate_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --&amp;gt; bad!
qqnorm(resid(H1_Climate_ME_Sparrows)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Climate_ME_Sparrows)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;1440&#34; /&gt;
Quite evidently, the assumption of linearity is violated. Notice that we would not like to use this model for predictions, but will carry it forward for the purpose of subsequent &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/&#34; target=&#34;_blank&#34;&gt; Model Selection and Validation&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_Climate_ME_Sparrows)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##   Data: Sparrows_df 
##        AIC      BIC    logLik
##   3557.109 3586.922 -1772.554
## 
## Random effects:
##  Formula: ~1 | Population.Status
##         (Intercept)
## StdDev: 0.001507855
## 
##  Formula: ~1 | Index %in% Population.Status
##         (Intercept) Residual
## StdDev:    2.640311 1.237155
## 
## Fixed effects:  Weight ~ TAvg + TSD 
##                Value Std.Error   DF    t-value p-value
## (Intercept) 37.83099 31.229059 1055  1.2114034  0.2260
## TAvg        -0.03070  0.104602    7 -0.2934692  0.7777
## TSD          0.27536  0.265143    7  1.0385452  0.3336
##  Correlation: 
##      (Intr) TAvg  
## TAvg -0.999       
## TSD  -0.826  0.809
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.956660984 -0.746001839  0.004452834  0.722973350  2.617329146 
## 
## Number of Observations: 1066
## Number of Groups: 
##            Population.Status Index %in% Population.Status 
##                            2                           11
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;central-north-american-model&#34;&gt;Central-/North-American Model&lt;/h4&gt;
&lt;p&gt;Accounting for population status in among the Central-/North-American sites makes no sense as all of them are introduced populations.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Climate_ME_CNA &amp;lt;- lme(Weight ~ TAvg + TSD,
  random = list(Index = ~1),
  data = CentralNorthAm_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Climate_ME_CNA), resid(H1_Climate_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Climate_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --&amp;gt; good!
qqnorm(resid(H1_Climate_ME_CNA)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Climate_ME_CNA)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With this model, all of our assumption are met nicely!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(H1_Climate_ME_CNA)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed-effects model fit by REML
##   Data: CentralNorthAm_df 
##        AIC      BIC    logLik
##   863.9566 881.5035 -426.9783
## 
## Random effects:
##  Formula: ~1 | Index
##         (Intercept) Residual
## StdDev:   0.3802608 1.301734
## 
## Fixed effects:  Weight ~ TAvg + TSD 
##                 Value Std.Error  DF   t-value p-value
## (Intercept) 16.598661 13.291655 247 1.2488031  0.2129
## TAvg         0.042146  0.042863   0 0.9832757     NaN
## TSD          0.381424  0.174011   0 2.1919464     NaN
##  Correlation: 
##      (Intr) TAvg  
## TAvg -0.999       
## TSD  -0.953  0.945
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -2.8111222 -0.7883782  0.0208856  0.7072618  2.4858581 
## 
## Number of Observations: 250
## Number of Groups: 3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;competition-1&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;With competition effects as my goal, I can now include climate classification as one of the random effects! Of course, this is with the exception of the Central-/North-American data as all of these sites are of the type &amp;ldquo;Coastal&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Again, we do so for a global and a local model:&lt;/p&gt;
&lt;h4 id=&#34;global-model-1&#34;&gt;Global Model&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Comp_ME_Sparrows &amp;lt;- lme(Weight ~ Home.Range * Flock.Size,
  random = list(
    Population.Status = ~1,
    Climate = ~1
  ),
  data = Sparrows_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Comp_ME_Sparrows), resid(H1_Comp_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Comp_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --&amp;gt; bad!
qqnorm(resid(H1_Comp_ME_Sparrows)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Comp_ME_Sparrows)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;central-north-american-model-1&#34;&gt;Central-/North-American Model&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Comp_ME_CNA &amp;lt;- lme(Weight ~ Home.Range * Flock.Size,
  random = list(Climate = ~1),
  data = CentralNorthAm_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Comp_ME_CNA), resid(H1_Comp_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Comp_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --&amp;gt; good!
qqnorm(resid(H1_Comp_ME_CNA)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Comp_ME_CNA)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;predation-1&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;With predation effects, I do the same as with competition effects and set a random intercept for climate classification at each site for a global and a local model:&lt;/p&gt;
&lt;h4 id=&#34;global-model-2&#34;&gt;Global Model&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Pred_ME_Sparrows &amp;lt;- lme(Weight ~ Predator.Type,
  random = list(
    Population.Status = ~1,
    Climate = ~1
  ),
  data = Sparrows_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Pred_ME_Sparrows), resid(H1_Pred_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Pred_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --&amp;gt; bad!
qqnorm(resid(H1_Pred_ME_Sparrows)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Pred_ME_Sparrows)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;central-north-american-model-2&#34;&gt;Central-/North-American Model&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Pred_ME_CNA &amp;lt;- lme(Weight ~ Predator.Type,
  random = list(Index = ~1),
  data = CentralNorthAm_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Pred_ME_CNA), resid(H1_Pred_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Pred_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --&amp;gt; good!
qqnorm(resid(H1_Pred_ME_CNA)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Pred_ME_CNA)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;full-model&#34;&gt;Full Model&lt;/h3&gt;
&lt;h4 id=&#34;global-model-3&#34;&gt;Global Model&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Full_ME_Sparrows &amp;lt;- lme(Weight ~ Predator.Type + Flock.Size * Home.Range + TAvg + TSD,
  random = list(Population.Status = ~1),
  data = Sparrows_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Full_ME_Sparrows), resid(H1_Full_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Full_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --&amp;gt; bad!
qqnorm(resid(H1_Full_ME_Sparrows)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Full_ME_Sparrows)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-30-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;central-north-american-model-3&#34;&gt;Central-/North-American Model&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Full_ME_CNA &amp;lt;- lme(Weight ~ Flock.Size * Home.Range + TAvg + TSD,
  random = list(Index = ~1),
  data = CentralNorthAm_df
)
par(mfrow = c(2, 2))
plot(fitted(H1_Full_ME_CNA), resid(H1_Full_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --&amp;gt; good!
plot(fitted(H1_Full_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --&amp;gt; good!
qqnorm(resid(H1_Full_ME_CNA)) # Normality, residuals are normal distributed -&amp;gt; good!
hist(leverage(H1_Full_ME_CNA)[, 1]) # Leverage, not really any outliers --&amp;gt; good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;summary-of-mixed-effect-models&#34;&gt;Summary of Mixed Effect Models&lt;/h3&gt;
&lt;p&gt;Mixed effect models are hard and I have certainly not given them full credit for what they are worth here. I highly suggest giving 
&lt;a href=&#34;https://ourcodingclub.github.io/tutorials/mixed-models/#three&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; a read if you see yourself using mixed effect models.&lt;/p&gt;
&lt;p&gt;For now, I want to carry along only the full models for our session on &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/&#34; target=&#34;_blank&#34;&gt; Model Selection and Validation&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_ModelSparrows_ls$Mixed_Full &amp;lt;- H1_Full_ME_Sparrows
H1_ModelCNA_ls$Mixed_Full &amp;lt;- H1_Full_ME_CNA
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;generalised-linear-models&#34;&gt;Generalised Linear Models&lt;/h2&gt;
&lt;p&gt;For a generalised linear model, we may want to run a logistic regression, which we &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/classifications-order-from-chaos/#binary-logistic-regression-1&#34; target=&#34;_blank&#34;&gt; already did&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For a different example, we now turn to &lt;em&gt;poisson models&lt;/em&gt; by trying to understand how &lt;code&gt;Flock.Size&lt;/code&gt; comes about.&lt;/p&gt;
&lt;p&gt;Firstly, we limit our data set to necessary variables and then cut all duplicate rows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Flock_df &amp;lt;- Sparrows_df[, c(&amp;quot;Flock.Size&amp;quot;, &amp;quot;TAvg&amp;quot;, &amp;quot;TSD&amp;quot;, &amp;quot;Index&amp;quot;, &amp;quot;Climate&amp;quot;, &amp;quot;Predator.Type&amp;quot;)]
Flock_df &amp;lt;- unique(Flock_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are ready to build a basic linear model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Flock_lm &amp;lt;- lm(Flock.Size ~ TAvg * TSD * Predator.Type, data = Flock_df)
par(mfrow = c(2, 2))
plot(Flock_lm)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-34-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Everything looks line but that Scale-Location plot. That one seems to indicate that variance in our &lt;code&gt;Flock.Size&lt;/code&gt; increases as the &lt;code&gt;Flock.Size&lt;/code&gt; itself increases - a very typical example of a poisson distributed variable.&lt;/p&gt;
&lt;p&gt;GLMs to the rescue with the poisson GLM:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;poisson.model &amp;lt;- glm(Flock.Size ~ TAvg * TSD * Predator.Type, data = Flock_df, family = poisson(link = &amp;quot;log&amp;quot;))
par(mfrow = c(2, 2))
plot(poisson.model)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;6_Regressions---Correlations-for-the-Advanced_files/figure-html/unnamed-chunk-35-1.png&#34; width=&#34;1440&#34; /&gt;
We fixed it! Now just for the parameter estimates:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(poisson.model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = Flock.Size ~ TAvg * TSD * Predator.Type, family = poisson(link = &amp;quot;log&amp;quot;), 
##     data = Flock_df)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.02420  -0.88953  -0.09629   0.94122   2.12737  
## 
## Coefficients: (1 not defined because of singularities)
##                                   Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)                     -13.822674   2.540369  -5.441 5.29e-08 ***
## TAvg                              0.061744   0.008564   7.209 5.62e-13 ***
## TSD                               7.243621   1.056843   6.854 7.18e-12 ***
## Predator.TypeNon-Avian          -48.160439   9.412905  -5.116 3.11e-07 ***
## Predator.TypeNone                10.338971   8.694652   1.189    0.234    
## TAvg:TSD                         -0.026895   0.003936  -6.833 8.34e-12 ***
## TAvg:Predator.TypeNon-Avian       0.171883   0.033327   5.157 2.50e-07 ***
## TAvg:Predator.TypeNone           -0.039510   0.029180  -1.354    0.176    
## TSD:Predator.TypeNon-Avian        0.067442   0.041609   1.621    0.105    
## TSD:Predator.TypeNone            -6.742437   1.177538  -5.726 1.03e-08 ***
## TAvg:TSD:Predator.TypeNon-Avian         NA         NA      NA       NA    
## TAvg:TSD:Predator.TypeNone        0.025061   0.004321   5.800 6.64e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 276.538  on 49  degrees of freedom
## Residual deviance:  53.417  on 39  degrees of freedom
## AIC: 310.71
## 
## Number of Fisher Scoring iterations: 4
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;final-models&#34;&gt;Final Models&lt;/h2&gt;
&lt;p&gt;In our upcoming &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/&#34; target=&#34;_blank&#34;&gt; Model Selection and Validation&lt;/a&gt; Session, we will look into how to compare and validate models. We now need to select some models we have created here today and want to carry forward to said session.&lt;/p&gt;
&lt;p&gt;We have already created &lt;code&gt;list&lt;/code&gt; objects for this purpose. Let&amp;rsquo;s save them alongside the data that was used to create them (in the case of the localised models, at least). Let&amp;rsquo;s save these as a separate object ready to be loaded into our &lt;code&gt;R&lt;/code&gt; environment in the coming session:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;save(H1_ModelSparrows_ls, H1_ModelCNA_ls, CentralNorthAm_df, Sparrows_df, file = file.path(&amp;quot;Data&amp;quot;, &amp;quot;H1_Models.RData&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sessioninfo&#34;&gt;SessionInfo&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sessionInfo()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.2.3 (2023-03-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur ... 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] HLMdiag_0.5.0 nlme_3.1-162  ggplot2_3.4.1
## 
## loaded via a namespace (and not attached):
##  [1] styler_1.9.1      tidyselect_1.2.0  xfun_0.37         bslib_0.4.2       janitor_2.2.0     reshape2_1.4.4    purrr_1.0.1       splines_4.2.3     lattice_0.20-45   snakecase_0.11.0 
## [11] colorspace_2.1-0  vctrs_0.5.2       generics_0.1.3    htmltools_0.5.4   mgcv_1.8-42       yaml_2.3.7        utf8_1.2.3        rlang_1.0.6       R.oo_1.25.0       jquerylib_0.1.4  
## [21] pillar_1.8.1      glue_1.6.2        withr_2.5.0       R.utils_2.12.2    plyr_1.8.8        R.cache_0.16.0    lifecycle_1.0.3   stringr_1.5.0     munsell_0.5.0     blogdown_1.16    
## [31] gtable_0.3.1      R.methodsS3_1.8.2 diagonals_6.4.0   evaluate_0.20     labeling_0.4.2    knitr_1.42        fastmap_1.1.1     fansi_1.0.4       highr_0.10        Rcpp_1.0.10      
## [41] scales_1.2.1      cachem_1.0.7      jsonlite_1.8.4    farver_2.1.1      digest_0.6.31     stringi_1.7.12    bookdown_0.33     dplyr_1.1.0       grid_4.2.3        cli_3.6.0        
## [51] tools_4.2.3       magrittr_2.0.3    sass_0.4.5        tibble_3.2.0      pkgconfig_2.0.3   MASS_7.3-58.2     Matrix_1.5-3      lubridate_1.9.2   timechange_0.2.0  rmarkdown_2.20   
## [61] rstudioapi_0.14   R6_2.5.1          compiler_4.2.3
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Data Handling and Data Mining</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/data-handling-and-data-mining/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/data-handling-and-data-mining/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our first &amp;ldquo;real&amp;rdquo; practical experience in &lt;code&gt;R&lt;/code&gt;. The following notes present you with an example of how data handling (also known as data cleaning) can be done. Obviously, the possibility for flaws to occur in any given data set are seemingly endless and so the following, tedious procedure should be thought of as less of an recipe of how to fix common flaws in biological data sets but make you aware of how important proper data collection and data entry is.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/07---Data-Handling-and-Data-Mining_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/SparrowData.csv&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;The following three sections are what I consider to be &lt;em&gt;essential&lt;/em&gt; parts of the preamble to any &lt;code&gt;R&lt;/code&gt;-based analysis. I highly recommend clearly indicating these bits in your code.&lt;/p&gt;
&lt;p&gt;More often than not, you will use variations of these code chunks whether you are working on data handling, data exploration or full-fledged statistical analyses.&lt;/p&gt;
&lt;h3 id=&#34;necessary-steps-for-reproducibility&#34;&gt;Necessary Steps For Reproducibility&lt;/h3&gt;
&lt;p&gt;Reproducibility is the be-all and end-all of any statistical analysis, particularly in light of the peer-review process in life sciences.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you get into highly complex statistical analyses, you may wish to break up chunks of your analysis into separate documents. To ensure that remnants of an earlier analysis or analysis chunk do not influence the results of your current analysis, you may wish to &lt;em&gt;empty&lt;/em&gt; &lt;code&gt;R&lt;/code&gt;&amp;rsquo;s cache (&lt;em&gt;Environment&lt;/em&gt;) before attempting a new analysis. This is achieved via the command &lt;code&gt;rm(list=ls())&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, you &lt;em&gt;need&lt;/em&gt; to remember the importance of &lt;em&gt;soft-coding&lt;/em&gt; for the sake of reproducibility. One of the worst offences to the peer-review process in &lt;code&gt;R&lt;/code&gt;-based statistics is the erroneous hard-coding of the working directory. The &lt;code&gt;getwd()&lt;/code&gt; function shown above solves this exact problem. However, for this workaround to function properly you need to open the code document of interest by double-clicking it within its containing folder.&lt;/p&gt;
&lt;p&gt;When using the &lt;code&gt;xlsx&lt;/code&gt; package or any &lt;em&gt;Excel&lt;/em&gt;-reliant process via &lt;code&gt;R&lt;/code&gt;, your code will automatically run a Java process in the background. By default the Java engine is limited as far as RAM allocation goes and tends to fail when faced with enormous data sets. The workaround &lt;code&gt;options(java.parameters = &amp;quot;-Xmx8g&amp;quot;)&lt;/code&gt; gets rid of this issue by allocation 8 GBs of RAM to Java.&lt;/p&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Packages are &lt;code&gt;R&lt;/code&gt;&amp;rsquo;s way of giving you access to a seemingly infinite repository of functions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;dplyr&amp;quot; # we need this package to fix the most common data errors
                 )
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;dplyr&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dplyr 
##  TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the above function is way more sophisticated than the usual &lt;code&gt;install.packages()&lt;/code&gt; + &lt;code&gt;library()&lt;/code&gt; approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.&lt;/p&gt;
&lt;h3 id=&#34;loading-the-data&#34;&gt;Loading The Data&lt;/h3&gt;
&lt;p&gt;Loading data is crucial to any analysis in &lt;code&gt;R&lt;/code&gt;. Period.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;R&lt;/code&gt; offers a plethora of approaches to data loading and you will usually be taught the &lt;code&gt;read.table()&lt;/code&gt; command in basic biostatistics courses. However, I have found to prefer the functionality provided by the &lt;code&gt;xlsx&lt;/code&gt; package since most data recording is taking place in Excel. As this package is dependant on the installation of Java and &lt;code&gt;RJava&lt;/code&gt;, we will settle on the base &lt;code&gt;R&lt;/code&gt; function &lt;code&gt;read.csv()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- read.csv(file = paste(Dir.Data, &amp;quot;/SparrowData.csv&amp;quot;, sep=&amp;quot;&amp;quot;), header = TRUE)
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another trick to have up your sleeve (if your RAM enables you to act on it) is to duplicate your initial data onto a new object once loaded into &lt;code&gt;R&lt;/code&gt;. This will enable you to easily remedy mistakes in data treatment without having to reload your initial data set from the data file.&lt;/p&gt;
&lt;h2 id=&#34;inspecting-the-data&#34;&gt;Inspecting The Data&lt;/h2&gt;
&lt;p&gt;Once the data is loaded into &lt;code&gt;R&lt;/code&gt;, you &lt;em&gt;need to inspect&lt;/em&gt; it to make sure it is ready for use.&lt;/p&gt;
&lt;h3 id=&#34;assessing-a-data-frame-in-r&#34;&gt;Assessing A Data Frame in &lt;code&gt;R&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Most, if not all, data you will ever load into &lt;code&gt;R&lt;/code&gt; will be stored as a &lt;code&gt;data.frame&lt;/code&gt; within &lt;code&gt;R&lt;/code&gt;. Some of the most important functions for inspecting data frames (&amp;ldquo;df&amp;rdquo; in the following) in base &lt;code&gt;R&lt;/code&gt; are the following four:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dim(df)&lt;/code&gt; returns the dimensions (Rows $\times$ Columns)of the data frame&lt;/li&gt;
&lt;li&gt;&lt;code&gt;head(df)&lt;/code&gt; returns the first 6 rows of the data frame by default (here changed to 4)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tail(df)&lt;/code&gt; returns the last 6 rows of the data frame by default (here changed to 4)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;View(df)&lt;/code&gt; opens nearly any &lt;code&gt;R&lt;/code&gt; object in a separate tab for further inspection. Since we are dealing with an enormous data set here, I will exclude this function for now to save you from printing unnecessary pages.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1068   21
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(Data_df, n = 4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X    Site Index Latitude Longitude     Climate Population.Status Weight
## 1 1 Siberia    SI       60       100 Continental            Native  34,05
## 2 2 Siberia    SI       60       100 Continental            Native  34,86
## 3 3 Siberia    SI       60       100 Continental            Native  32,34
## 4 4 Siberia    SI       60       100 Continental            Native  34,78
##   Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs
## 1  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA
## 2  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA
## 3  12.66       6.64  Black Female        Shrub           35.6              1
## 4  15.09       7.00  Brown Female        Shrub          47.75              0
##   Egg.Weight Flock Home.Range Flock.Size Predator.Presence Predator.Type
## 1         NA     B      Large         16               Yes         Avian
## 2         NA     B      Large         16               Yes         Avian
## 3       3.21     C      Large         14               Yes         Avian
## 4         NA     E      Large         10               Yes         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tail(Data_df, n = 4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         X           Site Index Latitude Longitude Climate Population.Status
## 1065 1065 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
## 1066 1066 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
## 1067 1067 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
## 1068 1068 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
##      Weight Height Wing.Chord Colour  Sex Nesting.Site Nesting.Height
## 1065  34.25  15.26       7.04   Grey Male                            
## 1066  31.76  12.78       6.67   Grey Male                            
## 1067  31.48  12.49       6.63  Black Male                            
## 1068  31.94  12.96       6.70   Grey Male                            
##      Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size Predator.Presence
## 1065                               A      Large         19               Yes
## 1066                               A      Large         19               Yes
## 1067                               C      Large         18               Yes
## 1068                               A      Large         19               Yes
##      Predator.Type
## 1065         Avian
## 1066         Avian
## 1067         Avian
## 1068         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When having an initial look at the results of &lt;code&gt;head(Data_df)&lt;/code&gt; and &lt;code&gt;tail(Data_df)&lt;/code&gt; we can spot two important things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NA&lt;/code&gt;s in head and tail of our data set are stored differently. This is a common problem with biological data sets and we will deal with this issue extensively in the next few sections of this document.&lt;/li&gt;
&lt;li&gt;Due to our data loading procedure we ended up with a redundant first column that is simply showing the respective row numbers. However, this is unnecessary in &lt;code&gt;R&lt;/code&gt; and so we can delete this column as seen below.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df[,-1] # eliminating the erroneous first column as it is redundant
dim(Data_df) # checking if the elimination went right
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1068   20
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-summary-function&#34;&gt;The &lt;code&gt;Summary()&lt;/code&gt; Function&lt;/h3&gt;
&lt;p&gt;As already stated in our seminar series, the &lt;code&gt;summary()&lt;/code&gt; function is &lt;em&gt;invaluable&lt;/em&gt; to data exploration and data inspection. However, it is only partially applicable as it will not work flawlessly on every class of data. Examples of this are shown below.&lt;/p&gt;
&lt;p&gt;The weight data contained within our data frame should be numeric and thus pose no issue to the &lt;code&gt;summary()&lt;/code&gt; function. However, as shown in the next section, it is currently of type character which leads the &lt;code&gt;summary()&lt;/code&gt; function to work improperly.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The height data within our data set, on the other hand, is stored correctly as class numeric. Thus the &lt;code&gt;summary()&lt;/code&gt; function performs flawlessly.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.35   13.52   14.52   15.39   16.22  135.40
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Making data inspection more easy, one may which to automate the use of the &lt;code&gt;summary()&lt;/code&gt; function. However, this only makes sense, when every data column is presenting data in the correct class type. Therefore, we will first fix the column classes and then use the &lt;code&gt;summary()&lt;/code&gt; command.&lt;/p&gt;
&lt;h2 id=&#34;data-cleaning-workflow&#34;&gt;Data Cleaning Workflow&lt;/h2&gt;
&lt;h3 id=&#34;identifying-problems&#34;&gt;Identifying Problems&lt;/h3&gt;
&lt;p&gt;Indentifying most problems in any data set you may ever encounter comes down to mostly two manifestations of inadequate data entry or handling:&lt;/p&gt;
&lt;p&gt;**1. Types/Classes  **&lt;br&gt;
Before even opening a data set, we should know what kind of data classes we expect for every variable (for example, height records as a &lt;code&gt;factor&lt;/code&gt; don&amp;rsquo;t make much sense). Problems with data/variable classes can have lasting influence on your analyses and so we need to test the class for each variable (column) individually. Before we alter any column classes, we will first need to identify columns whose classes need fixing. Doing so is as easy applying the &lt;code&gt;class()&lt;/code&gt; function to the data contained within every column of our data frame separately.&lt;br&gt;
&lt;code&gt;R&lt;/code&gt; offers multiple functions for this but I find the &lt;code&gt;lapply()&lt;/code&gt; function to perform flawlessly as shown below. Since &lt;code&gt;lapply()&lt;/code&gt; returns a &lt;code&gt;list&lt;/code&gt; of class identifiers and these don&amp;rsquo;t translate well to paper, I have opted to transform the list into a named character vector using the &lt;code&gt;unlist()&lt;/code&gt; command. One could also use the &lt;code&gt;str()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unlist(lapply(Data_df, class))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Site             Index          Latitude         Longitude 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;         &amp;quot;numeric&amp;quot;         &amp;quot;numeric&amp;quot; 
##           Climate Population.Status            Weight            Height 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;         &amp;quot;numeric&amp;quot; 
##        Wing.Chord            Colour               Sex      Nesting.Site 
##         &amp;quot;numeric&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot; 
##    Nesting.Height    Number.of.Eggs        Egg.Weight             Flock 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot; 
##        Home.Range        Flock.Size Predator.Presence     Predator.Type 
##       &amp;quot;character&amp;quot;         &amp;quot;integer&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For further inspection, one may want to combine the information obtained by using the &lt;code&gt;class()&lt;/code&gt; function with either the &lt;code&gt;summary()&lt;/code&gt; function (for all non-numeric records) or the &lt;code&gt;hist&lt;/code&gt; function (particularly useful for numeric records).&lt;/p&gt;
&lt;p&gt;**2. Contents/Values  **&lt;br&gt;
Typos and the like will always lead to some data that simply doesn&amp;rsquo;t make sense given the context of your project. Sometimes, errors like these are salvageable but doing so can be a very difficult process. Before we alter any column contents, we will first need to identify columns whose contents need fixing, however. Doing so is as easy applying an automated version of &lt;code&gt;summary()&lt;/code&gt; to the data contained within every column of our data frame separately after having fixed possibly erroneous data classes.&lt;/p&gt;
&lt;h3 id=&#34;fixing-the-problems&#34;&gt;Fixing The Problems&lt;/h3&gt;
&lt;p&gt;Fixing the problems in our data sets always comes down to altering data classes, altering faulty values or removing them entirely.&lt;br&gt;
To make sure we fix all problems, we may often wish to enlist the &lt;code&gt;summary()&lt;/code&gt; function as well as the &lt;code&gt;hist()&lt;/code&gt; function for data inspection and visualisation.&lt;/p&gt;
&lt;p&gt;Before we alter any column contents, we will first need to identify columns whose contents need fixing.&lt;/p&gt;
&lt;!-- Doing so is as easy applying an automated version of `summary()` to the data contained within every column of our data frame separately which is now possible since we have fixed the column types.   --&gt;
&lt;!-- The code below does exactly that: --&gt;
&lt;!-- ```{r ColContProblems} --&gt;
&lt;!-- for(i in 1:dim(Data_df)[2]){ --&gt;
&lt;!--   print(colnames(Data_df)[i]) --&gt;
&lt;!--   print(summary(Data_df[,i])) --&gt;
&lt;!--   print(&#34;------------------------------------------------------&#34;) --&gt;
&lt;!-- } --&gt;
&lt;!-- ``` --&gt;
&lt;!-- There are some glaring issues her which we will address in the following sections. --&gt;
&lt;h2 id=&#34;our-data&#34;&gt;Our Data&lt;/h2&gt;
&lt;h3 id=&#34;site&#34;&gt;Site&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (only 11 possible values)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-1&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Site records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;index&#34;&gt;Index&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (only 11 possible values)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-2&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Index records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Index)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Index)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to. Pay attention that thes shortened index numbers lign up with the numbers of site records!&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-1&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;p&gt;\newpage&lt;/p&gt;
&lt;h3 id=&#34;latitude&#34;&gt;Latitude&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (Latitude is inherently continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-3&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Latitude records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Latitude)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Latitude) # use this instead of summary due to station-dependency here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -51.75    -25  -21.1      4   10.5  17.25     31     54     55     60     70 
##     69     88     95    250    114    105     81     68     68     66     64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-2&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;longitude&#34;&gt;Longitude&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (Longitude is inherently continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-4&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Longitude records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Longitude)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Longitude) # use this instead of summary due to station-dependency here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    -97    -92    -90 -88.75    -67 -59.17    -53     -2   55.6    100    135 
##     68     81     64    105    114     69    250     68     95     66     88
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-3&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;climate&#34;&gt;Climate&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: coastal, semi-coastal, continental)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-5&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Climate records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-4&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;population-status&#34;&gt;Population Status&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: native, introduced)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-6&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Population Status records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Population.Status)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Population.Status)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-5&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;weight&#34;&gt;Weight&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (weight is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-7&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Weight records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously, something is wrong.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-6&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;As seen above, weight records are currently stored as character which they shouldn&amp;rsquo;t. So how do we fix this?&lt;/p&gt;
&lt;p&gt;Firstly, let&amp;rsquo;s try an intuitive &lt;code&gt;as.numeric()&lt;/code&gt; approach which attempts to convert all values contained within a vector into numeric records.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(Data_df_base$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   26.34   30.38   29.40   31.87  420.00      66
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, this didn&amp;rsquo;t do the trick since weight data values (recorded in g) below 13 and above 40 are highly unlikely for &lt;em&gt;Passer domesticus&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Sometimes, the &lt;code&gt;as.numeric()&lt;/code&gt; can be made more powerful by handing it data of class &lt;code&gt;character&lt;/code&gt;. To do so, simply combine &lt;code&gt;as.numeric()&lt;/code&gt; with &lt;code&gt;as.character()&lt;/code&gt; as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(as.character(Data_df_base$Weight))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   26.34   30.38   29.40   31.87  420.00      66
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That still didn&amp;rsquo;t resolve our problem. Weight measurements were taken for all study organisms and so there shouldn&amp;rsquo;t be any &lt;code&gt;NA&lt;/code&gt;s and yet we find 66.&lt;/p&gt;
&lt;p&gt;Interestingly enough this is the exact same number as observations available for Siberia. A closer look at the data frame shows us that weight data for Siberia has been recorded with commas as decimal delimiters whilst the rest of the data set utilises dots.&lt;/p&gt;
&lt;p&gt;Fixing this is not necessarily difficult but it is an erroneous issue for data handling which comes up often and is easy to avoid. Getting rid of the flaws is as simple as using the &lt;code&gt;gsub()&lt;/code&gt; function contained within the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(gsub(pattern = &amp;quot;,&amp;quot;, replacement = &amp;quot;.&amp;quot;, x = Data_df_base$Weight))
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   19.38   27.90   30.63   29.69   32.24  420.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is one data record left hat exceeds the biologically viable span for body weight records of &lt;em&gt;Passer domesticus&lt;/em&gt;. This data record holds the value 420. Since this is unlikely to be a simple mistake of placing the decimal delimiter in the wrong place (both 4.2 and 42 grams are also not feasible weight records for house sparrows), we have to delete the weight data record in question:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight[which(Data_df_base$Weight == 420)] &amp;lt;- NA 
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   27.89   30.63   29.33   32.23   36.66       1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(Data_df$Weight, breaks = 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;07---Data-Handling-and-Data-Mining_files/figure-html/ColContWeight-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;height&#34;&gt;Height&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (height is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-8&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Height records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.35   13.52   14.52   15.39   16.22  135.40
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, some of our data don&amp;rsquo;t behave the way the should (a 135.4 or  1.35 cm tall sparrow are just absurd).&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-7&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Height (or &amp;ldquo;Length&amp;rdquo;) records of &lt;em&gt;Passer domesticus&lt;/em&gt; should fall roughly between 10cm and 22cm. Looking at the data which exceed these thresholds, it is apparent that these are generated simply through misplaced decimal delimiters. So we fix them as follows and use a histogram to check if it worked.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;lt; 10)] # decimal point placed wrong here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.350 1.446
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;lt; 10)] &amp;lt;- Data_df$Height[which(Data_df$Height &amp;lt; 10)] * 10 # FIXED IT!
Data_df$Height[which(Data_df$Height &amp;gt; 22)] # decimal point placed wrong here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 126.7 135.4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;gt; 22)] &amp;lt;- Data_df$Height[which(Data_df$Height &amp;gt; 22)]/10 # FIXED IT!
summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   11.09   13.52   14.51   15.20   16.20   21.68
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(Data_df$Height, breaks = 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;07---Data-Handling-and-Data-Mining_files/figure-html/ColContHeight-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;wing-chord&#34;&gt;Wing Chord&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (wing chord is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-9&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Wing Chord records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   6.410   6.840   7.050   7.337   7.400   9.000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-8&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;colour&#34;&gt;Colour&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: black, grey, brown)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-10&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Colour records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some of the colour records are very odd.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-9&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;The colour records &amp;ldquo;Bright black&amp;rdquo; and &amp;ldquo;Grey with black spots&amp;rdquo; should be &amp;ldquo;Grey&amp;rdquo;. Someone clearly got too eager on the assignment of colours here. The fix is as easy as identifying the data records which are &amp;ldquo;too precise&amp;rdquo; and overwrite them with the correct assignment:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Colour[which(Data_df$Colour == &amp;quot;Bright black&amp;quot;)] &amp;lt;- &amp;quot;Grey&amp;quot;
Data_df$Colour[which(Data_df$Colour == &amp;quot;Grey with black spots&amp;quot;)] &amp;lt;- &amp;quot;Grey&amp;quot;
Data_df$Colour &amp;lt;- droplevels(factor(Data_df$Colour)) # drop unused factor levels
summary(Data_df$Colour) # FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Black Brown  Grey 
##   356   298   414
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;sex&#34;&gt;Sex&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: male and female)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-11&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Climate records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-10&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;nesting-site&#34;&gt;Nesting Site&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: shrub and tree)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-12&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Nesting Site records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;fixing-problems-11&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;One individual is recording to be nesting on the ground. This is something house sparrows don&amp;rsquo;t do. Therefore, we have to assume that this individual is not even a &lt;em&gt;Passer domesticus&lt;/em&gt; to begin with.&lt;/p&gt;
&lt;p&gt;The only way to solve this is to remove all observations pertaining to this individual:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df[-which(Data_df$Nesting.Site == &amp;quot;Ground&amp;quot;), ]
summary(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We just deleted a data record. This affects the flock size of the flock it belongs to (basically, this column contains hard-coded values) which we are going to deal with later.&lt;br&gt;
Still, there are manually entered &lt;code&gt;NA&lt;/code&gt; records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The nesting site for a data record where sex reads &amp;ldquo;Male&amp;rdquo; has to be &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Nesting.Site[which(Data_df$Sex == &amp;quot;Male&amp;quot;)] &amp;lt;- NA 
Data_df$Nesting.Site &amp;lt;- droplevels(factor(Data_df$Nesting.Site)) # drop unused factor levels
summary(Data_df$Nesting.Site)# FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Shrub  Tree  NA&#39;s 
##   292   231   544
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;nesting-height&#34;&gt;Nesting Height&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (continuous records in two clusters corresponding to shrubs and trees)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-13&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Nesting Height records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are obviously some issues here.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-12&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Nesting height is a clear example of a variable that should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet our data frame currently stores them as character.&lt;/p&gt;
&lt;p&gt;Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Nesting.Height))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in summary(as.numeric(Data_df$Nesting.Height)): NAs introduced by
## coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   11.78   42.34   64.85  480.59  951.38 1950.86     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly, something went horribly wrong here. When taking a closer look, the number of 1s is artificially inflated. This is due to the &lt;code&gt;NA&lt;/code&gt;s contained within the data set. These are currently stored as characters since they have been entered into the Excel sheet itself. The &lt;code&gt;as.numeric()&lt;/code&gt; function transforms these into 1s.&lt;/p&gt;
&lt;p&gt;One way of circumventing this issue is to combine the &lt;code&gt;as.numeric()&lt;/code&gt; function with the &lt;code&gt;as.character()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Nesting.Height &amp;lt;- as.numeric(as.character(Data_df$Nesting.Height))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   11.78   42.34   64.85  480.59  951.38 1950.86     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This quite clearly fixed our problems.&lt;/p&gt;
&lt;!-- As can be seen in the histograms below there are now far less erroneously small values. --&gt;
&lt;!-- ```{r plottingpanesNestingHeight, fig.height=2.75} --&gt;
&lt;!-- par(mfrow=c(1,2)) # plotting panes as 1 by 2 --&gt;
&lt;!-- hist(as.numeric(Data_df_base$Nesting.Height), main = &#34;Numeric(Data)&#34;, breaks = 100) --&gt;
&lt;!-- hist(as.numeric(as.character(Data_df_base$Nesting.Height)), main = &#34;Numeric(Character(Data))&#34;, breaks = 100) --&gt;
&lt;!-- ``` --&gt;
&lt;h3 id=&#34;number-of-eggs&#34;&gt;Number of Eggs&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (no a priori knowledge of levels)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-14&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Number of Eggs records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One very out of the ordinary record is to be seen.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-13&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Number of eggs is another variable which should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet is currently stored as character.&lt;/p&gt;
&lt;p&gt;Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Number.of.Eggs))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in summary(as.numeric(Data_df$Number.of.Eggs)): NAs introduced by
## coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   2.000   3.000   3.746   4.000  10.000     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, this didn&amp;rsquo;t do the trick. The number of 1s might be inflated and we expect exactly 544 (number of males) &lt;code&gt;NA&lt;/code&gt;s since number of eggs have only been recorded for female house sparrows.&lt;/p&gt;
&lt;p&gt;We already know that improperly stored &lt;code&gt;NA&lt;/code&gt; records are prone to causing an inflation of data records of value 1. We also remember that head and tail of our data frame hold different types of &lt;code&gt;NA&lt;/code&gt; records. Let&amp;rsquo;s find out who entered &lt;code&gt;NA&lt;/code&gt;s correctly:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Site[which(is.na(Data_df$Egg.Weight))])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code above identifies the sites at which proper &lt;code&gt;NA&lt;/code&gt; recording has been done. The Falkland Isle team did it right (&lt;code&gt;NA&lt;/code&gt; fields in Excel were left blank). Fixing this is actually a bit more challenging and so we do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make everything into characters
Data_df$Number.of.Eggs &amp;lt;- as.character(Data_df$Number.of.Eggs) 
# writing character NA onto actual NAs
Data_df$Number.of.Eggs[which(is.na(Data_df$Number.of.Eggs))] &amp;lt;- &amp;quot;  NA&amp;quot;
# make all character NAs into proper NAs
Data_df$Number.of.Eggs[Data_df$Number.of.Eggs == &amp;quot;  NA&amp;quot;] &amp;lt;- NA 
# make everything numeric
Data_df$Number.of.Eggs &amp;lt;- as.numeric(as.character(Data_df$Number.of.Eggs))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   2.000   3.000   3.746   4.000  10.000     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We did it!&lt;/p&gt;
&lt;h3 id=&#34;egg-weight&#34;&gt;Egg Weight&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (another weight measurement that needs to be continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-15&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Egg Weight records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;fixing-problems-14&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Egg weight should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet is currently stored as character. Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Egg.Weight))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in summary(as.numeric(Data_df$Egg.Weight)): NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.580   2.340   2.670   2.619   2.890   3.590     590
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Something is wrong here. Not enough &lt;code&gt;NA&lt;/code&gt;s are recorded. We expect exactly 590 &lt;code&gt;NA&lt;/code&gt;s (Number of males + Number of Females with zero eggs). Additionally, there are way too many 1s.
Our problem, again, lies with the way the &lt;code&gt;NA&lt;/code&gt;s have been entered into the data set from the beginning and so we use the following fix again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make everything into characters
Data_df$Egg.Weight &amp;lt;- as.character(Data_df$Egg.Weight) 
# writing character NA onto actual NAs
Data_df$Egg.Weight[which(is.na(Data_df$Egg.Weight))] &amp;lt;- &amp;quot;  NA&amp;quot; 
# make all character NAs into proper NAs
Data_df$Egg.Weight[Data_df$Egg.Weight == &amp;quot;  NA&amp;quot;] &amp;lt;- NA 
# make everything numeric
Data_df$Egg.Weight &amp;lt;- as.numeric(as.character(Data_df$Egg.Weight))
summary(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.580   2.340   2.670   2.619   2.890   3.590     590
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;flock&#34;&gt;Flock&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (each sparrow was assigned to one particular flock)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-16&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Flock records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Flock)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Flock)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-15&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;home-range&#34;&gt;Home Range&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: small, medium, large)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-17&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Home Range records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Home.Range)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Home.Range)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-16&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;flock-size&#34;&gt;Flock Size&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (continuous measurement of how many sparrows are in each flock - measured as integers)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-18&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Flock Size records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Flock.Size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Flock.Size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    7.00   16.00   19.00   25.81   31.00   58.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-17&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;predator-presence&#34;&gt;Predator Presence&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: yes and no)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-19&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Predator Presence records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-18&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;predator-type&#34;&gt;Predator Type&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: Avian, Non-Avian, and &lt;code&gt;NA&lt;/code&gt;)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-20&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Predator Type records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Something doesn&amp;rsquo;t sit well here.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-19&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Someone got overly eager when recording Predator Type and specified the presence of a hawk instead of taking down &amp;ldquo;Avian&amp;rdquo;. We fix this as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Predator.Type[which(Data_df$Predator.Type == &amp;quot;Hawk&amp;quot;)] &amp;lt;- &amp;quot;Avian&amp;quot;
summary(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This fixed it  but there are still manually entered &lt;code&gt;NA&lt;/code&gt; records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The predator type for a data record where predator presence reads &amp;ldquo;No&amp;rdquo; has to be &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Predator.Type[which(Data_df$Predator.Presence == &amp;quot;No&amp;quot;)] &amp;lt;- NA 
Data_df$Predator.Type &amp;lt;- droplevels(factor(Data_df$Predator.Type)) # drop unused factor levels
summary(Data_df$Predator.Type)# FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Avian Non-Avian      NA&#39;s 
##       490       220       357
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;redundant-data&#34;&gt;Redundant Data&lt;/h3&gt;
&lt;p&gt;Our data contains redundant columns (i.e.: columns whose data is present in another column already). These are (1) Flock Size (data contained in Flock column) and (2) Flock.Size (data contained in Index column). The fix to this is as easy as removing the columns in question.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- within(Data_df, rm(Flock.Size, Site))
dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1067   18
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fixed it!&lt;/p&gt;
&lt;p&gt;By doing so, we have gotten rid of our flock size problem stemming from the deletion of a data record. You could also argue that the columns &lt;code&gt;Site&lt;/code&gt; and &lt;code&gt;Index&lt;/code&gt; are redundant. We keep both for quality-of-life when interpreting our results (make use of &lt;code&gt;Sites&lt;/code&gt;) and coding (make use os &lt;code&gt;Index&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;saving-the-fixed-data-set&#34;&gt;Saving The Fixed Data Set&lt;/h2&gt;
&lt;p&gt;We fixed out entire data set! The data set is now ready for use.&lt;/p&gt;
&lt;p&gt;Keep in mind that the data set I provided you with was relatively clean and real-world messy data sets can be far more difficult to clean up.&lt;/p&gt;
&lt;p&gt;Before going forth, we need to save it. &lt;strong&gt;Attention:&lt;/strong&gt; don&amp;rsquo;t overwrite your initial data file!&lt;/p&gt;
&lt;h3 id=&#34;final-check&#34;&gt;Final Check&lt;/h3&gt;
&lt;p&gt;Before exporting you may want to ensure that everything is in order and do a final round of data inspection. This can be achieved by running the automated &lt;code&gt;summary()&lt;/code&gt; command from earlier again as follows. I am not including the output here to save some space.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;for(i in 1:dim(Data_df)[2]){
  print(colnames(Data_df)[i])
  print(summary(Data_df[,i]))
  print(&amp;quot;------------------------------------------------------&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Everything checks out. Let&amp;rsquo;s save our final data frame.&lt;/p&gt;
&lt;h3 id=&#34;exporting-the-altered-data&#34;&gt;Exporting The Altered Data&lt;/h3&gt;
&lt;p&gt;Since Excel is readily available for viewing data outside of R, I like to save my final data set in excel format as can be seen below. Additionally, I recommend saving your final data frame as an RDS file. These are &lt;code&gt;R&lt;/code&gt; specific data files which you will not be able to alter outside of &lt;code&gt;R&lt;/code&gt; thus saving yourself from accidentally changing records when only trying to view your data. On top of that, RDS files take up less space than either Excel or TXT files do.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# saving in excel sheet
write.csv(Data_df, file = paste(Dir.Data, &amp;quot;/SparrowData_FIXED.csv&amp;quot;, sep=&amp;quot;&amp;quot;))
# saving as R data frame object
saveRDS(Data_df, file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;)) 
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Data Handling and Data Mining</title>
      <link>https://www.erikkusch.com/courses/biostat101/data-handling-and-data-mining/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/data-handling-and-data-mining/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our first &amp;ldquo;real&amp;rdquo; practical experience in &lt;code&gt;R&lt;/code&gt;. The following notes present you with an example of how data handling (also known as data cleaning) can be done. Obviously, the possibility for flaws to occur in any given data set are seemingly endless and so the following, tedious procedure should be thought of as less of an recipe of how to fix common flaws in biological data sets but make you aware of how important proper data collection and data entry is. I have prepared some slides for this session: &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/07---Data-Handling-and-Data-Mining_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/07---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/SparrowData.csv&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;The following three sections are what I consider to be &lt;em&gt;essential&lt;/em&gt; parts of the preamble to any &lt;code&gt;R&lt;/code&gt;-based analysis. I highly recommend clearly indicating these bits in your code.&lt;/p&gt;
&lt;p&gt;More often than not, you will use variations of these code chunks whether you are working on data handling, data exploration or full-fledged statistical analyses.&lt;/p&gt;
&lt;h3 id=&#34;necessary-steps-for-reproducibility&#34;&gt;Necessary Steps For Reproducibility&lt;/h3&gt;
&lt;p&gt;Reproducibility is the be-all and end-all of any statistical analysis, particularly in light of the peer-review process in life sciences.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you get into highly complex statistical analyses, you may wish to break up chunks of your analysis into separate documents. To ensure that remnants of an earlier analysis or analysis chunk do not influence the results of your current analysis, you may wish to &lt;em&gt;empty&lt;/em&gt; &lt;code&gt;R&lt;/code&gt;&amp;rsquo;s cache (&lt;em&gt;Environment&lt;/em&gt;) before attempting a new analysis. This is achieved via the command &lt;code&gt;rm(list=ls())&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, you &lt;em&gt;need&lt;/em&gt; to remember the importance of &lt;em&gt;soft-coding&lt;/em&gt; for the sake of reproducibility. One of the worst offences to the peer-review process in &lt;code&gt;R&lt;/code&gt;-based statistics is the erroneous hard-coding of the working directory. The &lt;code&gt;getwd()&lt;/code&gt; function shown above solves this exact problem. However, for this workaround to function properly you need to open the code document of interest by double-clicking it within its containing folder.&lt;/p&gt;
&lt;p&gt;When using the &lt;code&gt;xlsx&lt;/code&gt; package or any &lt;em&gt;Excel&lt;/em&gt;-reliant process via &lt;code&gt;R&lt;/code&gt;, your code will automatically run a Java process in the background. By default the Java engine is limited as far as RAM allocation goes and tends to fail when faced with enormous data sets. The workaround &lt;code&gt;options(java.parameters = &amp;quot;-Xmx8g&amp;quot;)&lt;/code&gt; gets rid of this issue by allocation 8 GBs of RAM to Java.&lt;/p&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Packages are &lt;code&gt;R&lt;/code&gt;&amp;rsquo;s way of giving you access to a seemingly infinite repository of functions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;dplyr&amp;quot; # we need this package to fix the most common data errors
                 )
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: dplyr
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;dplyr&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dplyr 
##  TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the above function is way more sophisticated than the usual &lt;code&gt;install.packages()&lt;/code&gt; + &lt;code&gt;library()&lt;/code&gt; approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.&lt;/p&gt;
&lt;h3 id=&#34;loading-the-data&#34;&gt;Loading The Data&lt;/h3&gt;
&lt;p&gt;Loading data is crucial to any analysis in &lt;code&gt;R&lt;/code&gt;. Period.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;R&lt;/code&gt; offers a plethora of approaches to data loading and you will usually be taught the &lt;code&gt;read.table()&lt;/code&gt; command in basic biostatistics courses. However, I have found to prefer the functionality provided by the &lt;code&gt;xlsx&lt;/code&gt; package since most data recording is taking place in Excel. As this package is dependant on the installation of Java and &lt;code&gt;RJava&lt;/code&gt;, we will settle on the base &lt;code&gt;R&lt;/code&gt; function &lt;code&gt;read.csv()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Data_df_base &amp;lt;- read.csv(file = paste(Dir.Data, &amp;quot;/SparrowData.csv&amp;quot;, sep=&amp;quot;&amp;quot;), header = TRUE)
Data_df_base &amp;lt;- read.csv(&amp;quot;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/SparrowData.csv&amp;quot;, 
                         header = TRUE)
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another trick to have up your sleeve (if your RAM enables you to act on it) is to duplicate your initial data onto a new object once loaded into &lt;code&gt;R&lt;/code&gt;. This will enable you to easily remedy mistakes in data treatment without having to reload your initial data set from the data file.&lt;/p&gt;
&lt;h2 id=&#34;inspecting-the-data&#34;&gt;Inspecting The Data&lt;/h2&gt;
&lt;p&gt;Once the data is loaded into &lt;code&gt;R&lt;/code&gt;, you &lt;em&gt;need to inspect&lt;/em&gt; it to make sure it is ready for use.&lt;/p&gt;
&lt;h3 id=&#34;assessing-a-data-frame-in-r&#34;&gt;Assessing A Data Frame in &lt;code&gt;R&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Most, if not all, data you will ever load into &lt;code&gt;R&lt;/code&gt; will be stored as a &lt;code&gt;data.frame&lt;/code&gt; within &lt;code&gt;R&lt;/code&gt;. Some of the most important functions for inspecting data frames (&amp;ldquo;df&amp;rdquo; in the following) in base &lt;code&gt;R&lt;/code&gt; are the following four:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dim(df)&lt;/code&gt; returns the dimensions (Rows $\times$ Columns)of the data frame&lt;/li&gt;
&lt;li&gt;&lt;code&gt;head(df)&lt;/code&gt; returns the first 6 rows of the data frame by default (here changed to 4)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tail(df)&lt;/code&gt; returns the last 6 rows of the data frame by default (here changed to 4)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;View(df)&lt;/code&gt; opens nearly any &lt;code&gt;R&lt;/code&gt; object in a separate tab for further inspection. Since we are dealing with an enormous data set here, I will exclude this function for now to save you from printing unnecessary pages.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1068   21
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(Data_df, n = 4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X    Site Index Latitude Longitude     Climate Population.Status Weight
## 1 1 Siberia    SI       60       100 Continental            Native  34,05
## 2 2 Siberia    SI       60       100 Continental            Native  34,86
## 3 3 Siberia    SI       60       100 Continental            Native  32,34
## 4 4 Siberia    SI       60       100 Continental            Native  34,78
##   Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs
## 1  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA
## 2  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA
## 3  12.66       6.64  Black Female        Shrub           35.6              1
## 4  15.09       7.00  Brown Female        Shrub          47.75              0
##   Egg.Weight Flock Home.Range Flock.Size Predator.Presence Predator.Type
## 1         NA     B      Large         16               Yes         Avian
## 2         NA     B      Large         16               Yes         Avian
## 3       3.21     C      Large         14               Yes         Avian
## 4         NA     E      Large         10               Yes         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tail(Data_df, n = 4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         X           Site Index Latitude Longitude Climate Population.Status
## 1065 1065 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
## 1066 1066 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
## 1067 1067 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
## 1068 1068 Falkland Isles    FI   -51.75    -59.17 Coastal        Introduced
##      Weight Height Wing.Chord Colour  Sex Nesting.Site Nesting.Height
## 1065  34.25  15.26       7.04   Grey Male                            
## 1066  31.76  12.78       6.67   Grey Male                            
## 1067  31.48  12.49       6.63  Black Male                            
## 1068  31.94  12.96       6.70   Grey Male                            
##      Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size Predator.Presence
## 1065                               A      Large         19               Yes
## 1066                               A      Large         19               Yes
## 1067                               C      Large         18               Yes
## 1068                               A      Large         19               Yes
##      Predator.Type
## 1065         Avian
## 1066         Avian
## 1067         Avian
## 1068         Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When having an initial look at the results of &lt;code&gt;head(Data_df)&lt;/code&gt; and &lt;code&gt;tail(Data_df)&lt;/code&gt; we can spot two important things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NA&lt;/code&gt;s in head and tail of our data set are stored differently. This is a common problem with biological data sets and we will deal with this issue extensively in the next few sections of this document.&lt;/li&gt;
&lt;li&gt;Due to our data loading procedure we ended up with a redundant first column that is simply showing the respective row numbers. However, this is unnecessary in &lt;code&gt;R&lt;/code&gt; and so we can delete this column as seen below.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df[,-1] # eliminating the erroneous first column as it is redundant
dim(Data_df) # checking if the elimination went right
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1068   20
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-summary-function&#34;&gt;The &lt;code&gt;Summary()&lt;/code&gt; Function&lt;/h3&gt;
&lt;p&gt;As already stated in our seminar series, the &lt;code&gt;summary()&lt;/code&gt; function is &lt;em&gt;invaluable&lt;/em&gt; to data exploration and data inspection. However, it is only partially applicable as it will not work flawlessly on every class of data. Examples of this are shown below.&lt;/p&gt;
&lt;p&gt;The weight data contained within our data frame should be numeric and thus pose no issue to the &lt;code&gt;summary()&lt;/code&gt; function. However, as shown in the next section, it is currently of type character which leads the &lt;code&gt;summary()&lt;/code&gt; function to work improperly.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The height data within our data set, on the other hand, is stored correctly as class numeric. Thus the &lt;code&gt;summary()&lt;/code&gt; function performs flawlessly.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.35   13.52   14.52   15.39   16.22  135.40
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Making data inspection more easy, one may which to automate the use of the &lt;code&gt;summary()&lt;/code&gt; function. However, this only makes sense, when every data column is presenting data in the correct class type. Therefore, we will first fix the column classes and then use the &lt;code&gt;summary()&lt;/code&gt; command.&lt;/p&gt;
&lt;h2 id=&#34;data-cleaning-workflow&#34;&gt;Data Cleaning Workflow&lt;/h2&gt;
&lt;h3 id=&#34;identifying-problems&#34;&gt;Identifying Problems&lt;/h3&gt;
&lt;p&gt;Indentifying most problems in any data set you may ever encounter comes down to mostly two manifestations of inadequate data entry or handling:&lt;/p&gt;
&lt;p&gt;**1. Types/Classes  **&lt;br&gt;
Before even opening a data set, we should know what kind of data classes we expect for every variable (for example, height records as a &lt;code&gt;factor&lt;/code&gt; don&amp;rsquo;t make much sense). Problems with data/variable classes can have lasting influence on your analyses and so we need to test the class for each variable (column) individually. Before we alter any column classes, we will first need to identify columns whose classes need fixing. Doing so is as easy applying the &lt;code&gt;class()&lt;/code&gt; function to the data contained within every column of our data frame separately.&lt;br&gt;
&lt;code&gt;R&lt;/code&gt; offers multiple functions for this but I find the &lt;code&gt;lapply()&lt;/code&gt; function to perform flawlessly as shown below. Since &lt;code&gt;lapply()&lt;/code&gt; returns a &lt;code&gt;list&lt;/code&gt; of class identifiers and these don&amp;rsquo;t translate well to paper, I have opted to transform the list into a named character vector using the &lt;code&gt;unlist()&lt;/code&gt; command. One could also use the &lt;code&gt;str()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unlist(lapply(Data_df, class))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Site             Index          Latitude         Longitude 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;         &amp;quot;numeric&amp;quot;         &amp;quot;numeric&amp;quot; 
##           Climate Population.Status            Weight            Height 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;         &amp;quot;numeric&amp;quot; 
##        Wing.Chord            Colour               Sex      Nesting.Site 
##         &amp;quot;numeric&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot; 
##    Nesting.Height    Number.of.Eggs        Egg.Weight             Flock 
##       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot; 
##        Home.Range        Flock.Size Predator.Presence     Predator.Type 
##       &amp;quot;character&amp;quot;         &amp;quot;integer&amp;quot;       &amp;quot;character&amp;quot;       &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For further inspection, one may want to combine the information obtained by using the &lt;code&gt;class()&lt;/code&gt; function with either the &lt;code&gt;summary()&lt;/code&gt; function (for all non-numeric records) or the &lt;code&gt;hist&lt;/code&gt; function (particularly useful for numeric records).&lt;/p&gt;
&lt;p&gt;**2. Contents/Values  **&lt;br&gt;
Typos and the like will always lead to some data that simply doesn&amp;rsquo;t make sense given the context of your project. Sometimes, errors like these are salvageable but doing so can be a very difficult process. Before we alter any column contents, we will first need to identify columns whose contents need fixing, however. Doing so is as easy applying an automated version of &lt;code&gt;summary()&lt;/code&gt; to the data contained within every column of our data frame separately after having fixed possibly erroneous data classes.&lt;/p&gt;
&lt;h3 id=&#34;fixing-the-problems&#34;&gt;Fixing The Problems&lt;/h3&gt;
&lt;p&gt;Fixing the problems in our data sets always comes down to altering data classes, altering faulty values or removing them entirely.&lt;br&gt;
To make sure we fix all problems, we may often wish to enlist the &lt;code&gt;summary()&lt;/code&gt; function as well as the &lt;code&gt;hist()&lt;/code&gt; function for data inspection and visualisation.&lt;/p&gt;
&lt;p&gt;Before we alter any column contents, we will first need to identify columns whose contents need fixing.&lt;/p&gt;
&lt;!-- Doing so is as easy applying an automated version of `summary()` to the data contained within every column of our data frame separately which is now possible since we have fixed the column types.   --&gt;
&lt;!-- The code below does exactly that: --&gt;
&lt;!-- ```{r ColContProblems} --&gt;
&lt;!-- for(i in 1:dim(Data_df)[2]){ --&gt;
&lt;!--   print(colnames(Data_df)[i]) --&gt;
&lt;!--   print(summary(Data_df[,i])) --&gt;
&lt;!--   print(&#34;------------------------------------------------------&#34;) --&gt;
&lt;!-- } --&gt;
&lt;!-- ``` --&gt;
&lt;!-- There are some glaring issues her which we will address in the following sections. --&gt;
&lt;h2 id=&#34;our-data&#34;&gt;Our Data&lt;/h2&gt;
&lt;h3 id=&#34;site&#34;&gt;Site&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (only 11 possible values)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-1&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Site records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;index&#34;&gt;Index&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (only 11 possible values)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-2&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Index records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Index)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Index)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to. Pay attention that thes shortened index numbers lign up with the numbers of site records!&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-1&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;p&gt;\newpage&lt;/p&gt;
&lt;h3 id=&#34;latitude&#34;&gt;Latitude&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (Latitude is inherently continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-3&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Latitude records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Latitude)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Latitude) # use this instead of summary due to station-dependency here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -51.75    -25  -21.1      4   10.5  17.25     31     54     55     60     70 
##     69     88     95    250    114    105     81     68     68     66     64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-2&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;longitude&#34;&gt;Longitude&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (Longitude is inherently continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-4&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Longitude records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Longitude)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Longitude) # use this instead of summary due to station-dependency here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##    -97    -92    -90 -88.75    -67 -59.17    -53     -2   55.6    100    135 
##     68     81     64    105    114     69    250     68     95     66     88
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-3&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;climate&#34;&gt;Climate&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: coastal, semi-coastal, continental)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-5&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Climate records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-4&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;population-status&#34;&gt;Population Status&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: native, introduced)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-6&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Population Status records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Population.Status)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Population.Status)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-5&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;weight&#34;&gt;Weight&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (weight is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-7&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Weight records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously, something is wrong.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-6&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;As seen above, weight records are currently stored as character which they shouldn&amp;rsquo;t. So how do we fix this?&lt;/p&gt;
&lt;p&gt;Firstly, let&amp;rsquo;s try an intuitive &lt;code&gt;as.numeric()&lt;/code&gt; approach which attempts to convert all values contained within a vector into numeric records.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(Data_df_base$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   26.34   30.38   29.40   31.87  420.00      66
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, this didn&amp;rsquo;t do the trick since weight data values (recorded in g) below 13 and above 40 are highly unlikely for &lt;em&gt;Passer domesticus&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Sometimes, the &lt;code&gt;as.numeric()&lt;/code&gt; can be made more powerful by handing it data of class &lt;code&gt;character&lt;/code&gt;. To do so, simply combine &lt;code&gt;as.numeric()&lt;/code&gt; with &lt;code&gt;as.character()&lt;/code&gt; as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(as.character(Data_df_base$Weight))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   26.34   30.38   29.40   31.87  420.00      66
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That still didn&amp;rsquo;t resolve our problem. Weight measurements were taken for all study organisms and so there shouldn&amp;rsquo;t be any &lt;code&gt;NA&lt;/code&gt;s and yet we find 66.&lt;/p&gt;
&lt;p&gt;Interestingly enough this is the exact same number as observations available for Siberia. A closer look at the data frame shows us that weight data for Siberia has been recorded with commas as decimal delimiters whilst the rest of the data set utilises dots.&lt;/p&gt;
&lt;p&gt;Fixing this is not necessarily difficult but it is an erroneous issue for data handling which comes up often and is easy to avoid. Getting rid of the flaws is as simple as using the &lt;code&gt;gsub()&lt;/code&gt; function contained within the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight &amp;lt;- as.numeric(gsub(pattern = &amp;quot;,&amp;quot;, replacement = &amp;quot;.&amp;quot;, x = Data_df_base$Weight))
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   19.38   27.90   30.63   29.69   32.24  420.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is one data record left hat exceeds the biologically viable span for body weight records of &lt;em&gt;Passer domesticus&lt;/em&gt;. This data record holds the value 420. Since this is unlikely to be a simple mistake of placing the decimal delimiter in the wrong place (both 4.2 and 42 grams are also not feasible weight records for house sparrows), we have to delete the weight data record in question:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Weight[which(Data_df_base$Weight == 420)] &amp;lt;- NA 
summary(Data_df$Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   19.38   27.89   30.63   29.33   32.23   36.66       1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(Data_df$Weight, breaks = 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;07---Data-Handling-and-Data-Mining_files/figure-html/ColContWeight-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;height&#34;&gt;Height&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (height is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-8&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Height records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.35   13.52   14.52   15.39   16.22  135.40
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, some of our data don&amp;rsquo;t behave the way the should (a 135.4 or  1.35 cm tall sparrow are just absurd).&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-7&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Height (or &amp;ldquo;Length&amp;rdquo;) records of &lt;em&gt;Passer domesticus&lt;/em&gt; should fall roughly between 10cm and 22cm. Looking at the data which exceed these thresholds, it is apparent that these are generated simply through misplaced decimal delimiters. So we fix them as follows and use a histogram to check if it worked.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;lt; 10)] # decimal point placed wrong here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.350 1.446
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;lt; 10)] &amp;lt;- Data_df$Height[which(Data_df$Height &amp;lt; 10)] * 10 # FIXED IT!
Data_df$Height[which(Data_df$Height &amp;gt; 22)] # decimal point placed wrong here
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 126.7 135.4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Height[which(Data_df$Height &amp;gt; 22)] &amp;lt;- Data_df$Height[which(Data_df$Height &amp;gt; 22)]/10 # FIXED IT!
summary(Data_df$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   11.09   13.52   14.51   15.20   16.20   21.68
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(Data_df$Height, breaks = 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;07---Data-Handling-and-Data-Mining_files/figure-html/ColContHeight-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;wing-chord&#34;&gt;Wing Chord&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (wing chord is a continuous metric)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-9&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Wing Chord records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   6.410   6.840   7.050   7.337   7.400   9.000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-8&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;colour&#34;&gt;Colour&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: black, grey, brown)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-10&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Colour records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some of the colour records are very odd.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-9&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;The colour records &amp;ldquo;Bright black&amp;rdquo; and &amp;ldquo;Grey with black spots&amp;rdquo; should be &amp;ldquo;Grey&amp;rdquo;. Someone clearly got too eager on the assignment of colours here. The fix is as easy as identifying the data records which are &amp;ldquo;too precise&amp;rdquo; and overwrite them with the correct assignment:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Colour[which(Data_df$Colour == &amp;quot;Bright black&amp;quot;)] &amp;lt;- &amp;quot;Grey&amp;quot;
Data_df$Colour[which(Data_df$Colour == &amp;quot;Grey with black spots&amp;quot;)] &amp;lt;- &amp;quot;Grey&amp;quot;
Data_df$Colour &amp;lt;- droplevels(factor(Data_df$Colour)) # drop unused factor levels
summary(Data_df$Colour) # FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Black Brown  Grey 
##   356   298   414
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We finally fixed it!&lt;/p&gt;
&lt;h3 id=&#34;sex&#34;&gt;Sex&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: male and female)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-11&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Climate records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-10&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;nesting-site&#34;&gt;Nesting Site&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: shrub and tree)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-12&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Nesting Site records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1068 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;fixing-problems-11&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;One individual is recording to be nesting on the ground. This is something house sparrows don&amp;rsquo;t do. Therefore, we have to assume that this individual is not even a &lt;em&gt;Passer domesticus&lt;/em&gt; to begin with.&lt;/p&gt;
&lt;p&gt;The only way to solve this is to remove all observations pertaining to this individual:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df[-which(Data_df$Nesting.Site == &amp;quot;Ground&amp;quot;), ]
summary(Data_df$Nesting.Site)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We just deleted a data record. This affects the flock size of the flock it belongs to (basically, this column contains hard-coded values) which we are going to deal with later.&lt;br&gt;
Still, there are manually entered &lt;code&gt;NA&lt;/code&gt; records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The nesting site for a data record where sex reads &amp;ldquo;Male&amp;rdquo; has to be &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Nesting.Site[which(Data_df$Sex == &amp;quot;Male&amp;quot;)] &amp;lt;- NA 
Data_df$Nesting.Site &amp;lt;- droplevels(factor(Data_df$Nesting.Site)) # drop unused factor levels
summary(Data_df$Nesting.Site)# FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Shrub  Tree  NA&#39;s 
##   292   231   544
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;nesting-height&#34;&gt;Nesting Height&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (continuous records in two clusters corresponding to shrubs and trees)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-13&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Nesting Height records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are obviously some issues here.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-12&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Nesting height is a clear example of a variable that should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet our data frame currently stores them as character.&lt;/p&gt;
&lt;p&gt;Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Nesting.Height))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in summary(as.numeric(Data_df$Nesting.Height)): NAs introduced by
## coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   11.78   42.34   64.85  480.59  951.38 1950.86     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly, something went horribly wrong here. When taking a closer look, the number of 1s is artificially inflated. This is due to the &lt;code&gt;NA&lt;/code&gt;s contained within the data set. These are currently stored as characters since they have been entered into the Excel sheet itself. The &lt;code&gt;as.numeric()&lt;/code&gt; function transforms these into 1s.&lt;/p&gt;
&lt;p&gt;One way of circumventing this issue is to combine the &lt;code&gt;as.numeric()&lt;/code&gt; function with the &lt;code&gt;as.character()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Nesting.Height &amp;lt;- as.numeric(as.character(Data_df$Nesting.Height))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Nesting.Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   11.78   42.34   64.85  480.59  951.38 1950.86     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This quite clearly fixed our problems.&lt;/p&gt;
&lt;!-- As can be seen in the histograms below there are now far less erroneously small values. --&gt;
&lt;!-- ```{r plottingpanesNestingHeight, fig.height=2.75} --&gt;
&lt;!-- par(mfrow=c(1,2)) # plotting panes as 1 by 2 --&gt;
&lt;!-- hist(as.numeric(Data_df_base$Nesting.Height), main = &#34;Numeric(Data)&#34;, breaks = 100) --&gt;
&lt;!-- hist(as.numeric(as.character(Data_df_base$Nesting.Height)), main = &#34;Numeric(Character(Data))&#34;, breaks = 100) --&gt;
&lt;!-- ``` --&gt;
&lt;h3 id=&#34;number-of-eggs&#34;&gt;Number of Eggs&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (no a priori knowledge of levels)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-14&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Number of Eggs records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One very out of the ordinary record is to be seen.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-13&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Number of eggs is another variable which should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet is currently stored as character.&lt;/p&gt;
&lt;p&gt;Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Number.of.Eggs))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in summary(as.numeric(Data_df$Number.of.Eggs)): NAs introduced by
## coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   2.000   3.000   3.746   4.000  10.000     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, this didn&amp;rsquo;t do the trick. The number of 1s might be inflated and we expect exactly 544 (number of males) &lt;code&gt;NA&lt;/code&gt;s since number of eggs have only been recorded for female house sparrows.&lt;/p&gt;
&lt;p&gt;We already know that improperly stored &lt;code&gt;NA&lt;/code&gt; records are prone to causing an inflation of data records of value 1. We also remember that head and tail of our data frame hold different types of &lt;code&gt;NA&lt;/code&gt; records. Let&amp;rsquo;s find out who entered &lt;code&gt;NA&lt;/code&gt;s correctly:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Site[which(is.na(Data_df$Egg.Weight))])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## character(0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code above identifies the sites at which proper &lt;code&gt;NA&lt;/code&gt; recording has been done. The Falkland Isle team did it right (&lt;code&gt;NA&lt;/code&gt; fields in Excel were left blank). Fixing this is actually a bit more challenging and so we do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make everything into characters
Data_df$Number.of.Eggs &amp;lt;- as.character(Data_df$Number.of.Eggs) 
# writing character NA onto actual NAs
Data_df$Number.of.Eggs[which(is.na(Data_df$Number.of.Eggs))] &amp;lt;- &amp;quot;  NA&amp;quot;
# make all character NAs into proper NAs
Data_df$Number.of.Eggs[Data_df$Number.of.Eggs == &amp;quot;  NA&amp;quot;] &amp;lt;- NA 
# make everything numeric
Data_df$Number.of.Eggs &amp;lt;- as.numeric(as.character(Data_df$Number.of.Eggs))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Number.of.Eggs)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   2.000   3.000   3.746   4.000  10.000     544
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We did it!&lt;/p&gt;
&lt;h3 id=&#34;egg-weight&#34;&gt;Egg Weight&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (another weight measurement that needs to be continuous)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-15&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Egg Weight records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;fixing-problems-14&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Egg weight should be recorded as &lt;code&gt;numeric&lt;/code&gt; and yet is currently stored as character. Our first approach to fixing this, again, is using the &lt;code&gt;as.numeric()&lt;/code&gt; function again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(as.numeric(Data_df$Egg.Weight))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in summary(as.numeric(Data_df$Egg.Weight)): NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.580   2.340   2.670   2.619   2.890   3.590     590
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Something is wrong here. Not enough &lt;code&gt;NA&lt;/code&gt;s are recorded. We expect exactly 590 &lt;code&gt;NA&lt;/code&gt;s (Number of males + Number of Females with zero eggs). Additionally, there are way too many 1s.
Our problem, again, lies with the way the &lt;code&gt;NA&lt;/code&gt;s have been entered into the data set from the beginning and so we use the following fix again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make everything into characters
Data_df$Egg.Weight &amp;lt;- as.character(Data_df$Egg.Weight) 
# writing character NA onto actual NAs
Data_df$Egg.Weight[which(is.na(Data_df$Egg.Weight))] &amp;lt;- &amp;quot;  NA&amp;quot; 
# make all character NAs into proper NAs
Data_df$Egg.Weight[Data_df$Egg.Weight == &amp;quot;  NA&amp;quot;] &amp;lt;- NA 
# make everything numeric
Data_df$Egg.Weight &amp;lt;- as.numeric(as.character(Data_df$Egg.Weight))
summary(Data_df$Egg.Weight)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.580   2.340   2.670   2.619   2.890   3.590     590
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;flock&#34;&gt;Flock&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (each sparrow was assigned to one particular flock)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-16&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Flock records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Flock)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Flock)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-15&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;home-range&#34;&gt;Home Range&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: small, medium, large)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-17&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Home Range records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Home.Range)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Home.Range)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-16&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;flock-size&#34;&gt;Flock Size&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;numeric&lt;/code&gt; (continuous measurement of how many sparrows are in each flock - measured as integers)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-18&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Flock Size records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Flock.Size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Flock.Size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    7.00   16.00   19.00   25.81   31.00   58.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-17&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;predator-presence&#34;&gt;Predator Presence&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (two levels: yes and no)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-19&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Predator Presence records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, they do behave just like we&amp;rsquo;d expect them to.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-18&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t need to fix anything here.&lt;/p&gt;
&lt;h3 id=&#34;predator-type&#34;&gt;Predator Type&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Variable Class Expectation:&lt;/strong&gt; &lt;code&gt;factor&lt;/code&gt; (three levels: Avian, Non-Avian, and &lt;code&gt;NA&lt;/code&gt;)&lt;/p&gt;
&lt;h4 id=&#34;identifying-problems-20&#34;&gt;Identifying Problems&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses our Predator Type records for our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals and check whether they behave as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Something doesn&amp;rsquo;t sit well here.&lt;/p&gt;
&lt;h4 id=&#34;fixing-problems-19&#34;&gt;Fixing Problems&lt;/h4&gt;
&lt;p&gt;Someone got overly eager when recording Predator Type and specified the presence of a hawk instead of taking down &amp;ldquo;Avian&amp;rdquo;. We fix this as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Predator.Type[which(Data_df$Predator.Type == &amp;quot;Hawk&amp;quot;)] &amp;lt;- &amp;quot;Avian&amp;quot;
summary(Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length     Class      Mode 
##      1067 character character
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This fixed it  but there are still manually entered &lt;code&gt;NA&lt;/code&gt; records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The predator type for a data record where predator presence reads &amp;ldquo;No&amp;rdquo; has to be &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Predator.Type[which(Data_df$Predator.Presence == &amp;quot;No&amp;quot;)] &amp;lt;- NA 
Data_df$Predator.Type &amp;lt;- droplevels(factor(Data_df$Predator.Type)) # drop unused factor levels
summary(Data_df$Predator.Type)# FIXED IT!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Avian Non-Avian      NA&#39;s 
##       490       220       357
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;redundant-data&#34;&gt;Redundant Data&lt;/h3&gt;
&lt;p&gt;Our data contains redundant columns (i.e.: columns whose data is present in another column already). These are (1) Flock Size (data contained in Flock column) and (2) Flock.Size (data contained in Index column). The fix to this is as easy as removing the columns in question.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- within(Data_df, rm(Flock.Size, Site))
dim(Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1067   18
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fixed it!&lt;/p&gt;
&lt;p&gt;By doing so, we have gotten rid of our flock size problem stemming from the deletion of a data record. You could also argue that the columns &lt;code&gt;Site&lt;/code&gt; and &lt;code&gt;Index&lt;/code&gt; are redundant. We keep both for quality-of-life when interpreting our results (make use of &lt;code&gt;Sites&lt;/code&gt;) and coding (make use os &lt;code&gt;Index&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;saving-the-fixed-data-set&#34;&gt;Saving The Fixed Data Set&lt;/h2&gt;
&lt;p&gt;We fixed out entire data set! The data set is now ready for use.&lt;/p&gt;
&lt;p&gt;Keep in mind that the data set I provided you with was relatively clean and real-world messy data sets can be far more difficult to clean up.&lt;/p&gt;
&lt;p&gt;Before going forth, we need to save it. &lt;strong&gt;Attention:&lt;/strong&gt; don&amp;rsquo;t overwrite your initial data file!&lt;/p&gt;
&lt;h3 id=&#34;final-check&#34;&gt;Final Check&lt;/h3&gt;
&lt;p&gt;Before exporting you may want to ensure that everything is in order and do a final round of data inspection. This can be achieved by running the automated &lt;code&gt;summary()&lt;/code&gt; command from earlier again as follows. I am not including the output here to save some space.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;for(i in 1:dim(Data_df)[2]){
  print(colnames(Data_df)[i])
  print(summary(Data_df[,i]))
  print(&amp;quot;------------------------------------------------------&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Everything checks out. Let&amp;rsquo;s save our final data frame.&lt;/p&gt;
&lt;h3 id=&#34;exporting-the-altered-data&#34;&gt;Exporting The Altered Data&lt;/h3&gt;
&lt;p&gt;Since Excel is readily available for viewing data outside of R, I like to save my final data set in excel format as can be seen below. Additionally, I recommend saving your final data frame as an RDS file. These are &lt;code&gt;R&lt;/code&gt; specific data files which you will not be able to alter outside of &lt;code&gt;R&lt;/code&gt; thus saving yourself from accidentally changing records when only trying to view your data. On top of that, RDS files take up less space than either Excel or TXT files do.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# saving in excel sheet
write.csv(Data_df, file = paste(Dir.Data, &amp;quot;/SparrowData_FIXED.csv&amp;quot;, sep=&amp;quot;&amp;quot;))
# saving as R data frame object
saveRDS(Data_df, file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;)) 
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Model Selection</title>
      <link>https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.&lt;/p&gt;
&lt;p&gt;I have prepared some I have prepared some &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/Excursions-into-Biostatistics/Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session. For a more mathematical look at these concepts, I cannot recommend enough 
&lt;a href=&#34;https://bookdown.org/egarpor/PM-UC3M/lm-ii-modsel.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eduardo GarcÃ­a PortuguÃ©s&#39; blog&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;r-environment&#34;&gt;&lt;code&gt;R&lt;/code&gt; Environment&lt;/h2&gt;
&lt;p&gt;For this exercise, we will need the following packages:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;)
  }
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(
  &amp;quot;ggplot2&amp;quot;, # for visualisation
  &amp;quot;leaflet&amp;quot;, # for maps
  &amp;quot;splitstackshape&amp;quot;, # for stratified sampling
  &amp;quot;caret&amp;quot;, # for cross-validation exercises
  &amp;quot;boot&amp;quot;, # for bootstrap parameter estimates
  &amp;quot;tidyr&amp;quot;, # for reshaping data frames
  &amp;quot;tidybayes&amp;quot;, # for visualisation of bootstrap estimates
  &amp;quot;pROC&amp;quot;, # for ROC-curves
  &amp;quot;olsrr&amp;quot;, # for subset selection
  &amp;quot;MASS&amp;quot;, # for stepwise subset selection
  &amp;quot;nlme&amp;quot;, # for mixed effect models
  &amp;quot;mclust&amp;quot;, # for k-means clustering,
  &amp;quot;randomForest&amp;quot;, # for randomForest classifier
  &amp;quot;lmeresampler&amp;quot; # for validation of lmer models
)
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         ggplot2         leaflet splitstackshape           caret            boot           tidyr       tidybayes            pROC           olsrr            MASS            nlme          mclust 
##            TRUE            TRUE            TRUE            TRUE            TRUE            TRUE            TRUE            TRUE            TRUE            TRUE            TRUE            TRUE 
##    randomForest    lmeresampler 
##            TRUE            TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the above function is way more sophisticated than the usual &lt;code&gt;install.packages()&lt;/code&gt; &amp;amp; &lt;code&gt;library()&lt;/code&gt; approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.&lt;/p&gt;
&lt;h2 id=&#34;our-resarch-project&#34;&gt;Our Resarch Project&lt;/h2&gt;
&lt;p&gt;Today, we are looking at a big (and entirely fictional) data base of the common house sparrow (&lt;em&gt;Passer domesticus&lt;/em&gt;). In particular, we are interested in the &lt;strong&gt;Evolution of &lt;em&gt;Passer domesticus&lt;/em&gt; in Response to Climate Change&lt;/strong&gt; which was previously explained &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;I have created a large data set for this exercise which is available &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/excursions-into-biostatistics/Data.rar&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt; and we previously cleaned up so that is now usable &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;reading-the-data-into-r&#34;&gt;Reading the Data into &lt;code&gt;R&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start by reading the data into &lt;code&gt;R&lt;/code&gt; and taking an initial look at it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sparrows_df &amp;lt;- readRDS(file.path(&amp;quot;Data&amp;quot;, &amp;quot;SparrowDataClimate.rds&amp;quot;))
head(Sparrows_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Index Latitude Longitude     Climate Population.Status Weight Height Wing.Chord Colour    Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type
## 1    SI       60       100 Continental            Native  34.05  12.87       6.67  Brown   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 2    SI       60       100 Continental            Native  34.86  13.68       6.79   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 3    SI       60       100 Continental            Native  32.34  12.66       6.64  Black Female        Shrub          35.60              1       3.21     C      Large               Yes         Avian
## 4    SI       60       100 Continental            Native  34.78  15.09       7.00  Brown Female        Shrub          47.75              0         NA     E      Large               Yes         Avian
## 5    SI       60       100 Continental            Native  35.01  13.82       6.81   Grey   Male         &amp;lt;NA&amp;gt;             NA             NA         NA     B      Large               Yes         Avian
## 6    SI       60       100 Continental            Native  32.36  12.67       6.64  Brown Female        Shrub          32.47              1       3.17     E      Large               Yes         Avian
##       TAvg      TSD
## 1 269.9596 15.71819
## 2 269.9596 15.71819
## 3 269.9596 15.71819
## 4 269.9596 15.71819
## 5 269.9596 15.71819
## 6 269.9596 15.71819
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;hypotheses&#34;&gt;Hypotheses&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s remember our hypotheses:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Sparrow Morphology&lt;/strong&gt; is determined by:&lt;br&gt;
A. &lt;em&gt;Climate Conditions&lt;/em&gt; with sparrows in stable, warm environments fairing better than those in colder, less stable ones.&lt;br&gt;
B. &lt;em&gt;Competition&lt;/em&gt; with sparrows in small flocks doing better than those in big flocks.&lt;br&gt;
C. &lt;em&gt;Predation&lt;/em&gt; with sparrows under pressure of predation doing worse than those without.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sites&lt;/strong&gt;  accurately represent &lt;strong&gt;sparrow morphology&lt;/strong&gt;. This may mean:&lt;br&gt;
A. &lt;em&gt;Population status&lt;/em&gt; as inferred through morphology.&lt;br&gt;
B. &lt;em&gt;Site index&lt;/em&gt; as inferred through morphology.&lt;br&gt;
C. &lt;em&gt;Climate&lt;/em&gt; as inferred through morphology.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We have already built some models for these &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/classifications-order-from-chaos/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt; and &lt;a href=&#34;https://www.erikkusch.com/courses/excursions-into-biostatistics/regressions-correlations-for-the-advanced/&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;candidate-models&#34;&gt;Candidate Models&lt;/h2&gt;
&lt;p&gt;Before we can get started on model selection and validation, we need some actual models. Let&amp;rsquo;s create some. Since the data set contains three variables pertaining to sparrow morphology (i.e. &lt;code&gt;Weight&lt;/code&gt;, &lt;code&gt;Height&lt;/code&gt;, &lt;code&gt;Wing.Chord&lt;/code&gt;) and I don&amp;rsquo;t want this exercise to spiral out of control with models that account for more than one response variable, we need to settle on one as our response variable in the first hypothesis. I am going with &lt;code&gt;Weight&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, because I am under a bit of time pressure in creating this material, I forego all checking of assumptions on any of the following candidate models as the goal with this material is model selection/validation and not model assumption checking.&lt;/p&gt;
&lt;h3 id=&#34;continuous-models&#34;&gt;Continuous Models&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(file = file.path(&amp;quot;Data&amp;quot;, &amp;quot;H1_Models.RData&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This just loaded three objects into &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;H1_ModelSparrows_ls&lt;/code&gt; - a list of candidate models built for the entire &lt;code&gt;Sparrow_df&lt;/code&gt; data set&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Sparrows_df&lt;/code&gt; - the data frame used to build the global candidate models&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H1_ModelCNA_ls&lt;/code&gt; - a list of candidate models built just for three coastal sites across Central and North America&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CentralNorthAm_df&lt;/code&gt; - the data frame used to build the candidate model for Central and North America&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;global-models&#34;&gt;Global Models&lt;/h4&gt;
&lt;p&gt;Global regression models include:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_ModelSparrows_ls, &amp;quot;[[&amp;quot;, &amp;quot;call&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Null
## lm(formula = Weight ~ 1, data = Sparrows_df)
## 
## $Comp_Flock.Size
## lm(formula = Weight ~ Flock.Size, data = Sparrows_df)
## 
## $Comp_Full
## lm(formula = Weight ~ Home.Range * Flock.Size, data = Sparrows_df)
## 
## $Full
## lm(formula = Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + 
##     Predator.Type, data = Sparrows_df)
## 
## $Mixed_Full
## lme.formula(fixed = Weight ~ Predator.Type + Flock.Size * Home.Range + 
##     TAvg + TSD, data = Sparrows_df, random = list(Population.Status = ~1))
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;local-models&#34;&gt;Local Models&lt;/h4&gt;
&lt;p&gt;Local regression models for the region of Central/North America include:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_ModelCNA_ls, &amp;quot;[[&amp;quot;, &amp;quot;call&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Null
## lm(formula = Weight ~ 1, data = CentralNorthAm_df)
## 
## $Clim_TAvg
## lm(formula = Weight ~ TAvg, data = CentralNorthAm_df)
## 
## $Clim_TSD
## lm(formula = Weight ~ TSD, data = CentralNorthAm_df)
## 
## $Clim_Full
## lm(formula = Weight ~ TAvg + TSD, data = CentralNorthAm_df)
## 
## $Pred_Pres
## lm(formula = Weight ~ Predator.Presence, data = CentralNorthAm_df)
## 
## $Pred_Type
## lm(formula = Weight ~ Predator.Type, data = CentralNorthAm_df)
## 
## $Full
## lm(formula = Weight ~ TAvg + TSD + Home.Range * Flock.Size + 
##     Predator.Type, data = CentralNorthAm_df)
## 
## $Mixed_Full
## lme.formula(fixed = Weight ~ Flock.Size * Home.Range + TAvg + 
##     TSD, data = CentralNorthAm_df, random = list(Index = ~1))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;categorical-models&#34;&gt;Categorical Models&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(file = file.path(&amp;quot;Data&amp;quot;, &amp;quot;H2_Models.RData&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This just loaded three objects into &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;H2_PS_mclust&lt;/code&gt; - a k-means classifier aiming to group &lt;code&gt;Population.Status&lt;/code&gt; by &lt;code&gt;Weight&lt;/code&gt;, &lt;code&gt;Height&lt;/code&gt;, and &lt;code&gt;Wing.Chord&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H2_PS_RF&lt;/code&gt; - a random forest classifier which identifies &lt;code&gt;Population.Status&lt;/code&gt; by &lt;code&gt;Weight&lt;/code&gt;, &lt;code&gt;Height&lt;/code&gt;, and &lt;code&gt;Wing.Chord&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H2_Index_RF&lt;/code&gt; - a random forest classifier which identifies &lt;code&gt;Index&lt;/code&gt; of sites by &lt;code&gt;Weight&lt;/code&gt;, &lt;code&gt;Height&lt;/code&gt;, and &lt;code&gt;Wing.Chord&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;model-comparisonselection&#34;&gt;Model Comparison/Selection&lt;/h2&gt;
&lt;h3 id=&#34;adjusted-coefficient-of-determination&#34;&gt;(adjusted) Coefficient of Determination&lt;/h3&gt;
&lt;p&gt;The coefficient of determination ($R^2$) measures the proportion of variation in our response (&lt;code&gt;Weight&lt;/code&gt;) that can be explained by regression using our predictor(s). The higher this value, the better. Unfortunately, $R^2$ does not penalize complex models (i.e. those with multiple parameters) while the adjusted $R^2$ does. Extracting these for a model object is as easy as writing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ExampleModel &amp;lt;- H1_ModelSparrows_ls$Comp_Flock.Size
summary(ExampleModel)$r.squared
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7837715
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(ExampleModel)$adj.r.squared
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7835683
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tells us that the flock size model explains roughly 0.784% of the variation in the &lt;code&gt;Weight&lt;/code&gt; variable. That is pretty decent.&lt;/p&gt;
&lt;p&gt;To check for all other models, I have written a quick &lt;code&gt;sapply&lt;/code&gt; function that does the extraction for us. Because obtaining (adjusted) $R^2$ requires additional packages, I am excluding these from this analysis:&lt;/p&gt;
&lt;h4 id=&#34;global-regression-models&#34;&gt;Global Regression Models&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Summary_ls &amp;lt;- sapply(H1_ModelSparrows_ls[-length(H1_ModelSparrows_ls)], summary)
R2_df &amp;lt;- data.frame(
  R2 = sapply(H1_Summary_ls, &amp;quot;[[&amp;quot;, &amp;quot;r.squared&amp;quot;),
  Adj.R2 = sapply(H1_Summary_ls, &amp;quot;[[&amp;quot;, &amp;quot;adj.r.squared&amp;quot;)
)
R2_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                        R2    Adj.R2
## Null            0.0000000 0.0000000
## Comp_Flock.Size 0.7837715 0.7835683
## Comp_Full       0.8051421 0.8042229
## Full            0.8460500 0.8444433
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can immediately see that some of our candidate models are doing quite well for themselves.&lt;/p&gt;
&lt;h4 id=&#34;local-regression-models&#34;&gt;Local Regression Models&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Summary_ls &amp;lt;- sapply(H1_ModelCNA_ls[-length(H1_ModelCNA_ls)], summary)
R2_df &amp;lt;- data.frame(
  R2 = sapply(H1_Summary_ls, &amp;quot;[[&amp;quot;, &amp;quot;r.squared&amp;quot;),
  Adj.R2 = sapply(H1_Summary_ls, &amp;quot;[[&amp;quot;, &amp;quot;adj.r.squared&amp;quot;)
)
R2_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   R2     Adj.R2
## Null      0.00000000 0.00000000
## Clim_TAvg 0.23733707 0.23426182
## Clim_TSD  0.32632351 0.32360707
## Clim_Full 0.34671348 0.34142371
## Pred_Pres 0.03710799 0.03322536
## Pred_Type 0.34671348 0.34142371
## Full      0.37651991 0.35848536
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Oof! None of our locally fitted models did well at explaining the data to begin with. With that identified, we are sure not going to trust them when it comes to predictions and so we are scrapping all of them.&lt;/p&gt;
&lt;p&gt;Consequently, we can generalise our naming conventions a bit and now write:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Model_ls &amp;lt;- H1_ModelSparrows_ls
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;anova&#34;&gt;Anova&lt;/h3&gt;
&lt;p&gt;Analysis of Variance (Anova) is another tool you will often run into when trying to understand explanatory power of a model. Here, I do something relatively complex to run an anova for all models in our list without having to type them all out. Again,we omit the mixed effect model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;eval(parse(text = paste(&amp;quot;anova(&amp;quot;, paste(&amp;quot;H1_Model_ls[[&amp;quot;, 1:(length(H1_Model_ls) - 1), &amp;quot;]]&amp;quot;, sep = &amp;quot;&amp;quot;, collapse = &amp;quot;,&amp;quot;), &amp;quot;)&amp;quot;)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: Weight ~ 1
## Model 2: Weight ~ Flock.Size
## Model 3: Weight ~ Home.Range * Flock.Size
## Model 4: Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + Predator.Type
##   Res.Df     RSS Df Sum of Sq        F    Pr(&amp;gt;F)    
## 1   1065 17627.2                                    
## 2   1064  3811.5  1   13815.7 5365.996 &amp;lt; 2.2e-16 ***
## 3   1060  3434.8  4     376.7   36.578 &amp;lt; 2.2e-16 ***
## 4   1054  2713.7  6     721.1   46.678 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, according to this, all of our models are doing much better in explaining our underlying data when compared to the Null Model.&lt;/p&gt;
&lt;h3 id=&#34;information-criteria&#34;&gt;Information Criteria&lt;/h3&gt;
&lt;p&gt;Personally, I would like to have a model that&amp;rsquo;s good at predicting things instead of &amp;ldquo;just&amp;rdquo; explaining things and so we step into &lt;em&gt;information criteria&lt;/em&gt; next. These aim to provide us with exactly that information: &amp;ldquo;How well will our model predict new data?&amp;rdquo; Information criteria make use of information theory which allows us to make such statements with pretty decent certainty despite not having new data.&lt;/p&gt;
&lt;h4 id=&#34;akaike-information-criterion-aic&#34;&gt;Akaike Information Criterion (AIC)&lt;/h4&gt;
&lt;p&gt;Looking at the AIC:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_Model_ls, AIC)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Null Comp_Flock.Size       Comp_Full            Full      Mixed_Full 
##        6019.872        4389.378        4286.445        4047.250        4162.779
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our full model is the clear favourite here.&lt;/p&gt;
&lt;h4 id=&#34;bayesian-information-criterion-bic&#34;&gt;Bayesian Information Criterion (BIC)&lt;/h4&gt;
&lt;p&gt;As far as the BIC is concerned:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_Model_ls, BIC)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Null Comp_Flock.Size       Comp_Full            Full      Mixed_Full 
##        6029.815        4404.293        4321.247        4111.882        4222.326
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our full model wins again!&lt;/p&gt;
&lt;h4 id=&#34;receiver-operator-characteristic-roc&#34;&gt;Receiver-Operator Characteristic (ROC)&lt;/h4&gt;
&lt;p&gt;The Receiver-Operator Characteristic (ROC) shows the trade-off between &lt;em&gt;Sensitivity&lt;/em&gt; (rate of true positives) and &lt;em&gt;Specificity&lt;/em&gt; (rate of true negatives). It also provides an &lt;em&gt;Area under the Curve&lt;/em&gt; which serves as a proxy of classification accuracy.&lt;/p&gt;
&lt;p&gt;First, we establish the ROC-Curve for our classification of &lt;code&gt;Population.Status&lt;/code&gt; given sparrow Morphology and a k-means algorithm:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Mclust_PS.roc &amp;lt;- roc(
  Sparrows_df$Population.Status, # known outcome
  H2_PS_mclust$z[, 1] # probability of assigning one out of two outcomes
)
plot(Mclust_PS.roc)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;auc(Mclust_PS.roc)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Area under the curve: 0.6341
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Certainly, we could do better! Let&amp;rsquo;s see what more advanced methods have to offer.&lt;/p&gt;
&lt;p&gt;With that, we turn to random forest:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;RF_PS.roc &amp;lt;- roc(
  Sparrows_df$Population.Status,
  H2_PS_RF$votes[, 1]
)
plot(RF_PS.roc)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;auc(RF_PS.roc)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Area under the curve: 0.9274
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this is doing much better!&lt;/p&gt;
&lt;p&gt;Lastly, we want to look at the site &lt;code&gt;Index&lt;/code&gt; as predicted by sparrow morphology given a random forest algorithm:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;RF_Index.roc &amp;lt;- multiclass.roc(
  Sparrows_df$Index, # known outcome
  H2_Index_RF$votes # matrix of certainties of prediction
)
RF_Index.roc[[&amp;quot;auc&amp;quot;]] # average ROC-AUC
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Multi-class area under the curve: 0.9606
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Plot ROC curve for each binary comparison
rs &amp;lt;- RF_Index.roc[[&amp;quot;rocs&amp;quot;]] ## extract comparisons
plot.roc(rs[[1]][[1]]) # blot first comparison
plot.roc(rs[[1]][[2]], add = TRUE) # plot first comparison, in opposite direction
invisible(capture.output(sapply(2:length(rs), function(i) lines.roc(rs[[i]][[1]], col = i))))
invisible(capture.output(sapply(2:length(rs), function(i) lines.roc(rs[[i]][[2]], col = i))))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is certainly busy, but look at that average AUC of almost 1! That is the power of Random Forest.&lt;/p&gt;
&lt;h3 id=&#34;summary-of-model-selection&#34;&gt;Summary of Model Selection&lt;/h3&gt;
&lt;h4 id=&#34;morphology-hypothesis&#34;&gt;Morphology Hypothesis&lt;/h4&gt;
&lt;p&gt;Regarding our morphology hypothesis, we saw that most of our hypothesised effects can be detected. However, some models clearly perform better than others. Usual model selection exercises would have us discard all but the best model (&lt;code&gt;Full&lt;/code&gt;, in this case) and leave the rest never to be spoken of again. Doing so would have us miss a pretty neat opportunity to do some &lt;strong&gt;model comparison&lt;/strong&gt; which can already help us identify which effects to focus on in particular.&lt;/p&gt;
&lt;p&gt;To demonstrate some of this, allow me step into the local regression models:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_ModelCNA_ls, AIC)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Null  Clim_TAvg   Clim_TSD  Clim_Full  Pred_Pres  Pred_Type       Full Mixed_Full 
##   948.7346   882.9998   851.9833   846.2997   941.2811   846.2997   844.6250   875.7659
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as well as global regression models:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_Model_ls, AIC)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Null Comp_Flock.Size       Comp_Full            Full      Mixed_Full 
##        6019.872        4389.378        4286.445        4047.250        4162.779
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Climate&lt;/em&gt; - interestingly,  temperature variability is much more informative than average temperature and even adding the two into the same model only marginally improves over the variability-only model. This tells us much about which effects are probably meaningful and which aren&amp;rsquo;t.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Competition&lt;/em&gt; -  The competition models did well across the board, but were aided immensely by adding climate information and accounting for random effects.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Predation&lt;/em&gt; - predation effects were best explained by predation type with only a marginal improvement of adding predator presence. That is because predator type already contains all of the information that is within predator presence.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What we can do so far, is remove some obviously erroneous models which in this case is the entirety of local regression models.&lt;/p&gt;
&lt;h4 id=&#34;categorisation-hypothesis&#34;&gt;Categorisation Hypothesis&lt;/h4&gt;
&lt;p&gt;As far as the categorisation hypotheses are concerned, we now have confirmation that population status and sparrow morphology are linked quite well.&lt;/p&gt;
&lt;p&gt;We have also learned that random forest is an incredibly powerful method for classification and variable selection.&lt;/p&gt;
&lt;h2 id=&#34;model-validation&#34;&gt;Model Validation&lt;/h2&gt;
&lt;p&gt;So far, we have not introduced our models to any new data. We have looked at &lt;em&gt;explanatory power&lt;/em&gt; with (adjusted) $R^2$, and the Anova. We have also looked at &lt;em&gt;estimates of predictive power&lt;/em&gt; with our information criteria (e.g. AIC, BIC).&lt;/p&gt;
&lt;p&gt;What about actually seeing how robust and accurate our models are? That&amp;rsquo;s what Model Validation is for!&lt;/p&gt;
&lt;h3 id=&#34;cross-validation&#34;&gt;Cross-Validation&lt;/h3&gt;
&lt;p&gt;Before we get started, I remove the Null model from our model list. Doing cross-validation on this does not make any sense because there are no actual predictors in it which could be affected by cross-validation processes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Model_ls &amp;lt;- H1_Model_ls[-1]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;training-vs-test-data&#34;&gt;Training vs. Test Data&lt;/h4&gt;
&lt;p&gt;The simplest example of cross-validation is the &lt;em&gt;validation data cross-validation&lt;/em&gt; approach; also known as &lt;strong&gt;Training vs. Test Data&lt;/strong&gt; approach.&lt;/p&gt;
&lt;p&gt;To make use of this approach, we need to (1) randomly split our data, (2) build our models using the training data, and (3) test our models on the test data.&lt;/p&gt;
&lt;p&gt;Since we have highly compartmentalised data at different sites, I am employing a stratified sampling scheme to ensure all of my sites are represented in each data set resulting from the split:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(42) # make randomness reproducible
Stratified_ls &amp;lt;- stratified(Sparrows_df, # what to split
  group = &amp;quot;Index&amp;quot;, # by which group to stratify
  size = .7, # what proportion of each group shall be contained in the training data
  bothSets = TRUE # save both training and test data
)
Train_df &amp;lt;- Stratified_ls$SAMP1 # extract training data
Test_df &amp;lt;- Stratified_ls$SAMP2 # extract test data
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have our training and test data, we are ready to run our pre-specified models on said data and subsequently test it&amp;rsquo;s performance on the test data by predicting with the newly trained model and calculating mean squared test error.&lt;/p&gt;
&lt;p&gt;For a single model, we can do it like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ExampleModel &amp;lt;- H1_ModelSparrows_ls$Comp_Flock.Size # extract Model from list
ExampleModel &amp;lt;- update(ExampleModel, data = Train_df) # train model on training data
Prediction &amp;lt;- predict(ExampleModel, newdata = Test_df) # predict outcome for test data
sum((Test_df$Weight - Prediction)^2) # Mean Squared Error
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1133.996
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we have multiple models stored in a list, here&amp;rsquo;s a way to do the above for the entire list:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;H1_Train_ls &amp;lt;- sapply(X = H1_Model_ls, FUN = function(x) update(x, data = Train_df))
H1_Test_mat &amp;lt;- sapply(X = H1_Train_ls, FUN = function(x) predict(x, newdata = Test_df))
apply(H1_Test_mat, MARGIN = 2, FUN = function(x) sum((Test_df$Weight - x)^2))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Comp_Flock.Size       Comp_Full            Full      Mixed_Full 
##       1133.9958       1026.2199        816.5166        866.2941
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, our full model comes out on top!&lt;/p&gt;
&lt;p&gt;Unfortunately, this approach is fickle due to the randomness of the data split. How can we make this more robust? Easy. We split many, many times and average our mean squared errors out.&lt;/p&gt;
&lt;p&gt;This bring us to traditional Cross-Validation approaches. Luckily, the complex parts of cross-validation are already offered to us with the &lt;code&gt;caret&lt;/code&gt; package in &lt;code&gt;R&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;leave-one-out-cross-validation-loocv&#34;&gt;Leave-One-Out Cross-Validation (LOOCV)&lt;/h4&gt;
&lt;p&gt;Leave-One-Out Cross-Validation is a method within which we split our data into a training data set with $n-1$ observation and a test data set that contains just $1$ observation. We do training and testing as above on this split and then repeat this procedure until every observation has been left out once.&lt;/p&gt;
&lt;p&gt;For a simple model, this can be done like such:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train(Weight ~ Climate,
  data = Sparrows_df,
  method = &amp;quot;lm&amp;quot;,
  trControl = trainControl(method = &amp;quot;LOOCV&amp;quot;)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear Regression 
## 
## 1066 samples
##    1 predictor
## 
## No pre-processing
## Resampling: Leave-One-Out Cross-Validation 
## Summary of sample sizes: 1065, 1065, 1065, 1065, 1065, 1065, ... 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   3.628905  0.2036173  2.976221
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice the RMSE (Residual mean squared error). That&amp;rsquo;s what we use to compare models.&lt;/p&gt;
&lt;p&gt;Here, I create a function that automatically rebuilds our models for the LOOCV so we can run this on our list of models later.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;CV_LOOCV &amp;lt;- function(x) {
  if (length(x[[&amp;quot;terms&amp;quot;]][[3]]) == 1) {
    Terms &amp;lt;- paste(x[[&amp;quot;terms&amp;quot;]][[3]], collapse = &amp;quot; + &amp;quot;)
  } else {
    Terms &amp;lt;- paste(x[[&amp;quot;terms&amp;quot;]][[3]][-1], collapse = &amp;quot; + &amp;quot;)
  }
  train(as.formula(paste(&amp;quot;Weight ~&amp;quot;, Terms)),
    data = Sparrows_df,
    method = &amp;quot;lm&amp;quot;,
    trControl = trainControl(method = &amp;quot;LOOCV&amp;quot;)
  )
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, this cannot be executed for mixed effect models, so for now, I only run this on all our models except the mixed effect model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Begin &amp;lt;- Sys.time()
H1_LOOCV_ls &amp;lt;- sapply(H1_Model_ls[-length(H1_Model_ls)], CV_LOOCV)
End &amp;lt;- Sys.time()
End - Begin
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 9.41841 secs
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_LOOCV_ls, &amp;quot;[[&amp;quot;, &amp;quot;results&amp;quot;)[-1, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          Comp_Flock.Size Comp_Full Full     
## RMSE     1.894279        1.865854  1.609296 
## Rsquared 0.7829992       0.7894634 0.8433834
## MAE      1.520181        1.492409  1.279003
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unsurprisingly, our full model has the lowest RMSE (which is the mark of a good model).&lt;/p&gt;
&lt;p&gt;So what about our mixed effect model? Luckily, doing LOOCV by hand isn&amp;rsquo;t all that difficult and so we can still compute a RMSE for LOOCV for our mixed effect model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;RMSE_LOOCV &amp;lt;- rep(NA, nrow(Sparrows_df))
for (Fold_Iter in 1:nrow(Sparrows_df)) {
  Iter_mod &amp;lt;- update(H1_Model_ls$Mixed_Full, data = Sparrows_df[-Fold_Iter, ])
  Prediction &amp;lt;- predict(Iter_mod, newdata = Sparrows_df[Fold_Iter, ])
  RMSE_LOOCV[Fold_Iter] &amp;lt;- (Sparrows_df[Fold_Iter, ]$Weight - Prediction)^2
}
mean(RMSE_LOOCV)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.757373
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ouh&amp;hellip; that is quite worse than out other models. Curious. This goes to show how much less robust a more complex model can be.&lt;/p&gt;
&lt;h4 id=&#34;k-fold-cross-validation-k-fold-cv&#34;&gt;k-Fold Cross-Validation (k-fold CV)&lt;/h4&gt;
&lt;p&gt;k-Fold Cross-Validation uses the same concept as all of the previous cross-validation methods, but at less of a computational cost than LOOCV and more robustly than the training/test data approach:&lt;/p&gt;
&lt;p&gt;Again, I write a function for this and run it on my list of models without the mixed effect model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;CV_kFold &amp;lt;- function(x) {
  if (length(x[[&amp;quot;terms&amp;quot;]][[3]]) == 1) {
    Terms &amp;lt;- paste(x[[&amp;quot;terms&amp;quot;]][[3]], collapse = &amp;quot; + &amp;quot;)
  } else {
    Terms &amp;lt;- paste(x[[&amp;quot;terms&amp;quot;]][[3]][-1], collapse = &amp;quot; + &amp;quot;)
  }
  train(as.formula(paste(&amp;quot;Weight ~&amp;quot;, Terms)),
    data = Sparrows_df,
    method = &amp;quot;lm&amp;quot;,
    trControl = trainControl(method = &amp;quot;cv&amp;quot;, number = 15)
  )
}
Begin &amp;lt;- Sys.time()
H1_kFold_ls &amp;lt;- sapply(H1_Model_ls[-length(H1_Model_ls)], CV_kFold)
End &amp;lt;- Sys.time()
End - Begin
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 0.3413441 secs
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_kFold_ls, &amp;quot;[[&amp;quot;, &amp;quot;results&amp;quot;)[-1, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Comp_Flock.Size Comp_Full  Full      
## RMSE       1.889439        1.859135   1.603168  
## Rsquared   0.7882333       0.7942782  0.8465977 
## MAE        1.519962        1.491493   1.277595  
## RMSESD     0.1408563       0.1520344  0.1491081 
## RsquaredSD 0.03375562      0.03153792 0.03034729
## MAESD      0.1382304       0.1122565  0.1150599
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Full model performs best still and see how much quicker that was done!&lt;/p&gt;
&lt;h3 id=&#34;bootstrap&#34;&gt;Bootstrap&lt;/h3&gt;
&lt;p&gt;On to the Bootstrap. God, I love the boostrap.&lt;/p&gt;
&lt;p&gt;The idea here is to run a model multiple times on a random sample of the underlying data and then store all of the estimates or the parameters as well as avaerage out the RMSE:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;BootStrap &amp;lt;- function(x) {
  if (length(x[[&amp;quot;terms&amp;quot;]][[3]]) == 1) {
    Terms &amp;lt;- paste(x[[&amp;quot;terms&amp;quot;]][[3]], collapse = &amp;quot; + &amp;quot;)
  } else {
    Terms &amp;lt;- paste(x[[&amp;quot;terms&amp;quot;]][[3]][-1], collapse = &amp;quot; + &amp;quot;)
  }
  train(as.formula(paste(&amp;quot;Weight ~&amp;quot;, Terms)),
    data = Sparrows_df,
    method = &amp;quot;lm&amp;quot;,
    trControl = trainControl(method = &amp;quot;boot&amp;quot;, number = 100)
  )
}
Begin &amp;lt;- Sys.time()
H1_BootStrap_ls &amp;lt;- sapply(H1_Model_ls[-length(H1_Model_ls)], BootStrap)
End &amp;lt;- Sys.time()
End - Begin
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 1.308739 secs
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_BootStrap_ls, &amp;quot;[[&amp;quot;, &amp;quot;results&amp;quot;)[-1, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Comp_Flock.Size Comp_Full  Full      
## RMSE       1.893652        1.871873   1.622079  
## Rsquared   0.7835412       0.7896534  0.8425108 
## MAE        1.520457        1.498216   1.288087  
## RMSESD     0.04675792      0.05178669 0.04885059
## RsquaredSD 0.01243994      0.01318599 0.01092356
## MAESD      0.04287091      0.04531032 0.03910463
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The full model is still doing great, of course.&lt;/p&gt;
&lt;p&gt;But what about our mixed effect model? Luckily, there is a function that can do bootstrapping for us on our &lt;code&gt;lme&lt;/code&gt; objects:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Bootstrap mixed model
Mixed_boot &amp;lt;- lmeresampler::bootstrap(H1_Model_ls[[length(H1_Model_ls)]], .f = fixef, type = &amp;quot;parametric&amp;quot;, B = 3e3)
Mixed_boot
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Bootstrap type: parametric 
## 
## Number of resamples: 3000 
## 
##                           term      observed      rep.mean          se          bias
## 1                  (Intercept)  2.212717e+01 22.0672111291 2.853845096 -0.0599612233
## 2       Predator.TypeNon-Avian  6.626664e-01  0.6580310750 0.161081567 -0.0046353000
## 3            Predator.TypeNone  2.694373e-02  0.0212966961 0.152739708 -0.0056470340
## 4                   Flock.Size  1.497092e-05  0.0005839265 0.019216411  0.0005689556
## 5             Home.RangeMedium  1.261878e+00  1.2675791500 0.881426872  0.0057008365
## 6              Home.RangeSmall  3.049068e+00  3.0583903125 0.417796779  0.0093225898
## 7                         TAvg  3.015153e-02  0.0303345903 0.009892483  0.0001830556
## 8                          TSD  1.983744e-01  0.1984962823 0.021196164  0.0001219321
## 9  Flock.Size:Home.RangeMedium -1.208598e-01 -0.1213017777 0.057929474 -0.0004419594
## 10  Flock.Size:Home.RangeSmall -2.110972e-01 -0.2117971129 0.019731749 -0.0006998822
## 
## There were 0 messages, 0 warnings, and 0 errors.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this, we are getting into the heart of the bootstrap. Distributions of our parameter estimates. These give us an amazing understanding of just which parameter values our model sees as plausible given our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Estimates_df &amp;lt;- data.frame(Mixed_boot[[&amp;quot;replicates&amp;quot;]])
## reshape estimates data frame for plotting
Hist_df &amp;lt;- data.frame(pivot_longer(
  data = Estimates_df,
  cols = colnames(Estimates_df)
))
## plot parameter estimate distributions
ggplot(data = Hist_df, aes(x = value, group = name)) +
  tidybayes::stat_pointinterval() +
  tidybayes::stat_dots() +
  facet_wrap(~name, scales = &amp;quot;free&amp;quot;) +
  labs(
    x = &amp;quot;Parameter Estimate&amp;quot;, y = &amp;quot;Parameter&amp;quot;,
    title = paste(&amp;quot;Bootstrap parameter estimates of&amp;quot;, names(H1_Model_ls[[length(H1_Model_ls)]]), &amp;quot;Model&amp;quot;)
  ) +
  theme_bw()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-30-1.png&#34; width=&#34;1440&#34; /&gt;
As you can see for our mixed effect model, while most parameter estimates are nicely constrained, the Intercept estimate can vary wildly. This is likely to do with our model being very flexible and allowing for a bunch of different combinations of intercepts.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s do the same for our remaining three candidate models:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;BootPlot_ls &amp;lt;- as.list(rep(NA, (length(H1_Model_ls) - 1)))
for (Model_Iter in 1:(length(H1_Model_ls) - 1)) { # loop over all models except the null model
  ## Formula to compute coefficients
  x &amp;lt;- H1_Model_ls[[Model_Iter]]
  if (length(x[[&amp;quot;terms&amp;quot;]][[3]]) == 1) {
    Terms &amp;lt;- as.character(x[[&amp;quot;terms&amp;quot;]][[3]])
  } else {
    Terms &amp;lt;- paste(as.character(x[[&amp;quot;terms&amp;quot;]][[3]])[-1], collapse = as.character(x[[&amp;quot;terms&amp;quot;]][[3]])[1])
  }
  model_coef &amp;lt;- function(data, index) {
    coef(lm(as.formula(paste(&amp;quot;Weight ~&amp;quot;, Terms)), data = data, subset = index))
  }
  ## Bootstrapping
  Boot_test &amp;lt;- boot(data = Sparrows_df, statistic = model_coef, R = 3e3)
  ## set column names of estimates to coefficients
  colnames(Boot_test[[&amp;quot;t&amp;quot;]]) &amp;lt;- names(H1_Model_ls[[Model_Iter]][[&amp;quot;coefficients&amp;quot;]])
  ## make data frame of estimates
  Estimates_df &amp;lt;- data.frame(Boot_test[[&amp;quot;t&amp;quot;]])
  ## reshape estimates data frame for plotting
  Hist_df &amp;lt;- data.frame(pivot_longer(
    data = Estimates_df,
    cols = colnames(Estimates_df)
  ))
  ## plot parameter estimate distributions
  BootPlot_ls[[Model_Iter]] &amp;lt;- ggplot(data = Hist_df, aes(x = value, group = name)) +
    tidybayes::stat_pointinterval() +
    tidybayes::stat_dots() +
    facet_wrap(~name, scales = &amp;quot;free&amp;quot;) +
    labs(
      x = &amp;quot;Parameter Estimate&amp;quot;, y = &amp;quot;Parameter&amp;quot;,
      title = paste(&amp;quot;Bootstrap parameter estimates of&amp;quot;, names(H1_Model_ls)[[Model_Iter]], &amp;quot;Model&amp;quot;),
      subtitle = paste(&amp;quot;Weight ~&amp;quot;, Terms)
    ) +
    theme_bw()
}
BootPlot_ls[[1]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;BootPlot_ls[[2]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-31-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;BootPlot_ls[[3]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-31-3.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;subset-selection&#34;&gt;Subset Selection&lt;/h2&gt;
&lt;p&gt;So far, we have built our own models according to out intuition. Did we test all possible models? No. Should we go back and test all possible models by hand? Hell no! Can we let &lt;code&gt;R&lt;/code&gt; do it for us? You bet we can!&lt;/p&gt;
&lt;h3 id=&#34;best-subset-selection&#34;&gt;Best Subset Selection&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start with best subset selection. Doing so asks us/&lt;code&gt;R&lt;/code&gt; to establish all possible models and then select the one that performs best according to information criteria. Because our data set contains over 20 variables, including all of our variables would have us establish close to 1 million (you read that right) models. THat is, of course, infeasible.&lt;/p&gt;
&lt;p&gt;Therefore, let&amp;rsquo;s just allow our subset selection to use all variables we have used ourselves thus far (with the exclusion of &lt;code&gt;Index&lt;/code&gt; because it&amp;rsquo;s an amazing, but ultimately useless shorthand):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Reduced_df &amp;lt;- Sparrows_df[, c(&amp;quot;Weight&amp;quot;, &amp;quot;Climate&amp;quot;, &amp;quot;TAvg&amp;quot;, &amp;quot;TSD&amp;quot;, &amp;quot;Population.Status&amp;quot;, &amp;quot;Flock.Size&amp;quot;, &amp;quot;Predator.Type&amp;quot;, &amp;quot;Predator.Presence&amp;quot;)] # reduce data
model &amp;lt;- lm(Weight ~ ., data = Reduced_df) # specify full model
k &amp;lt;- ols_step_best_subset(model) # create all models and select the best
k # show us comparison of best subsets
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                   Best Subsets Regression                                   
## --------------------------------------------------------------------------------------------
## Model Index    Predictors
## --------------------------------------------------------------------------------------------
##      1         Flock.Size                                                                    
##      2         Climate Flock.Size                                                            
##      3         Climate TAvg Flock.Size                                                       
##      4         Climate TAvg Flock.Size Predator.Type                                         
##      5         Climate TAvg TSD Flock.Size Predator.Type                                     
##      6         Climate TAvg TSD Population.Status Flock.Size Predator.Type                   
##      7         Climate TAvg TSD Population.Status Flock.Size Predator.Type Predator.Presence 
## --------------------------------------------------------------------------------------------
## 
##                                                     Subsets Regression Summary                                                    
## ----------------------------------------------------------------------------------------------------------------------------------
##                        Adj.        Pred                                                                                            
## Model    R-Square    R-Square    R-Square      C(p)         AIC       SBIC       SBC         MSEP        FPE       HSP       APC  
## ----------------------------------------------------------------------------------------------------------------------------------
##   1        0.7838      0.7836       0.783    298.7733    4389.3782      NA    4404.2932    3818.6664    3.5890    0.0034    0.2170 
##   2        0.8175      0.8169      0.8163     88.8025    4212.8692      NA    4237.7276    3226.8597    3.0384    0.0029    0.1836 
##   3        0.8227      0.8220      0.8213     58.0852    4184.0693      NA    4213.8994    3137.9149    2.9575    0.0028    0.1787 
##   4        0.8315      0.8305      0.8296      4.5702    4133.6815      NA    4173.4549    2984.6456    2.8183    0.0026    0.1701 
##   5        0.8320      0.8309      0.8298      3.3977    4132.4880      NA    4177.2330    2978.5274    2.8151    0.0026    0.1699 
##   6        0.8320      0.8308      0.8296      5.0000    4134.0870      NA    4183.8036    2980.2214    2.8194    0.0026    0.1702 
##   7        0.8320      0.8308      0.8296      5.0000    4136.0870      NA    4190.7753    2980.2214    2.8194    0.0026    0.1702 
## ----------------------------------------------------------------------------------------------------------------------------------
## AIC: Akaike Information Criteria 
##  SBIC: Sawa&#39;s Bayesian Information Criteria 
##  SBC: Schwarz Bayesian Criteria 
##  MSEP: Estimated error of prediction, assuming multivariate normality 
##  FPE: Final Prediction Error 
##  HSP: Hocking&#39;s Sp 
##  APC: Amemiya Prediction Criteria
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Model 5 (&lt;code&gt;Climate TAvg TSD Flock.Size Predator.Type &lt;/code&gt;) is the one we want to go for here.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at visualisation of our different model selection criteria:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(k)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;1440&#34; /&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-33-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;forward-subset-selection&#34;&gt;Forward Subset Selection&lt;/h3&gt;
&lt;p&gt;Ok. So best subset selection can become intractable given a lot of variables. How about building our models up to be increasingly complex until we hit on gold?&lt;/p&gt;
&lt;p&gt;Unfortunately, doing so does not guarantee finding an optimal model and can easily get stuck, depending on what the model starts off with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(Weight ~ Climate, data = Reduced_df)
step.model &amp;lt;- stepAIC(model,
  direction = &amp;quot;forward&amp;quot;,
  trace = FALSE
)
summary(step.model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Climate, data = Reduced_df)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.020 -2.033  1.050  2.640  6.610 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)          28.3998     0.1248 227.628  &amp;lt; 2e-16 ***
## ClimateContinental    4.9785     0.3188  15.616  &amp;lt; 2e-16 ***
## ClimateSemi-Coastal   3.3400     0.4606   7.252  7.9e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.629 on 1063 degrees of freedom
## Multiple R-squared:  0.2059,	Adjusted R-squared:  0.2044 
## F-statistic: 137.8 on 2 and 1063 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We immediately remain on &lt;code&gt;Climate&lt;/code&gt; as the only predictor in this example.&lt;/p&gt;
&lt;p&gt;What if we start with a true null model?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(Weight ~ 1, data = Reduced_df)
step.model &amp;lt;- stepAIC(model,
  direction = &amp;quot;forward&amp;quot;,
  trace = FALSE
)
summary(step.model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ 1, data = Reduced_df)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.944 -1.452  1.291  2.913  7.336 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  29.3243     0.1246   235.3   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.068 on 1065 degrees of freedom
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We even get stuck on our null model!&lt;/p&gt;
&lt;h3 id=&#34;backward-subset-selection&#34;&gt;Backward Subset Selection&lt;/h3&gt;
&lt;p&gt;So what about making our full model simpler?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(Weight ~ ., data = Reduced_df)
step.model &amp;lt;- stepAIC(model,
  direction = &amp;quot;backward&amp;quot;,
  trace = FALSE
)
summary(step.model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type, 
##     data = Reduced_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.2398 -1.1180  0.1215  1.1474  4.9151 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)            53.505428   3.748484  14.274  &amp;lt; 2e-16 ***
## ClimateContinental      2.978894   0.301131   9.892  &amp;lt; 2e-16 ***
## ClimateSemi-Coastal    -0.640161   0.310970  -2.059   0.0398 *  
## TAvg                   -0.068582   0.012713  -5.395 8.47e-08 ***
## TSD                    -0.069306   0.038900  -1.782   0.0751 .  
## Flock.Size             -0.189607   0.005122 -37.019  &amp;lt; 2e-16 ***
## Predator.TypeNon-Avian  0.379606   0.161332   2.353   0.0188 *  
## Predator.TypeNone       1.258391   0.165347   7.611 6.02e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.673 on 1058 degrees of freedom
## Multiple R-squared:  0.832,	Adjusted R-squared:  0.8309 
## F-statistic: 748.4 on 7 and 1058 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interesting. This time, we have hit on the same model that was identified by the best subset selection above.&lt;/p&gt;
&lt;h3 id=&#34;forward--backward&#34;&gt;Forward &amp;amp; Backward&lt;/h3&gt;
&lt;p&gt;Can we combine the directions of stepwise model selection? Yes, we can:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(Weight ~ ., data = Reduced_df)
step.model &amp;lt;- stepAIC(model,
  direction = &amp;quot;both&amp;quot;,
  trace = FALSE
)
summary(step.model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type, 
##     data = Reduced_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.2398 -1.1180  0.1215  1.1474  4.9151 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)            53.505428   3.748484  14.274  &amp;lt; 2e-16 ***
## ClimateContinental      2.978894   0.301131   9.892  &amp;lt; 2e-16 ***
## ClimateSemi-Coastal    -0.640161   0.310970  -2.059   0.0398 *  
## TAvg                   -0.068582   0.012713  -5.395 8.47e-08 ***
## TSD                    -0.069306   0.038900  -1.782   0.0751 .  
## Flock.Size             -0.189607   0.005122 -37.019  &amp;lt; 2e-16 ***
## Predator.TypeNon-Avian  0.379606   0.161332   2.353   0.0188 *  
## Predator.TypeNone       1.258391   0.165347   7.611 6.02e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.673 on 1058 degrees of freedom
## Multiple R-squared:  0.832,	Adjusted R-squared:  0.8309 
## F-statistic: 748.4 on 7 and 1058 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, we land on our best subset selection model!&lt;/p&gt;
&lt;h3 id=&#34;subset-selection-vs-our-intuition&#34;&gt;Subset Selection vs. Our Intuition&lt;/h3&gt;
&lt;p&gt;Given our best subset selection, we have a very good idea of which model to go for.&lt;/p&gt;
&lt;p&gt;To see how well said model shapes up against our full model, we can simply look at LOOCV:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train(Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type,
  data = Sparrows_df,
  method = &amp;quot;lm&amp;quot;,
  trControl = trainControl(method = &amp;quot;LOOCV&amp;quot;)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear Regression 
## 
## 1066 samples
##    5 predictor
## 
## No pre-processing
## Resampling: Leave-One-Out Cross-Validation 
## Summary of sample sizes: 1065, 1065, 1065, 1065, 1065, 1065, ... 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   1.677673  0.8297908  1.338399
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sapply(H1_LOOCV_ls, &amp;quot;[[&amp;quot;, &amp;quot;results&amp;quot;)[-1, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          Comp_Flock.Size Comp_Full Full     
## RMSE     1.894279        1.865854  1.609296 
## Rsquared 0.7829992       0.7894634 0.8433834
## MAE      1.520181        1.492409  1.279003
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And our full model still wins! But why? Didn&amp;rsquo;t we test for all models? Yes, we tested for all additive models, but our Full model contains an interaction terms which the automated functions above just cannot handle, sadly.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s ask a completely different question. Would we have even adopted the best subset selection model if we had thought of it given the assumptions of a linear regression?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow = c(2, 2))
plot(lm(Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type, data = Sparrows_df))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;7_Model-Selection-and-Statistical-Significance---Reporting-the-Best-Science_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As it turns out, this is a perfectly reasonable model. It&amp;rsquo;s just not as good as our full model.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nominal Tests</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/nominal-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/nominal-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our second practical experience in &lt;code&gt;R&lt;/code&gt;. Throughout the following notes, I will introduce you to a couple nominal statistical test approaches that might be useful to you and are often used in biology.&lt;br&gt;
To do so, I will enlist the sparrow data set we handled in our last exercise.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/08---Nominal-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;nonpar&amp;quot;, # needed for Cochran&#39;s Q
                 &amp;quot;ggplot2&amp;quot;) # data visualisation
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: nonpar
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  nonpar ggplot2 
##    TRUE    TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our last exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;binomial-test&#34;&gt;Binomial Test&lt;/h2&gt;
&lt;p&gt;As the name would suggest, a binomial test can only accommodate variables on a binomial scale. A binomial test is used to test whether both values of the binomial variable are present in equal proportions within the data set. The only binomial variables contained within the &lt;em&gt;Passer domesticus&lt;/em&gt; data set are &lt;code&gt;Sex&lt;/code&gt; (Male, Female) and &lt;code&gt;Predator.Presence&lt;/code&gt; (Yes, No). The &lt;code&gt;R&lt;/code&gt; function to carry out a binomial test comes with base &lt;code&gt;R&lt;/code&gt; and is called &lt;code&gt;binom.test()&lt;/code&gt;. The &lt;strong&gt;Null Hypothesis&lt;/strong&gt; we operate on is that &lt;strong&gt;both data values are equally likely to occur&lt;/strong&gt; although one can specify a different expectations using the &lt;code&gt;p = &lt;/code&gt; statement within the &lt;code&gt;binom.test()&lt;/code&gt; function.&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are the sexes represented in equal proportions?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, we want to test whether our data has a bias leaning towards either sex of the surveyed sparrows. To do so, we may wish to first convert the binomial data into count records using the &lt;code&gt;table()&lt;/code&gt; command of R as follows. The result of this can then be feed to &lt;code&gt;binom.test()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Female   Male 
##    523    544
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(table(Data_df$Sex))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  table(Data_df$Sex)
## number of successes = 523, number of trials = 1067, p-value = 0.5404
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4597580 0.5206151
## sample estimates:
## probability of success 
##              0.4901593
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, there is no skew towards either male or female abundance of individuals of &lt;em&gt;Passer domesticus&lt;/em&gt; and so we have to &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;. Note that, although our data is recorded in terms of Male and Female, the &lt;code&gt;binom.test()&lt;/code&gt; function works with records of success and failure.&lt;/p&gt;
&lt;p&gt;This is to be expected. After all no bias for sex is known in &lt;em&gt;Passer domesticus&lt;/em&gt; and indeed the species does reproduce monogamously so a skew between the sexes wouldn&amp;rsquo;t go anywhere as far as evolution is concerned.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are the sites dominated by predators?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s see if there is a skew towards predators being present at our sites or not. This time, however we make use of a different syntax for the &lt;code&gt;binom.test()&lt;/code&gt; function. We do this for no reason of functionality but simply to show that there are multiple ways to using it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  No Yes 
## 357 710
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(x = sum(Data_df$Predator.Presence == &amp;quot;Yes&amp;quot;), n = length(Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  sum(Data_df$Predator.Presence == &amp;quot;Yes&amp;quot;) and length(Data_df$Predator.Presence)
## number of successes = 710, number of trials = 1067, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.6362102 0.6937082
## sample estimates:
## probability of success 
##              0.6654171
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, these proportions aren&amp;rsquo;t as equal as the ones of the sex example. In fact, they exhibit statistically significant proportion sizes within our data set (p $\approx$ 0).&lt;/p&gt;
&lt;p&gt;This is in concordance with what we&amp;rsquo;d expect from the natural world since predation is common in nature after all and so we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;mcnemar&#34;&gt;McNemar&lt;/h2&gt;
&lt;p&gt;The McNemar Test (sometimes referred to as McNemar&amp;rsquo;s Chi-Square test because the test statistic has a chi-square distribution) is used when you are interested in finding a change in proportion for paired data. This is very common in repeated sampling analyses.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;null hypothesis&lt;/strong&gt; reads: &lt;strong&gt;Class assignment probabilities do not change within different treatments&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-the-data&#34;&gt;Preparing The Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do sex ratios change over time?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, our data does not allow for these types of analyses and so we will need to create some additional data here.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say we wanted to resample the sex ratio of &lt;em&gt;Passer domesticus&lt;/em&gt; in Australia (AU) a year after our initial survey because of an especially hostile winter and we&amp;rsquo;d like to see whether this resulted in an alteration of the sex ratio.&lt;/p&gt;
&lt;p&gt;What is our sex ratio before the winter?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Sex[which(Data_df$Index == &amp;quot;AU&amp;quot;)])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Female   Male 
##     44     44
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sexes_AU_Now_vec &amp;lt;- Data_df$Sex[which(Data_df$Index == &amp;quot;AU&amp;quot;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sex ratio is not skewed. So let&amp;rsquo;s hypothesise about what might happen to the sex ratio when a strong winter hits our population. The sex ratio could either (1) stay the same or (2) change. Although it would make sense to assume that the population would shrink, McNemar tests can&amp;rsquo;t account for that and so we assume that our population size will stay the same and only the sex ratio might change. Let&amp;rsquo;s create some new data for a changed sex ratio that is male biased:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sexes &amp;lt;- c(&amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;) # creating a vector of sexes to sample from
set.seed(42) # making it reproducible
Sexes_AU_Next_vec &amp;lt;- sample(Sexes, sum(Data_df$Index==&amp;quot;AU&amp;quot;), replace = TRUE, prob = c(0.8,0.2))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s the data we will be testing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Sexes_AU_Now_vec) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Sexes_AU_Now_vec
## Female   Male 
##     44     44
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Sexes_AU_Next_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Sexes_AU_Next_vec
## Female   Male 
##     21     67
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;running-the-test&#34;&gt;Running The Test&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s go on to test the unbiased vs. the male-skewed sex ratio:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mcnemar_matrix_change &amp;lt;- matrix(rbind(table(Sexes_AU_Now_vec), table(Sexes_AU_Next_vec)), 2)
mcnemar.test(mcnemar_matrix_change)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	McNemar&#39;s Chi-squared test with continuity correction
## 
## data:  mcnemar_matrix_change
## McNemar&#39;s chi-squared = 7.4462, df = 1, p-value = 0.006357
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously, with this data we would record a statistically significant change and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;making-sense-of-the-results&#34;&gt;Making Sense Of The Results&lt;/h3&gt;
&lt;p&gt;Unfortunately, McNemar only tells us &lt;em&gt;that&lt;/em&gt; there is a difference without any information about the &lt;em&gt;direction&lt;/em&gt; of the difference. For now, we will have to settle on a visualisation of the sexes to shed some light on the difference.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# preparing plotting
plot_df &amp;lt;- data.frame(Data = c(prop.table(mcnemar_matrix_change[1,]),
                               prop.table(mcnemar_matrix_change[2,])),
                      Identifiers = rep(c(&amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;), 2),
                      Year = rep(c(&amp;quot;Now&amp;quot;, &amp;quot;Next Year&amp;quot;), each = 2))
# plotting
ggplot(plot_df, aes(x = Year, y = Data, fill = Identifiers)) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  ggtitle(label = &amp;quot;Abundances of the sexes among study organisms&amp;quot;) + theme_bw() +
  ylab(&amp;quot;Proportion&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;08---Nominal-Tests_files/figure-html/McNemar6-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above plot is very crude and should only ever be used for data exploration and not for publishing purposes. Clearly, we can see the change in sex ratio towards a male-biased state (blue colour represents males).&lt;/p&gt;
&lt;h2 id=&#34;cochrans-q&#34;&gt;Cochran&amp;rsquo;s Q&lt;/h2&gt;
&lt;p&gt;Cochran&amp;rsquo;s Q is a non parametric test for finding differences in matched sets of three or more frequencies or proportions.&lt;/p&gt;
&lt;p&gt;As such, the Cochran&amp;rsquo;s Q Test is an extension of the McNemar test - the two tests are equal if Cochran&amp;rsquo;s Q is calculated for two groups.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;null hypothesis&lt;/strong&gt; for Cochran&amp;rsquo;s Q postulates an &lt;strong&gt;equal proportion of class assignents for all treatments&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-the-data-1&#34;&gt;Preparing The Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are colours related to sex or predator parameters?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When exploring our data, we can clearly see a pattern concerning the colour polymorphism of house sparrows arise which is dependant on the value of Predator Presence.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;counts &amp;lt;- table(Data_df$Colour, Data_df$Predator.Presence)
# preparing plotting
plot_df &amp;lt;- data.frame(Data = c(prop.table(counts[,1]), prop.table(counts[,2])),
                      Identifiers = rep(c(&amp;quot;Black&amp;quot;, &amp;quot;Brown&amp;quot;, &amp;quot;Grey&amp;quot;), 2),
                      Predation = rep(c(&amp;quot;No&amp;quot;, &amp;quot;Yes&amp;quot;), each = 3))
# plotting
ggplot(plot_df, aes(x = Predation, y = Data, fill = Identifiers)) + geom_bar(stat=&amp;quot;identity&amp;quot;) + ggtitle(label = &amp;quot;Colour Variations of the common House Sparrow&amp;quot;) + theme_bw() +ylab(&amp;quot;Proportions&amp;quot;) + scale_fill_manual(values=c(&amp;quot;black&amp;quot;, &amp;quot;saddlebrown&amp;quot;, &amp;quot;grey&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;08---Nominal-Tests_files/figure-html/ChochranPrep-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This might lead us to believe that the presence of predators cause an evolutionary change of the plumage colour of &lt;em&gt;Passer domesticus&lt;/em&gt; (we will have a more in-depth look on this in later seminars) and we might even postulate that &amp;ldquo;Black&amp;rdquo; and &amp;ldquo;Grey&amp;rdquo; serve as camouflage.&lt;/p&gt;
&lt;p&gt;Cochran&amp;rsquo;s Q requires data to be delivered as binomial records. Therefore, we prepare colour as a binary variable of &amp;ldquo;Brown&amp;rdquo; and &amp;ldquo;Camouflage&amp;rdquo; (which we postulate to encompass &amp;ldquo;Grey&amp;rdquo; and &amp;ldquo;Black&amp;rdquo;). Since Colour is of type &lt;code&gt;factor&lt;/code&gt; within our data set, we need to take some precautions in changing the data records. Predator Presence and Sex don&amp;rsquo;t need any additional preparation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Colour 
CochColour &amp;lt;- Data_df_base$Colour
# adding new level to factor list
levels(CochColour) &amp;lt;- c(levels(CochColour), &amp;quot;Camouflage&amp;quot;) 
# defining black and grey to be camouflage
CochColour[which(CochColour == &amp;quot;Grey&amp;quot;)] &amp;lt;- &amp;quot;Camouflage&amp;quot; 
CochColour[which(CochColour == &amp;quot;Black&amp;quot;)] &amp;lt;- &amp;quot;Camouflage&amp;quot; 
# dropping unnecessary factor levels
CochColour &amp;lt;- droplevels(CochColour) 

# Predator Presence
CochPredator.Presence &amp;lt;- factor(Data_df_base$Predator.Presence)

# Sex
CochSex &amp;lt;- factor(Data_df_base$Sex)

# Making vectors into a matrix
CochMatrix &amp;lt;- matrix(c(CochColour, CochPredator.Presence, CochSex), ncol = 3) - 1
colnames(CochMatrix) &amp;lt;- c(&amp;quot;Colour&amp;quot;, &amp;quot;Predator Presence&amp;quot;, &amp;quot;Sex&amp;quot;)
head(CochMatrix)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Colour Predator Presence Sex
## [1,]      0                 1   1
## [2,]      1                 1   1
## [3,]      1                 1   0
## [4,]      0                 1   0
## [5,]      1                 1   1
## [6,]      0                 1   0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;runing-the-test&#34;&gt;Runing The Test&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s run our test using the &lt;code&gt;cochrans.q()&lt;/code&gt; function that comes with the &lt;code&gt;nonpar&lt;/code&gt; package:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cochrans.q(CochMatrix)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Cochran&#39;s Q Test 
##  
##  H0: There is no difference in the effectiveness of treatments. 
##  HA: There is a difference in the effectiveness of treatments. 
##  
##  Q = 122.984939759036 
##  
##  Degrees of Freedom = 2 
##  
##  Significance Level = 0.05 
##  The p-value is  0 
##  There is enough evidence to conclude that the effectiveness of at least two treatments differ. 
## 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the output from this function is extremely user friendly. Additionally, as was to be expected the assignment probabilities for each class in each treatment are not equal thus forcing us to &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;making-sense-of-the-results-1&#34;&gt;Making Sense Of The Results&lt;/h3&gt;
&lt;p&gt;Where are the differences coming from?&lt;/p&gt;
&lt;p&gt;As you may recall from just a few pages ago, using the binomial test, we can identify the assignment proportions for any binomial variable individually.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Firstly&lt;/em&gt;, let&amp;rsquo;s test the &lt;strong&gt;binary version&lt;/strong&gt; of the &lt;strong&gt;colour&lt;/strong&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(CochColour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## CochColour
##      Brown Camouflage 
##        298        769
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(table(CochColour))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  table(CochColour)
## number of successes = 298, number of trials = 1067, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.2525387 0.3072599
## sample estimates:
## probability of success 
##              0.2792877
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this result, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; of binary colour records being equally likely to occur.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Secondly&lt;/em&gt;, let&amp;rsquo;s test the &lt;strong&gt;predator presence&lt;/strong&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(CochPredator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## CochPredator.Presence
##  No Yes 
## 357 710
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(table(CochPredator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  table(CochPredator.Presence)
## number of successes = 357, number of trials = 1067, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.3062918 0.3637898
## sample estimates:
## probability of success 
##              0.3345829
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this result, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; of predator presence records being equally likely to occur.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Lastly&lt;/em&gt;, recall the binomial test run on the &lt;strong&gt;sex&lt;/strong&gt; data records which exhibit an almost even 50/50 split.&lt;/p&gt;
&lt;p&gt;Whilst none of these test give us any idea about the overlap of similar assignments along these variable vectors, a 50/50 split (sex) can never link up comparably with a roughly 30/70 split (predator presence and binary colour). Therefore, we could hypothesize a linkage of predator presence and colour rather than sex and colour morphs.&lt;/p&gt;
&lt;h2 id=&#34;chi-squared&#34;&gt;Chi-Squared&lt;/h2&gt;
&lt;p&gt;The Chi-Squared (also known as $Chi^2$) Test can be regarded as a functional extension of the binomial test and is used to test the similarity of class assignment proportions for a categorical/nominal variable. Unlike the binomial test, however, this test is not constrained to binomial records alone.&lt;/p&gt;
&lt;p&gt;The null hypothesis states that: &lt;strong&gt;Every class assignment contained within a given variable is equally likely&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The Chi-Squared Test can be applied in a one or two sample situation. One sample represents one variable in this setting.&lt;/p&gt;
&lt;h3 id=&#34;one-sample-situation&#34;&gt;One Sample Situation&lt;/h3&gt;
&lt;h4 id=&#34;binary-colour&#34;&gt;Binary Colour&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses the proportions of one variable we have already looked at - the &lt;strong&gt;binary version&lt;/strong&gt; of the &lt;strong&gt;colour&lt;/strong&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(CochColour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## CochColour
##      Brown Camouflage 
##        298        769
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(CochColour))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Chi-squared test for given probabilities
## 
## data:  table(CochColour)
## X-squared = 207.91, df = 1, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this result, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; of binary colour records being equally likely to occur. Note how the Chi-Squared test returns the same p-value as the binomial test above (within the Cochran&amp;rsquo;s Q section).&lt;/p&gt;
&lt;h4 id=&#34;colour&#34;&gt;Colour&lt;/h4&gt;
&lt;p&gt;Now let&amp;rsquo;s run the same test on the non-binary &lt;strong&gt;colour&lt;/strong&gt; data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Black Brown  Grey 
##   356   298   413
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Chi-squared test for given probabilities
## 
## data:  table(Data_df$Colour)
## X-squared = 18.592, df = 2, p-value = 9.178e-05
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; thus concluding differing class proportions for every possible class of &amp;ldquo;Colour&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;two-sample-situation&#34;&gt;Two Sample Situation&lt;/h3&gt;
&lt;p&gt;The two sample Chi-Squared approach lets us identify whether class assignment proportions of one variable differ when they are considered in a dependency of another nominal variable.&lt;/p&gt;
&lt;h4 id=&#34;sexual-dimorphism-1&#34;&gt;Sexual Dimorphism&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Are colours of Passer domesticus related to their sexes?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Firstly&lt;/em&gt;, let&amp;rsquo;s see if males and females share the same likelihoods of being of a certain colour:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Female Male
##   Black    320   36
##   Brown    122  176
##   Grey      81  332
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour, Data_df$Sex))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  table(Data_df$Colour, Data_df$Sex)
## X-squared = 388.63, df = 2, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly, they don&amp;rsquo;t and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;predation-1&#34;&gt;Predation&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Are colours of Passer domesticus related to predator parameters?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Secondly&lt;/em&gt;, we test whether colour proportions change when considering predator presence. Although we partially considered this already in the Cochran&amp;rsquo;s Q section. This time, however, we use a non-binary version of the colour variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Black  64 292
##   Brown 211  87
##   Grey   82 331
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  table(Data_df$Colour, Data_df$Predator.Presence)
## X-squared = 259.34, df = 2, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The statement holds. Predator presence seems likely to be a driver of the colour polymorphism in &lt;em&gt;Passer domesticus&lt;/em&gt; and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So what about a possible link of sparrow colour and predator type?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Black   197        95
##   Brown    60        27
##   Grey    233        98
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  table(Data_df$Colour, Data_df$Predator.Type)
## X-squared = 0.62164, df = 2, p-value = 0.7328
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nope, no link here. We have to &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and conclude that there may be no causal link of predator type and sparrow colour.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are nesting sites of Passer domesticus related to predator parameters?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Third&lt;/em&gt;, let&amp;rsquo;s test whether nesting site assignments might differ based on predator presence:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Shrub  87 205
##   Tree   94 137
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  table(Data_df$Nesting.Site, Data_df$Predator.Presence)
## X-squared = 6.2955, df = 1, p-value = 0.0121
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There seems to be a link here and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So what about a link of predator type and nesting site?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Shrub   182        23
##   Tree     49        88
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  table(Data_df$Nesting.Site, Data_df$Predator.Type)
## X-squared = 102.88, df = 1, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, there is a really strong one and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nominal Tests</title>
      <link>https://www.erikkusch.com/courses/biostat101/nominal-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/nominal-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our second practical experience in &lt;code&gt;R&lt;/code&gt;. Throughout the following notes, I will introduce you to a couple nominal statistical test approaches that might be useful to you and are often used in biology. To do so, I will enlist the sparrow data set we handled in our last exercise. I have prepared some slides for this session: &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/08---Nominal-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/08---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;nonpar&amp;quot;, # needed for Cochran&#39;s Q
                 &amp;quot;ggplot2&amp;quot;) # data visualisation
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: nonpar
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  nonpar ggplot2 
##    TRUE    TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our last exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;binomial-test&#34;&gt;Binomial Test&lt;/h2&gt;
&lt;p&gt;As the name would suggest, a binomial test can only accommodate variables on a binomial scale. A binomial test is used to test whether both values of the binomial variable are present in equal proportions within the data set. The only binomial variables contained within the &lt;em&gt;Passer domesticus&lt;/em&gt; data set are &lt;code&gt;Sex&lt;/code&gt; (Male, Female) and &lt;code&gt;Predator.Presence&lt;/code&gt; (Yes, No). The &lt;code&gt;R&lt;/code&gt; function to carry out a binomial test comes with base &lt;code&gt;R&lt;/code&gt; and is called &lt;code&gt;binom.test()&lt;/code&gt;. The &lt;strong&gt;Null Hypothesis&lt;/strong&gt; we operate on is that &lt;strong&gt;both data values are equally likely to occur&lt;/strong&gt; although one can specify a different expectations using the &lt;code&gt;p = &lt;/code&gt; statement within the &lt;code&gt;binom.test()&lt;/code&gt; function.&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are the sexes represented in equal proportions?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, we want to test whether our data has a bias leaning towards either sex of the surveyed sparrows. To do so, we may wish to first convert the binomial data into count records using the &lt;code&gt;table()&lt;/code&gt; command of R as follows. The result of this can then be feed to &lt;code&gt;binom.test()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Female   Male 
##    523    544
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(table(Data_df$Sex))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  table(Data_df$Sex)
## number of successes = 523, number of trials = 1067, p-value = 0.5404
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4597580 0.5206151
## sample estimates:
## probability of success 
##              0.4901593
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, there is no skew towards either male or female abundance of individuals of &lt;em&gt;Passer domesticus&lt;/em&gt; and so we have to &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;. Note that, although our data is recorded in terms of Male and Female, the &lt;code&gt;binom.test()&lt;/code&gt; function works with records of success and failure.&lt;/p&gt;
&lt;p&gt;This is to be expected. After all no bias for sex is known in &lt;em&gt;Passer domesticus&lt;/em&gt; and indeed the species does reproduce monogamously so a skew between the sexes wouldn&amp;rsquo;t go anywhere as far as evolution is concerned.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are the sites dominated by predators?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s see if there is a skew towards predators being present at our sites or not. This time, however we make use of a different syntax for the &lt;code&gt;binom.test()&lt;/code&gt; function. We do this for no reason of functionality but simply to show that there are multiple ways to using it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  No Yes 
## 357 710
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(x = sum(Data_df$Predator.Presence == &amp;quot;Yes&amp;quot;), n = length(Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  sum(Data_df$Predator.Presence == &amp;quot;Yes&amp;quot;) and length(Data_df$Predator.Presence)
## number of successes = 710, number of trials = 1067, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.6362102 0.6937082
## sample estimates:
## probability of success 
##              0.6654171
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, these proportions aren&amp;rsquo;t as equal as the ones of the sex example. In fact, they exhibit statistically significant proportion sizes within our data set (p $\approx$ 0).&lt;/p&gt;
&lt;p&gt;This is in concordance with what we&amp;rsquo;d expect from the natural world since predation is common in nature after all and so we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;mcnemar&#34;&gt;McNemar&lt;/h2&gt;
&lt;p&gt;The McNemar Test (sometimes referred to as McNemar&amp;rsquo;s Chi-Square test because the test statistic has a chi-square distribution) is used when you are interested in finding a change in proportion for paired data. This is very common in repeated sampling analyses.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;null hypothesis&lt;/strong&gt; reads: &lt;strong&gt;Class assignment probabilities do not change within different treatments&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-the-data&#34;&gt;Preparing The Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do sex ratios change over time?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, our data does not allow for these types of analyses and so we will need to create some additional data here.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say we wanted to resample the sex ratio of &lt;em&gt;Passer domesticus&lt;/em&gt; in Australia (AU) a year after our initial survey because of an especially hostile winter and we&amp;rsquo;d like to see whether this resulted in an alteration of the sex ratio.&lt;/p&gt;
&lt;p&gt;What is our sex ratio before the winter?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Sex[which(Data_df$Index == &amp;quot;AU&amp;quot;)])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Female   Male 
##     44     44
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sexes_AU_Now_vec &amp;lt;- Data_df$Sex[which(Data_df$Index == &amp;quot;AU&amp;quot;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sex ratio is not skewed. So let&amp;rsquo;s hypothesise about what might happen to the sex ratio when a strong winter hits our population. The sex ratio could either (1) stay the same or (2) change. Although it would make sense to assume that the population would shrink, McNemar tests can&amp;rsquo;t account for that and so we assume that our population size will stay the same and only the sex ratio might change. Let&amp;rsquo;s create some new data for a changed sex ratio that is male biased:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Sexes &amp;lt;- c(&amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;) # creating a vector of sexes to sample from
set.seed(42) # making it reproducible
Sexes_AU_Next_vec &amp;lt;- sample(Sexes, sum(Data_df$Index==&amp;quot;AU&amp;quot;), replace = TRUE, prob = c(0.8,0.2))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s the data we will be testing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Sexes_AU_Now_vec) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Sexes_AU_Now_vec
## Female   Male 
##     44     44
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Sexes_AU_Next_vec)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Sexes_AU_Next_vec
## Female   Male 
##     21     67
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;running-the-test&#34;&gt;Running The Test&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s go on to test the unbiased vs. the male-skewed sex ratio:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mcnemar_matrix_change &amp;lt;- matrix(rbind(table(Sexes_AU_Now_vec), table(Sexes_AU_Next_vec)), 2)
mcnemar.test(mcnemar_matrix_change)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	McNemar&#39;s Chi-squared test with continuity correction
## 
## data:  mcnemar_matrix_change
## McNemar&#39;s chi-squared = 7.4462, df = 1, p-value = 0.006357
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously, with this data we would record a statistically significant change and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;making-sense-of-the-results&#34;&gt;Making Sense Of The Results&lt;/h3&gt;
&lt;p&gt;Unfortunately, McNemar only tells us &lt;em&gt;that&lt;/em&gt; there is a difference without any information about the &lt;em&gt;direction&lt;/em&gt; of the difference. For now, we will have to settle on a visualisation of the sexes to shed some light on the difference.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# preparing plotting
plot_df &amp;lt;- data.frame(Data = c(prop.table(mcnemar_matrix_change[1,]),
                               prop.table(mcnemar_matrix_change[2,])),
                      Identifiers = rep(c(&amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;), 2),
                      Year = rep(c(&amp;quot;Now&amp;quot;, &amp;quot;Next Year&amp;quot;), each = 2))
# plotting
ggplot(plot_df, aes(x = Year, y = Data, fill = Identifiers)) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  ggtitle(label = &amp;quot;Abundances of the sexes among study organisms&amp;quot;) + theme_bw() +
  ylab(&amp;quot;Proportion&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;08---Nominal-Tests_files/figure-html/McNemar6-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above plot is very crude and should only ever be used for data exploration and not for publishing purposes. Clearly, we can see the change in sex ratio towards a male-biased state (blue colour represents males).&lt;/p&gt;
&lt;h2 id=&#34;cochrans-q&#34;&gt;Cochran&amp;rsquo;s Q&lt;/h2&gt;
&lt;p&gt;Cochran&amp;rsquo;s Q is a non parametric test for finding differences in matched sets of three or more frequencies or proportions.&lt;/p&gt;
&lt;p&gt;As such, the Cochran&amp;rsquo;s Q Test is an extension of the McNemar test - the two tests are equal if Cochran&amp;rsquo;s Q is calculated for two groups.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;null hypothesis&lt;/strong&gt; for Cochran&amp;rsquo;s Q postulates an &lt;strong&gt;equal proportion of class assignents for all treatments&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-the-data-1&#34;&gt;Preparing The Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are colours related to sex or predator parameters?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When exploring our data, we can clearly see a pattern concerning the colour polymorphism of house sparrows arise which is dependant on the value of Predator Presence.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;counts &amp;lt;- table(Data_df$Colour, Data_df$Predator.Presence)
# preparing plotting
plot_df &amp;lt;- data.frame(Data = c(prop.table(counts[,1]), prop.table(counts[,2])),
                      Identifiers = rep(c(&amp;quot;Black&amp;quot;, &amp;quot;Brown&amp;quot;, &amp;quot;Grey&amp;quot;), 2),
                      Predation = rep(c(&amp;quot;No&amp;quot;, &amp;quot;Yes&amp;quot;), each = 3))
# plotting
ggplot(plot_df, aes(x = Predation, y = Data, fill = Identifiers)) + geom_bar(stat=&amp;quot;identity&amp;quot;) + ggtitle(label = &amp;quot;Colour Variations of the common House Sparrow&amp;quot;) + theme_bw() +ylab(&amp;quot;Proportions&amp;quot;) + scale_fill_manual(values=c(&amp;quot;black&amp;quot;, &amp;quot;saddlebrown&amp;quot;, &amp;quot;grey&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;08---Nominal-Tests_files/figure-html/ChochranPrep-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This might lead us to believe that the presence of predators cause an evolutionary change of the plumage colour of &lt;em&gt;Passer domesticus&lt;/em&gt; (we will have a more in-depth look on this in later seminars) and we might even postulate that &amp;ldquo;Black&amp;rdquo; and &amp;ldquo;Grey&amp;rdquo; serve as camouflage.&lt;/p&gt;
&lt;p&gt;Cochran&amp;rsquo;s Q requires data to be delivered as binomial records. Therefore, we prepare colour as a binary variable of &amp;ldquo;Brown&amp;rdquo; and &amp;ldquo;Camouflage&amp;rdquo; (which we postulate to encompass &amp;ldquo;Grey&amp;rdquo; and &amp;ldquo;Black&amp;rdquo;). Since Colour is of type &lt;code&gt;factor&lt;/code&gt; within our data set, we need to take some precautions in changing the data records. Predator Presence and Sex don&amp;rsquo;t need any additional preparation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Colour 
CochColour &amp;lt;- Data_df_base$Colour
# adding new level to factor list
levels(CochColour) &amp;lt;- c(levels(CochColour), &amp;quot;Camouflage&amp;quot;) 
# defining black and grey to be camouflage
CochColour[which(CochColour == &amp;quot;Grey&amp;quot;)] &amp;lt;- &amp;quot;Camouflage&amp;quot; 
CochColour[which(CochColour == &amp;quot;Black&amp;quot;)] &amp;lt;- &amp;quot;Camouflage&amp;quot; 
# dropping unnecessary factor levels
CochColour &amp;lt;- droplevels(CochColour) 

# Predator Presence
CochPredator.Presence &amp;lt;- factor(Data_df_base$Predator.Presence)

# Sex
CochSex &amp;lt;- factor(Data_df_base$Sex)

# Making vectors into a matrix
CochMatrix &amp;lt;- matrix(c(
  as.numeric(CochColour), 
  as.numeric(CochPredator.Presence), 
  as.numeric(CochSex)
  ), 
  ncol = 3)  - 1
colnames(CochMatrix) &amp;lt;- c(&amp;quot;Colour&amp;quot;, &amp;quot;Predator Presence&amp;quot;, &amp;quot;Sex&amp;quot;)
head(CochMatrix)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Colour Predator Presence Sex
## [1,]      0                 1   1
## [2,]      1                 1   1
## [3,]      1                 1   0
## [4,]      0                 1   0
## [5,]      1                 1   1
## [6,]      0                 1   0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;runing-the-test&#34;&gt;Runing The Test&lt;/h3&gt;
&lt;p&gt;Now let&amp;rsquo;s run our test using the &lt;code&gt;cochrans.q()&lt;/code&gt; function that comes with the &lt;code&gt;nonpar&lt;/code&gt; package:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cochrans.q(CochMatrix)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Cochran&#39;s Q Test 
##  
##  H0: There is no difference in the effectiveness of treatments. 
##  HA: There is a difference in the effectiveness of treatments. 
##  
##  Q = 122.984939759036 
##  
##  Degrees of Freedom = 2 
##  
##  Significance Level = 0.05 
##  The p-value is  0 
##  There is enough evidence to conclude that the effectiveness of at least two treatments differ. 
## 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, the output from this function is extremely user friendly. Additionally, as was to be expected the assignment probabilities for each class in each treatment are not equal thus forcing us to &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;making-sense-of-the-results-1&#34;&gt;Making Sense Of The Results&lt;/h3&gt;
&lt;p&gt;Where are the differences coming from?&lt;/p&gt;
&lt;p&gt;As you may recall from just a few pages ago, using the binomial test, we can identify the assignment proportions for any binomial variable individually.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Firstly&lt;/em&gt;, let&amp;rsquo;s test the &lt;strong&gt;binary version&lt;/strong&gt; of the &lt;strong&gt;colour&lt;/strong&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(CochColour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## CochColour
##      Brown Camouflage 
##        298        769
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(table(CochColour))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  table(CochColour)
## number of successes = 298, number of trials = 1067, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.2525387 0.3072599
## sample estimates:
## probability of success 
##              0.2792877
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this result, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; of binary colour records being equally likely to occur.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Secondly&lt;/em&gt;, let&amp;rsquo;s test the &lt;strong&gt;predator presence&lt;/strong&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(CochPredator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## CochPredator.Presence
##  No Yes 
## 357 710
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;binom.test(table(CochPredator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Exact binomial test
## 
## data:  table(CochPredator.Presence)
## number of successes = 357, number of trials = 1067, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.3062918 0.3637898
## sample estimates:
## probability of success 
##              0.3345829
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this result, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; of predator presence records being equally likely to occur.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Lastly&lt;/em&gt;, recall the binomial test run on the &lt;strong&gt;sex&lt;/strong&gt; data records which exhibit an almost even 50/50 split.&lt;/p&gt;
&lt;p&gt;Whilst none of these test give us any idea about the overlap of similar assignments along these variable vectors, a 50/50 split (sex) can never link up comparably with a roughly 30/70 split (predator presence and binary colour). Therefore, we could hypothesize a linkage of predator presence and colour rather than sex and colour morphs.&lt;/p&gt;
&lt;h2 id=&#34;chi-squared&#34;&gt;Chi-Squared&lt;/h2&gt;
&lt;p&gt;The Chi-Squared (also known as $Chi^2$) Test can be regarded as a functional extension of the binomial test and is used to test the similarity of class assignment proportions for a categorical/nominal variable. Unlike the binomial test, however, this test is not constrained to binomial records alone.&lt;/p&gt;
&lt;p&gt;The null hypothesis states that: &lt;strong&gt;Every class assignment contained within a given variable is equally likely&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The Chi-Squared Test can be applied in a one or two sample situation. One sample represents one variable in this setting.&lt;/p&gt;
&lt;h3 id=&#34;one-sample-situation&#34;&gt;One Sample Situation&lt;/h3&gt;
&lt;h4 id=&#34;binary-colour&#34;&gt;Binary Colour&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s asses the proportions of one variable we have already looked at - the &lt;strong&gt;binary version&lt;/strong&gt; of the &lt;strong&gt;colour&lt;/strong&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(CochColour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## CochColour
##      Brown Camouflage 
##        298        769
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(CochColour))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Chi-squared test for given probabilities
## 
## data:  table(CochColour)
## X-squared = 207.91, df = 1, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this result, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; of binary colour records being equally likely to occur. Note how the Chi-Squared test returns the same p-value as the binomial test above (within the Cochran&amp;rsquo;s Q section).&lt;/p&gt;
&lt;h4 id=&#34;colour&#34;&gt;Colour&lt;/h4&gt;
&lt;p&gt;Now let&amp;rsquo;s run the same test on the non-binary &lt;strong&gt;colour&lt;/strong&gt; data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Black Brown  Grey 
##   356   298   413
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Chi-squared test for given probabilities
## 
## data:  table(Data_df$Colour)
## X-squared = 18.592, df = 2, p-value = 9.178e-05
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; thus concluding differing class proportions for every possible class of &amp;ldquo;Colour&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;two-sample-situation&#34;&gt;Two Sample Situation&lt;/h3&gt;
&lt;p&gt;The two sample Chi-Squared approach lets us identify whether class assignment proportions of one variable differ when they are considered in a dependency of another nominal variable.&lt;/p&gt;
&lt;h4 id=&#34;sexual-dimorphism-1&#34;&gt;Sexual Dimorphism&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Are colours of Passer domesticus related to their sexes?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Firstly&lt;/em&gt;, let&amp;rsquo;s see if males and females share the same likelihoods of being of a certain colour:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Sex)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Female Male
##   Black    320   36
##   Brown    122  176
##   Grey      81  332
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour, Data_df$Sex))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  table(Data_df$Colour, Data_df$Sex)
## X-squared = 388.63, df = 2, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly, they don&amp;rsquo;t and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;predation-1&#34;&gt;Predation&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Are colours of Passer domesticus related to predator parameters?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Secondly&lt;/em&gt;, we test whether colour proportions change when considering predator presence. Although we partially considered this already in the Cochran&amp;rsquo;s Q section. This time, however, we use a non-binary version of the colour variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Black  64 292
##   Brown 211  87
##   Grey   82 331
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  table(Data_df$Colour, Data_df$Predator.Presence)
## X-squared = 259.34, df = 2, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The statement holds. Predator presence seems likely to be a driver of the colour polymorphism in &lt;em&gt;Passer domesticus&lt;/em&gt; and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So what about a possible link of sparrow colour and predator type?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Black   197        95
##   Brown    60        27
##   Grey    233        98
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Colour, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  table(Data_df$Colour, Data_df$Predator.Type)
## X-squared = 0.62164, df = 2, p-value = 0.7328
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nope, no link here. We have to &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and conclude that there may be no causal link of predator type and sparrow colour.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are nesting sites of Passer domesticus related to predator parameters?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Third&lt;/em&gt;, let&amp;rsquo;s test whether nesting site assignments might differ based on predator presence:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Shrub  87 205
##   Tree   94 137
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  table(Data_df$Nesting.Site, Data_df$Predator.Presence)
## X-squared = 6.2955, df = 1, p-value = 0.0121
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There seems to be a link here and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So what about a link of predator type and nesting site?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Shrub   182        23
##   Tree     49        88
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  table(Data_df$Nesting.Site, Data_df$Predator.Type)
## X-squared = 102.88, df = 1, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, there is a really strong one and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Correlation Tests</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/correlation-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/correlation-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our third practical experience in R. Throughout the following notes, I will introduce you to a couple statistical correlation approaches that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/09---Correlation-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;DescTools&amp;quot;, # Needed for Contingency Coefficient
                 &amp;quot;ggplot2&amp;quot; # needed for data visualisation
                 )
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: DescTools
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## DescTools   ggplot2 
##      TRUE      TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;nominal-scale---contingency-coefficient&#34;&gt;Nominal Scale - Contingency Coefficient&lt;/h2&gt;
&lt;p&gt;We can analyse correlations/dependencies of variables of the categorical kind using the contingency coefficient by calling the &lt;code&gt;ContCoef()&lt;/code&gt; function of base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Keep in mind that the contingency coefficient is not &lt;em&gt;really&lt;/em&gt; a measure of correlation but merely of association of variables. A value of $c \approx 0$ indicates independent variables.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are colour morphs of Passer domesticus linked to predator presence and/or predator type?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This analysis builds on our findings within our previous exercise (Nominal Tests - Analysing The Sparrow Data Set). Remember that, using the two-sample situation Chi-Squared Test, we found no change in treatment effects (as far as colour polymorphism went) for predator type values but did so regarding the presence of predators. Let&amp;rsquo;s repeat this here:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Black  64 292
##   Brown 211  87
##   Grey   82 331
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Colour, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4421914
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Black   197        95
##   Brown    60        27
##   Grey    233        98
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Colour, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02957682
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, we find the same results as when using the Chi-Squared statistic and conclude that colour morphs of the common house sparrow are likely to be driven by predator presence but not the type of predator that is present.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are nesting sites of Passer domesticus linked to predator presence and/or predator type?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, following our two-sample situation Chi-Squared analysis from last exercise, we want to test whether nesting site and predator presence/predator type are linked. The Chi-Squared analyses identified a possible link of nesting site and predator type but nor predator presence.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Shrub  87 205
##   Tree   94 137
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1130328
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Shrub   182        23
##   Tree     49        88
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4851588
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whilst there doesn&amp;rsquo;t seem to be any strong evidence linking nesting site and predator presence, predator type seems to be linked to what kind of nesting site &lt;em&gt;Passer domesticus&lt;/em&gt; prefers thus supporting our Chi-Squared results.&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are sex ratios of Passer domesticus related to climate types?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Recall that, in our last exercise, we found no discrepancy of proportions of the sexes among the entire data set using a binomial test. What we didn&amp;rsquo;t check yet was whether the sexes are distributed across the sites somewhat homogeneously or whether the sex ratios might be skewed according to climate types. Let&amp;rsquo;s do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
# select all data belonging to the stations at which all parameters except for climate type are held constant
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,]
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))

# analysis
table(Data_df$Sex, Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         
##          Coastal Continental
##   Female      91          76
##   Male        72          78
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Sex, Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06470702
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, they aren&amp;rsquo;t and, if there are any patterns in sex ratios to emerge, these are not likely to stem from climate types. Also keep in mind that we have a plethora of other variables at play whilst the information contained within the climate type variable is somewhat constrained and, in this case, bordering on uninformative (i.e. a coastal site in the Arctic might be more closely resembled by a continental mid-latitude site than by a tropical coastal site).&lt;/p&gt;
&lt;h2 id=&#34;ordinal-scale---kendalls-tau&#34;&gt;Ordinal Scale - Kendall&amp;rsquo;s Tau&lt;/h2&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do heavier sparrows have heavier/less eggs?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A heavier weight of individual females alludes to a higher pool of resources being allocated by said individuals. There are multiple ways they might make use of it, one of them being investment in reproduction. To test how heavier females of &lt;em&gt;Passer domesticus&lt;/em&gt; utilise their resources in reproduction, we use a Kendall&amp;rsquo;s Tau approach to finding links between female weight and average egg weight per nest/number of eggs per nest.&lt;br&gt;
Obviously, both weight variables are metric in nature and so we could use other methods as well. On top of that, we first need to convert these into ranks before being able to run a Kendall&amp;rsquo;s Tau analysis as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# overwriting changes in Data_df with base data
Data_df &amp;lt;- Data_df_base
# Establishing Ranks of Egg Weight
RankedEggWeight &amp;lt;- rank(Data_df$Egg.Weight[which(Data_df$Sex == &amp;quot;Female&amp;quot;)],
                        ties.method = &amp;quot;average&amp;quot;)
# Establishing Ranks of Female Weight
RankedWeight_Female &amp;lt;- rank(Data_df$Weight[which(Data_df$Sex == &amp;quot;Female&amp;quot;)],
                            ties.method = &amp;quot;average&amp;quot;)
# Extracting Numbers of Eggs
RankedEggs &amp;lt;- Data_df$Number.of.Eggs[which(Data_df$Sex == &amp;quot;Female&amp;quot;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Luckily enough, the number of eggs per nest already represent a ranked (ordinal) variable and so we can move straight on to running our analyses:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Test ranked female weight vs. ranked egg weight
cor.test(x = RankedWeight_Female, y = RankedEggWeight, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;kendall&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kendall&#39;s rank correlation tau
## 
## data:  RankedWeight_Female and RankedEggWeight
## z = 19.771, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##       tau 
## 0.5804546
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is strong evidence to suggest that heavier females tend to lay heavier eggs (tau = 0.5804546 at p $\approx$ 0).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Test ranked female weight vs. number of eggs
cor.test(x = RankedWeight_Female, y = RankedEggs, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;kendall&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kendall&#39;s rank correlation tau
## 
## data:  RankedWeight_Female and RankedEggs
## z = -21.787, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##        tau 
## -0.6880932
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additionally, the heavier a female of &lt;em&gt;Passer domesticus&lt;/em&gt;, the less eggs she produces (tau = -0.6880932 at p $\approx$ 0).&lt;/p&gt;
&lt;p&gt;Now we can visualise the underlying patterns:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot_df &amp;lt;- data.frame(RankedWeight = RankedWeight_Female,
                      RankedEggWeight = RankedEggWeight,
                      RankedEggNumber = RankedEggs)
# plot ranked female weight vs. ranked egg weight
ggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggWeight)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Ranked female weight of Passer domesticus vs. Ranked weigt of eggs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Kendall.26b-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# plot ranked female weight vs. number of eggs
ggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggNumber)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Ranked female weight of Passer domesticus vs. Ranked number of eggs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Kendall.26b-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This highlights an obvious and intuitive trade-off in nature and has us &lt;strong&gt;reject the null hypotheses&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;metric-and-ordinal-scales&#34;&gt;Metric and Ordinal Scales&lt;/h2&gt;
&lt;p&gt;Metric scale correlation analyses call for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Spearman&lt;/em&gt; correlation test (non-parametric)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Pearson&lt;/em&gt; correlation test (parametric, requires data to be normal distributed)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-for-normality&#34;&gt;Testing for Normality&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DISCLAIMER:&lt;/strong&gt; I do not expect you to do it this way as of right now but wanted to give you reference material of how to automate this testing step.&lt;/p&gt;
&lt;p&gt;Since most of our following analyses are focussing on latitude effects (i.e. &amp;ldquo;climate warming&amp;rdquo;), we need to alter our base data. Before we can run the analyses, we need to eliminate the sites that we have set aside for testing climate extreme effects on (Siberia, United Kingdom, Reunion and Australia) from the data set. We are also not interested in all variables and so reduce the data set further.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index != &amp;quot;SI&amp;quot; &amp;amp; Index != &amp;quot;UK&amp;quot; &amp;amp; Index != &amp;quot;RE&amp;quot; &amp;amp; Index != &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,c(&amp;quot;Index&amp;quot;, &amp;quot;Latitude&amp;quot;, &amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Nesting.Height&amp;quot;, 
                             &amp;quot;Number.of.Eggs&amp;quot;, &amp;quot;Egg.Weight&amp;quot;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to know which test we can use with which variable, we need to first identify whether our data is normal distributed using the Shapiro-Test (Seminar 3) as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Normal_df &amp;lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)
for(i in 2:length(colnames(Data_df))){
  Normal_df[1,i] &amp;lt;- colnames(Data_df)[i]
  Normal_df[2,i] &amp;lt;- round(shapiro.test(as.numeric(Data_df[,i]))$p.value, 2)
}
colnames(Normal_df) &amp;lt;- c()
rownames(Normal_df) &amp;lt;- c(&amp;quot;Variable&amp;quot;, &amp;quot;p&amp;quot;)
Normal_df &amp;lt;- Normal_df[,-1] # removing superfluous Index column
Normal_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                         
## Variable Latitude Weight Height Wing.Chord Nesting.Height Number.of.Eggs
## p               0      0      0          0              0              0
##                    
## Variable Egg.Weight
## p                 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, none of these variables seem to be normal distributed (this was to be expected for some, to be fair) thus barring us from using Pearson correlation on the entire data set leaving us with the Spearman correlation method.&lt;/p&gt;
&lt;h3 id=&#34;spearman&#34;&gt;Spearman&lt;/h3&gt;
&lt;h4 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h4&gt;
&lt;h5 id=&#34;heightlength&#34;&gt;Height/Length&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do height/length records of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Following Bergmann&amp;rsquo;s rule, we expect a positive correlation between sparrow height/length and absolute values of latitude:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Height, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Height, :
## Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Height
## S = 128104735, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.8219373
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Height)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Height of Passer domesticus vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman1-1.png&#34; width=&#34;1440&#34; /&gt;
Interestingly enough, our analysis yields a negative correlation which would disproof Bermann&amp;rsquo;s rule. This is a good example to show how important biological background knowledge is when doing biostatistics. Whilst a pure statistician might now believe to have just dis-proven a big rule of biology, it should be apparent to any biologist that Bergmann spoke of &amp;ldquo;bigger&amp;rdquo; organisms in colder climates (higher latitudes) and not of &amp;ldquo;taller&amp;rdquo; individuals. What our sparrows lack in height, they might make up for in circumference. This is an example where we would &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; but shouldn&amp;rsquo;t &lt;strong&gt;accept the alternative hypothesis&lt;/strong&gt; based on biological understanding.&lt;/p&gt;
&lt;h5 id=&#34;weight&#34;&gt;Weight&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do weight records of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, following Bergmann&amp;rsquo;s rule, we expect a positive correlation between sparrow weight and absolute values of latitude.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Weight, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Weight, :
## Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Weight
## S = 9349037, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.8670357
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Weight)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Weight of Passer domesticus vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman-1.png&#34; width=&#34;1440&#34; /&gt;
Bergmann was obviously right and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h5 id=&#34;wing-chord&#34;&gt;Wing Chord&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do wing chord/wing span records of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We would expect sparrows in higher latitudes (e.g. colder climates) to have smaller wings as to radiate less body heat.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord, :
## Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Wing.Chord
## S = 134573929, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.9139437
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Wing.Chord)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Wing chord of Passer domesticus vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman2-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And we were right! Sparrows have shorter wingspans in higher latitudes and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h5 id=&#34;number-of-eggs&#34;&gt;Number of Eggs&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do numbers of eggs per nest of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Due to resource constraints in colder climates, we expect female &lt;em&gt;Passer domesticus&lt;/em&gt; individuals to invest in quality over quantity by prioritising caring your fledglings by educing the amount of eggs they produce.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Number.of.Eggs, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y =
## Data_df$Number.of.Eggs, : Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Number.of.Eggs
## S = 14501794, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##      rho 
## -0.92853
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Number.of.Eggs)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Number of eggs of Passer domesticus nests vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 394 rows containing non-finite values (stat_smooth).
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 394 rows containing missing values (geom_point).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman3-1.png&#34; width=&#34;1440&#34; /&gt;
We were right. Female house sparrows produce less eggs per capita in higher latitudes and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h5 id=&#34;egg-weight&#34;&gt;Egg Weight&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Does average weight of eggs per nest of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Due to the reduced investment in egg numbers that we have just proven, we expect females of &lt;em&gt;Passer domesticus&lt;/em&gt; to allocate some of their saved resources into heavier eggs which may nurture unhatched offspring for longer and more effectively.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight, :
## Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Egg.Weight
## S = 1318221, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##     rho 
## 0.82321
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Egg.Weight)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Weight of Passer domesticus eggs vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 395 rows containing non-finite values (stat_smooth).
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 395 rows containing missing values (geom_point).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman4-1.png&#34; width=&#34;1440&#34; /&gt;
Indeed, the higher the latitude, the heavier the average egg per nest of &lt;em&gt;Passer domesticus&lt;/em&gt; and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;pearson&#34;&gt;Pearson&lt;/h3&gt;
&lt;p&gt;We already know that we can&amp;rsquo;t analyse the entire data set at once for these two variables since their data values are not normal distirbuted. How about site-wise variable value distributions, though?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Further reducing the data set
Data_df &amp;lt;- Data_df[,c(&amp;quot;Index&amp;quot;, &amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;)]
# establishing an empty data frame and an index vector that doesn&#39;t repeat
Normal_df &amp;lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)
Indices &amp;lt;- as.character(unique(Data_df_base$Index[Rows]))
# site-wise shapiro test
for(i in 2:length(colnames(Data_df))){ # variables
  for(k in 1:length(Indices)){ # sites
    Normal_df[i,k] &amp;lt;- round(shapiro.test(as.numeric(
          Data_df[,i][which(Data_df_base$Index[Rows] == Indices[k])])
        )$p.value, 2)}} # site loop, variable loop
rownames(Normal_df) &amp;lt;- colnames(Data_df)
colnames(Normal_df) &amp;lt;- Indices
Normal_df[-1,] # remove superfluous index row
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          NU   MA   LO   BE   FG   SA   FI
## Weight 0.57 0.12 0.50 0.38 0.18 0.76 0.43
## Height 0.23 0.03 0.19 0.59 0.88 0.27 0.86
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to these results intra-site correlations of sparrow weight and height can be carried out! So, in order to show Pearson correlation, we run a simple, site-wise correlation analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do weight and height records of Passer domesticus correlate within each site?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To shed some light on our previous findings, we might want to see whether weight and height of sparrows correlate. Without running the analysis, we can conclude that they do because both correlate with latitude and are thus what we call &lt;strong&gt;collinear&lt;/strong&gt;. However, now we are running the analysis on a site level - does the correlation still exist?&lt;/p&gt;
&lt;p&gt;Take note that we are now using our entire data set again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# overwriting altered Data_df
Data_df &amp;lt;- Data_df_base
# establishing an empty data frame and an index vector that doesn&#39;t repeat
Pearson_df &amp;lt;- data.frame(Pearson = as.character(), stringsAsFactors = FALSE)
Indices &amp;lt;- as.character(unique(Data_df$Index))
# site-internal correlation tests, weight and height
for(i in 1:length(unique(Data_df$Index))){
  Weights &amp;lt;- Data_df$Weight[which(Data_df$Index == Indices[i])]
  Heights &amp;lt;- Data_df$Height[which(Data_df$Index == Indices[i])]
  Pearson_df[1,i] &amp;lt;- round(cor.test(x = Weights, y = Heights, 
                                    use = &amp;quot;pairwise.complete.obs&amp;quot;)[[&amp;quot;estimate&amp;quot;]][[&amp;quot;cor&amp;quot;]], 2)
  Pearson_df[2,i] &amp;lt;- round(cor.test(x = Weights, y = Heights, 
                                    use = &amp;quot;pairwise.complete.obs&amp;quot;)$p.value, 2)}
colnames(Pearson_df) &amp;lt;- Indices
rownames(Pearson_df) &amp;lt;- c(&amp;quot;r&amp;quot;, &amp;quot;p&amp;quot;)
Pearson_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     SI   UK   AU   RE   NU   MA   LO   BE   FG   SA   FI
## r 0.76 0.83 0.77 0.75 0.84 0.84 0.79 0.82 0.79 0.76 0.81
## p    0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, it does. Heavier birds are taller!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Correlation Tests</title>
      <link>https://www.erikkusch.com/courses/biostat101/correlation-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/correlation-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our third practical experience in R. Throughout the following notes, I will introduce you to a couple statistical correlation approaches that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise. I have prepared some slides for this session: &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/09---Correlation-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/09---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;DescTools&amp;quot;, # Needed for Contingency Coefficient
                 &amp;quot;ggplot2&amp;quot; # needed for data visualisation
                 )
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: DescTools
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## DescTools   ggplot2 
##      TRUE      TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;nominal-scale---contingency-coefficient&#34;&gt;Nominal Scale - Contingency Coefficient&lt;/h2&gt;
&lt;p&gt;We can analyse correlations/dependencies of variables of the categorical kind using the contingency coefficient by calling the &lt;code&gt;ContCoef()&lt;/code&gt; function of base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Keep in mind that the contingency coefficient is not &lt;em&gt;really&lt;/em&gt; a measure of correlation but merely of association of variables. A value of $c \approx 0$ indicates independent variables.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are colour morphs of Passer domesticus linked to predator presence and/or predator type?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This analysis builds on our findings within our previous exercise (Nominal Tests - Analysing The Sparrow Data Set). Remember that, using the two-sample situation Chi-Squared Test, we found no change in treatment effects (as far as colour polymorphism went) for predator type values but did so regarding the presence of predators. Let&amp;rsquo;s repeat this here:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Black  64 292
##   Brown 211  87
##   Grey   82 331
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Colour, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4421914
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Colour, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Black   197        95
##   Brown    60        27
##   Grey    233        98
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Colour, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02957682
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, we find the same results as when using the Chi-Squared statistic and conclude that colour morphs of the common house sparrow are likely to be driven by predator presence but not the type of predator that is present.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are nesting sites of Passer domesticus linked to predator presence and/or predator type?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, following our two-sample situation Chi-Squared analysis from last exercise, we want to test whether nesting site and predator presence/predator type are linked. The Chi-Squared analyses identified a possible link of nesting site and predator type but nor predator presence.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Presence)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##          No Yes
##   Shrub  87 205
##   Tree   94 137
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Presence))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1130328
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Data_df$Nesting.Site, Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         Avian Non-Avian
##   Shrub   182        23
##   Tree     49        88
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Type))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4851588
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whilst there doesn&amp;rsquo;t seem to be any strong evidence linking nesting site and predator presence, predator type seems to be linked to what kind of nesting site &lt;em&gt;Passer domesticus&lt;/em&gt; prefers thus supporting our Chi-Squared results.&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Are sex ratios of Passer domesticus related to climate types?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Recall that, in our last exercise, we found no discrepancy of proportions of the sexes among the entire data set using a binomial test. What we didn&amp;rsquo;t check yet was whether the sexes are distributed across the sites somewhat homogeneously or whether the sex ratios might be skewed according to climate types. Let&amp;rsquo;s do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
# select all data belonging to the stations at which all parameters except for climate type are held constant
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,]
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))

# analysis
table(Data_df$Sex, Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         
##          Coastal Continental
##   Female      91          76
##   Male        72          78
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ContCoef(table(Data_df$Sex, Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06470702
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, they aren&amp;rsquo;t and, if there are any patterns in sex ratios to emerge, these are not likely to stem from climate types. Also keep in mind that we have a plethora of other variables at play whilst the information contained within the climate type variable is somewhat constrained and, in this case, bordering on uninformative (i.e. a coastal site in the Arctic might be more closely resembled by a continental mid-latitude site than by a tropical coastal site).&lt;/p&gt;
&lt;h2 id=&#34;ordinal-scale---kendalls-tau&#34;&gt;Ordinal Scale - Kendall&amp;rsquo;s Tau&lt;/h2&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do heavier sparrows have heavier/less eggs?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A heavier weight of individual females alludes to a higher pool of resources being allocated by said individuals. There are multiple ways they might make use of it, one of them being investment in reproduction. To test how heavier females of &lt;em&gt;Passer domesticus&lt;/em&gt; utilise their resources in reproduction, we use a Kendall&amp;rsquo;s Tau approach to finding links between female weight and average egg weight per nest/number of eggs per nest.&lt;br&gt;
Obviously, both weight variables are metric in nature and so we could use other methods as well. On top of that, we first need to convert these into ranks before being able to run a Kendall&amp;rsquo;s Tau analysis as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# overwriting changes in Data_df with base data
Data_df &amp;lt;- Data_df_base
# Establishing Ranks of Egg Weight
RankedEggWeight &amp;lt;- rank(Data_df$Egg.Weight[which(Data_df$Sex == &amp;quot;Female&amp;quot;)],
                        ties.method = &amp;quot;average&amp;quot;)
# Establishing Ranks of Female Weight
RankedWeight_Female &amp;lt;- rank(Data_df$Weight[which(Data_df$Sex == &amp;quot;Female&amp;quot;)],
                            ties.method = &amp;quot;average&amp;quot;)
# Extracting Numbers of Eggs
RankedEggs &amp;lt;- Data_df$Number.of.Eggs[which(Data_df$Sex == &amp;quot;Female&amp;quot;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Luckily enough, the number of eggs per nest already represent a ranked (ordinal) variable and so we can move straight on to running our analyses:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Test ranked female weight vs. ranked egg weight
cor.test(x = RankedWeight_Female, y = RankedEggWeight, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;kendall&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kendall&#39;s rank correlation tau
## 
## data:  RankedWeight_Female and RankedEggWeight
## z = 19.771, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##       tau 
## 0.5804546
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is strong evidence to suggest that heavier females tend to lay heavier eggs (tau = 0.5804546 at p $\approx$ 0).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Test ranked female weight vs. number of eggs
cor.test(x = RankedWeight_Female, y = RankedEggs, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;kendall&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kendall&#39;s rank correlation tau
## 
## data:  RankedWeight_Female and RankedEggs
## z = -21.787, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##        tau 
## -0.6880932
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additionally, the heavier a female of &lt;em&gt;Passer domesticus&lt;/em&gt;, the less eggs she produces (tau = -0.6880932 at p $\approx$ 0).&lt;/p&gt;
&lt;p&gt;Now we can visualise the underlying patterns:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot_df &amp;lt;- data.frame(RankedWeight = RankedWeight_Female,
                      RankedEggWeight = RankedEggWeight,
                      RankedEggNumber = RankedEggs)
# plot ranked female weight vs. ranked egg weight
ggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggWeight)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Ranked female weight of Passer domesticus vs. Ranked weigt of eggs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Kendall.26b-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# plot ranked female weight vs. number of eggs
ggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggNumber)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Ranked female weight of Passer domesticus vs. Ranked number of eggs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Kendall.26b-2.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This highlights an obvious and intuitive trade-off in nature and has us &lt;strong&gt;reject the null hypotheses&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;metric-and-ordinal-scales&#34;&gt;Metric and Ordinal Scales&lt;/h2&gt;
&lt;p&gt;Metric scale correlation analyses call for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Spearman&lt;/em&gt; correlation test (non-parametric)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Pearson&lt;/em&gt; correlation test (parametric, requires data to be normal distributed)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-for-normality&#34;&gt;Testing for Normality&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DISCLAIMER:&lt;/strong&gt; I do not expect you to do it this way as of right now but wanted to give you reference material of how to automate this testing step.&lt;/p&gt;
&lt;p&gt;Since most of our following analyses are focussing on latitude effects (i.e. &amp;ldquo;climate warming&amp;rdquo;), we need to alter our base data. Before we can run the analyses, we need to eliminate the sites that we have set aside for testing climate extreme effects on (Siberia, United Kingdom, Reunion and Australia) from the data set. We are also not interested in all variables and so reduce the data set further.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index != &amp;quot;SI&amp;quot; &amp;amp; Index != &amp;quot;UK&amp;quot; &amp;amp; Index != &amp;quot;RE&amp;quot; &amp;amp; Index != &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,c(&amp;quot;Index&amp;quot;, &amp;quot;Latitude&amp;quot;, &amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Nesting.Height&amp;quot;, 
                             &amp;quot;Number.of.Eggs&amp;quot;, &amp;quot;Egg.Weight&amp;quot;)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to know which test we can use with which variable, we need to first identify whether our data is normal distributed using the Shapiro-Test (Seminar 3) as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Normal_df &amp;lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)
for(i in 2:length(colnames(Data_df))){
  Normal_df[1,i] &amp;lt;- colnames(Data_df)[i]
  Normal_df[2,i] &amp;lt;- round(shapiro.test(as.numeric(Data_df[,i]))$p.value, 2)
}
colnames(Normal_df) &amp;lt;- c()
rownames(Normal_df) &amp;lt;- c(&amp;quot;Variable&amp;quot;, &amp;quot;p&amp;quot;)
Normal_df &amp;lt;- Normal_df[,-1] # removing superfluous Index column
Normal_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                         
## Variable Latitude Weight Height Wing.Chord Nesting.Height Number.of.Eggs
## p               0      0      0          0              0              0
##                    
## Variable Egg.Weight
## p                 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, none of these variables seem to be normal distributed (this was to be expected for some, to be fair) thus barring us from using Pearson correlation on the entire data set leaving us with the Spearman correlation method.&lt;/p&gt;
&lt;h3 id=&#34;spearman&#34;&gt;Spearman&lt;/h3&gt;
&lt;h4 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h4&gt;
&lt;h5 id=&#34;heightlength&#34;&gt;Height/Length&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do height/length records of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Following Bergmann&amp;rsquo;s rule, we expect a positive correlation between sparrow height/length and absolute values of latitude:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Height, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Height, :
## Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Height
## S = 128104735, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.8219373
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Height)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Height of Passer domesticus vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman1-1.png&#34; width=&#34;1440&#34; /&gt;
Interestingly enough, our analysis yields a negative correlation which would disproof Bermann&amp;rsquo;s rule. This is a good example to show how important biological background knowledge is when doing biostatistics. Whilst a pure statistician might now believe to have just dis-proven a big rule of biology, it should be apparent to any biologist that Bergmann spoke of &amp;ldquo;bigger&amp;rdquo; organisms in colder climates (higher latitudes) and not of &amp;ldquo;taller&amp;rdquo; individuals. What our sparrows lack in height, they might make up for in circumference. This is an example where we would &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; but shouldn&amp;rsquo;t &lt;strong&gt;accept the alternative hypothesis&lt;/strong&gt; based on biological understanding.&lt;/p&gt;
&lt;h5 id=&#34;weight&#34;&gt;Weight&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do weight records of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, following Bergmann&amp;rsquo;s rule, we expect a positive correlation between sparrow weight and absolute values of latitude.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Weight, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Weight, :
## Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Weight
## S = 9349037, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.8670357
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Weight)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Weight of Passer domesticus vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman-1.png&#34; width=&#34;1440&#34; /&gt;
Bergmann was obviously right and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h5 id=&#34;wing-chord&#34;&gt;Wing Chord&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do wing chord/wing span records of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We would expect sparrows in higher latitudes (e.g. colder climates) to have smaller wings as to radiate less body heat.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord,
## : Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Wing.Chord
## S = 134573929, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.9139437
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Wing.Chord)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Wing chord of Passer domesticus vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman2-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And we were right! Sparrows have shorter wingspans in higher latitudes and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h5 id=&#34;number-of-eggs&#34;&gt;Number of Eggs&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Do numbers of eggs per nest of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Due to resource constraints in colder climates, we expect female &lt;em&gt;Passer domesticus&lt;/em&gt; individuals to invest in quality over quantity by prioritising caring your fledglings by educing the amount of eggs they produce.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Number.of.Eggs, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y =
## Data_df$Number.of.Eggs, : Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Number.of.Eggs
## S = 14501794, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##      rho 
## -0.92853
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Number.of.Eggs)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Number of eggs of Passer domesticus nests vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 394 rows containing non-finite values (`stat_smooth()`).
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 394 rows containing missing values (`geom_point()`).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman3-1.png&#34; width=&#34;1440&#34; /&gt;
We were right. Female house sparrows produce less eggs per capita in higher latitudes and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h5 id=&#34;egg-weight&#34;&gt;Egg Weight&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Does average weight of eggs per nest of Passer domesticus and latitude correlate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Due to the reduced investment in egg numbers that we have just proven, we expect females of &lt;em&gt;Passer domesticus&lt;/em&gt; to allocate some of their saved resources into heavier eggs which may nurture unhatched offspring for longer and more effectively.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.test(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight, 
         use = &amp;quot;pairwise.complete.obs&amp;quot;, method = &amp;quot;spearman&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight,
## : Cannot compute exact p-value with ties
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  abs(Data_df$Latitude) and Data_df$Egg.Weight
## S = 1318221, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##     rho 
## 0.82321
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(data = Data_df, aes(x = abs(Latitude), y = Egg.Weight)) +
  geom_point() + theme_bw() + stat_smooth(method = &amp;quot;lm&amp;quot;) + 
  labs(title = &amp;quot;Weight of Passer domesticus eggs vs. Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula = &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 395 rows containing non-finite values (`stat_smooth()`).
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 395 rows containing missing values (`geom_point()`).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;09---Correlation-Tests_files/figure-html/Spearman4-1.png&#34; width=&#34;1440&#34; /&gt;
Indeed, the higher the latitude, the heavier the average egg per nest of &lt;em&gt;Passer domesticus&lt;/em&gt; and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;pearson&#34;&gt;Pearson&lt;/h3&gt;
&lt;p&gt;We already know that we can&amp;rsquo;t analyse the entire data set at once for these two variables since their data values are not normal distirbuted. How about site-wise variable value distributions, though?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Further reducing the data set
Data_df &amp;lt;- Data_df[,c(&amp;quot;Index&amp;quot;, &amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;)]
# establishing an empty data frame and an index vector that doesn&#39;t repeat
Normal_df &amp;lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)
Indices &amp;lt;- as.character(unique(Data_df_base$Index[Rows]))
# site-wise shapiro test
for(i in 2:length(colnames(Data_df))){ # variables
  for(k in 1:length(Indices)){ # sites
    Normal_df[i,k] &amp;lt;- round(shapiro.test(as.numeric(
          Data_df[,i][which(Data_df_base$Index[Rows] == Indices[k])])
        )$p.value, 2)}} # site loop, variable loop
rownames(Normal_df) &amp;lt;- colnames(Data_df)
colnames(Normal_df) &amp;lt;- Indices
Normal_df[-1,] # remove superfluous index row
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          NU   MA   LO   BE   FG   SA   FI
## Weight 0.57 0.12 0.50 0.38 0.18 0.76 0.43
## Height 0.23 0.03 0.19 0.59 0.88 0.27 0.86
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to these results intra-site correlations of sparrow weight and height can be carried out! So, in order to show Pearson correlation, we run a simple, site-wise correlation analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do weight and height records of Passer domesticus correlate within each site?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To shed some light on our previous findings, we might want to see whether weight and height of sparrows correlate. Without running the analysis, we can conclude that they do because both correlate with latitude and are thus what we call &lt;strong&gt;collinear&lt;/strong&gt;. However, now we are running the analysis on a site level - does the correlation still exist?&lt;/p&gt;
&lt;p&gt;Take note that we are now using our entire data set again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# overwriting altered Data_df
Data_df &amp;lt;- Data_df_base
# establishing an empty data frame and an index vector that doesn&#39;t repeat
Pearson_df &amp;lt;- data.frame(Pearson = as.character(), stringsAsFactors = FALSE)
Indices &amp;lt;- as.character(unique(Data_df$Index))
# site-internal correlation tests, weight and height
for(i in 1:length(unique(Data_df$Index))){
  Weights &amp;lt;- Data_df$Weight[which(Data_df$Index == Indices[i])]
  Heights &amp;lt;- Data_df$Height[which(Data_df$Index == Indices[i])]
  Pearson_df[1,i] &amp;lt;- round(cor.test(x = Weights, y = Heights, 
                                    use = &amp;quot;pairwise.complete.obs&amp;quot;)[[&amp;quot;estimate&amp;quot;]][[&amp;quot;cor&amp;quot;]], 2)
  Pearson_df[2,i] &amp;lt;- round(cor.test(x = Weights, y = Heights, 
                                    use = &amp;quot;pairwise.complete.obs&amp;quot;)$p.value, 2)}
colnames(Pearson_df) &amp;lt;- Indices
rownames(Pearson_df) &amp;lt;- c(&amp;quot;r&amp;quot;, &amp;quot;p&amp;quot;)
Pearson_df
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     SI   UK   AU   RE   NU   MA   LO   BE   FG   SA   FI
## r 0.76 0.83 0.77 0.75 0.84 0.84 0.79 0.82 0.79 0.76 0.81
## p    0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, it does. Heavier birds are taller!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ordinal &amp; Metric Tests (Two-Sample Situations)</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/ordinal-metric-tests-two-sample-situations/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/ordinal-metric-tests-two-sample-situations/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our fourth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/10---Ordinal-and-Metric-Test--Two-Sample-_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/2b%20-%20Sparrow_ResettledSIUK_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c()
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## list()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we don&amp;rsquo;t need any packages for our analyses in this practical.&lt;/p&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;mann-whitney-u-test&#34;&gt;Mann-Whitney U Test&lt;/h2&gt;
&lt;p&gt;We can analyse the significance of two population/sample medians of metric variables which are independent of one another using the &lt;code&gt;wilcox.test()&lt;/code&gt; function in base &lt;code&gt;R&lt;/code&gt; whilst specifying &lt;code&gt;paired = FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Logically, we&amp;rsquo;d expect morphological aspects of &lt;em&gt;Passer domesticus&lt;/em&gt; to change given different frequencies and severities of climate extremes. Don&amp;rsquo;t forget, however, that our statistical procedures are usually built on the null hypothesis of no differences or correlations being present and so is the Mann-Whitney U Test.&lt;/p&gt;
&lt;p&gt;Our data set recorded three aspects of sparrow morphology and three climate levels (). Remember, however, that we set aside four stations (Siberia, United Kingdom, Reunion and Australia) to test climate effects on which are strictly limited to continental and coastal climate types. We need to exclude all other sites records from our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,]
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;sparrow-weight&#34;&gt;Sparrow Weight&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start with the weight of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Weight[Climate == &amp;quot;Continental&amp;quot;], 
                 y = Weight[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Weight[Climate == &amp;quot;Continental&amp;quot;] and Weight[Climate != &amp;quot;Continental&amp;quot;]
## W = 22104, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Weight[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Weight[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, the weight of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $1.7179744\times 10^{-32}$) and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;. Weights of sparrows in continental climates are, on average, heavier than respective weights of their peers in coastal climates.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-height&#34;&gt;Sparrow Height&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Height[Climate == &amp;quot;Continental&amp;quot;], 
                 y = Height[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Height[Climate == &amp;quot;Continental&amp;quot;] and Height[Climate != &amp;quot;Continental&amp;quot;]
## W = 11498, p-value = 0.1971
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Height[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Height[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We conclude that the height of sparrows seems to not be dependent on the type of climate the individuals are suspected to (p = $0.1970959$) and &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;. Sparrows in continental climates are, on average, smaller than their peers in coastal climates but not to a statistically significant degree.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-wing-chord&#34;&gt;Sparrow Wing Chord&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Wing.Chord[Climate == &amp;quot;Continental&amp;quot;], 
                 y = Wing.Chord[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Wing.Chord[Climate == &amp;quot;Continental&amp;quot;] and Wing.Chord[Climate != &amp;quot;Continental&amp;quot;]
## W = 10505, p-value = 0.01213
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Wing.Chord[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Wing.Chord[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, the wing chord of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $0.0121264$) and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;. Sparrows in continental climates have, generally speaking, shorter wings than their peers in coastal climates.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height of nest sites of Passer domesticus depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In our second practical (Nominal Tests), we used a Chi-Squared approach in a two-sample situation to identify whether predator presence and type had any influence over the nesting sites that individuals of &lt;em&gt;Passer domesticus&lt;/em&gt; preferred. Our findings showed that they did and so we should expect similar results here when using &lt;code&gt;Nesting Site&lt;/code&gt; as our response variable instead of &lt;code&gt;Nesting Height&lt;/code&gt; as these two are highly related to each other.&lt;/p&gt;
&lt;p&gt;Additionally, to save some space in these notes, I am not showing how to identify the direction of the effect via code any more for now. We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;predator-presence&#34;&gt;Predator Presence&lt;/h4&gt;
&lt;p&gt;First, we start with a possible link to predator presence and nesting height chosen by common house sparrows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Nesting.Height[Predator.Presence == &amp;quot;Yes&amp;quot;], 
                 y = Nesting.Height[Predator.Presence != &amp;quot;Yes&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Nesting.Height[Predator.Presence == &amp;quot;Yes&amp;quot;] and Nesting.Height[Predator.Presence != &amp;quot;Yes&amp;quot;]
## W = 25420, p-value = 0.0007678
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The nesting height of sparrows depends on whether a predator is present or not (p = $7.6777684\times 10^{-4}$) thus &lt;strong&gt;rejecting the null hypothesis&lt;/strong&gt;. Sparrows tend to go for nesting sites in more elevated positions when no predator is present.&lt;/p&gt;
&lt;h4 id=&#34;predator-type&#34;&gt;Predator Type&lt;/h4&gt;
&lt;p&gt;Again, we might want to check whether the position of a given nest might be related to what kind of predator is present:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Nesting.Height[Predator.Type == &amp;quot;Avian&amp;quot;], 
                 y = Nesting.Height[Predator.Type != &amp;quot;Avian&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Nesting.Height[Predator.Type == &amp;quot;Avian&amp;quot;] and Nesting.Height[Predator.Type != &amp;quot;Avian&amp;quot;]
## W = 5228, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We conclude that the nesting height of sparrows depends on what kind of predator is present (p = $7.4380407\times 10^{-19}$) conclusively &lt;strong&gt;rejecting the null hypothesis&lt;/strong&gt;. Therefore, we are confident in stating that sparrows tend to go for nesting sites in more elevated positions when non-avian predators are present.&lt;/p&gt;
&lt;h3 id=&#34;competition&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do home ranges of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We might expect different behaviour of &lt;em&gt;Passer domesticus&lt;/em&gt; given different climate types. Since &lt;code&gt;Home Range&lt;/code&gt; is on an ordinal scale () we can run a Mann-Whitney U Test on these whilst taking &lt;code&gt;Climate&lt;/code&gt; into account as our predictor variable.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,]
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To be able to use the &lt;code&gt;wilcox.test()&lt;/code&gt; function on &lt;code&gt;Home Range&lt;/code&gt;, we need to transform its elements into a numeric type. Luckily, this is as easy as using the &lt;code&gt;as.numeric()&lt;/code&gt; function on the data since it will assign every factor level a number corresponding to its position in &lt;code&gt;levels()&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(factor(Data_df$Home.Range))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Large&amp;quot;  &amp;quot;Medium&amp;quot; &amp;quot;Small&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HR_vec &amp;lt;- as.numeric(factor((Data_df$Home.Range)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the levels of &lt;code&gt;Home.Range&lt;/code&gt; are ordered alphabetically. The &lt;code&gt;as.numeric()&lt;/code&gt; command will thus transform every record of &lt;code&gt;&amp;quot;Large&amp;quot;&lt;/code&gt; into &lt;code&gt;1&lt;/code&gt;, every record of &lt;code&gt;&amp;quot;Medium&amp;quot;&lt;/code&gt; into &lt;code&gt;2&lt;/code&gt; and every record of &lt;code&gt;&amp;quot;Small&amp;quot;&lt;/code&gt; into &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We are ready to run the analysis:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = HR_vec[Climate == &amp;quot;Continental&amp;quot;], 
                 y = HR_vec[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  HR_vec[Climate == &amp;quot;Continental&amp;quot;] and HR_vec[Climate != &amp;quot;Continental&amp;quot;]
## W = 11897, p-value = 0.3666
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(HR_vec[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(HR_vec[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to the output of our analysis, the home ranges of &lt;em&gt;Passer domesticus&lt;/em&gt; do not depend on the climate characteristics of their respective habitats (p = $0.2766088$). Thus, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;br&gt;
As you can see, the median of numeric home ranges is smaller in continental climates (just not statistically significant). Remember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that  climates force common house sparrows to adapt to bigger home ranges.&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on sex?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If we assume a sexual dimorphism to have manifested itself in &lt;em&gt;Passer domesticus&lt;/em&gt; over evolutionary time, we&amp;rsquo;d expect different morphological features of males and females. In our second practical (Nominal Tests) we already assessed this using a Chi-Squared approach in a two-sample situation on colour morphs of the common house sparrows. At the time, we concluded that colouring is not equal for the sexes. So what about characteristics of our sparrows we can put into a meaningful order?&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;sparrow-weight-1&#34;&gt;Sparrow Weight&lt;/h4&gt;
&lt;p&gt;We start by assessing the median weight of sparrows again, as driven by their sexes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Weight[Sex == &amp;quot;Male&amp;quot;], 
                 y = Weight[Sex != &amp;quot;Male&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Weight[Sex == &amp;quot;Male&amp;quot;] and Weight[Sex != &amp;quot;Male&amp;quot;]
## W = 187772, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Weight[which(Data_df$Sex == &amp;quot;Male&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Weight[which(Data_df$Sex != &amp;quot;Male&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We already identified &lt;code&gt;Climate&lt;/code&gt; to be a major driver of median sparrow weight within this practical. Now, we need to add &lt;code&gt;Sex&lt;/code&gt; to the list of drivers of sparrow weight (p = $8.2580833\times 10^{-20}$) and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; that sparrow weights do not differ according to Sex.  Males tend to be heavier than females.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-height-1&#34;&gt;Sparrow Height&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s move on and see if the height/length of our observed sparrows are dependent on their sexes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Height[Sex == &amp;quot;Male&amp;quot;], 
                 y = Height[Sex != &amp;quot;Male&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Height[Sex == &amp;quot;Male&amp;quot;] and Height[Sex != &amp;quot;Male&amp;quot;]
## W = 141956, p-value = 0.9525
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We already identified &lt;code&gt;Climate&lt;/code&gt; to be a major driver of median sparrow height within this practical. Sparrow &lt;code&gt;Sex&lt;/code&gt; does not seem to be an informative characteristic when trying to understand sparrow heights (p = $0.9524599$). So we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and don&amp;rsquo;t identify any direction of effects since there is no effect.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-wing-chord-1&#34;&gt;Sparrow Wing Chord&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Wing.Chord[Sex == &amp;quot;Male&amp;quot;], 
                 y = Wing.Chord[Sex != &amp;quot;Male&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Wing.Chord[Sex == &amp;quot;Male&amp;quot;] and Wing.Chord[Sex != &amp;quot;Male&amp;quot;]
## W = 141637, p-value = 0.9021
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to our previous analysis within this practical, &lt;code&gt;Climate&lt;/code&gt; has been determined to be a major driver wing chords of common house sparrows. With our current analysis in mind, we can conclude that the &lt;code&gt;Sex&lt;/code&gt; of any given &lt;em&gt;Passer domesticus&lt;/em&gt; individual does not influence the wing chord of said individual (p = $0.9020933$). Therefore we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and don&amp;rsquo;t identify any direction of effects since there is no effect.&lt;/p&gt;
&lt;h2 id=&#34;wilcoxon-signed-rank-test&#34;&gt;Wilcoxon Signed Rank Test&lt;/h2&gt;
&lt;p&gt;We can analyse the significance of two population/sample medians of metric variables which are dependent of one another using the &lt;code&gt;wilcox.test()&lt;/code&gt; function in base &lt;code&gt;R&lt;/code&gt; whilst specifying &lt;code&gt;paired = TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-data&#34;&gt;Preparing Data&lt;/h3&gt;
&lt;p&gt;Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.&lt;/p&gt;
&lt;p&gt;Conclusively, we need an &lt;strong&gt;additional data set with truly paired records&lt;/strong&gt; of sparrows. Within our study set-up, think of a &lt;strong&gt;resettling experiment&lt;/strong&gt;, were you take &lt;em&gt;Passer domesticus&lt;/em&gt; individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.&lt;br&gt;
To this end, presume we have taken the entire &lt;em&gt;Passer domesticus&lt;/em&gt; population found at our &lt;strong&gt;Siberian&lt;/strong&gt; research station and moved them to the &lt;strong&gt;United Kingdom&lt;/strong&gt;. Whilst this keeps the latitude stable, the sparrows &lt;em&gt;now experience a coastal climate instead of a continental one&lt;/em&gt;. After some time (let&amp;rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.&lt;/p&gt;
&lt;p&gt;You will find the corresponding &lt;em&gt;new data&lt;/em&gt; in &lt;code&gt;2b - Sparrow_ResettledSIUK_READY.rds&lt;/code&gt;. Take note that this set only contains records for the transferred individuals in the &lt;strong&gt;same order&lt;/strong&gt; as in the old data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_Resettled &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2b - Sparrow_ResettledSIUK_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their &lt;strong&gt;plasticity&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have already concluded that the overall morphological aspects of populations of &lt;em&gt;Passer domesticus&lt;/em&gt; are shaped by climate, but what happens if we take birds from one climate and resettle them to another climate?&lt;/p&gt;
&lt;h4 id=&#34;sparrow-weight-2&#34;&gt;Sparrow Weight&lt;/h4&gt;
&lt;p&gt;First, let&amp;rsquo;s see how the average weight of our individual sparrows changed a year after they were relocated from Siberia to the UK:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Weight, y = Data_df_Resettled$Weight, paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  Weight and Data_df_Resettled$Weight
## V = 2044, p-value = 2.073e-09
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, the weight of the individual sparrows have significantly changed following their relocation (p = $2.0725016\times 10^{-9}$) and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Earlier, we identified sparrows to be heavier in continental climates when compared to coastal climates - does this sentiment hold true with relocated birds?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Weight[which(Data_df$Index == &amp;quot;SI&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df_Resettled$Weight, na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, it does. The resettled birds have reduced their median weight (probably not a conscious decision on behalf of the sparrows).&lt;/p&gt;
&lt;h4 id=&#34;sparrow-height-2&#34;&gt;Sparrow Height&lt;/h4&gt;
&lt;p&gt;Secondly, have our relocated sparrows become taller or shorter?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Height, y = Data_df_Resettled$Height, paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in wilcox.test.default(x = Height, y = Data_df_Resettled$Height, :
## cannot compute exact p-value with zeroes
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  Height and Data_df_Resettled$Height
## V = 0, p-value = NA
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interestingly enough, we do not receive either meaningful W (&lt;code&gt;V&lt;/code&gt;) statistic nor an informative p-value (&lt;code&gt;NA&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;This could only be due to one reason:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Height[which(Data_df$Index == &amp;quot;SI&amp;quot;)] == Data_df_Resettled$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our sparrows have not become any shorter or taller! In fact, no height/length record has changed for any of the sparrows we relocated. This may usually be indicative of a data handling error but, in this case, makes a lot of sense when considering how difficult it may be for mature individuals to change in size.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-wing-chord-2&#34;&gt;Sparrow Wing Chord&lt;/h4&gt;
&lt;p&gt;Third, let&amp;rsquo;s check whether wing chords have changed across the board. We can expect them to behave just like height records did:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Wing.Chord, y = Data_df_Resettled$Wing.Chord, paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in wilcox.test.default(x = Wing.Chord, y =
## Data_df_Resettled$Wing.Chord, : cannot compute exact p-value with zeroes
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  Wing.Chord and Data_df_Resettled$Wing.Chord
## V = 0, p-value = NA
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Wing.Chord[which(Data_df$Index == &amp;quot;SI&amp;quot;)] == Data_df_Resettled$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, none of the wing chord records have changed.&lt;/p&gt;
&lt;h3 id=&#34;predation-1&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height of nest sites of Passer domesticus depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have already identified predator characteristics at our sites to be influential in the overall nesting site and height of &lt;em&gt;Passer domesticus&lt;/em&gt;. Does this trend hold true when considering a relocation experiment?&lt;/p&gt;
&lt;p&gt;Firstly, we will test whether nesting heights have changed after the relocation. Before we do so, we should first check whether we&amp;rsquo;d expect a change based on whether &lt;strong&gt;predator presence&lt;/strong&gt; is different between Siberia and the UK:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PP_Sib &amp;lt;- unique(Data_df$Predator.Presence[which(Data_df$Index == &amp;quot;SI&amp;quot;)])
PP_UK &amp;lt;- unique(Data_df_Resettled$Predator.Presence)

PP_Sib == PP_UK
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, predators are present at both of these sites and so we would not expect a significant change in nesting height. Let&amp;rsquo;s check this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Nesting.Height, 
                 y = Data_df_Resettled$Nesting.Height, 
                 paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank exact test
## 
## data:  Nesting.Height and Data_df_Resettled$Nesting.Height
## V = 65, p-value = 7.404e-05
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There actually is an effect after the resettling! Therefore, we have to &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $7.4040145\times 10^{-5}$)! How can this be?&lt;/p&gt;
&lt;p&gt;Maybe it has to do with the kind of predator at each site:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Predator.Type[which(Data_df$Index == &amp;quot;SI&amp;quot;)])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Avian
## Levels: Avian Non-Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df_Resettled$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Non-Avian
## Levels: Avian Non-Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, Siberian sparrows are subject to avian predation whilst the sparrow populations that we monitored in the UK are experiencing non-avian predator presence. A &lt;strong&gt;causal link between nesting height and predator type&lt;/strong&gt; seems to be logical!&lt;/p&gt;
&lt;p&gt;Which direction is the effect headed? Earlier within this practical, we hypothesized that avian predation forces lower nesting heights in &lt;em&gt;Passer domesticus&lt;/em&gt; - does this hold true?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;NH_Sib &amp;lt;- mean(Data_df$Nesting.Height[which(Data_df$Index == &amp;quot;SI&amp;quot;)], na.rm = TRUE) 
NH_UK &amp;lt;- mean(Data_df_Resettled$Nesting.Height, na.rm = TRUE)

NH_Sib &amp;lt; NH_UK
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, it does!&lt;/p&gt;
&lt;h3 id=&#34;competition-1&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do home ranges of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Earlier in this practical, we have shown that home ranges of flocks of &lt;em&gt;Passer domesticus&lt;/em&gt; are affected by the climate conditions they are experiencing. Let&amp;rsquo;s see if our relocated sparrows have altered their behaviour:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = as.numeric(factor(Home.Range)), 
                 y = as.numeric(factor(Data_df_Resettled$Home.Range)), 
                 paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  as.numeric(factor(Home.Range)) and as.numeric(factor(Data_df_Resettled$Home.Range))
## V = 348.5, p-value = 0.002891
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.002890788
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, they haven&amp;rsquo;t! Given the p-value of 7.4040145\times 10^{-5}, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and conclude that home ranges of our flocks of sparrows have not changed significantly after the relocation to the UK.&lt;/p&gt;
&lt;p&gt;Due to our earlier analysis, we would expect smaller home ranges of sparrows in the UK when compared to their previous home ranges in Siberia. Before testing this, remember that, when converted to numeric records, low values indicate larger home ranges:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HR_Sib &amp;lt;- as.numeric(Data_df$Home.Range[which(Data_df$Index == &amp;quot;SI&amp;quot;)])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HR_UK &amp;lt;- as.numeric(Data_df_Resettled$Home.Range)

median(HR_Sib, na.rm = TRUE) &amp;lt; median(HR_UK, na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We were right! The assignment of home ranges did shift to accommodate smaller home ranges in the coastal climate of the UK it is just not intense enough for statistical significance - this will be further evaluated in our next seminar.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ordinal &amp; Metric Tests (Two-Sample Situations)</title>
      <link>https://www.erikkusch.com/courses/biostat101/ordinal-metric-tests-two-sample-situations/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/ordinal-metric-tests-two-sample-situations/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our fourth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise. I have prepared some slides for this session: &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/10---Ordinal-and-Metric-Test--Two-Sample-_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/10---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/2b%20-%20Sparrow_ResettledSIUK_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c()
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## list()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we don&amp;rsquo;t need any packages for our analyses in this practical.&lt;/p&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;mann-whitney-u-test&#34;&gt;Mann-Whitney U Test&lt;/h2&gt;
&lt;p&gt;We can analyse the significance of two population/sample medians of metric variables which are independent of one another using the &lt;code&gt;wilcox.test()&lt;/code&gt; function in base &lt;code&gt;R&lt;/code&gt; whilst specifying &lt;code&gt;paired = FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Logically, we&amp;rsquo;d expect morphological aspects of &lt;em&gt;Passer domesticus&lt;/em&gt; to change given different frequencies and severities of climate extremes. Don&amp;rsquo;t forget, however, that our statistical procedures are usually built on the null hypothesis of no differences or correlations being present and so is the Mann-Whitney U Test.&lt;/p&gt;
&lt;p&gt;Our data set recorded three aspects of sparrow morphology and three climate levels (). Remember, however, that we set aside four stations (Siberia, United Kingdom, Reunion and Australia) to test climate effects on which are strictly limited to continental and coastal climate types. We need to exclude all other sites records from our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,]
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;sparrow-weight&#34;&gt;Sparrow Weight&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start with the weight of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Weight[Climate == &amp;quot;Continental&amp;quot;], 
                 y = Weight[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Weight[Climate == &amp;quot;Continental&amp;quot;] and Weight[Climate != &amp;quot;Continental&amp;quot;]
## W = 22104, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Weight[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Weight[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite obviously, the weight of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $1.7179744\times 10^{-32}$) and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;. Weights of sparrows in continental climates are, on average, heavier than respective weights of their peers in coastal climates.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-height&#34;&gt;Sparrow Height&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Height[Climate == &amp;quot;Continental&amp;quot;], 
                 y = Height[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Height[Climate == &amp;quot;Continental&amp;quot;] and Height[Climate != &amp;quot;Continental&amp;quot;]
## W = 11498, p-value = 0.1971
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Height[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Height[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We conclude that the height of sparrows seems to not be dependent on the type of climate the individuals are suspected to (p = $0.1970959$) and &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;. Sparrows in continental climates are, on average, smaller than their peers in coastal climates but not to a statistically significant degree.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-wing-chord&#34;&gt;Sparrow Wing Chord&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Wing.Chord[Climate == &amp;quot;Continental&amp;quot;], 
                 y = Wing.Chord[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Wing.Chord[Climate == &amp;quot;Continental&amp;quot;] and Wing.Chord[Climate != &amp;quot;Continental&amp;quot;]
## W = 10505, p-value = 0.01213
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Wing.Chord[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Wing.Chord[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, the wing chord of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $0.0121264$) and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;. Sparrows in continental climates have, generally speaking, shorter wings than their peers in coastal climates.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height of nest sites of Passer domesticus depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In our second practical (Nominal Tests), we used a Chi-Squared approach in a two-sample situation to identify whether predator presence and type had any influence over the nesting sites that individuals of &lt;em&gt;Passer domesticus&lt;/em&gt; preferred. Our findings showed that they did and so we should expect similar results here when using &lt;code&gt;Nesting Site&lt;/code&gt; as our response variable instead of &lt;code&gt;Nesting Height&lt;/code&gt; as these two are highly related to each other.&lt;/p&gt;
&lt;p&gt;Additionally, to save some space in these notes, I am not showing how to identify the direction of the effect via code any more for now. We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;predator-presence&#34;&gt;Predator Presence&lt;/h4&gt;
&lt;p&gt;First, we start with a possible link to predator presence and nesting height chosen by common house sparrows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Nesting.Height[Predator.Presence == &amp;quot;Yes&amp;quot;], 
                 y = Nesting.Height[Predator.Presence != &amp;quot;Yes&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Nesting.Height[Predator.Presence == &amp;quot;Yes&amp;quot;] and Nesting.Height[Predator.Presence != &amp;quot;Yes&amp;quot;]
## W = 25420, p-value = 0.0007678
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The nesting height of sparrows depends on whether a predator is present or not (p = $7.6777684\times 10^{-4}$) thus &lt;strong&gt;rejecting the null hypothesis&lt;/strong&gt;. Sparrows tend to go for nesting sites in more elevated positions when no predator is present.&lt;/p&gt;
&lt;h4 id=&#34;predator-type&#34;&gt;Predator Type&lt;/h4&gt;
&lt;p&gt;Again, we might want to check whether the position of a given nest might be related to what kind of predator is present:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Nesting.Height[Predator.Type == &amp;quot;Avian&amp;quot;], 
                 y = Nesting.Height[Predator.Type != &amp;quot;Avian&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Nesting.Height[Predator.Type == &amp;quot;Avian&amp;quot;] and Nesting.Height[Predator.Type != &amp;quot;Avian&amp;quot;]
## W = 5228, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We conclude that the nesting height of sparrows depends on what kind of predator is present (p = $7.4380407\times 10^{-19}$) conclusively &lt;strong&gt;rejecting the null hypothesis&lt;/strong&gt;. Therefore, we are confident in stating that sparrows tend to go for nesting sites in more elevated positions when non-avian predators are present.&lt;/p&gt;
&lt;h3 id=&#34;competition&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do home ranges of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We might expect different behaviour of &lt;em&gt;Passer domesticus&lt;/em&gt; given different climate types. Since &lt;code&gt;Home Range&lt;/code&gt; is on an ordinal scale () we can run a Mann-Whitney U Test on these whilst taking &lt;code&gt;Climate&lt;/code&gt; into account as our predictor variable.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; )
Data_df &amp;lt;- Data_df[Rows,]
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To be able to use the &lt;code&gt;wilcox.test()&lt;/code&gt; function on &lt;code&gt;Home Range&lt;/code&gt;, we need to transform its elements into a numeric type. Luckily, this is as easy as using the &lt;code&gt;as.numeric()&lt;/code&gt; function on the data since it will assign every factor level a number corresponding to its position in &lt;code&gt;levels()&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(factor(Data_df$Home.Range))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Large&amp;quot;  &amp;quot;Medium&amp;quot; &amp;quot;Small&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HR_vec &amp;lt;- as.numeric(factor((Data_df$Home.Range)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the levels of &lt;code&gt;Home.Range&lt;/code&gt; are ordered alphabetically. The &lt;code&gt;as.numeric()&lt;/code&gt; command will thus transform every record of &lt;code&gt;&amp;quot;Large&amp;quot;&lt;/code&gt; into &lt;code&gt;1&lt;/code&gt;, every record of &lt;code&gt;&amp;quot;Medium&amp;quot;&lt;/code&gt; into &lt;code&gt;2&lt;/code&gt; and every record of &lt;code&gt;&amp;quot;Small&amp;quot;&lt;/code&gt; into &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We are ready to run the analysis:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = HR_vec[Climate == &amp;quot;Continental&amp;quot;], 
                 y = HR_vec[Climate != &amp;quot;Continental&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  HR_vec[Climate == &amp;quot;Continental&amp;quot;] and HR_vec[Climate != &amp;quot;Continental&amp;quot;]
## W = 11897, p-value = 0.3666
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(HR_vec[which(Data_df$Climate == &amp;quot;Continental&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(HR_vec[which(Data_df$Climate != &amp;quot;Continental&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to the output of our analysis, the home ranges of &lt;em&gt;Passer domesticus&lt;/em&gt; do not depend on the climate characteristics of their respective habitats (p = $0.2766088$). Thus, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;br&gt;
As you can see, the median of numeric home ranges is smaller in continental climates (just not statistically significant). Remember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that  climates force common house sparrows to adapt to bigger home ranges.&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on sex?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If we assume a sexual dimorphism to have manifested itself in &lt;em&gt;Passer domesticus&lt;/em&gt; over evolutionary time, we&amp;rsquo;d expect different morphological features of males and females. In our second practical (Nominal Tests) we already assessed this using a Chi-Squared approach in a two-sample situation on colour morphs of the common house sparrows. At the time, we concluded that colouring is not equal for the sexes. So what about characteristics of our sparrows we can put into a meaningful order?&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;sparrow-weight-1&#34;&gt;Sparrow Weight&lt;/h4&gt;
&lt;p&gt;We start by assessing the median weight of sparrows again, as driven by their sexes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Analysis
with(Data_df, 
     wilcox.test(x = Weight[Sex == &amp;quot;Male&amp;quot;], 
                 y = Weight[Sex != &amp;quot;Male&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Weight[Sex == &amp;quot;Male&amp;quot;] and Weight[Sex != &amp;quot;Male&amp;quot;]
## W = 187772, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Weight[which(Data_df$Sex == &amp;quot;Male&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df$Weight[which(Data_df$Sex != &amp;quot;Male&amp;quot;)], na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We already identified &lt;code&gt;Climate&lt;/code&gt; to be a major driver of median sparrow weight within this practical. Now, we need to add &lt;code&gt;Sex&lt;/code&gt; to the list of drivers of sparrow weight (p = $8.2580833\times 10^{-20}$) and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; that sparrow weights do not differ according to Sex.  Males tend to be heavier than females.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-height-1&#34;&gt;Sparrow Height&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s move on and see if the height/length of our observed sparrows are dependent on their sexes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Height[Sex == &amp;quot;Male&amp;quot;], 
                 y = Height[Sex != &amp;quot;Male&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Height[Sex == &amp;quot;Male&amp;quot;] and Height[Sex != &amp;quot;Male&amp;quot;]
## W = 141956, p-value = 0.9525
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We already identified &lt;code&gt;Climate&lt;/code&gt; to be a major driver of median sparrow height within this practical. Sparrow &lt;code&gt;Sex&lt;/code&gt; does not seem to be an informative characteristic when trying to understand sparrow heights (p = $0.9524599$). So we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and don&amp;rsquo;t identify any direction of effects since there is no effect.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-wing-chord-1&#34;&gt;Sparrow Wing Chord&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df, 
     wilcox.test(x = Wing.Chord[Sex == &amp;quot;Male&amp;quot;], 
                 y = Wing.Chord[Sex != &amp;quot;Male&amp;quot;], 
                 paired = FALSE)
     )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Wing.Chord[Sex == &amp;quot;Male&amp;quot;] and Wing.Chord[Sex != &amp;quot;Male&amp;quot;]
## W = 141636, p-value = 0.9021
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to our previous analysis within this practical, &lt;code&gt;Climate&lt;/code&gt; has been determined to be a major driver wing chords of common house sparrows. With our current analysis in mind, we can conclude that the &lt;code&gt;Sex&lt;/code&gt; of any given &lt;em&gt;Passer domesticus&lt;/em&gt; individual does not influence the wing chord of said individual (p = $0.9020933$). Therefore we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and don&amp;rsquo;t identify any direction of effects since there is no effect.&lt;/p&gt;
&lt;h2 id=&#34;wilcoxon-signed-rank-test&#34;&gt;Wilcoxon Signed Rank Test&lt;/h2&gt;
&lt;p&gt;We can analyse the significance of two population/sample medians of metric variables which are dependent of one another using the &lt;code&gt;wilcox.test()&lt;/code&gt; function in base &lt;code&gt;R&lt;/code&gt; whilst specifying &lt;code&gt;paired = TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-data&#34;&gt;Preparing Data&lt;/h3&gt;
&lt;p&gt;Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.&lt;/p&gt;
&lt;p&gt;Conclusively, we need an &lt;strong&gt;additional data set with truly paired records&lt;/strong&gt; of sparrows. Within our study set-up, think of a &lt;strong&gt;resettling experiment&lt;/strong&gt;, were you take &lt;em&gt;Passer domesticus&lt;/em&gt; individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.&lt;br&gt;
To this end, presume we have taken the entire &lt;em&gt;Passer domesticus&lt;/em&gt; population found at our &lt;strong&gt;Siberian&lt;/strong&gt; research station and moved them to the &lt;strong&gt;United Kingdom&lt;/strong&gt;. Whilst this keeps the latitude stable, the sparrows &lt;em&gt;now experience a coastal climate instead of a continental one&lt;/em&gt;. After some time (let&amp;rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.&lt;/p&gt;
&lt;p&gt;You will find the corresponding &lt;em&gt;new data&lt;/em&gt; in &lt;code&gt;2b - Sparrow_ResettledSIUK_READY.rds&lt;/code&gt;. Take note that this set only contains records for the transferred individuals in the &lt;strong&gt;same order&lt;/strong&gt; as in the old data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_Resettled &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2b - Sparrow_ResettledSIUK_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their &lt;strong&gt;plasticity&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have already concluded that the overall morphological aspects of populations of &lt;em&gt;Passer domesticus&lt;/em&gt; are shaped by climate, but what happens if we take birds from one climate and resettle them to another climate?&lt;/p&gt;
&lt;h4 id=&#34;sparrow-weight-2&#34;&gt;Sparrow Weight&lt;/h4&gt;
&lt;p&gt;First, let&amp;rsquo;s see how the average weight of our individual sparrows changed a year after they were relocated from Siberia to the UK:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Weight, y = Data_df_Resettled$Weight, paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  Weight and Data_df_Resettled$Weight
## V = 2044, p-value = 2.073e-09
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, the weight of the individual sparrows have significantly changed following their relocation (p = $2.0725016\times 10^{-9}$) and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Earlier, we identified sparrows to be heavier in continental climates when compared to coastal climates - does this sentiment hold true with relocated birds?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Direction of effect
median(Data_df$Weight[which(Data_df$Index == &amp;quot;SI&amp;quot;)], na.rm = TRUE) &amp;gt; 
  median(Data_df_Resettled$Weight, na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, it does. The resettled birds have reduced their median weight (probably not a conscious decision on behalf of the sparrows).&lt;/p&gt;
&lt;h4 id=&#34;sparrow-height-2&#34;&gt;Sparrow Height&lt;/h4&gt;
&lt;p&gt;Secondly, have our relocated sparrows become taller or shorter?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Height, y = Data_df_Resettled$Height, paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in wilcox.test.default(x = Height, y = Data_df_Resettled$Height, :
## cannot compute exact p-value with zeroes
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  Height and Data_df_Resettled$Height
## V = 0, p-value = NA
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interestingly enough, we do not receive either meaningful W (&lt;code&gt;V&lt;/code&gt;) statistic nor an informative p-value (&lt;code&gt;NA&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;This could only be due to one reason:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Height[which(Data_df$Index == &amp;quot;SI&amp;quot;)] == Data_df_Resettled$Height)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our sparrows have not become any shorter or taller! In fact, no height/length record has changed for any of the sparrows we relocated. This may usually be indicative of a data handling error but, in this case, makes a lot of sense when considering how difficult it may be for mature individuals to change in size.&lt;/p&gt;
&lt;h4 id=&#34;sparrow-wing-chord-2&#34;&gt;Sparrow Wing Chord&lt;/h4&gt;
&lt;p&gt;Third, let&amp;rsquo;s check whether wing chords have changed across the board. We can expect them to behave just like height records did:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Wing.Chord, y = Data_df_Resettled$Wing.Chord, paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in wilcox.test.default(x = Wing.Chord, y =
## Data_df_Resettled$Wing.Chord, : cannot compute exact p-value with zeroes
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  Wing.Chord and Data_df_Resettled$Wing.Chord
## V = 0, p-value = NA
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Wing.Chord[which(Data_df$Index == &amp;quot;SI&amp;quot;)] == Data_df_Resettled$Wing.Chord)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, none of the wing chord records have changed.&lt;/p&gt;
&lt;h3 id=&#34;predation-1&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height of nest sites of Passer domesticus depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have already identified predator characteristics at our sites to be influential in the overall nesting site and height of &lt;em&gt;Passer domesticus&lt;/em&gt;. Does this trend hold true when considering a relocation experiment?&lt;/p&gt;
&lt;p&gt;Firstly, we will test whether nesting heights have changed after the relocation. Before we do so, we should first check whether we&amp;rsquo;d expect a change based on whether &lt;strong&gt;predator presence&lt;/strong&gt; is different between Siberia and the UK:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PP_Sib &amp;lt;- unique(Data_df$Predator.Presence[which(Data_df$Index == &amp;quot;SI&amp;quot;)])
PP_UK &amp;lt;- unique(Data_df_Resettled$Predator.Presence)

PP_Sib == PP_UK
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, predators are present at both of these sites and so we would not expect a significant change in nesting height. Let&amp;rsquo;s check this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = Nesting.Height, 
                 y = Data_df_Resettled$Nesting.Height, 
                 paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank exact test
## 
## data:  Nesting.Height and Data_df_Resettled$Nesting.Height
## V = 65, p-value = 7.404e-05
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There actually is an effect after the resettling! Therefore, we have to &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $7.4040145\times 10^{-5}$)! How can this be?&lt;/p&gt;
&lt;p&gt;Maybe it has to do with the kind of predator at each site:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df$Predator.Type[which(Data_df$Index == &amp;quot;SI&amp;quot;)])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Avian
## Levels: Avian Non-Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(Data_df_Resettled$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Non-Avian
## Levels: Avian Non-Avian
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, Siberian sparrows are subject to avian predation whilst the sparrow populations that we monitored in the UK are experiencing non-avian predator presence. A &lt;strong&gt;causal link between nesting height and predator type&lt;/strong&gt; seems to be logical!&lt;/p&gt;
&lt;p&gt;Which direction is the effect headed? Earlier within this practical, we hypothesized that avian predation forces lower nesting heights in &lt;em&gt;Passer domesticus&lt;/em&gt; - does this hold true?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;NH_Sib &amp;lt;- mean(Data_df$Nesting.Height[which(Data_df$Index == &amp;quot;SI&amp;quot;)], na.rm = TRUE) 
NH_UK &amp;lt;- mean(Data_df_Resettled$Nesting.Height, na.rm = TRUE)

NH_Sib &amp;lt; NH_UK
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, it does!&lt;/p&gt;
&lt;h3 id=&#34;competition-1&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do home ranges of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Earlier in this practical, we have shown that home ranges of flocks of &lt;em&gt;Passer domesticus&lt;/em&gt; are affected by the climate conditions they are experiencing. Let&amp;rsquo;s see if our relocated sparrows have altered their behaviour:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with(Data_df[which(Data_df$Index == &amp;quot;SI&amp;quot;),], 
     wilcox.test(x = as.numeric(factor(Home.Range)), 
                 y = as.numeric(factor(Data_df_Resettled$Home.Range)), 
                 paired = TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  as.numeric(factor(Home.Range)) and as.numeric(factor(Data_df_Resettled$Home.Range))
## V = 348.5, p-value = 0.002891
## alternative hypothesis: true location shift is not equal to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.002890788
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, they haven&amp;rsquo;t! Given the p-value of 7.4040145\times 10^{-5}, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; and conclude that home ranges of our flocks of sparrows have not changed significantly after the relocation to the UK.&lt;/p&gt;
&lt;p&gt;Due to our earlier analysis, we would expect smaller home ranges of sparrows in the UK when compared to their previous home ranges in Siberia. Before testing this, remember that, when converted to numeric records, low values indicate larger home ranges:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HR_Sib &amp;lt;- as.numeric(Data_df$Home.Range[which(Data_df$Index == &amp;quot;SI&amp;quot;)])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HR_UK &amp;lt;- as.numeric(Data_df_Resettled$Home.Range)

median(HR_Sib, na.rm = TRUE) &amp;lt; median(HR_UK, na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We were right! The assignment of home ranges did shift to accommodate smaller home ranges in the coastal climate of the UK it is just not intense enough for statistical significance - this will be further evaluated in our next seminar.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ordinal &amp; Metric Tests (More-Than-Two-Sample Situations)</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/ordinal-metric-tests-more-than-two-sample-situations/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/ordinal-metric-tests-more-than-two-sample-situations/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our fifth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare more than two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;,  &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/2a%20-%20Sparrow_ResettledSIMA_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;, and &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/2b%20-%20Sparrow_ResettledSIUK_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c()
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## list()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we don&amp;rsquo;t need any packages for our analyses in this practical. Take note that I am not using &lt;code&gt;ggplot2&lt;/code&gt; for data visualisation today. Personally, I find it cumbersome for &amp;ldquo;behind-the-scenes&amp;rdquo; boxplots (which is what I&amp;rsquo;ll use a lot today) and so I am presenting you with the base &lt;code&gt;R&lt;/code&gt; alternative.&lt;/p&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;kruskal-wallis-test&#34;&gt;Kruskal-Wallis Test&lt;/h2&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using the Mann-Witney U Test in our last practical, we concluded that climate (when recorded as &amp;ldquo;Continental&amp;rdquo; and &amp;ldquo;Non-Continental&amp;rdquo;) is an important driver of &lt;em&gt;Passer domesticus&lt;/em&gt; morphology. Now we will see whether this holds true when considering non-continental climates as coastal and semi-coastal ones.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;weight&#34;&gt;Weight&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start with weight records of common house sparrows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;WeightCont &amp;lt;- with(Data_df, Weight[which(Climate == &amp;quot;Continental&amp;quot;)])
WeightSemi &amp;lt;- with(Data_df, Weight[which(Climate == &amp;quot;Semi-Coastal&amp;quot;)])
WeightCoast &amp;lt;- with(Data_df, Weight[which(Climate == &amp;quot;Coastal&amp;quot;)])
Weights_vec &amp;lt;- c(WeightCont, WeightSemi, WeightCoast)

Climates &amp;lt;- c(
  rep(&amp;quot;Continental&amp;quot;, length(WeightCont)),
  rep(&amp;quot;Semi-Coastal&amp;quot;, length(WeightSemi)),
  rep(&amp;quot;Coastal&amp;quot;, length(WeightCoast))
)
Climates &amp;lt;- as.factor(Climates)

kruskal.test(Weights_vec, Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kruskal-Wallis rank sum test
## 
## data:  Weights_vec and Climates
## Kruskal-Wallis chi-squared = 150.98, df = 2, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We conclude that the three-level climate variable is an important source of information to understand what drives weight records of &lt;em&gt;Passer domesticus&lt;/em&gt; and thus &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $1.6418184\times 10^{-33}$).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(Weights_vec ~ Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite1b-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the boxplot, we can understand the distribution of weight records as grouped by climate types and identify weight records to be biggest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of weight records of &lt;em&gt;Passer domesticus&lt;/em&gt; with a markedly lower median than the two previous categories.&lt;/p&gt;
&lt;h4 id=&#34;height&#34;&gt;Height&lt;/h4&gt;
&lt;p&gt;Secondly, let&amp;rsquo;s repeat the above Kruskal-Wallis Test for the height/length records of our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HeightCont &amp;lt;- with(Data_df, Height[which(Climate == &amp;quot;Continental&amp;quot;)])
HeightSemi &amp;lt;- with(Data_df, Height[which(Climate == &amp;quot;Semi-Coastal&amp;quot;)])
HeightCoast &amp;lt;- with(Data_df, Height[which(Climate == &amp;quot;Coastal&amp;quot;)])
Heights_vec &amp;lt;- c(HeightCont, HeightSemi, HeightCoast)

Climates &amp;lt;- c(
  rep(&amp;quot;Continental&amp;quot;, length(HeightCont)),
  rep(&amp;quot;Semi-Coastal&amp;quot;, length(HeightSemi)),
  rep(&amp;quot;Coastal&amp;quot;, length(HeightCoast))
)
Climates &amp;lt;- as.factor(Climates)

kruskal.test(Heights_vec, Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kruskal-Wallis rank sum test
## 
## data:  Heights_vec and Climates
## Kruskal-Wallis chi-squared = 15.635, df = 2, p-value = 0.0004027
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(Heights_vec ~ Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite2a-1.png&#34; width=&#34;1440&#34; /&gt;
We conclude that the three-level climate variable is an important source of information to understand what drives height records of &lt;em&gt;Passer domesticus&lt;/em&gt; and thus &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $4.0267296\times 10^{-4}$).&lt;/p&gt;
&lt;p&gt;Looking at the boxplot, we can understand the distribution of height records as grouped by climate types and identify height records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of height records of &lt;em&gt;Passer domesticus&lt;/em&gt; with a markedly higher median than the two previous categories.&lt;/p&gt;
&lt;h4 id=&#34;wing-chord&#34;&gt;Wing Chord&lt;/h4&gt;
&lt;p&gt;Third, we will test whether climate is a good predictor for wing chord of common house sparrows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Wing.ChordCont &amp;lt;- with(Data_df, Wing.Chord[which(Climate == &amp;quot;Continental&amp;quot;)])
Wing.ChordSemi &amp;lt;- with(Data_df, Wing.Chord[which(Climate == &amp;quot;Semi-Coastal&amp;quot;)])
Wing.ChordCoast &amp;lt;- with(Data_df, Wing.Chord[which(Climate == &amp;quot;Coastal&amp;quot;)])
Wing.Chords_vec &amp;lt;- c(Wing.ChordCont, Wing.ChordSemi, Wing.ChordCoast)

Climates &amp;lt;- c(
  rep(&amp;quot;Continental&amp;quot;, length(Wing.ChordCont)),
  rep(&amp;quot;Semi-Coastal&amp;quot;, length(Wing.ChordSemi)),
  rep(&amp;quot;Coastal&amp;quot;, length(Wing.ChordCoast))
)
Climates &amp;lt;- as.factor(Climates)

kruskal.test(Wing.Chords_vec, Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kruskal-Wallis rank sum test
## 
## data:  Wing.Chords_vec and Climates
## Kruskal-Wallis chi-squared = 41.539, df = 2, p-value = 9.548e-10
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(Wing.Chords_vec ~ Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite3a-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We conclude that the three-level climate variable is an important source of information to understand what drives wing chord records of &lt;em&gt;Passer domesticus&lt;/em&gt; and thus &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $9.5482279\times 10^{-10}$).&lt;/p&gt;
&lt;p&gt;Looking at the boxplot, we can understand the distribution of wing chord records as grouped by climate types and identify wing chord records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of wing chord records of &lt;em&gt;Passer domesticus&lt;/em&gt; with a markedly higher median than the two previous categories.&lt;/p&gt;
&lt;h4 id=&#34;automating-the-analysis&#34;&gt;Automating the Analysis&lt;/h4&gt;
&lt;p&gt;As we have seen, running seperate tests for every research question may be a bit cumbersome and so we may want to automate the analysis by establishing our own user-defined function as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;AutomatedKruskal &amp;lt;- function(Variables, Groups, Plotting){
# establish data frame to save results to
Export &amp;lt;- data.frame(
  Variables = Variables,
  Grouped_by = rep(Groups, length(Variables)),
  Chi_Squared = rep(NA, length(Variables)),
  DF = rep(NA, length(Variables)),
  p_value = rep(NA, length(Variables))
)

for(i in 1:length(Variables)){
# extract data and groups from data frame
YData &amp;lt;- Data_df[,which(colnames(Data_df)==Variables[i])]
XData &amp;lt;- Data_df[,which(colnames(Data_df)==Groups)]

# establish a list holding our groups for our data
Data &amp;lt;- list()
Grouping &amp;lt;- list()
for(k in 1:length(unique(XData))){
  Data[[k]] &amp;lt;- YData[which(XData == unique(XData)[k])]
  Grouping[[k]] &amp;lt;- rep(unique(XData)[k], length = length(Data[[k]]))
} # end of k-loop

Data &amp;lt;- unlist(Data)
Grouping &amp;lt;- unlist(Grouping)

# fill data frame
Export[i, 3] &amp;lt;- kruskal.test(Data, Grouping)[[&amp;quot;statistic&amp;quot;]][[&amp;quot;Kruskal-Wallis chi-squared&amp;quot;]]
Export[i, 4] &amp;lt;- kruskal.test(Data, Grouping)[[&amp;quot;parameter&amp;quot;]]
Export[i, 5] &amp;lt;- kruskal.test(Data, Grouping)[[&amp;quot;p.value&amp;quot;]]

# optional plotting
if(Plotting == TRUE){
plot(Data ~ factor(Grouping), ylab = Variables[i])
}

} # end of i loop

# return data frame to R outside of function
return(Export)
} # end of function
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function is &lt;em&gt;named&lt;/em&gt; &lt;code&gt;AutomatedKruskal()&lt;/code&gt; and takes three &lt;em&gt;arguments&lt;/em&gt;: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of character typed identifiers for the variables we want to have tested, (2) &lt;code&gt;Groups&lt;/code&gt; - a character string identifying the grouping variable, (3) &lt;code&gt;Plotting&lt;/code&gt; - a logical statement (&lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;) whether boxplots shall be produced.&lt;/p&gt;
&lt;p&gt;The function then proceeds to establish an empty data frame which it will store the results of our Kurskal-Wallis Tests in. Afterwards, it cycles through all variables contained within the &lt;code&gt;Variables&lt;/code&gt; statement, extracts the relevant data, grouping it according to the specified grouping variable (&lt;code&gt;Groups&lt;/code&gt;), runs the test, fills the data frame and plots the data if &lt;code&gt;Plotting&lt;/code&gt; has been set to &lt;code&gt;TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s re-run our earlier test on sparrow morphology as influenced by climate using this function by &lt;em&gt;calling&lt;/em&gt; it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow = c(3,1)) # adjust plotting panes
AutomatedKruskal(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), 
                 Groups = &amp;quot;Climate&amp;quot;, 
                 Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite7b-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF      p_value
## 1     Weight    Climate   150.97901  2 1.641818e-33
## 2     Height    Climate    15.63477  2 4.026730e-04
## 3 Wing.Chord    Climate    41.53899  2 9.548228e-10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see from the results above, our function works flawlessly and we can use it going ahead.&lt;/p&gt;
&lt;p&gt;Furthermore, we can confirm some of the results of our Mann-Whitney U Test from last seminar.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, using the Mann-WHitney U Test in our last exercise, we identified both predator presence as well as predator type to be important predictors for nesting height of &lt;em&gt;Passer domesticus&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the Kruskal-Wallis Test, we can combine these two predictors by turning every record of predator type that is recorded as &lt;code&gt;NA&lt;/code&gt; into &amp;ldquo;None&amp;rdquo; which will then serve as an identifier for the absence of any predators effectively making the predator presence variable redundant:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# changing levels in predator type
levels(Data_df$Predator.Type) &amp;lt;- c(levels(Data_df$Predator.Type), &amp;quot;None&amp;quot;)
Data_df$Predator.Type[which(is.na(Data_df$Predator.Type))] &amp;lt;- &amp;quot;None&amp;quot;

# running analysis
AutomatedKruskal(Variables = &amp;quot;Nesting.Height&amp;quot;, Groups = &amp;quot;Predator.Type&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalPredationa-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        Variables    Grouped_by Chi_Squared DF      p_value
## 1 Nesting.Height Predator.Type    88.81797  2 5.169206e-20
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using our &lt;code&gt;Automated Kruskal()&lt;/code&gt; function, we can conclude that the aggregation of predator presence to predator type records serve as an excellent predictor for sparrow nesting height and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $5.169206\times 10^{-20}$).&lt;/p&gt;
&lt;p&gt;Therefore, we can argue that avian predation forces sparrows into low nesting sites, non-avian predation leads to more elevated nesting sites in &lt;em&gt;Passer domesticus&lt;/em&gt; and absence of predators seems to not force nesting height in any direction or restricting its spread.&lt;/p&gt;
&lt;h3 id=&#34;competition&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does home range depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Having used the Mann-Whitney U Test to identify possible climate-driven changes in home ranges of &lt;em&gt;Passer domesticus&lt;/em&gt; in our last seminar, we concluded that climate types largely affect home ranges of the common house sparrow.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s test this for our three-level climate variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Home.Range &amp;lt;- as.numeric(factor(Data_df$Home.Range))
AutomatedKruskal(Variables = &amp;quot;Home.Range&amp;quot;, Groups = &amp;quot;Climate&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalCompetitiona-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF    p_value
## 1 Home.Range    Climate    6.243918  2 0.04407075
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using our &lt;code&gt;Automated Kruskal()&lt;/code&gt; function, we can conclude that the three-loevel climate variable serves as an excellent predictor for sparrow home range and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $0.0440707$) thus being at odds with our Mann-Whitney U results (that were only based on two climate types).&lt;/p&gt;
&lt;p&gt;Remember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that  climates force common house sparrows to adapt to bigger home ranges.&lt;/p&gt;
&lt;h2 id=&#34;friedman-test&#34;&gt;Friedman Test&lt;/h2&gt;
&lt;p&gt;We can analyse the significance of more than two population/sample medians of metric variables which are dependent of one another using the &lt;code&gt;friedman.test()&lt;/code&gt; function in base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-data&#34;&gt;Preparing Data&lt;/h3&gt;
&lt;p&gt;Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.&lt;/p&gt;
&lt;p&gt;Conclusively, we need &lt;strong&gt;additional data sets with truly paired records&lt;/strong&gt; of sparrows. Within our study set-up, think of a &lt;strong&gt;resettling experiment&lt;/strong&gt;, were you take &lt;em&gt;Passer domesticus&lt;/em&gt; individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.&lt;br&gt;
To this end, presume we have taken the entire &lt;em&gt;Passer domesticus&lt;/em&gt; population found at our &lt;strong&gt;Siberian&lt;/strong&gt; research station and moved them to &lt;strong&gt;Manitoba&lt;/strong&gt;. After a given time at their new location, we are again moving the population from Manitoba to the &lt;strong&gt;United Kingdom&lt;/strong&gt;. Whilst this keeps the latitude stable, the sparrows &lt;em&gt;now experience a semi-coastal climate followed by a coastal one instead of a continental one&lt;/em&gt;. After some time (let&amp;rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again. Within our data, none of the original individuals have gone missing or died throghout our study period. This is usually not the case in nature and such records would need to be deleted from the data set.&lt;/p&gt;
&lt;p&gt;You will find the corresponding &lt;em&gt;new data&lt;/em&gt; in &lt;code&gt;2a - Sparrow_ResettledSIMA_READY.rds&lt;/code&gt; (Siberia to Manitoba) and &lt;code&gt;2b - Sparrow_ResettledSIUK_READY.rds&lt;/code&gt; (former SIberian population from manitoba to the UK). Take note that these sets only contain records for the transferred individuals in the &lt;strong&gt;same order&lt;/strong&gt; as in the old data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_SIMA &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2a - Sparrow_ResettledSIMA_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df_SIUK &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2b - Sparrow_ResettledSIUK_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their &lt;strong&gt;plasticity&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As such, this program is very reminiscent of the resettling program in our last exercise when using Wilcoxon Signed Rank Test to account for plasticity of our sparrow individuals. This new program includes the additional step of transferring sparrows via Manitoba first. Why have we chosen this order of resettlements?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Our stations SI, MA and UK are all on roughly the same latitude.&lt;/li&gt;
&lt;li&gt;Moving the sparrows from SI to UK via MA results in them experiencing a gradient from continental to semi-coastal to coastal climate.&lt;/li&gt;
&lt;li&gt;Whilst Siberia is populated by avian predators, no predators are present at Manitoba and our sparrows are subject to non-avian predation in the UK.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of this serves to &lt;strong&gt;maximise variation&lt;/strong&gt; that we want to research whilst &lt;strong&gt;minising constraining factors&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Thinking back to out Wilcoxon Signed Rank test, we can already argue that weight records of sparrows should change according to climate whilst height and wing chord records should remain unaltered for every individual.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since this involves testing three seperate criterions of sparrow morphology, we again establish a user-defined function. This one is called &lt;code&gt;AutomatedFried()&lt;/code&gt; and has dropped the &lt;code&gt;Groups&lt;/code&gt; argument that was present in &lt;code&gt;AutomatedKruskal()&lt;/code&gt; since the grouping will always be our three stations:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;AutomatedFried &amp;lt;- function(Variables, Plotting){
# establish data frame to save results to
Export &amp;lt;- data.frame(
  Variables = Variables,
  Grouped_by = rep(&amp;quot;Resettling&amp;quot;, length(Variables)),
  Chi_Squared = rep(NA, length(Variables)),
  DF = rep(NA, length(Variables)),
  p_value = rep(NA, length(Variables))
)

for(i in 1:length(Variables)){
# extract data and groups from data frame
YDataSI &amp;lt;- Data_df[,which(colnames(Data_df)==Variables[i])]
YDataMA &amp;lt;- Data_df_SIMA[,which(colnames(Data_df)==Variables[i])]
YDataUK &amp;lt;- Data_df_SIUK[,which(colnames(Data_df)==Variables[i])]

Data &amp;lt;- matrix(c(YDataSI[which(Data_df$Index == &amp;quot;SI&amp;quot;)],
          YDataMA, YDataUK), nrow = dim(Data_df_SIMA)[1],
       byrow = FALSE, dimnames = list(1:dim(Data_df_SIMA)[1], 
                                      c(&amp;quot;SI&amp;quot;, &amp;quot;MA&amp;quot;, &amp;quot;UK&amp;quot;))
  )

# fill data frame
Export[i, 3] &amp;lt;- friedman.test(Data)[[&amp;quot;statistic&amp;quot;]][[&amp;quot;Friedman chi-squared&amp;quot;]]
Export[i, 4] &amp;lt;- friedman.test(Data)[[&amp;quot;parameter&amp;quot;]]
Export[i, 5] &amp;lt;- friedman.test(Data)[[&amp;quot;p.value&amp;quot;]]

# optional plotting
if(Plotting == TRUE){
  
  # prepare plotting data
  PlotData &amp;lt;- as.vector(Data)
  Grouping &amp;lt;- as.factor(
    rep(c(&amp;quot;SI&amp;quot;, &amp;quot;MA&amp;quot;, &amp;quot;UK&amp;quot;), each = dim(Data_df_SIMA)[1])
    )
  # plotting
  plot(PlotData ~ Grouping, ylab = Variables[i])
}
} # end of i loop

# return data frame to R outside of function
return(Export)
} # end of function
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As such, the above function operates a lot like the earlier user-defined counterpart for the Kruskal-Wallis Test. It returns the important test characteristics and allows for plots. Internally, however, it is built on a matrix rather than vectors.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s get to testing our prediction:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow = c(3,1)) # adjust plotting panes
AutomatedFried(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/FriedClimateb-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF      p_value
## 1     Weight Resettling    97.84848  2 5.655506e-22
## 2     Height Resettling         NaN  2          NaN
## 3 Wing.Chord Resettling         NaN  2          NaN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, whilst climate is a good predictor for the weight of resettled sparrows (weight in continental climates is higher than in semi-coastal or coastal ones), height and wing chord records couldn&amp;rsquo;t be properly tested on using the &lt;code&gt;friedman.test()&lt;/code&gt; function since they have remained unalterd. Thetrefore, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; for weight records of &lt;em&gt;Passer domesticus&lt;/em&gt; and &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; for height and wing chord records.&lt;/p&gt;
&lt;h3 id=&#34;predation-1&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;According to the results of our last practical, we would assume &lt;em&gt;Passer doemsticus&lt;/em&gt; to adhere to local conditions when chosing a nesting site and corresponding nesting height depending on predator presence:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;AutomatedFried(Variables = &amp;quot;Nesting.Height&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/FriedPreda-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        Variables Grouped_by Chi_Squared DF     p_value
## 1 Nesting.Height Resettling      10.864  2 0.004374338
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like we expected, nesting height of resettled sparrows depends hugely on predator presence at the sties they have been moved to (p = $7.3991389\times 10^{-19}$) and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;competition-1&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does home range depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As we&amp;rsquo;ve seen in our last seminar, a statistically signficant change in home ranges did not occur when resettling Siberian sparrows directly to the UK. How about when we resettle them via Manitoba?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_SIMA$Home.Range &amp;lt;- as.numeric(Data_df_SIMA$Home.Range)
Data_df_SIUK$Home.Range &amp;lt;- as.numeric(Data_df_SIUK$Home.Range)

AutomatedFried(Variables = &amp;quot;Home.Range&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/FriedCompetitiona-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF      p_value
## 1 Home.Range Resettling         132  2 2.170522e-29
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With our three-step resettling program we do record a statistically significant change in home ranges of our sparrow flocks and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $2.170522\times 10^{-29}$).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ordinal &amp; Metric Tests (More-Than-Two-Sample Situations)</title>
      <link>https://www.erikkusch.com/courses/biostat101/ordinal-metric-tests-more-than-two-sample-situations/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/ordinal-metric-tests-more-than-two-sample-situations/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our fifth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare more than two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise. I have prepared some slides for this session: &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/11---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;,  &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/2a%20-%20Sparrow_ResettledSIMA_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;, and &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/2b%20-%20Sparrow_ResettledSIUK_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c()
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## list()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we don&amp;rsquo;t need any packages for our analyses in this practical. Take note that I am not using &lt;code&gt;ggplot2&lt;/code&gt; for data visualisation today. Personally, I find it cumbersome for &amp;ldquo;behind-the-scenes&amp;rdquo; boxplots (which is what I&amp;rsquo;ll use a lot today) and so I am presenting you with the base &lt;code&gt;R&lt;/code&gt; alternative.&lt;/p&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;kruskal-wallis-test&#34;&gt;Kruskal-Wallis Test&lt;/h2&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does morphology of Passer domesticus depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using the Mann-Witney U Test in our last practical, we concluded that climate (when recorded as &amp;ldquo;Continental&amp;rdquo; and &amp;ldquo;Non-Continental&amp;rdquo;) is an important driver of &lt;em&gt;Passer domesticus&lt;/em&gt; morphology. Now we will see whether this holds true when considering non-continental climates as coastal and semi-coastal ones.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;weight&#34;&gt;Weight&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s start with weight records of common house sparrows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;WeightCont &amp;lt;- with(Data_df, Weight[which(Climate == &amp;quot;Continental&amp;quot;)])
WeightSemi &amp;lt;- with(Data_df, Weight[which(Climate == &amp;quot;Semi-Coastal&amp;quot;)])
WeightCoast &amp;lt;- with(Data_df, Weight[which(Climate == &amp;quot;Coastal&amp;quot;)])
Weights_vec &amp;lt;- c(WeightCont, WeightSemi, WeightCoast)

Climates &amp;lt;- c(
  rep(&amp;quot;Continental&amp;quot;, length(WeightCont)),
  rep(&amp;quot;Semi-Coastal&amp;quot;, length(WeightSemi)),
  rep(&amp;quot;Coastal&amp;quot;, length(WeightCoast))
)
Climates &amp;lt;- as.factor(Climates)

kruskal.test(Weights_vec, Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kruskal-Wallis rank sum test
## 
## data:  Weights_vec and Climates
## Kruskal-Wallis chi-squared = 150.98, df = 2, p-value &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We conclude that the three-level climate variable is an important source of information to understand what drives weight records of &lt;em&gt;Passer domesticus&lt;/em&gt; and thus &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $1.6418184\times 10^{-33}$).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(Weights_vec ~ Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite1b-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the boxplot, we can understand the distribution of weight records as grouped by climate types and identify weight records to be biggest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of weight records of &lt;em&gt;Passer domesticus&lt;/em&gt; with a markedly lower median than the two previous categories.&lt;/p&gt;
&lt;h4 id=&#34;height&#34;&gt;Height&lt;/h4&gt;
&lt;p&gt;Secondly, let&amp;rsquo;s repeat the above Kruskal-Wallis Test for the height/length records of our &lt;em&gt;Passer domesticus&lt;/em&gt; individuals:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HeightCont &amp;lt;- with(Data_df, Height[which(Climate == &amp;quot;Continental&amp;quot;)])
HeightSemi &amp;lt;- with(Data_df, Height[which(Climate == &amp;quot;Semi-Coastal&amp;quot;)])
HeightCoast &amp;lt;- with(Data_df, Height[which(Climate == &amp;quot;Coastal&amp;quot;)])
Heights_vec &amp;lt;- c(HeightCont, HeightSemi, HeightCoast)

Climates &amp;lt;- c(
  rep(&amp;quot;Continental&amp;quot;, length(HeightCont)),
  rep(&amp;quot;Semi-Coastal&amp;quot;, length(HeightSemi)),
  rep(&amp;quot;Coastal&amp;quot;, length(HeightCoast))
)
Climates &amp;lt;- as.factor(Climates)

kruskal.test(Heights_vec, Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kruskal-Wallis rank sum test
## 
## data:  Heights_vec and Climates
## Kruskal-Wallis chi-squared = 15.635, df = 2, p-value = 0.0004027
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(Heights_vec ~ Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite2a-1.png&#34; width=&#34;1440&#34; /&gt;
We conclude that the three-level climate variable is an important source of information to understand what drives height records of &lt;em&gt;Passer domesticus&lt;/em&gt; and thus &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $4.0267296\times 10^{-4}$).&lt;/p&gt;
&lt;p&gt;Looking at the boxplot, we can understand the distribution of height records as grouped by climate types and identify height records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of height records of &lt;em&gt;Passer domesticus&lt;/em&gt; with a markedly higher median than the two previous categories.&lt;/p&gt;
&lt;h4 id=&#34;wing-chord&#34;&gt;Wing Chord&lt;/h4&gt;
&lt;p&gt;Third, we will test whether climate is a good predictor for wing chord of common house sparrows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Wing.ChordCont &amp;lt;- with(Data_df, Wing.Chord[which(Climate == &amp;quot;Continental&amp;quot;)])
Wing.ChordSemi &amp;lt;- with(Data_df, Wing.Chord[which(Climate == &amp;quot;Semi-Coastal&amp;quot;)])
Wing.ChordCoast &amp;lt;- with(Data_df, Wing.Chord[which(Climate == &amp;quot;Coastal&amp;quot;)])
Wing.Chords_vec &amp;lt;- c(Wing.ChordCont, Wing.ChordSemi, Wing.ChordCoast)

Climates &amp;lt;- c(
  rep(&amp;quot;Continental&amp;quot;, length(Wing.ChordCont)),
  rep(&amp;quot;Semi-Coastal&amp;quot;, length(Wing.ChordSemi)),
  rep(&amp;quot;Coastal&amp;quot;, length(Wing.ChordCoast))
)
Climates &amp;lt;- as.factor(Climates)

kruskal.test(Wing.Chords_vec, Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Kruskal-Wallis rank sum test
## 
## data:  Wing.Chords_vec and Climates
## Kruskal-Wallis chi-squared = 41.539, df = 2, p-value = 9.548e-10
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(Wing.Chords_vec ~ Climates)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite3a-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We conclude that the three-level climate variable is an important source of information to understand what drives wing chord records of &lt;em&gt;Passer domesticus&lt;/em&gt; and thus &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $9.5482279\times 10^{-10}$).&lt;/p&gt;
&lt;p&gt;Looking at the boxplot, we can understand the distribution of wing chord records as grouped by climate types and identify wing chord records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of wing chord records of &lt;em&gt;Passer domesticus&lt;/em&gt; with a markedly higher median than the two previous categories.&lt;/p&gt;
&lt;h4 id=&#34;automating-the-analysis&#34;&gt;Automating the Analysis&lt;/h4&gt;
&lt;p&gt;As we have seen, running seperate tests for every research question may be a bit cumbersome and so we may want to automate the analysis by establishing our own user-defined function as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;AutomatedKruskal &amp;lt;- function(Variables, Groups, Plotting){
# establish data frame to save results to
Export &amp;lt;- data.frame(
  Variables = Variables,
  Grouped_by = rep(Groups, length(Variables)),
  Chi_Squared = rep(NA, length(Variables)),
  DF = rep(NA, length(Variables)),
  p_value = rep(NA, length(Variables))
)

for(i in 1:length(Variables)){
# extract data and groups from data frame
YData &amp;lt;- Data_df[,which(colnames(Data_df)==Variables[i])]
XData &amp;lt;- Data_df[,which(colnames(Data_df)==Groups)]

# establish a list holding our groups for our data
Data &amp;lt;- list()
Grouping &amp;lt;- list()
for(k in 1:length(unique(XData))){
  Data[[k]] &amp;lt;- YData[which(XData == unique(XData)[k])]
  Grouping[[k]] &amp;lt;- rep(unique(XData)[k], length = length(Data[[k]]))
} # end of k-loop

Data &amp;lt;- unlist(Data)
Grouping &amp;lt;- unlist(Grouping)

# fill data frame
Export[i, 3] &amp;lt;- kruskal.test(Data, Grouping)[[&amp;quot;statistic&amp;quot;]][[&amp;quot;Kruskal-Wallis chi-squared&amp;quot;]]
Export[i, 4] &amp;lt;- kruskal.test(Data, Grouping)[[&amp;quot;parameter&amp;quot;]]
Export[i, 5] &amp;lt;- kruskal.test(Data, Grouping)[[&amp;quot;p.value&amp;quot;]]

# optional plotting
if(Plotting == TRUE){
plot(Data ~ factor(Grouping), ylab = Variables[i])
}

} # end of i loop

# return data frame to R outside of function
return(Export)
} # end of function
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function is &lt;em&gt;named&lt;/em&gt; &lt;code&gt;AutomatedKruskal()&lt;/code&gt; and takes three &lt;em&gt;arguments&lt;/em&gt;: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of character typed identifiers for the variables we want to have tested, (2) &lt;code&gt;Groups&lt;/code&gt; - a character string identifying the grouping variable, (3) &lt;code&gt;Plotting&lt;/code&gt; - a logical statement (&lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;) whether boxplots shall be produced.&lt;/p&gt;
&lt;p&gt;The function then proceeds to establish an empty data frame which it will store the results of our Kurskal-Wallis Tests in. Afterwards, it cycles through all variables contained within the &lt;code&gt;Variables&lt;/code&gt; statement, extracts the relevant data, grouping it according to the specified grouping variable (&lt;code&gt;Groups&lt;/code&gt;), runs the test, fills the data frame and plots the data if &lt;code&gt;Plotting&lt;/code&gt; has been set to &lt;code&gt;TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s re-run our earlier test on sparrow morphology as influenced by climate using this function by &lt;em&gt;calling&lt;/em&gt; it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow = c(3,1)) # adjust plotting panes
AutomatedKruskal(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), 
                 Groups = &amp;quot;Climate&amp;quot;, 
                 Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalSite7b-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF      p_value
## 1     Weight    Climate   150.97901  2 1.641818e-33
## 2     Height    Climate    15.63477  2 4.026730e-04
## 3 Wing.Chord    Climate    41.53899  2 9.548228e-10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see from the results above, our function works flawlessly and we can use it going ahead.&lt;/p&gt;
&lt;p&gt;Furthermore, we can confirm some of the results of our Mann-Whitney U Test from last seminar.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, using the Mann-WHitney U Test in our last exercise, we identified both predator presence as well as predator type to be important predictors for nesting height of &lt;em&gt;Passer domesticus&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the Kruskal-Wallis Test, we can combine these two predictors by turning every record of predator type that is recorded as &lt;code&gt;NA&lt;/code&gt; into &amp;ldquo;None&amp;rdquo; which will then serve as an identifier for the absence of any predators effectively making the predator presence variable redundant:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# changing levels in predator type
levels(Data_df$Predator.Type) &amp;lt;- c(levels(Data_df$Predator.Type), &amp;quot;None&amp;quot;)
Data_df$Predator.Type[which(is.na(Data_df$Predator.Type))] &amp;lt;- &amp;quot;None&amp;quot;

# running analysis
AutomatedKruskal(Variables = &amp;quot;Nesting.Height&amp;quot;, Groups = &amp;quot;Predator.Type&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalPredationa-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        Variables    Grouped_by Chi_Squared DF      p_value
## 1 Nesting.Height Predator.Type    88.81797  2 5.169206e-20
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using our &lt;code&gt;Automated Kruskal()&lt;/code&gt; function, we can conclude that the aggregation of predator presence to predator type records serve as an excellent predictor for sparrow nesting height and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $5.169206\times 10^{-20}$).&lt;/p&gt;
&lt;p&gt;Therefore, we can argue that avian predation forces sparrows into low nesting sites, non-avian predation leads to more elevated nesting sites in &lt;em&gt;Passer domesticus&lt;/em&gt; and absence of predators seems to not force nesting height in any direction or restricting its spread.&lt;/p&gt;
&lt;h3 id=&#34;competition&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does home range depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Having used the Mann-Whitney U Test to identify possible climate-driven changes in home ranges of &lt;em&gt;Passer domesticus&lt;/em&gt; in our last seminar, we concluded that climate types largely affect home ranges of the common house sparrow.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s test this for our three-level climate variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df$Home.Range &amp;lt;- as.numeric(factor(Data_df$Home.Range))
AutomatedKruskal(Variables = &amp;quot;Home.Range&amp;quot;, Groups = &amp;quot;Climate&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/KruskalCompetitiona-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF    p_value
## 1 Home.Range    Climate    6.243918  2 0.04407075
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using our &lt;code&gt;Automated Kruskal()&lt;/code&gt; function, we can conclude that the three-loevel climate variable serves as an excellent predictor for sparrow home range and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $0.0440707$) thus being at odds with our Mann-Whitney U results (that were only based on two climate types).&lt;/p&gt;
&lt;p&gt;Remember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that  climates force common house sparrows to adapt to bigger home ranges.&lt;/p&gt;
&lt;h2 id=&#34;friedman-test&#34;&gt;Friedman Test&lt;/h2&gt;
&lt;p&gt;We can analyse the significance of more than two population/sample medians of metric variables which are dependent of one another using the &lt;code&gt;friedman.test()&lt;/code&gt; function in base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;preparing-data&#34;&gt;Preparing Data&lt;/h3&gt;
&lt;p&gt;Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.&lt;/p&gt;
&lt;p&gt;Conclusively, we need &lt;strong&gt;additional data sets with truly paired records&lt;/strong&gt; of sparrows. Within our study set-up, think of a &lt;strong&gt;resettling experiment&lt;/strong&gt;, were you take &lt;em&gt;Passer domesticus&lt;/em&gt; individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.&lt;br&gt;
To this end, presume we have taken the entire &lt;em&gt;Passer domesticus&lt;/em&gt; population found at our &lt;strong&gt;Siberian&lt;/strong&gt; research station and moved them to &lt;strong&gt;Manitoba&lt;/strong&gt;. After a given time at their new location, we are again moving the population from Manitoba to the &lt;strong&gt;United Kingdom&lt;/strong&gt;. Whilst this keeps the latitude stable, the sparrows &lt;em&gt;now experience a semi-coastal climate followed by a coastal one instead of a continental one&lt;/em&gt;. After some time (let&amp;rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again. Within our data, none of the original individuals have gone missing or died throghout our study period. This is usually not the case in nature and such records would need to be deleted from the data set.&lt;/p&gt;
&lt;p&gt;You will find the corresponding &lt;em&gt;new data&lt;/em&gt; in &lt;code&gt;2a - Sparrow_ResettledSIMA_READY.rds&lt;/code&gt; (Siberia to Manitoba) and &lt;code&gt;2b - Sparrow_ResettledSIUK_READY.rds&lt;/code&gt; (former SIberian population from manitoba to the UK). Take note that these sets only contain records for the transferred individuals in the &lt;strong&gt;same order&lt;/strong&gt; as in the old data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_SIMA &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2a - Sparrow_ResettledSIMA_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df_SIUK &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2b - Sparrow_ResettledSIUK_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their &lt;strong&gt;plasticity&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As such, this program is very reminiscent of the resettling program in our last exercise when using Wilcoxon Signed Rank Test to account for plasticity of our sparrow individuals. This new program includes the additional step of transferring sparrows via Manitoba first. Why have we chosen this order of resettlements?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Our stations SI, MA and UK are all on roughly the same latitude.&lt;/li&gt;
&lt;li&gt;Moving the sparrows from SI to UK via MA results in them experiencing a gradient from continental to semi-coastal to coastal climate.&lt;/li&gt;
&lt;li&gt;Whilst Siberia is populated by avian predators, no predators are present at Manitoba and our sparrows are subject to non-avian predation in the UK.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of this serves to &lt;strong&gt;maximise variation&lt;/strong&gt; that we want to research whilst &lt;strong&gt;minising constraining factors&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Thinking back to out Wilcoxon Signed Rank test, we can already argue that weight records of sparrows should change according to climate whilst height and wing chord records should remain unaltered for every individual.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since this involves testing three seperate criterions of sparrow morphology, we again establish a user-defined function. This one is called &lt;code&gt;AutomatedFried()&lt;/code&gt; and has dropped the &lt;code&gt;Groups&lt;/code&gt; argument that was present in &lt;code&gt;AutomatedKruskal()&lt;/code&gt; since the grouping will always be our three stations:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;AutomatedFried &amp;lt;- function(Variables, Plotting){
# establish data frame to save results to
Export &amp;lt;- data.frame(
  Variables = Variables,
  Grouped_by = rep(&amp;quot;Resettling&amp;quot;, length(Variables)),
  Chi_Squared = rep(NA, length(Variables)),
  DF = rep(NA, length(Variables)),
  p_value = rep(NA, length(Variables))
)

for(i in 1:length(Variables)){
# extract data and groups from data frame
YDataSI &amp;lt;- Data_df[,which(colnames(Data_df)==Variables[i])]
YDataMA &amp;lt;- Data_df_SIMA[,which(colnames(Data_df)==Variables[i])]
YDataUK &amp;lt;- Data_df_SIUK[,which(colnames(Data_df)==Variables[i])]

Data &amp;lt;- matrix(c(YDataSI[which(Data_df$Index == &amp;quot;SI&amp;quot;)],
          YDataMA, YDataUK), nrow = dim(Data_df_SIMA)[1],
       byrow = FALSE, dimnames = list(1:dim(Data_df_SIMA)[1], 
                                      c(&amp;quot;SI&amp;quot;, &amp;quot;MA&amp;quot;, &amp;quot;UK&amp;quot;))
  )

# fill data frame
Export[i, 3] &amp;lt;- friedman.test(Data)[[&amp;quot;statistic&amp;quot;]][[&amp;quot;Friedman chi-squared&amp;quot;]]
Export[i, 4] &amp;lt;- friedman.test(Data)[[&amp;quot;parameter&amp;quot;]]
Export[i, 5] &amp;lt;- friedman.test(Data)[[&amp;quot;p.value&amp;quot;]]

# optional plotting
if(Plotting == TRUE){
  
  # prepare plotting data
  PlotData &amp;lt;- as.vector(Data)
  Grouping &amp;lt;- as.factor(
    rep(c(&amp;quot;SI&amp;quot;, &amp;quot;MA&amp;quot;, &amp;quot;UK&amp;quot;), each = dim(Data_df_SIMA)[1])
    )
  # plotting
  plot(PlotData ~ Grouping, ylab = Variables[i])
}
} # end of i loop

# return data frame to R outside of function
return(Export)
} # end of function
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As such, the above function operates a lot like the earlier user-defined counterpart for the Kruskal-Wallis Test. It returns the important test characteristics and allows for plots. Internally, however, it is built on a matrix rather than vectors.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s get to testing our prediction:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow = c(3,1)) # adjust plotting panes
AutomatedFried(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/FriedClimateb-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF      p_value
## 1     Weight Resettling    97.84848  2 5.655506e-22
## 2     Height Resettling         NaN  2          NaN
## 3 Wing.Chord Resettling         NaN  2          NaN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed, whilst climate is a good predictor for the weight of resettled sparrows (weight in continental climates is higher than in semi-coastal or coastal ones), height and wing chord records couldn&amp;rsquo;t be properly tested on using the &lt;code&gt;friedman.test()&lt;/code&gt; function since they have remained unalterd. Thetrefore, we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; for weight records of &lt;em&gt;Passer domesticus&lt;/em&gt; and &lt;strong&gt;accept the null hypothesis&lt;/strong&gt; for height and wing chord records.&lt;/p&gt;
&lt;h3 id=&#34;predation-1&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;According to the results of our last practical, we would assume &lt;em&gt;Passer doemsticus&lt;/em&gt; to adhere to local conditions when chosing a nesting site and corresponding nesting height depending on predator presence:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;AutomatedFried(Variables = &amp;quot;Nesting.Height&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/FriedPreda-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        Variables Grouped_by Chi_Squared DF     p_value
## 1 Nesting.Height Resettling      10.864  2 0.004374338
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like we expected, nesting height of resettled sparrows depends hugely on predator presence at the sties they have been moved to (p = $7.3991389\times 10^{-19}$) and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;competition-1&#34;&gt;Competition&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does home range depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As we&amp;rsquo;ve seen in our last seminar, a statistically signficant change in home ranges did not occur when resettling Siberian sparrows directly to the UK. How about when we resettle them via Manitoba?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_SIMA$Home.Range &amp;lt;- as.numeric(Data_df_SIMA$Home.Range)
Data_df_SIUK$Home.Range &amp;lt;- as.numeric(Data_df_SIUK$Home.Range)

AutomatedFried(Variables = &amp;quot;Home.Range&amp;quot;, Plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;11---Ordinal-and-Metric-Test--More-Than-Two-Sample-_files/figure-html/FriedCompetitiona-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##    Variables Grouped_by Chi_Squared DF      p_value
## 1 Home.Range Resettling         132  2 2.170522e-29
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With our three-step resettling program we do record a statistically significant change in home ranges of our sparrow flocks and &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; (p = $2.170522\times 10^{-29}$).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simple Parametric Tests</title>
      <link>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/simple-parametric-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/an-introduction-to-biostatistics/simple-parametric-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our sixth practical experience in R. Throughout the following notes, I will introduce you to a couple of simple parametric test. Whilst parametric tests are used extremely often in biological statistics, they can be somewhat challenging to fit to your data as you will see soon. To do so, I will enlist the sparrow data set we handled in our first exercise. Additionally, todays seminar is showing plotting via base plot instead of &lt;code&gt;ggplot2&lt;/code&gt; to highlight the usefulness of base plot and show you the base notation.&lt;/p&gt;
&lt;p&gt;I have prepared some &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/12---Simple-Parametric-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt; Lecture Slides &lt;/a&gt; for this session.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt; and &lt;a href=&#34;https://www.erikkusch.com/courses/an-introduction-to-biostatistics/Data/2b%20-%20Sparrow_ResettledSIUK_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;car&amp;quot;) # needed for the Levene Test for Homogeneity
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: car
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: carData
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  car 
## TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;t-test-unpaired&#34;&gt;t-Test (unpaired)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the unpaired t-Test:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variable is binary&lt;/li&gt;
&lt;li&gt;Response variable is metric and &lt;strong&gt;normal distributed&lt;/strong&gt; within their groups&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, test whether variance of response variable values in groups are equal (&lt;code&gt;var.test()&lt;/code&gt;) and adjust &lt;code&gt;t.test()&lt;/code&gt; argument &lt;code&gt;var.equal&lt;/code&gt; accordingly.&lt;/p&gt;
&lt;h3 id=&#34;testing-for-normality-and-homogeneity&#34;&gt;Testing For Normality And Homogeneity&lt;/h3&gt;
&lt;p&gt;We need to test the distribution of our response variables within each predictor variable group for their normality and variance. Since this involves two Shapiro tests and one variance test per variable for each response variable, we might want to write our own function to do so:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ShapiroTest &amp;lt;- function(Variables, Grouping){
  Output &amp;lt;- data.frame(x = Variables)
  for(i in 1:length(Variables)){
    
    X &amp;lt;- Data_df[,Variables[i]]
    Levels &amp;lt;- levels(factor(Data_df[,Grouping]))
    
    Output[i,2] &amp;lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[1])])$p.value
    Output[i,3] &amp;lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[2])])$p.value
    Output[i,4] &amp;lt;- var.test(x = X[which(Data_df[,Grouping] == Levels[1])], 
                            y = X[which(Data_df[,Grouping] == Levels[2])])$p.value
  }
  colnames(Output) &amp;lt;- c(&amp;quot;Variable&amp;quot;, &amp;quot;P.value1&amp;quot;, &amp;quot;P.value2&amp;quot;, &amp;quot;Var.Test&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function (&lt;code&gt;ShapiroTest()&lt;/code&gt;) takes two arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of characters holding the names of the variables we want to have tested, and (2) &lt;code&gt;Grouping&lt;/code&gt; - the binary variable by which to group our variables. The function returns a data frame holding the p-values of the Shapiro tests on each variable group values as well as the &lt;code&gt;var.test()&lt;/code&gt; p-value.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using multiple different methods (i.e. Kruskal-Wallis and Mann-Whitney U Test), we have already identified climate (be it in its binary form or when recorded as a three-level variable) is a strong driving force of sparrow morphology. We expect the same results when using a t-Test.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;testing-for-normality-and-variance&#34;&gt;Testing for Normality and Variance&lt;/h4&gt;
&lt;p&gt;Before we can make use of our data with a t-Test, we need to do an &lt;strong&gt;assumption check&lt;/strong&gt;. To this end, we first turn &lt;code&gt;Climate&lt;/code&gt; records into a binary variable by turning records of a semi-coastal climate into a coastal one.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make climate binary
Data_df$Climate[which(Data_df$Climate == &amp;quot;Semi-Coastal&amp;quot;)] &amp;lt;- &amp;quot;Coastal&amp;quot;
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s make sure our assumptions are met:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ShapiroTest(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Grouping = &amp;quot;Climate&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Variable  P.value1  P.value2    Var.Test
## 1     Weight 0.1699442 0.2521182 0.326240416
## 2     Height 0.1676977 0.3645040 0.010632158
## 3 Wing.Chord 0.0538642 0.1722528 0.002942433
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Luckily, all of our variables allow for the calculation of t-Test. Take note though that some need different specification of the &lt;code&gt;var.equal&lt;/code&gt; argument than others.&lt;/p&gt;
&lt;h4 id=&#34;analyses&#34;&gt;Analyses&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Sparrow Weight&lt;/strong&gt;&lt;br&gt;
Let&amp;rsquo;s start with the weight of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(Data_df$Weight ~ Data_df$Climate, var.equal = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Two Sample t-test
## 
## data:  Data_df$Weight by Data_df$Climate
## t = -14.852, df = 381, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -2.428439 -1.860640
## sample estimates:
##     mean in group Coastal mean in group Continental 
##                  31.23383                  33.37837
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to our analysis, which has us &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;, we conclude that binary climate records are valuable information criteria for predicting sparrow weight with sparrows in coastal climates being lighter than sparrows in continental ones thus effectively varifying the results of our non-parametric approaches (Kruskal-Wallis, Mann-Whitney U).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sparrow Height&lt;/strong&gt;&lt;br&gt;
Let&amp;rsquo;s move on to the height of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(Data_df$Height ~ Data_df$Climate, var.equal = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Welch Two Sample t-test
## 
## data:  Data_df$Height by Data_df$Climate
## t = -0.27916, df = 365.69, p-value = 0.7803
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.2329126  0.1750052
## sample estimates:
##     mean in group Coastal mean in group Continental 
##                  13.91670                  13.94565
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Confirming the results of our Mann-Whitney U Test, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sparrow Wing Chord&lt;/strong&gt;&lt;br&gt;
Lastly, we test the wing chords of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(Data_df$Wing.Chord ~ Data_df$Climate, var.equal = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Welch Two Sample t-test
## 
## data:  Data_df$Wing.Chord by Data_df$Climate
## t = -0.12285, df = 370.22, p-value = 0.9023
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.03985039  0.03516377
## sample estimates:
##     mean in group Coastal mean in group Continental 
##                  6.898696                  6.901039
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Without confirming the results of our Mann-Whitney U Test, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;br&gt;
Here&amp;rsquo;s what we&amp;rsquo;ve learned from the t-Test so far:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sparrow weight depends on (binary) climate types&lt;/li&gt;
&lt;li&gt;Sparrow height does not depend on (binary) climate types&lt;/li&gt;
&lt;li&gt;Sparrow wing chord does not depend on (binary) climate types&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s end this by viusalising all of the data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(2,2))
plot(Data_df$Weight ~ Data_df$Climate)
plot(Data_df$Height ~ Data_df$Climate)
plot(Data_df$Wing.Chord ~ Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/t-test1-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on Sex?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using the Mann-Whitney U Test, we have already identified the sex of &lt;em&gt;Passer domesticus&lt;/em&gt; is a good information criterion for understanding sparrow weight but not sparrow height or wing chord. Let&amp;rsquo;s see if we can reproduce this using a t-Test approach.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;testing-for-normality-and-variance-1&#34;&gt;Testing for Normality and Variance&lt;/h4&gt;
&lt;p&gt;Again, before we can use our data in a t-Test for this purpose, we have to make sure that our assumptions are met. To this end, we can make use of our user defined &lt;code&gt;ShapiroTest()&lt;/code&gt; function as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ShapiroTest(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Grouping = &amp;quot;Sex&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Variable     P.value1     P.value2  Var.Test
## 1     Weight 2.878769e-21 1.744517e-21 0.7475085
## 2     Height 4.028475e-17 6.600273e-19 0.4006799
## 3 Wing.Chord 3.438104e-25 1.628147e-26 0.5554935
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, our data does not allow for any t-Test (this happens often in real studies). However, we can create sex-driven subgroups within each site and test whether these meet the requirements for our t-Test. This is out of the scope of this course though and so we will skip it. Spoler alert: I have done this and the findings did not reveal anything we didn&amp;rsquo;t uncover so far.&lt;/p&gt;
&lt;!-- In order to do so, we need to do some minor tweaking to our `ShapiroTest()` function: --&gt;
&lt;!-- ```{r ShapiroSex} --&gt;
&lt;!-- ShapiroTestSites &lt;- function(Variables, Grouping){ --&gt;
&lt;!--   list &lt;- list() --&gt;
&lt;!--   for(k in 1:length(unique(Data_df$Index))){ --&gt;
&lt;!--     Output &lt;- data.frame(x = Variables) --&gt;
&lt;!--     Data &lt;- Data_df[which(Data_df$Index == unique(Data_df$Index)[k]), ] --&gt;
&lt;!--     for(i in 1:length(Variables)){ --&gt;
&lt;!--       X &lt;- Data[,Variables[i]] --&gt;
&lt;!--       Levels &lt;- levels(Data[,Grouping]) --&gt;
&lt;!--       Output[i,2] &lt;- shapiro.test(X[which(Data[,Grouping] == Levels[1])])$p.value --&gt;
&lt;!--       Output[i,3] &lt;- shapiro.test(X[which(Data[,Grouping] == Levels[2])])$p.value --&gt;
&lt;!--       Output[i,4] &lt;- var.test(x = X[which(Data_df[,Grouping] == Levels[1])],  --&gt;
&lt;!--                             y = X[which(Data_df[,Grouping] == Levels[2])]) --&gt;
&lt;!--     } --&gt;
&lt;!--     colnames(Output) &lt;- c(&#34;Variable&#34;, &#34;P.value1&#34;, &#34;P.value2&#34;, &#34;Var.Test&#34;) --&gt;
&lt;!--     list[[k]] &lt;- Output --&gt;
&lt;!--   } --&gt;
&lt;!--   return(list) --&gt;
&lt;!-- } --&gt;
&lt;!-- ``` --&gt;
&lt;!-- This function (`ShapiroTestSites()`) takes two arguments: (1) `Variables` - a vector of characters holding the names of the variables we want to have tested, and (2) `Grouping` - the binary variable by which to group our variables. The function returns a list of data frames for each site holding the p-values of the Shapiro tests on each variable group values as well as the `var.test()` p-value.  --&gt;
&lt;!--  --&gt;
&lt;!-- Let&#39;s put this function to the test: --&gt;
&lt;!-- ```{r ShapiroSex1} --&gt;
&lt;!-- ShapiroTestSites(Variables = c(&#34;Weight&#34;, &#34;Height&#34;, &#34;Wing.Chord&#34;), Grouping = &#34;Sex&#34;) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- With the exception for sparrow morphology records at:   --&gt;
&lt;!-- - Siberia (SI, height and wing chord of males)   --&gt;
&lt;!-- - Manitoba (MA, morphology of females)   --&gt;
&lt;!-- - South Africa (SA, morphology of females)   --&gt;
&lt;!-- all of our data groups variables are normal distributed with equal variances between the groups per site.   --&gt;
&lt;!-- Since our problematic sites are still relatively close to fulfilling our requirements of the data, we will use them going forward as if they did. --&gt;
&lt;!-- ### Analyses --&gt;
&lt;!-- Running three t-Tests (Weight, Height, Wing Chord) for each of our eleven sites is absolute mania! Therefore, we write our own function again that let&#39;s us apply the tests exactly the way we want to: --&gt;
&lt;!-- ```{r ttestSex0} --&gt;
&lt;!-- t_testSite &lt;- function(Variables, Grouping, data, VarEqual){ --&gt;
&lt;!--   Data &lt;- data --&gt;
&lt;!--   Index &lt;- unique(Data$Index) --&gt;
&lt;!--   Indexes &lt;- Data$Index --&gt;
&lt;!--   list &lt;- list() --&gt;
&lt;!--   for(i in 1:length(Variables)){ --&gt;
&lt;!--     Output &lt;- data.frame(NA) --&gt;
&lt;!--     for(k in 1:length(Index)){ --&gt;
&lt;!--       # data and test --&gt;
&lt;!--       X &lt;- Data[, Variables[i]][which(Indexes == Index[k])] --&gt;
&lt;!--       Y &lt;- Data[, Grouping][which(Indexes == Index[k])] --&gt;
&lt;!--       Test &lt;- t.test(X ~ Y, paired = FALSE, var.equal = VarEqual) --&gt;
&lt;!--       # filling data frame --&gt;
&lt;!--       Output[1,k] &lt;- Test[[&#34;p.value&#34;]] --&gt;
&lt;!--       Output[2,k] &lt;- Test[[&#34;estimate&#34;]][[1]] --&gt;
&lt;!--       Output[3,k] &lt;- Test[[&#34;estimate&#34;]][[2]] --&gt;
&lt;!--     } --&gt;
&lt;!--     # data frame to list --&gt;
&lt;!--     colnames(Output) &lt;- Index --&gt;
&lt;!--     rownames(Output) &lt;- c(&#34;p&#34;, &#34;Mean1&#34;, &#34;Mean2&#34;) --&gt;
&lt;!--     list[[i]] &lt;- Output --&gt;
&lt;!--   } --&gt;
&lt;!--   return(list) --&gt;
&lt;!-- } --&gt;
&lt;!-- ``` --&gt;
&lt;!-- This `t_testSite()` function takes four arguments: (1) `Variables` - a vector of characters holding the names of the variables we want to have tested, (2) `Grouping` - the binary variable by which to group our variables, (3) `data` - the data frame which contains the `Variables` and the `Grouping` factor, and (4) `VarEqual` - a logical indicator of whether to perform a t-Test assuming equal variance of the groups or not.   --&gt;
&lt;!-- The function returns a list of data frames (one per variable) containing the p-values of the unpaired t-Tests for each variable at every site as well as the predicted group means. --&gt;
&lt;!--  --&gt;
&lt;!-- Although our function `t_testSite()` can handle multiple variables at once, we will now use it on each of our morphological sparrow variables individually to disentangle them a bit easier:   --&gt;
&lt;!-- \begin{center} --&gt;
&lt;!-- \textit{Does sparrow weight depend on sex when assessed at each of our sites individually?} --&gt;
&lt;!-- \end{center} --&gt;
&lt;!-- ```{r tTestSex1} --&gt;
&lt;!-- t_testSite(Variables = &#34;Weight&#34;, Grouping = &#34;Sex&#34;, data = Data_df, VarEqual = TRUE) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- As it turns out, sex is a statistically significant predictor for sparrow weight at each site. This was to be expected. Using a binomial test in our second practical, we identified no bias in sexes for our sparrow populations. In addition, using the Mann-Whitney U-Test in our fourth practical, we identified sex to be an important information criterion for sparrow weight across all of our sites. Given these two conditions, we were expecting a results like the one presented here with males being, on average, heavier than females in *Passer domesticus* and we **reject the null hypothesis**.   --&gt;
&lt;!-- \hfill \linebreak --&gt;
&lt;!-- \begin{center} --&gt;
&lt;!-- \textit{Does sparrow height depend on sex when assessed at each of our sites individually?} --&gt;
&lt;!-- \end{center} --&gt;
&lt;!-- ```{r tTestSex2} --&gt;
&lt;!-- t_testSite(Variables = &#34;Height&#34;, Grouping = &#34;Sex&#34;, data = Data_df, VarEqual = TRUE) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- Like with our Mann-Whitney U-Test, we fail to identify a significant effect of sex on sparrow height records at each of our sites and so we **accept the null hypothesis**. --&gt;
&lt;!-- \hfill \linebreak --&gt;
&lt;!-- \begin{center} --&gt;
&lt;!-- \textit{Does sparrow wing chord depend on sex when assessed at each of our sites individually?} --&gt;
&lt;!-- \end{center} --&gt;
&lt;!-- ```{r tTestSex3} --&gt;
&lt;!-- t_testSite(Variables = &#34;Wing.Chord&#34;, Grouping = &#34;Sex&#34;, data = Data_df, VarEqual = TRUE) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- Like with our Mann-Whitney U-Test, we fail to identify a significant effect of sex on sparrow wing chord records at each of our sites and so we **accept the null hypothesis**. --&gt;
&lt;!--  --&gt;
&lt;h2 id=&#34;t-test-paired&#34;&gt;t-Test (paired)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the paired t-Test:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variable is binary&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Difference of response variable pairs&lt;/em&gt; is &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;dependent&lt;/strong&gt; (paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;preparing-data&#34;&gt;Preparing Data&lt;/h3&gt;
&lt;p&gt;For this purpose, we need an &lt;strong&gt;additional data set with truly paired records&lt;/strong&gt; of sparrows and so we implement the same solution as we&amp;rsquo;ve used within our fourth seminar using the Wilcoxon Signed Rank Test. Within our study set-up, think of a &lt;strong&gt;resettling experiment&lt;/strong&gt;, were you take &lt;em&gt;Passer domesticus&lt;/em&gt; individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.&lt;br&gt;
To this end, presume we have taken the entire &lt;em&gt;Passer domesticus&lt;/em&gt; population found at our &lt;strong&gt;Siberian&lt;/strong&gt; research station and moved them to the &lt;strong&gt;United Kingdom&lt;/strong&gt;. Whilst this keeps the latitude stable, the sparrows &lt;em&gt;now experience a coastal climate instead of a continental one&lt;/em&gt;. After some time (let&amp;rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.&lt;/p&gt;
&lt;p&gt;You will find the corresponding &lt;em&gt;new data&lt;/em&gt; in &lt;code&gt;2b - Sparrow_ResettledSIUK_READY.rds&lt;/code&gt;. Take note that this set only contains records for the transferred individuals in the &lt;strong&gt;same order&lt;/strong&gt; as in the old data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_Resettled &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2b - Sparrow_ResettledSIUK_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since earlier analysis such as the Wilcoxon Signed Rank test (fourth practical) and the Friedman Test (fifth practical) showed that height and wing chord records do not change when sparrows are resettled at all, we have excluded these here and &lt;strong&gt;focus solely on sparrow weight&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;testing-for-normality&#34;&gt;Testing for Normality&lt;/h3&gt;
&lt;p&gt;Before being able to run our paired t-Test, we must make sure that the &lt;em&gt;difference of response variable pairs&lt;/em&gt; is &lt;strong&gt;normal distributed&lt;/strong&gt;. We can do so using the &lt;code&gt;shapiro.test()&lt;/code&gt; of base &lt;code&gt;R&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# selecting pre-resettling weights
DataSI &amp;lt;- Data_df$Weight[which(Data_df$Index == &amp;quot;SI&amp;quot;)]
# calculating difference of before and after resettling weights
WeightDiff &amp;lt;- DataSI-Data_df_Resettled$Weight
# shapiro test
shapiro.test(WeightDiff)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  WeightDiff
## W = 0.97361, p-value = 0.1716
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thankfully, the &lt;strong&gt;assumption of normality&lt;/strong&gt; is &lt;strong&gt;met&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s visualise that using a qqplot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;qqnorm(WeightDiff)
qqline(WeightDiff)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Norm3-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s go on to test whether sparrow weights change significantly per individual due to our relocation experiment (we expect this from future test in our practicals):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(DataSI, Data_df_Resettled$Weight, paired = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Paired t-test
## 
## data:  DataSI and Data_df_Resettled$Weight
## t = 8.4762, df = 65, p-value = 4.17e-12
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  1.583629 2.559914
## sample estimates:
## mean of the differences 
##                2.071771
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We were right, individual sparrow weights change significantly after our relocation experiment and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;. This is in accordance with the results of the Wilcoxon Signed Rank Test as well as the Friedman Test.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s go on to visualise our data to make better sense of what is going on here:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Select the sparrow weights
Weights &amp;lt;- c(DataSI, Data_df_Resettled$Weight)
# Select the sites
Sites &amp;lt;- factor(rep(c(&amp;quot;SI&amp;quot;, &amp;quot;SI_UK&amp;quot;), each = length(DataSI)))
# Plot
plot(Weights ~ Sites)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/tpaired1-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Quite obviously sparrows observed in Siberia are heavier than when they are resettled to the United Kingdom (this may be due to the more forgiving climate in the UK). Just like the test stated, the difference of the average weights is roughly 2g between the sparrows at the two sites.&lt;/p&gt;
&lt;h2 id=&#34;one-way-anova&#34;&gt;One-Way ANOVA&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the One-Way ANOVA:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variable is categorical&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Response variable residuals&lt;/em&gt; are &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variance of populations/samples are equal (&lt;strong&gt;homogeneity&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-for-assumptions&#34;&gt;Testing For Assumptions&lt;/h3&gt;
&lt;p&gt;Firstly, we need to test the assumptions of our One-Way ANOVA. For this purpose, we write another user-defined function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# User-defined function
ANOVACheck &amp;lt;- function(Variables, Grouping, data, plotting){
  Output &amp;lt;- data.frame(x = NA)
  for(i in 1:length(Variables)){
    # data
    Y &amp;lt;- as.numeric(factor(data[,Variables[i]]))
    X &amp;lt;- data[,Grouping]
    Levels &amp;lt;- levels(factor(Data_df[,Grouping]))
    # Residuals?
    model &amp;lt;- lm(Y ~ X)
    Output[1,i] &amp;lt;- shapiro.test(residuals(model))$p.value
    # Homgeneity?
    Levene &amp;lt;- leveneTest(Y ~ X, 
                         center = median, 
                         data = data)
    Output[2,i] &amp;lt;- Levene[1,3]
    # Plotting
    if(plotting == TRUE){
      plot(model, 2)# Normality
      plot(model, 3)# Homogeneity
    }
  }
  colnames(Output) &amp;lt;- Variables
  rownames(Output) &amp;lt;- c(&amp;quot;Residual Normality&amp;quot;, &amp;quot;Homogeneity of Variances&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;code&gt;ANOVACheck()&lt;/code&gt; function takes four arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of characters holding the names of the variables we want to have tested, (2) &lt;code&gt;Grouping&lt;/code&gt; - the categorical variable by which to group our variables, (3) &lt;code&gt;data&lt;/code&gt; - the data frame which contains the &lt;code&gt;Variables&lt;/code&gt; and the &lt;code&gt;Grouping&lt;/code&gt; factor, and (4) &lt;code&gt;plotting&lt;/code&gt; - a logical indicator of whether to produce plots visualising the test results or not.&lt;br&gt;
The function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (&lt;code&gt;Residual Normality&lt;/code&gt;), and the p-values indexing whether variances between groups are homogeneous or not (&lt;code&gt;Homogeneity of Variances&lt;/code&gt;).&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-2&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using the Kruskal-Wallis Test in our last exercise, we already identified climate to be an important factor in determining &lt;em&gt;Passer domesticus&lt;/em&gt; morphology. Let&amp;rsquo;s see if this holds true.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;assumption-check&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s use the &lt;code&gt;ANOVACheck()&lt;/code&gt; function on our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(3,2))
ANOVACheck(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Grouping = &amp;quot;Climate&amp;quot;, data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.

## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.

## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck1b-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##                               Weight       Height  Wing.Chord
## Residual Normality       0.002521771 2.671414e-05 0.001685579
## Homogeneity of Variances 0.110120912 1.896577e-01 0.013575440
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, neither weight nor wing chord records fullfil our requirements.&lt;/p&gt;
&lt;h4 id=&#34;analysis&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s run our analysis for height as grouped by the three-level climate variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(Data_df$Height ~ Data_df$Climate)
anova(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Data_df$Height
##                  Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Data_df$Climate   2  14.99  7.4942  7.2494 0.0008129 ***
## Residuals       381 393.87  1.0338                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to this, climate is a meaningful predictor of height of sparrows and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; thus confirming the results of our Kruskall-Wallis analysis.&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s analyse the output a bit more in-depth:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Data_df$Height ~ Data_df$Climate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.98994 -0.69815 -0.01475  0.67142  2.37045 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                 14.07994    0.07964 176.800  &amp;lt; 2e-16 ***
## Data_df$ClimateContinental  -0.13429    0.11426  -1.175  0.24060    
## Data_df$ClimateSemi-Coastal -0.56039    0.14755  -3.798  0.00017 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.017 on 381 degrees of freedom
## Multiple R-squared:  0.03666,	Adjusted R-squared:  0.0316 
## F-statistic: 7.249 on 2 and 381 DF,  p-value: 0.0008129
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The mean sparrow height in coastal climates is 14.0799387cm (this is our &lt;strong&gt;Intercept&lt;/strong&gt;/&lt;em&gt;Baseline&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;The mean sparrow height in continental climates is -0.1342893cm bigger than the &lt;strong&gt;Intercept&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The mean sparrow height in semi-coastal climates is -0.5603864cm bigger than the &lt;strong&gt;Intercept&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Only the estimates in coastal and semi-coastal climates are statistically significant&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Personally, I would not place too much confidence in these results due to a couple of reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Our only semi-coastal site is on the northern hemisphere whereas two of our stations are located in the southern hemisphere&lt;/li&gt;
&lt;li&gt;Confounding factors such as population status might have an effect which we are not considering here&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s end this by plotting all of our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(2,2))
plot(Data_df$Weight ~ factor(Data_df$Climate))
plot(Data_df$Height ~ factor(Data_df$Climate))
plot(Data_df$Wing.Chord ~ factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis1-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, the variances are definitely not equal between our groups which explains why part of our assumption test failed.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, using the Kruskal-Wallis Test in our last exercise, we already identified predator characteristics to be an important factor in determining &lt;em&gt;Passer domesticus&lt;/em&gt; nesting height. Let&amp;rsquo;s see if this holds true.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;assumption-check-1&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s use our &lt;code&gt;ANOVACeck()&lt;/code&gt; function to test whether we can run our analysis. Before we can do so, however, we need to slightly adjust our predator type variable just like we did in our last exercise and as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# changing levels in predator type
levels(Data_df$Predator.Type) &amp;lt;- c(levels(Data_df$Predator.Type), &amp;quot;None&amp;quot;)
Data_df$Predator.Type[which(is.na(Data_df$Predator.Type))] &amp;lt;- &amp;quot;None&amp;quot;

# Assumption Check
par(mfrow=c(1,2))
ANOVACheck(Variables = &amp;quot;Nesting.Height&amp;quot;, Grouping = &amp;quot;Predator.Type&amp;quot;, data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##                          Nesting.Height
## Residual Normality         0.0017160318
## Homogeneity of Variances   0.0005845899
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, our data fails the assumption check. The residuals are definitely not normal distributed and the variance of nesting height records within our groups are not equal.&lt;/p&gt;
&lt;h4 id=&#34;analysis-1&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(Data_df$Nesting.Height ~ Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis2-1.png&#34; width=&#34;576&#34; /&gt;
Once more, we can see why our homogeneity of variances test failed.&lt;/p&gt;
&lt;h2 id=&#34;two-way-anova&#34;&gt;Two-Way ANOVA&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the Two-Way ANOVA:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variables are categorical&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Response variable residuals&lt;/em&gt; are &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variance of populations/samples are equal (&lt;strong&gt;homogeneity&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-for-assumptions-1&#34;&gt;Testing For Assumptions&lt;/h3&gt;
&lt;p&gt;Yet again, we need to check if our assumptions are met first. Automating this procedure is definitely a good idea and only needs slight modification from our &lt;code&gt;ANOVACheck()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# User-defined function
ANOVACheck_TWO &amp;lt;- function(Formulas, data, plotting){
  Output &amp;lt;- data.frame(x = NA)
  for(i in 1:length(Formulas)){
    # Check how many formulas there are
    if(length(Formulas) == 1){
      Expression &amp;lt;- Formulas[[1]]
    }else{
      Expression &amp;lt;- Formulas[[i]]
    }
    # Residuals?
    model &amp;lt;- lm(formula = Expression, data = data)
    Output[1,i] &amp;lt;- shapiro.test(residuals(model))$p.value
    # Homgeneity?
    Levene &amp;lt;- leveneTest(Expression, 
                         center = median, 
                         data = data)
    Output[2,i] &amp;lt;- Levene[1,3]
    # Plotting
    if(plotting == TRUE){
      plot(model, 2)# Normality
      plot(model, 3)# Homogeneity
    }
  }
  colnames(Output) &amp;lt;- as.character(Formulas)
  rownames(Output) &amp;lt;- c(&amp;quot;RN&amp;quot;, &amp;quot;HoV&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;code&gt;ANOVACheck_TWO()&lt;/code&gt; function takes four arguments: (1) &lt;code&gt;Formulas&lt;/code&gt; - a vector of formula specification for our ANOVA models we want to have tested, (2) &lt;code&gt;data&lt;/code&gt; - the data frame which contains the variables and the grouping factor called upon in our &lt;code&gt;Formulas&lt;/code&gt;, and (3) &lt;code&gt;plotting&lt;/code&gt; - a logical indicator of whether to produce plots visualising the test results or not.&lt;br&gt;
The function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (&lt;code&gt;RN&lt;/code&gt;), and the p-values indexing whether variances between groups are homogeneous or not (&lt;code&gt;HoV&lt;/code&gt;).&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism-1&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology depend on population status and sex?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given different factors affecting invasive species, we might expect different patterns of sexual dimorphism for invasive and native populations. Take note that we keep using the northern hemisphere subset our cimate testing sites as these present us with a nice set of invasive/native population records already whilst keeping confounding factors to a minimum.&lt;/p&gt;
&lt;h4 id=&#34;assumption-check-2&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;First, we need to check our assumptions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]

# analysis
par(mfrow=c(3,2))
ANOVACheck_TWO(Formulas = c(Weight ~ Population.Status*Sex, 
                            Height ~ Population.Status*Sex,
                            Wing.Chord ~ Population.Status*Sex)
               , data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck5-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##     Weight ~ Population.Status * Sex Height ~ Population.Status * Sex
## RN                       0.287959531                        0.2171916
## HoV                      0.004492103                        0.9057774
##     Wing.Chord ~ Population.Status * Sex
## RN                             0.1907782
## HoV                            0.9174340
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again our assumptions are not met except for sparrow height and wing chord as a product of sex and population status.&lt;/p&gt;
&lt;h4 id=&#34;analysis-2&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s run our analysis:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# height model
model &amp;lt;- lm(Height ~ Population.Status*Sex, data = Data_df)
anova(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Height
##                        Df  Sum Sq Mean Sq F value Pr(&amp;gt;F)
## Population.Status       1   0.338 0.33820  0.3190 0.5729
## Sex                     1   0.179 0.17896  0.1688 0.6816
## Population.Status:Sex   1   1.786 1.78585  1.6844 0.1959
## Residuals             197 208.865 1.06023
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# wing chord model
model &amp;lt;- lm(Wing.Chord ~ Population.Status*Sex, data = Data_df)
anova(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Wing.Chord
##                        Df Sum Sq  Mean Sq F value Pr(&amp;gt;F)
## Population.Status       1 0.0047 0.004669  0.1955 0.6589
## Sex                     1 0.0041 0.004125  0.1727 0.6782
## Population.Status:Sex   1 0.0399 0.039856  1.6688 0.1979
## Residuals             197 4.7049 0.023883
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# plotting
par(mfrow=c(1,2))
boxplot(Height ~ Population.Status*Sex, data = Data_df, col = c(&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;))
boxplot(Wing.Chord ~ Population.Status*Sex, data = Data_df, col = c(&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis5-1.png&#34; width=&#34;576&#34; /&gt;
As it turns out, population status and sex are no viable predictors for sparrow height or wing chord and so we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ancova&#34;&gt;ANCOVA&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the ANCOVA:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variables are categorical or continuous&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Response variable residuals&lt;/em&gt; are &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variance of populations/samples are equal (&lt;strong&gt;homogeneity&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;li&gt;Relationship between the response and covariate is &lt;strong&gt;linear&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;climate-warmingextremes-3&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do sparrow characteristics depend on climate and latitude?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Latitude may have masked some effects of climate on sparrow morphology in our preceding analyses and vice-versa. At times, we have been able to account for this by including our site records, which can be seen as binned versions of latitude records. Let&amp;rsquo;s test if the inclusion of raw latitude records are meaningful.&lt;/p&gt;
&lt;h4 id=&#34;assumption-check-3&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Again, we need to do an assumption check. However, we need a new function for this, since we now need to test whether our response variable and the covariate are linear or not:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# overwriting prior changes in Data_df
Data_df &amp;lt;- Data_df_base
Data_df$Latitude &amp;lt;- abs(Data_df$Latitude)
# User-defined function
ANCOVACheck &amp;lt;- function(Variables, Grouping, Covariate, data, plotting){
  Output &amp;lt;- data.frame(x = NA)
  for(i in 1:length(Variables)){
    # data
    Y &amp;lt;- as.numeric(factor(data[,Variables[i]]))
    X &amp;lt;- factor(data[,Grouping])
    Z &amp;lt;- data[, Covariate]
    # Residuals?
    model &amp;lt;- lm(Y ~ X*Z)
    Output[1,i] &amp;lt;- shapiro.test(residuals(model))$p.value
    # Homgeneity?
    Levene &amp;lt;- leveneTest(Y ~ X, 
                         center = median, 
                         data = data)
    Output[2,i] &amp;lt;- Levene[1,3]
    # Plotting
    if(plotting == TRUE){
      plot(model, 1)# Linearity
      plot(model, 2)# Normality
      plot(model, 3)# Homogeneity
    }
  }
  colnames(Output) &amp;lt;- Variables
  rownames(Output) &amp;lt;- c(&amp;quot;RN&amp;quot;, &amp;quot;HoV&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;code&gt;ANCOVACheck()&lt;/code&gt; function takes five arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of response variables used in our models, (2) &lt;code&gt;Grouping&lt;/code&gt; - the categorical variable by which to group our variables, (3) &lt;code&gt;Covariate&lt;/code&gt; - the covariate of our analysis, (4)&lt;code&gt;data&lt;/code&gt; - the data frame which contains the variables, the grouping factor and our covariate, and (5) &lt;code&gt;plotting&lt;/code&gt; - a logical indicator of whether to produce plots visualising the test results or not.&lt;br&gt;
The function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (&lt;code&gt;RN&lt;/code&gt;), and the p-values indexing whether variances between groups are homogeneous or not (&lt;code&gt;HoV&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ANCOVACheck(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Nesting.Height&amp;quot;, &amp;quot;Egg.Weight&amp;quot;, &amp;quot;Number.of.Eggs&amp;quot;, &amp;quot;Home.Range&amp;quot;), 
            Grouping = &amp;quot;Climate&amp;quot;, Covariate = &amp;quot;Latitude&amp;quot;, 
            data = Data_df, plotting = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Weight       Height   Wing.Chord Nesting.Height   Egg.Weight
## RN  2.082300e-02 1.502944e-04 4.535941e-07   5.190971e-06 2.943560e-03
## HoV 9.937376e-24 1.929783e-22 1.561040e-33   2.004612e-01 4.816355e-09
##     Number.of.Eggs   Home.Range
## RN    1.809197e-09 3.629841e-20
## HoV   2.750100e-14 1.157673e-08
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The assumptions aren&amp;rsquo;t met. I have set the &lt;code&gt;plotting&lt;/code&gt; argument to &lt;code&gt;FALSE&lt;/code&gt; tu suppress the plotting of model checking visualisation. The would be useful to judge linearity but not necessary here since the other two important assumptions (Homogeneity of variances and Normality of residuals) aren&amp;rsquo;t met to begin with.&lt;/p&gt;
&lt;h4 id=&#34;analysis-3&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone. We need a new function for this to do our plotting easily and automatically with some colours indicating our grouping factors whilst plotting response variables versus covariates.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PlotAncovas &amp;lt;- function(Variables, Grouping, Covariate, data){
  for(i in 1:length(Variables)){
    Y &amp;lt;- Data_df[,Variables[i]]
    if(class(Y) == &amp;quot;character&amp;quot;){Y &amp;lt;- factor(Y)}
    X &amp;lt;- Data_df[,Covariate]
    G &amp;lt;- factor(Data_df[, Grouping])
    plot(X, Y, col = G, xlab = Covariate, ylab = Variables[i])
    legend(&amp;quot;top&amp;quot;, # place legend at the top
           inset = -0.35, # move legend away from plot centre
           xpd = TRUE, # allow legend outside of plot area
           legend=levels(G), # what to include in legend
           bg = &amp;quot;white&amp;quot;, col = unique(G), ncol=length(levels(G)), # colours
           pch = 1, # plotting symbols
           title = Variables[i] # title of legend
           )
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;PlotAncovas()&lt;/code&gt; returns a scatter plot and takes four arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of response variables, (2) &lt;code&gt;Grouping&lt;/code&gt; - the name of the grouping factor according to which to colour the symbols in our plot, (3) &lt;code&gt;Covariate&lt;/code&gt; - the covariate against which to plot individuals variables, and (4) &lt;code&gt;data&lt;/code&gt; - the data frame which holds our variables.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s use our function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(1,2))
PlotAncovas(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Nesting.Height&amp;quot;, &amp;quot;Egg.Weight&amp;quot;, &amp;quot;Number.of.Eggs&amp;quot;, &amp;quot;Home.Range&amp;quot;), Grouping = &amp;quot;Climate&amp;quot;, Covariate = &amp;quot;Latitude&amp;quot;, data = Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will not interpret these plots here in text and leave this to you.&lt;/p&gt;
&lt;p&gt;Take note that this &lt;strong&gt;could&amp;rsquo;ve been achieved much easier with &lt;code&gt;ggplot2&lt;/code&gt;!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;sparrow-characteristics-and-sites&#34;&gt;Sparrow Characteristics And Sites&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;This was not part of what we set out to do according to the lecture slides but has been included as a logical conclusion to an earlier analysis.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, our previous attempt at an ANCOVA didn&amp;rsquo;t work. So what other covariate do we have available for sparrow characteristics?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Latitude&lt;/em&gt; doesn&amp;rsquo;t make sense to include when grouping by site index as these two are synonymous&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Longitude&lt;/em&gt; doesn&amp;rsquo;t make sense to include when grouping by site index as these two are synonymous&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Weight&lt;/em&gt; is well explained by other variables and we know the causal links&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Height&lt;/em&gt; is not that well explained by other variables&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Wing.Chord&lt;/em&gt; is not that well explained by other variables&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, there are more within our data set but it has become apparent that &lt;code&gt;Weight&lt;/code&gt; may make for an important covariate in our site-wise ANCOVA set-up. Using the Pearson correlation (third practical), we already identified a causal link between sparrow &lt;code&gt;Weight&lt;/code&gt; and &lt;code&gt;Height&lt;/code&gt; per site.&lt;/p&gt;
&lt;h4 id=&#34;assumption-check-4&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Firstly, we test whether assumptions are met. For brevities sake, we only test four variables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(1,3))
ANCOVACheck(Variables = c(&amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Egg.Weight&amp;quot;, &amp;quot;Number.of.Eggs&amp;quot;), Grouping = &amp;quot;Index&amp;quot;, Covariate = &amp;quot;Weight&amp;quot;, data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##           Height   Wing.Chord   Egg.Weight Number.of.Eggs
## RN  1.499909e-06 5.251393e-08 0.1565038171   9.220862e-07
## HoV 3.594021e-13 2.434880e-01 0.0002015813   2.660146e-02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, we can run our ANCOVA on &lt;code&gt;Egg.Weight&lt;/code&gt; when grouped by site &lt;code&gt;Index&lt;/code&gt; and driven by &lt;code&gt;Weight&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;analysis-4&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;First, let&amp;rsquo;s visualise our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PlotAncovas(Variables = &amp;quot;Egg.Weight&amp;quot;, Grouping = &amp;quot;Index&amp;quot;, Covariate = &amp;quot;Weight&amp;quot;, data = Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis7-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Quite obviously, Belize (BE) records are very different from the other stations, whose egg weight and weight records are grouped together. There seems to be some evidence for an overall linkage of sparrow weight and egg weight (a positive correlation).&lt;/p&gt;
&lt;p&gt;Now we run the analysis:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;LM_fit5 &amp;lt;- lm(Egg.Weight ~ Weight*Index, data = Data_df)
anova(LM_fit5)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Egg.Weight
##               Df Sum Sq Mean Sq   F value Pr(&amp;gt;F)    
## Weight         1 52.531  52.531 1442.5616 &amp;lt;2e-16 ***
## Index         10  8.087   0.809   22.2064 &amp;lt;2e-16 ***
## Weight:Index  10  0.129   0.013    0.3536 0.9653    
## Residuals    455 16.569   0.036                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above ANCOVA output tells us that there is no interaction effect between sites and sparrow weights when determining mean egg weight per nest of &lt;em&gt;Passer domesticus&lt;/em&gt; and so we do another iteration of our model and remove the postulated interaction:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;LM_fit6 &amp;lt;- lm(Egg.Weight ~ Weight+Index, data = Data_df)
anova(LM_fit6)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Egg.Weight
##            Df Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
## Weight      1 52.531  52.531 1462.898 &amp;lt; 2.2e-16 ***
## Index      10  8.087   0.809   22.519 &amp;lt; 2.2e-16 ***
## Residuals 465 16.698   0.036                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By now, all of our model coefficients are significant and we can go on to interpret them:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(LM_fit6)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Egg.Weight ~ Weight + Index, data = Data_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.58887 -0.13146 -0.00621  0.12033  0.55135 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  3.345984   0.280826  11.915  &amp;lt; 2e-16 ***
## Weight       0.001081   0.008614   0.125 0.900203    
## IndexBE     -0.708478   0.054864 -12.913  &amp;lt; 2e-16 ***
## IndexFG     -1.281168   0.099135 -12.923  &amp;lt; 2e-16 ***
## IndexFI     -0.625287   0.057442 -10.885  &amp;lt; 2e-16 ***
## IndexLO     -0.550137   0.051754 -10.630  &amp;lt; 2e-16 ***
## IndexMA     -0.513645   0.051352 -10.003  &amp;lt; 2e-16 ***
## IndexNU     -0.517015   0.053365  -9.688  &amp;lt; 2e-16 ***
## IndexRE     -0.612632   0.051418 -11.915  &amp;lt; 2e-16 ***
## IndexSA     -0.806045   0.056685 -14.220  &amp;lt; 2e-16 ***
## IndexSI     -0.272580   0.077868  -3.501 0.000509 ***
## IndexUK     -0.511667   0.051404  -9.954  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1895 on 465 degrees of freedom
##   (590 observations deleted due to missingness)
## Multiple R-squared:  0.784,	Adjusted R-squared:  0.7789 
## F-statistic: 153.5 on 11 and 465 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Simple Parametric Tests</title>
      <link>https://www.erikkusch.com/courses/biostat101/simple-parametric-tests/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/courses/biostat101/simple-parametric-tests/</guid>
      <description>&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;Welcome to our sixth practical experience in R. Throughout the following notes, I will introduce you to a couple of simple parametric test. Whilst parametric tests are used extremely often in biological statistics, they can be somewhat challenging to fit to your data as you will see soon. To do so, I will enlist the sparrow data set we handled in our first exercise. Additionally, todays seminar is showing plotting via base plot instead of &lt;code&gt;ggplot2&lt;/code&gt; to highlight the usefulness of base plot and show you the base notation. I have prepared some slides for this session: &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/biostat101/12---Simple-Parametric-Tests_Handout.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.erikkusch.com/courses/biostat101/12---BioStat101_featured.png&#34; width=&#34;900&#34; margin-top = &#34;0&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;Find the data for this exercise &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/1%20-%20Sparrow_Data_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt; and &lt;a href=&#34;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/2b%20-%20Sparrow_ResettledSIUK_READY.rds&#34; target=&#34;_blank&#34;&gt; here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;preparing-our-procedure&#34;&gt;Preparing Our Procedure&lt;/h2&gt;
&lt;p&gt;To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our &lt;code&gt;R&lt;/code&gt; coding file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rm(list=ls()) # clearing environment
Dir.Base &amp;lt;- getwd() # soft-coding our working directory
Dir.Data &amp;lt;- paste(Dir.Base, &amp;quot;Data&amp;quot;, sep=&amp;quot;/&amp;quot;) # soft-coding our data directory 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;packages&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Using the following, user-defined function, we install/load all the necessary packages into our current &lt;code&gt;R&lt;/code&gt; session.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# function to load packages and install them if they haven&#39;t been installed yet
install.load.package &amp;lt;- function(x) {
  if (!require(x, character.only = TRUE))
    install.packages(x)
  require(x, character.only = TRUE)
}
package_vec &amp;lt;- c(&amp;quot;car&amp;quot;) # needed for the Levene Test for Homogeneity
sapply(package_vec, install.load.package)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: car
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: carData
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  car 
## TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h3&gt;
&lt;p&gt;During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the &lt;code&gt;readRDS()&lt;/code&gt; command that comes with base &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_base &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/1 - Sparrow_Data_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
Data_df &amp;lt;- Data_df_base # duplicate and save initial data on a new object
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;t-test-unpaired&#34;&gt;t-Test (unpaired)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the unpaired t-Test:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variable is binary&lt;/li&gt;
&lt;li&gt;Response variable is metric and &lt;strong&gt;normal distributed&lt;/strong&gt; within their groups&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, test whether variance of response variable values in groups are equal (&lt;code&gt;var.test()&lt;/code&gt;) and adjust &lt;code&gt;t.test()&lt;/code&gt; argument &lt;code&gt;var.equal&lt;/code&gt; accordingly.&lt;/p&gt;
&lt;h3 id=&#34;testing-for-normality-and-homogeneity&#34;&gt;Testing For Normality And Homogeneity&lt;/h3&gt;
&lt;p&gt;We need to test the distribution of our response variables within each predictor variable group for their normality and variance. Since this involves two Shapiro tests and one variance test per variable for each response variable, we might want to write our own function to do so:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ShapiroTest &amp;lt;- function(Variables, Grouping){
  Output &amp;lt;- data.frame(x = Variables)
  for(i in 1:length(Variables)){
    
    X &amp;lt;- Data_df[,Variables[i]]
    Levels &amp;lt;- levels(factor(Data_df[,Grouping]))
    
    Output[i,2] &amp;lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[1])])$p.value
    Output[i,3] &amp;lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[2])])$p.value
    Output[i,4] &amp;lt;- var.test(x = X[which(Data_df[,Grouping] == Levels[1])], 
                            y = X[which(Data_df[,Grouping] == Levels[2])])$p.value
  }
  colnames(Output) &amp;lt;- c(&amp;quot;Variable&amp;quot;, &amp;quot;P.value1&amp;quot;, &amp;quot;P.value2&amp;quot;, &amp;quot;Var.Test&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function (&lt;code&gt;ShapiroTest()&lt;/code&gt;) takes two arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of characters holding the names of the variables we want to have tested, and (2) &lt;code&gt;Grouping&lt;/code&gt; - the binary variable by which to group our variables. The function returns a data frame holding the p-values of the Shapiro tests on each variable group values as well as the &lt;code&gt;var.test()&lt;/code&gt; p-value.&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using multiple different methods (i.e. Kruskal-Wallis and Mann-Whitney U Test), we have already identified climate (be it in its binary form or when recorded as a three-level variable) is a strong driving force of sparrow morphology. We expect the same results when using a t-Test.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;testing-for-normality-and-variance&#34;&gt;Testing for Normality and Variance&lt;/h4&gt;
&lt;p&gt;Before we can make use of our data with a t-Test, we need to do an &lt;strong&gt;assumption check&lt;/strong&gt;. To this end, we first turn &lt;code&gt;Climate&lt;/code&gt; records into a binary variable by turning records of a semi-coastal climate into a coastal one.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make climate binary
Data_df$Climate[which(Data_df$Climate == &amp;quot;Semi-Coastal&amp;quot;)] &amp;lt;- &amp;quot;Coastal&amp;quot;
Data_df$Climate &amp;lt;- droplevels(factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s make sure our assumptions are met:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ShapiroTest(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Grouping = &amp;quot;Climate&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Variable  P.value1  P.value2    Var.Test
## 1     Weight 0.1699442 0.2521182 0.326240416
## 2     Height 0.1676977 0.3645040 0.010632158
## 3 Wing.Chord 0.0538642 0.1722528 0.002942433
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Luckily, all of our variables allow for the calculation of t-Test. Take note though that some need different specification of the &lt;code&gt;var.equal&lt;/code&gt; argument than others.&lt;/p&gt;
&lt;h4 id=&#34;analyses&#34;&gt;Analyses&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Sparrow Weight&lt;/strong&gt;&lt;br&gt;
Let&amp;rsquo;s start with the weight of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(Data_df$Weight ~ Data_df$Climate, var.equal = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Two Sample t-test
## 
## data:  Data_df$Weight by Data_df$Climate
## t = -14.852, df = 381, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means between group Coastal and group Continental is not equal to 0
## 95 percent confidence interval:
##  -2.428439 -1.860640
## sample estimates:
##     mean in group Coastal mean in group Continental 
##                  31.23383                  33.37837
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to our analysis, which has us &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;, we conclude that binary climate records are valuable information criteria for predicting sparrow weight with sparrows in coastal climates being lighter than sparrows in continental ones thus effectively varifying the results of our non-parametric approaches (Kruskal-Wallis, Mann-Whitney U).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sparrow Height&lt;/strong&gt;&lt;br&gt;
Let&amp;rsquo;s move on to the height of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(Data_df$Height ~ Data_df$Climate, var.equal = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Welch Two Sample t-test
## 
## data:  Data_df$Height by Data_df$Climate
## t = -0.27916, df = 365.69, p-value = 0.7803
## alternative hypothesis: true difference in means between group Coastal and group Continental is not equal to 0
## 95 percent confidence interval:
##  -0.2329126  0.1750052
## sample estimates:
##     mean in group Coastal mean in group Continental 
##                  13.91670                  13.94565
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Confirming the results of our Mann-Whitney U Test, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sparrow Wing Chord&lt;/strong&gt;&lt;br&gt;
Lastly, we test the wing chords of &lt;em&gt;Passer domesticus&lt;/em&gt; individuals as grouped by the climate type present at the site weights have been recorded at:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(Data_df$Wing.Chord ~ Data_df$Climate, var.equal = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Welch Two Sample t-test
## 
## data:  Data_df$Wing.Chord by Data_df$Climate
## t = -0.12285, df = 370.22, p-value = 0.9023
## alternative hypothesis: true difference in means between group Coastal and group Continental is not equal to 0
## 95 percent confidence interval:
##  -0.03985039  0.03516377
## sample estimates:
##     mean in group Coastal mean in group Continental 
##                  6.898696                  6.901039
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Without confirming the results of our Mann-Whitney U Test, we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;br&gt;
Here&amp;rsquo;s what we&amp;rsquo;ve learned from the t-Test so far:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sparrow weight depends on (binary) climate types&lt;/li&gt;
&lt;li&gt;Sparrow height does not depend on (binary) climate types&lt;/li&gt;
&lt;li&gt;Sparrow wing chord does not depend on (binary) climate types&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s end this by viusalising all of the data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(2,2))
plot(Data_df$Weight ~ Data_df$Climate)
plot(Data_df$Height ~ Data_df$Climate)
plot(Data_df$Wing.Chord ~ Data_df$Climate)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/t-test1-1.png&#34; width=&#34;1440&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on Sex?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using the Mann-Whitney U Test, we have already identified the sex of &lt;em&gt;Passer domesticus&lt;/em&gt; is a good information criterion for understanding sparrow weight but not sparrow height or wing chord. Let&amp;rsquo;s see if we can reproduce this using a t-Test approach.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;testing-for-normality-and-variance-1&#34;&gt;Testing for Normality and Variance&lt;/h4&gt;
&lt;p&gt;Again, before we can use our data in a t-Test for this purpose, we have to make sure that our assumptions are met. To this end, we can make use of our user defined &lt;code&gt;ShapiroTest()&lt;/code&gt; function as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ShapiroTest(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Grouping = &amp;quot;Sex&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Variable     P.value1     P.value2  Var.Test
## 1     Weight 2.878769e-21 1.744517e-21 0.7475085
## 2     Height 4.028475e-17 6.600273e-19 0.4006799
## 3 Wing.Chord 3.438104e-25 1.628147e-26 0.5554935
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, our data does not allow for any t-Test (this happens often in real studies). However, we can create sex-driven subgroups within each site and test whether these meet the requirements for our t-Test. This is out of the scope of this course though and so we will skip it. Spoler alert: I have done this and the findings did not reveal anything we didn&amp;rsquo;t uncover so far.&lt;/p&gt;
&lt;!-- In order to do so, we need to do some minor tweaking to our `ShapiroTest()` function: --&gt;
&lt;!-- ```{r ShapiroSex} --&gt;
&lt;!-- ShapiroTestSites &lt;- function(Variables, Grouping){ --&gt;
&lt;!--   list &lt;- list() --&gt;
&lt;!--   for(k in 1:length(unique(Data_df$Index))){ --&gt;
&lt;!--     Output &lt;- data.frame(x = Variables) --&gt;
&lt;!--     Data &lt;- Data_df[which(Data_df$Index == unique(Data_df$Index)[k]), ] --&gt;
&lt;!--     for(i in 1:length(Variables)){ --&gt;
&lt;!--       X &lt;- Data[,Variables[i]] --&gt;
&lt;!--       Levels &lt;- levels(Data[,Grouping]) --&gt;
&lt;!--       Output[i,2] &lt;- shapiro.test(X[which(Data[,Grouping] == Levels[1])])$p.value --&gt;
&lt;!--       Output[i,3] &lt;- shapiro.test(X[which(Data[,Grouping] == Levels[2])])$p.value --&gt;
&lt;!--       Output[i,4] &lt;- var.test(x = X[which(Data_df[,Grouping] == Levels[1])],  --&gt;
&lt;!--                             y = X[which(Data_df[,Grouping] == Levels[2])]) --&gt;
&lt;!--     } --&gt;
&lt;!--     colnames(Output) &lt;- c(&#34;Variable&#34;, &#34;P.value1&#34;, &#34;P.value2&#34;, &#34;Var.Test&#34;) --&gt;
&lt;!--     list[[k]] &lt;- Output --&gt;
&lt;!--   } --&gt;
&lt;!--   return(list) --&gt;
&lt;!-- } --&gt;
&lt;!-- ``` --&gt;
&lt;!-- This function (`ShapiroTestSites()`) takes two arguments: (1) `Variables` - a vector of characters holding the names of the variables we want to have tested, and (2) `Grouping` - the binary variable by which to group our variables. The function returns a list of data frames for each site holding the p-values of the Shapiro tests on each variable group values as well as the `var.test()` p-value.  --&gt;
&lt;!--  --&gt;
&lt;!-- Let&#39;s put this function to the test: --&gt;
&lt;!-- ```{r ShapiroSex1} --&gt;
&lt;!-- ShapiroTestSites(Variables = c(&#34;Weight&#34;, &#34;Height&#34;, &#34;Wing.Chord&#34;), Grouping = &#34;Sex&#34;) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- With the exception for sparrow morphology records at:   --&gt;
&lt;!-- - Siberia (SI, height and wing chord of males)   --&gt;
&lt;!-- - Manitoba (MA, morphology of females)   --&gt;
&lt;!-- - South Africa (SA, morphology of females)   --&gt;
&lt;!-- all of our data groups variables are normal distributed with equal variances between the groups per site.   --&gt;
&lt;!-- Since our problematic sites are still relatively close to fulfilling our requirements of the data, we will use them going forward as if they did. --&gt;
&lt;!-- ### Analyses --&gt;
&lt;!-- Running three t-Tests (Weight, Height, Wing Chord) for each of our eleven sites is absolute mania! Therefore, we write our own function again that let&#39;s us apply the tests exactly the way we want to: --&gt;
&lt;!-- ```{r ttestSex0} --&gt;
&lt;!-- t_testSite &lt;- function(Variables, Grouping, data, VarEqual){ --&gt;
&lt;!--   Data &lt;- data --&gt;
&lt;!--   Index &lt;- unique(Data$Index) --&gt;
&lt;!--   Indexes &lt;- Data$Index --&gt;
&lt;!--   list &lt;- list() --&gt;
&lt;!--   for(i in 1:length(Variables)){ --&gt;
&lt;!--     Output &lt;- data.frame(NA) --&gt;
&lt;!--     for(k in 1:length(Index)){ --&gt;
&lt;!--       # data and test --&gt;
&lt;!--       X &lt;- Data[, Variables[i]][which(Indexes == Index[k])] --&gt;
&lt;!--       Y &lt;- Data[, Grouping][which(Indexes == Index[k])] --&gt;
&lt;!--       Test &lt;- t.test(X ~ Y, paired = FALSE, var.equal = VarEqual) --&gt;
&lt;!--       # filling data frame --&gt;
&lt;!--       Output[1,k] &lt;- Test[[&#34;p.value&#34;]] --&gt;
&lt;!--       Output[2,k] &lt;- Test[[&#34;estimate&#34;]][[1]] --&gt;
&lt;!--       Output[3,k] &lt;- Test[[&#34;estimate&#34;]][[2]] --&gt;
&lt;!--     } --&gt;
&lt;!--     # data frame to list --&gt;
&lt;!--     colnames(Output) &lt;- Index --&gt;
&lt;!--     rownames(Output) &lt;- c(&#34;p&#34;, &#34;Mean1&#34;, &#34;Mean2&#34;) --&gt;
&lt;!--     list[[i]] &lt;- Output --&gt;
&lt;!--   } --&gt;
&lt;!--   return(list) --&gt;
&lt;!-- } --&gt;
&lt;!-- ``` --&gt;
&lt;!-- This `t_testSite()` function takes four arguments: (1) `Variables` - a vector of characters holding the names of the variables we want to have tested, (2) `Grouping` - the binary variable by which to group our variables, (3) `data` - the data frame which contains the `Variables` and the `Grouping` factor, and (4) `VarEqual` - a logical indicator of whether to perform a t-Test assuming equal variance of the groups or not.   --&gt;
&lt;!-- The function returns a list of data frames (one per variable) containing the p-values of the unpaired t-Tests for each variable at every site as well as the predicted group means. --&gt;
&lt;!--  --&gt;
&lt;!-- Although our function `t_testSite()` can handle multiple variables at once, we will now use it on each of our morphological sparrow variables individually to disentangle them a bit easier:   --&gt;
&lt;!-- \begin{center} --&gt;
&lt;!-- \textit{Does sparrow weight depend on sex when assessed at each of our sites individually?} --&gt;
&lt;!-- \end{center} --&gt;
&lt;!-- ```{r tTestSex1} --&gt;
&lt;!-- t_testSite(Variables = &#34;Weight&#34;, Grouping = &#34;Sex&#34;, data = Data_df, VarEqual = TRUE) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- As it turns out, sex is a statistically significant predictor for sparrow weight at each site. This was to be expected. Using a binomial test in our second practical, we identified no bias in sexes for our sparrow populations. In addition, using the Mann-Whitney U-Test in our fourth practical, we identified sex to be an important information criterion for sparrow weight across all of our sites. Given these two conditions, we were expecting a results like the one presented here with males being, on average, heavier than females in *Passer domesticus* and we **reject the null hypothesis**.   --&gt;
&lt;!-- \hfill \linebreak --&gt;
&lt;!-- \begin{center} --&gt;
&lt;!-- \textit{Does sparrow height depend on sex when assessed at each of our sites individually?} --&gt;
&lt;!-- \end{center} --&gt;
&lt;!-- ```{r tTestSex2} --&gt;
&lt;!-- t_testSite(Variables = &#34;Height&#34;, Grouping = &#34;Sex&#34;, data = Data_df, VarEqual = TRUE) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- Like with our Mann-Whitney U-Test, we fail to identify a significant effect of sex on sparrow height records at each of our sites and so we **accept the null hypothesis**. --&gt;
&lt;!-- \hfill \linebreak --&gt;
&lt;!-- \begin{center} --&gt;
&lt;!-- \textit{Does sparrow wing chord depend on sex when assessed at each of our sites individually?} --&gt;
&lt;!-- \end{center} --&gt;
&lt;!-- ```{r tTestSex3} --&gt;
&lt;!-- t_testSite(Variables = &#34;Wing.Chord&#34;, Grouping = &#34;Sex&#34;, data = Data_df, VarEqual = TRUE) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- Like with our Mann-Whitney U-Test, we fail to identify a significant effect of sex on sparrow wing chord records at each of our sites and so we **accept the null hypothesis**. --&gt;
&lt;!--  --&gt;
&lt;h2 id=&#34;t-test-paired&#34;&gt;t-Test (paired)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the paired t-Test:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variable is binary&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Difference of response variable pairs&lt;/em&gt; is &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;dependent&lt;/strong&gt; (paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;preparing-data&#34;&gt;Preparing Data&lt;/h3&gt;
&lt;p&gt;For this purpose, we need an &lt;strong&gt;additional data set with truly paired records&lt;/strong&gt; of sparrows and so we implement the same solution as we&amp;rsquo;ve used within our fourth seminar using the Wilcoxon Signed Rank Test. Within our study set-up, think of a &lt;strong&gt;resettling experiment&lt;/strong&gt;, were you take &lt;em&gt;Passer domesticus&lt;/em&gt; individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.&lt;br&gt;
To this end, presume we have taken the entire &lt;em&gt;Passer domesticus&lt;/em&gt; population found at our &lt;strong&gt;Siberian&lt;/strong&gt; research station and moved them to the &lt;strong&gt;United Kingdom&lt;/strong&gt;. Whilst this keeps the latitude stable, the sparrows &lt;em&gt;now experience a coastal climate instead of a continental one&lt;/em&gt;. After some time (let&amp;rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.&lt;/p&gt;
&lt;p&gt;You will find the corresponding &lt;em&gt;new data&lt;/em&gt; in &lt;code&gt;2b - Sparrow_ResettledSIUK_READY.rds&lt;/code&gt;. Take note that this set only contains records for the transferred individuals in the &lt;strong&gt;same order&lt;/strong&gt; as in the old data set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df_Resettled &amp;lt;- readRDS(file = paste(Dir.Data, &amp;quot;/2b - Sparrow_ResettledSIUK_READY.rds&amp;quot;, sep=&amp;quot;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since earlier analysis such as the Wilcoxon Signed Rank test (fourth practical) and the Friedman Test (fifth practical) showed that height and wing chord records do not change when sparrows are resettled at all, we have excluded these here and &lt;strong&gt;focus solely on sparrow weight&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;testing-for-normality&#34;&gt;Testing for Normality&lt;/h3&gt;
&lt;p&gt;Before being able to run our paired t-Test, we must make sure that the &lt;em&gt;difference of response variable pairs&lt;/em&gt; is &lt;strong&gt;normal distributed&lt;/strong&gt;. We can do so using the &lt;code&gt;shapiro.test()&lt;/code&gt; of base &lt;code&gt;R&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# selecting pre-resettling weights
DataSI &amp;lt;- Data_df$Weight[which(Data_df$Index == &amp;quot;SI&amp;quot;)]
# calculating difference of before and after resettling weights
WeightDiff &amp;lt;- DataSI-Data_df_Resettled$Weight
# shapiro test
shapiro.test(WeightDiff)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  WeightDiff
## W = 0.97361, p-value = 0.1716
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thankfully, the &lt;strong&gt;assumption of normality&lt;/strong&gt; is &lt;strong&gt;met&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s visualise that using a qqplot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;qqnorm(WeightDiff)
qqline(WeightDiff)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Norm3-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-1&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s go on to test whether sparrow weights change significantly per individual due to our relocation experiment (we expect this from future test in our practicals):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;t.test(DataSI, Data_df_Resettled$Weight, paired = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Paired t-test
## 
## data:  DataSI and Data_df_Resettled$Weight
## t = 8.4762, df = 65, p-value = 4.17e-12
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  1.583629 2.559914
## sample estimates:
## mean difference 
##        2.071771
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We were right, individual sparrow weights change significantly after our relocation experiment and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt;. This is in accordance with the results of the Wilcoxon Signed Rank Test as well as the Friedman Test.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s go on to visualise our data to make better sense of what is going on here:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Select the sparrow weights
Weights &amp;lt;- c(DataSI, Data_df_Resettled$Weight)
# Select the sites
Sites &amp;lt;- factor(rep(c(&amp;quot;SI&amp;quot;, &amp;quot;SI_UK&amp;quot;), each = length(DataSI)))
# Plot
plot(Weights ~ Sites)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/tpaired1-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Quite obviously sparrows observed in Siberia are heavier than when they are resettled to the United Kingdom (this may be due to the more forgiving climate in the UK). Just like the test stated, the difference of the average weights is roughly 2g between the sparrows at the two sites.&lt;/p&gt;
&lt;h2 id=&#34;one-way-anova&#34;&gt;One-Way ANOVA&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the One-Way ANOVA:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variable is categorical&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Response variable residuals&lt;/em&gt; are &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variance of populations/samples are equal (&lt;strong&gt;homogeneity&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-for-assumptions&#34;&gt;Testing For Assumptions&lt;/h3&gt;
&lt;p&gt;Firstly, we need to test the assumptions of our One-Way ANOVA. For this purpose, we write another user-defined function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# User-defined function
ANOVACheck &amp;lt;- function(Variables, Grouping, data, plotting){
  Output &amp;lt;- data.frame(x = NA)
  for(i in 1:length(Variables)){
    # data
    Y &amp;lt;- as.numeric(factor(data[,Variables[i]]))
    X &amp;lt;- data[,Grouping]
    Levels &amp;lt;- levels(factor(Data_df[,Grouping]))
    # Residuals?
    model &amp;lt;- lm(Y ~ X)
    Output[1,i] &amp;lt;- shapiro.test(residuals(model))$p.value
    # Homgeneity?
    Levene &amp;lt;- leveneTest(Y ~ X, 
                         center = median, 
                         data = data)
    Output[2,i] &amp;lt;- Levene[1,3]
    # Plotting
    if(plotting == TRUE){
      plot(model, 2)# Normality
      plot(model, 3)# Homogeneity
    }
  }
  colnames(Output) &amp;lt;- Variables
  rownames(Output) &amp;lt;- c(&amp;quot;Residual Normality&amp;quot;, &amp;quot;Homogeneity of Variances&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;code&gt;ANOVACheck()&lt;/code&gt; function takes four arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of characters holding the names of the variables we want to have tested, (2) &lt;code&gt;Grouping&lt;/code&gt; - the categorical variable by which to group our variables, (3) &lt;code&gt;data&lt;/code&gt; - the data frame which contains the &lt;code&gt;Variables&lt;/code&gt; and the &lt;code&gt;Grouping&lt;/code&gt; factor, and (4) &lt;code&gt;plotting&lt;/code&gt; - a logical indicator of whether to produce plots visualising the test results or not.&lt;br&gt;
The function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (&lt;code&gt;Residual Normality&lt;/code&gt;), and the p-values indexing whether variances between groups are homogeneous or not (&lt;code&gt;Homogeneity of Variances&lt;/code&gt;).&lt;/p&gt;
&lt;h3 id=&#34;climate-warmingextremes-2&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology change depend on climate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using the Kruskal-Wallis Test in our last exercise, we already identified climate to be an important factor in determining &lt;em&gt;Passer domesticus&lt;/em&gt; morphology. Let&amp;rsquo;s see if this holds true.&lt;/p&gt;
&lt;p&gt;Take note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;RE&amp;quot; | Index == &amp;quot;AU&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;assumption-check&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s use the &lt;code&gt;ANOVACheck()&lt;/code&gt; function on our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(3,2))
ANOVACheck(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;), Grouping = &amp;quot;Climate&amp;quot;, data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.

## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.

## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck1b-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##                               Weight       Height  Wing.Chord
## Residual Normality       0.002521771 2.671414e-05 0.001685579
## Homogeneity of Variances 0.110120912 1.896577e-01 0.013575440
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, neither weight nor wing chord records fullfil our requirements.&lt;/p&gt;
&lt;h4 id=&#34;analysis&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s run our analysis for height as grouped by the three-level climate variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(Data_df$Height ~ Data_df$Climate)
anova(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Data_df$Height
##                  Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Data_df$Climate   2  14.99  7.4942  7.2494 0.0008129 ***
## Residuals       381 393.87  1.0338                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to this, climate is a meaningful predictor of height of sparrows and we &lt;strong&gt;reject the null hypothesis&lt;/strong&gt; thus confirming the results of our Kruskall-Wallis analysis.&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s analyse the output a bit more in-depth:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Data_df$Height ~ Data_df$Climate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.98994 -0.69815 -0.01475  0.67142  2.37045 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)                 14.07994    0.07964 176.800  &amp;lt; 2e-16 ***
## Data_df$ClimateContinental  -0.13429    0.11426  -1.175  0.24060    
## Data_df$ClimateSemi-Coastal -0.56039    0.14755  -3.798  0.00017 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.017 on 381 degrees of freedom
## Multiple R-squared:  0.03666,	Adjusted R-squared:  0.0316 
## F-statistic: 7.249 on 2 and 381 DF,  p-value: 0.0008129
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The mean sparrow height in coastal climates is 14.0799387cm (this is our &lt;strong&gt;Intercept&lt;/strong&gt;/&lt;em&gt;Baseline&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;The mean sparrow height in continental climates is -0.1342893cm bigger than the &lt;strong&gt;Intercept&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The mean sparrow height in semi-coastal climates is -0.5603864cm bigger than the &lt;strong&gt;Intercept&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Only the estimates in coastal and semi-coastal climates are statistically significant&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Personally, I would not place too much confidence in these results due to a couple of reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Our only semi-coastal site is on the northern hemisphere whereas two of our stations are located in the southern hemisphere&lt;/li&gt;
&lt;li&gt;Confounding factors such as population status might have an effect which we are not considering here&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s end this by plotting all of our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(2,2))
plot(Data_df$Weight ~ factor(Data_df$Climate))
plot(Data_df$Height ~ factor(Data_df$Climate))
plot(Data_df$Wing.Chord ~ factor(Data_df$Climate))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis1-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, the variances are definitely not equal between our groups which explains why part of our assumption test failed.&lt;/p&gt;
&lt;h3 id=&#34;predation&#34;&gt;Predation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does nesting height depend on predator characteristics?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Again, using the Kruskal-Wallis Test in our last exercise, we already identified predator characteristics to be an important factor in determining &lt;em&gt;Passer domesticus&lt;/em&gt; nesting height. Let&amp;rsquo;s see if this holds true.&lt;/p&gt;
&lt;p&gt;We may wish to use the entirety of our data set again for this purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Data_df &amp;lt;- Data_df_base
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;assumption-check-1&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s use our &lt;code&gt;ANOVACeck()&lt;/code&gt; function to test whether we can run our analysis. Before we can do so, however, we need to slightly adjust our predator type variable just like we did in our last exercise and as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# changing levels in predator type
levels(Data_df$Predator.Type) &amp;lt;- c(levels(Data_df$Predator.Type), &amp;quot;None&amp;quot;)
Data_df$Predator.Type[which(is.na(Data_df$Predator.Type))] &amp;lt;- &amp;quot;None&amp;quot;

# Assumption Check
par(mfrow=c(1,2))
ANOVACheck(Variables = &amp;quot;Nesting.Height&amp;quot;, Grouping = &amp;quot;Predator.Type&amp;quot;, data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##                          Nesting.Height
## Residual Normality         0.0017160318
## Homogeneity of Variances   0.0005845899
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, our data fails the assumption check. The residuals are definitely not normal distributed and the variance of nesting height records within our groups are not equal.&lt;/p&gt;
&lt;h4 id=&#34;analysis-1&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(Data_df$Nesting.Height ~ Data_df$Predator.Type)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis2-1.png&#34; width=&#34;576&#34; /&gt;
Once more, we can see why our homogeneity of variances test failed.&lt;/p&gt;
&lt;h2 id=&#34;two-way-anova&#34;&gt;Two-Way ANOVA&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the Two-Way ANOVA:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variables are categorical&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Response variable residuals&lt;/em&gt; are &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variance of populations/samples are equal (&lt;strong&gt;homogeneity&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-for-assumptions-1&#34;&gt;Testing For Assumptions&lt;/h3&gt;
&lt;p&gt;Yet again, we need to check if our assumptions are met first. Automating this procedure is definitely a good idea and only needs slight modification from our &lt;code&gt;ANOVACheck()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# User-defined function
ANOVACheck_TWO &amp;lt;- function(Formulas, data, plotting){
  Output &amp;lt;- data.frame(x = NA)
  for(i in 1:length(Formulas)){
    # Check how many formulas there are
    if(length(Formulas) == 1){
      Expression &amp;lt;- Formulas[[1]]
    }else{
      Expression &amp;lt;- Formulas[[i]]
    }
    # Residuals?
    model &amp;lt;- lm(formula = Expression, data = data)
    Output[1,i] &amp;lt;- shapiro.test(residuals(model))$p.value
    # Homgeneity?
    Levene &amp;lt;- leveneTest(Expression, 
                         center = median, 
                         data = data)
    Output[2,i] &amp;lt;- Levene[1,3]
    # Plotting
    if(plotting == TRUE){
      plot(model, 2)# Normality
      plot(model, 3)# Homogeneity
    }
  }
  colnames(Output) &amp;lt;- as.character(Formulas)
  rownames(Output) &amp;lt;- c(&amp;quot;RN&amp;quot;, &amp;quot;HoV&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;code&gt;ANOVACheck_TWO()&lt;/code&gt; function takes four arguments: (1) &lt;code&gt;Formulas&lt;/code&gt; - a vector of formula specification for our ANOVA models we want to have tested, (2) &lt;code&gt;data&lt;/code&gt; - the data frame which contains the variables and the grouping factor called upon in our &lt;code&gt;Formulas&lt;/code&gt;, and (3) &lt;code&gt;plotting&lt;/code&gt; - a logical indicator of whether to produce plots visualising the test results or not.&lt;br&gt;
The function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (&lt;code&gt;RN&lt;/code&gt;), and the p-values indexing whether variances between groups are homogeneous or not (&lt;code&gt;HoV&lt;/code&gt;).&lt;/p&gt;
&lt;h3 id=&#34;sexual-dimorphism-1&#34;&gt;Sexual Dimorphism&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Does sparrow morphology depend on population status and sex?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given different factors affecting invasive species, we might expect different patterns of sexual dimorphism for invasive and native populations. Take note that we keep using the northern hemisphere subset our cimate testing sites as these present us with a nice set of invasive/native population records already whilst keeping confounding factors to a minimum.&lt;/p&gt;
&lt;h4 id=&#34;assumption-check-2&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;First, we need to check our assumptions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# prepare climate type testing data
Data_df &amp;lt;- Data_df_base
Index &amp;lt;- Data_df$Index
Rows &amp;lt;- which(Index == &amp;quot;SI&amp;quot; | Index == &amp;quot;UK&amp;quot; | Index == &amp;quot;MA&amp;quot;)
Data_df &amp;lt;- Data_df[Rows,]

# analysis
par(mfrow=c(3,2))
ANOVACheck_TWO(Formulas = c(Weight ~ Population.Status*Sex, 
                            Height ~ Population.Status*Sex,
                            Wing.Chord ~ Population.Status*Sex)
               , data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck5-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##     Weight ~ Population.Status * Sex Height ~ Population.Status * Sex
## RN                       0.287959531                        0.2171916
## HoV                      0.004492103                        0.9057774
##     Wing.Chord ~ Population.Status * Sex
## RN                             0.1907782
## HoV                            0.9174340
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again our assumptions are not met except for sparrow height and wing chord as a product of sex and population status.&lt;/p&gt;
&lt;h4 id=&#34;analysis-2&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s run our analysis:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# height model
model &amp;lt;- lm(Height ~ Population.Status*Sex, data = Data_df)
anova(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Height
##                        Df  Sum Sq Mean Sq F value Pr(&amp;gt;F)
## Population.Status       1   0.338 0.33820  0.3190 0.5729
## Sex                     1   0.179 0.17896  0.1688 0.6816
## Population.Status:Sex   1   1.786 1.78585  1.6844 0.1959
## Residuals             197 208.865 1.06023
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# wing chord model
model &amp;lt;- lm(Wing.Chord ~ Population.Status*Sex, data = Data_df)
anova(model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Wing.Chord
##                        Df Sum Sq  Mean Sq F value Pr(&amp;gt;F)
## Population.Status       1 0.0047 0.004669  0.1955 0.6589
## Sex                     1 0.0041 0.004125  0.1727 0.6782
## Population.Status:Sex   1 0.0399 0.039856  1.6688 0.1979
## Residuals             197 4.7049 0.023883
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# plotting
par(mfrow=c(1,2))
boxplot(Height ~ Population.Status*Sex, data = Data_df, col = c(&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;))
boxplot(Wing.Chord ~ Population.Status*Sex, data = Data_df, col = c(&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis5-1.png&#34; width=&#34;576&#34; /&gt;
As it turns out, population status and sex are no viable predictors for sparrow height or wing chord and so we &lt;strong&gt;accept the null hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ancova&#34;&gt;ANCOVA&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions of the ANCOVA:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictor variables are categorical or continuous&lt;/li&gt;
&lt;li&gt;Response variable is metric&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Response variable residuals&lt;/em&gt; are &lt;strong&gt;normal distributed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Variance of populations/samples are equal (&lt;strong&gt;homogeneity&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Variable values are &lt;strong&gt;independent&lt;/strong&gt; (not paired)&lt;/li&gt;
&lt;li&gt;Relationship between the response and covariate is &lt;strong&gt;linear&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;climate-warmingextremes-3&#34;&gt;Climate Warming/Extremes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Do sparrow characteristics depend on climate and latitude?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Latitude may have masked some effects of climate on sparrow morphology in our preceding analyses and vice-versa. At times, we have been able to account for this by including our site records, which can be seen as binned versions of latitude records. Let&amp;rsquo;s test if the inclusion of raw latitude records are meaningful.&lt;/p&gt;
&lt;h4 id=&#34;assumption-check-3&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Again, we need to do an assumption check. However, we need a new function for this, since we now need to test whether our response variable and the covariate are linear or not:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# overwriting prior changes in Data_df
Data_df &amp;lt;- Data_df_base
Data_df$Latitude &amp;lt;- abs(Data_df$Latitude)
# User-defined function
ANCOVACheck &amp;lt;- function(Variables, Grouping, Covariate, data, plotting){
  Output &amp;lt;- data.frame(x = NA)
  for(i in 1:length(Variables)){
    # data
    Y &amp;lt;- as.numeric(factor(data[,Variables[i]]))
    X &amp;lt;- factor(data[,Grouping])
    Z &amp;lt;- data[, Covariate]
    # Residuals?
    model &amp;lt;- lm(Y ~ X*Z)
    Output[1,i] &amp;lt;- shapiro.test(residuals(model))$p.value
    # Homgeneity?
    Levene &amp;lt;- leveneTest(Y ~ X, 
                         center = median, 
                         data = data)
    Output[2,i] &amp;lt;- Levene[1,3]
    # Plotting
    if(plotting == TRUE){
      plot(model, 1)# Linearity
      plot(model, 2)# Normality
      plot(model, 3)# Homogeneity
    }
  }
  colnames(Output) &amp;lt;- Variables
  rownames(Output) &amp;lt;- c(&amp;quot;RN&amp;quot;, &amp;quot;HoV&amp;quot;)
  return(Output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;code&gt;ANCOVACheck()&lt;/code&gt; function takes five arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of response variables used in our models, (2) &lt;code&gt;Grouping&lt;/code&gt; - the categorical variable by which to group our variables, (3) &lt;code&gt;Covariate&lt;/code&gt; - the covariate of our analysis, (4)&lt;code&gt;data&lt;/code&gt; - the data frame which contains the variables, the grouping factor and our covariate, and (5) &lt;code&gt;plotting&lt;/code&gt; - a logical indicator of whether to produce plots visualising the test results or not.&lt;br&gt;
The function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (&lt;code&gt;RN&lt;/code&gt;), and the p-values indexing whether variances between groups are homogeneous or not (&lt;code&gt;HoV&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ANCOVACheck(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Nesting.Height&amp;quot;, &amp;quot;Egg.Weight&amp;quot;, &amp;quot;Number.of.Eggs&amp;quot;, &amp;quot;Home.Range&amp;quot;), 
            Grouping = &amp;quot;Climate&amp;quot;, Covariate = &amp;quot;Latitude&amp;quot;, 
            data = Data_df, plotting = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Weight       Height   Wing.Chord Nesting.Height   Egg.Weight
## RN  2.082300e-02 1.502944e-04 4.535941e-07   5.190971e-06 2.943560e-03
## HoV 9.937376e-24 1.929783e-22 1.561040e-33   2.004612e-01 4.816355e-09
##     Number.of.Eggs   Home.Range
## RN    1.809197e-09 3.629841e-20
## HoV   2.750100e-14 1.157673e-08
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The assumptions aren&amp;rsquo;t met. I have set the &lt;code&gt;plotting&lt;/code&gt; argument to &lt;code&gt;FALSE&lt;/code&gt; tu suppress the plotting of model checking visualisation. The would be useful to judge linearity but not necessary here since the other two important assumptions (Homogeneity of variances and Normality of residuals) aren&amp;rsquo;t met to begin with.&lt;/p&gt;
&lt;h4 id=&#34;analysis-3&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone. We need a new function for this to do our plotting easily and automatically with some colours indicating our grouping factors whilst plotting response variables versus covariates.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PlotAncovas &amp;lt;- function(Variables, Grouping, Covariate, data){
  for(i in 1:length(Variables)){
    Y &amp;lt;- Data_df[,Variables[i]]
    if(class(Y) == &amp;quot;character&amp;quot;){Y &amp;lt;- factor(Y)}
    X &amp;lt;- Data_df[,Covariate]
    G &amp;lt;- factor(Data_df[, Grouping])
    plot(X, Y, col = G, xlab = Covariate, ylab = Variables[i])
    legend(&amp;quot;top&amp;quot;, # place legend at the top
           inset = -0.35, # move legend away from plot centre
           xpd = TRUE, # allow legend outside of plot area
           legend=levels(G), # what to include in legend
           bg = &amp;quot;white&amp;quot;, col = unique(G), ncol=length(levels(G)), # colours
           pch = 1, # plotting symbols
           title = Variables[i] # title of legend
           )
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;PlotAncovas()&lt;/code&gt; returns a scatter plot and takes four arguments: (1) &lt;code&gt;Variables&lt;/code&gt; - a vector of response variables, (2) &lt;code&gt;Grouping&lt;/code&gt; - the name of the grouping factor according to which to colour the symbols in our plot, (3) &lt;code&gt;Covariate&lt;/code&gt; - the covariate against which to plot individuals variables, and (4) &lt;code&gt;data&lt;/code&gt; - the data frame which holds our variables.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s use our function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(1,2))
PlotAncovas(Variables = c(&amp;quot;Weight&amp;quot;, &amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Nesting.Height&amp;quot;, &amp;quot;Egg.Weight&amp;quot;, &amp;quot;Number.of.Eggs&amp;quot;, &amp;quot;Home.Range&amp;quot;), Grouping = &amp;quot;Climate&amp;quot;, Covariate = &amp;quot;Latitude&amp;quot;, data = Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will not interpret these plots here in text and leave this to you.&lt;/p&gt;
&lt;p&gt;Take note that this &lt;strong&gt;could&amp;rsquo;ve been achieved much easier with &lt;code&gt;ggplot2&lt;/code&gt;!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysisc-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;sparrow-characteristics-and-sites&#34;&gt;Sparrow Characteristics And Sites&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;This was not part of what we set out to do according to the lecture slides but has been included as a logical conclusion to an earlier analysis.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, our previous attempt at an ANCOVA didn&amp;rsquo;t work. So what other covariate do we have available for sparrow characteristics?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Latitude&lt;/em&gt; doesn&amp;rsquo;t make sense to include when grouping by site index as these two are synonymous&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Longitude&lt;/em&gt; doesn&amp;rsquo;t make sense to include when grouping by site index as these two are synonymous&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Weight&lt;/em&gt; is well explained by other variables and we know the causal links&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Height&lt;/em&gt; is not that well explained by other variables&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Wing.Chord&lt;/em&gt; is not that well explained by other variables&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, there are more within our data set but it has become apparent that &lt;code&gt;Weight&lt;/code&gt; may make for an important covariate in our site-wise ANCOVA set-up. Using the Pearson correlation (third practical), we already identified a causal link between sparrow &lt;code&gt;Weight&lt;/code&gt; and &lt;code&gt;Height&lt;/code&gt; per site.&lt;/p&gt;
&lt;h4 id=&#34;assumption-check-4&#34;&gt;Assumption Check&lt;/h4&gt;
&lt;p&gt;Firstly, we test whether assumptions are met. For brevities sake, we only test four variables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mfrow=c(1,3))
ANCOVACheck(Variables = c(&amp;quot;Height&amp;quot;, &amp;quot;Wing.Chord&amp;quot;, &amp;quot;Egg.Weight&amp;quot;, &amp;quot;Number.of.Eggs&amp;quot;), Grouping = &amp;quot;Index&amp;quot;, Covariate = &amp;quot;Weight&amp;quot;, data = Data_df, plotting = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-1.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-2.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-3.png&#34; width=&#34;576&#34; /&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/AssCheck7-4.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##           Height   Wing.Chord   Egg.Weight Number.of.Eggs
## RN  1.499909e-06 5.251393e-08 0.1565038171   9.220862e-07
## HoV 3.594021e-13 2.434880e-01 0.0002015813   2.660146e-02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, we can run our ANCOVA on &lt;code&gt;Egg.Weight&lt;/code&gt; when grouped by site &lt;code&gt;Index&lt;/code&gt; and driven by &lt;code&gt;Weight&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;analysis-4&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;First, let&amp;rsquo;s visualise our data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;PlotAncovas(Variables = &amp;quot;Egg.Weight&amp;quot;, Grouping = &amp;quot;Index&amp;quot;, Covariate = &amp;quot;Weight&amp;quot;, data = Data_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;12---Simple-Parametric-Tests_files/figure-html/Analysis7-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Quite obviously, Belize (BE) records are very different from the other stations, whose egg weight and weight records are grouped together. There seems to be some evidence for an overall linkage of sparrow weight and egg weight (a positive correlation).&lt;/p&gt;
&lt;p&gt;Now we run the analysis:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;LM_fit5 &amp;lt;- lm(Egg.Weight ~ Weight*Index, data = Data_df)
anova(LM_fit5)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Egg.Weight
##               Df Sum Sq Mean Sq   F value Pr(&amp;gt;F)    
## Weight         1 52.531  52.531 1442.5616 &amp;lt;2e-16 ***
## Index         10  8.087   0.809   22.2064 &amp;lt;2e-16 ***
## Weight:Index  10  0.129   0.013    0.3536 0.9653    
## Residuals    455 16.569   0.036                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above ANCOVA output tells us that there is no interaction effect between sites and sparrow weights when determining mean egg weight per nest of &lt;em&gt;Passer domesticus&lt;/em&gt; and so we do another iteration of our model and remove the postulated interaction:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;LM_fit6 &amp;lt;- lm(Egg.Weight ~ Weight+Index, data = Data_df)
anova(LM_fit6)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Response: Egg.Weight
##            Df Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
## Weight      1 52.531  52.531 1462.898 &amp;lt; 2.2e-16 ***
## Index      10  8.087   0.809   22.519 &amp;lt; 2.2e-16 ***
## Residuals 465 16.698   0.036                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By now, all of our model coefficients are significant and we can go on to interpret them:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(LM_fit6)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Egg.Weight ~ Weight + Index, data = Data_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.58887 -0.13146 -0.00621  0.12033  0.55135 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  3.345984   0.280826  11.915  &amp;lt; 2e-16 ***
## Weight       0.001081   0.008614   0.125 0.900203    
## IndexBE     -0.708478   0.054864 -12.913  &amp;lt; 2e-16 ***
## IndexFG     -1.281168   0.099135 -12.923  &amp;lt; 2e-16 ***
## IndexFI     -0.625287   0.057442 -10.885  &amp;lt; 2e-16 ***
## IndexLO     -0.550137   0.051754 -10.630  &amp;lt; 2e-16 ***
## IndexMA     -0.513645   0.051352 -10.003  &amp;lt; 2e-16 ***
## IndexNU     -0.517015   0.053365  -9.688  &amp;lt; 2e-16 ***
## IndexRE     -0.612632   0.051418 -11.915  &amp;lt; 2e-16 ***
## IndexSA     -0.806045   0.056685 -14.220  &amp;lt; 2e-16 ***
## IndexSI     -0.272580   0.077868  -3.501 0.000509 ***
## IndexUK     -0.511667   0.051404  -9.954  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1895 on 465 degrees of freedom
##   (590 observations deleted due to missingness)
## Multiple R-squared:  0.784,	Adjusted R-squared:  0.7789 
## F-statistic: 153.5 on 11 and 465 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Prototype biodiversity digital twin - crop wild relatives genetic resources for food security</title>
      <link>https://www.erikkusch.com/publication/prototype-biodiversity-digital-twin-crop-wild-relatives-genetic-resources-for-food-security/</link>
      <pubDate>Tue, 11 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/publication/prototype-biodiversity-digital-twin-crop-wild-relatives-genetic-resources-for-food-security/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Plant trait and vegetation data along a 1314m elevation gradient with fire history in Puna grasslands, PerÃº</title>
      <link>https://www.erikkusch.com/publication/plant-trait-and-vegetation-data-along-a-1314-m-elevation-gradient-with-fire-history-in-puna-grasslands-peru/</link>
      <pubDate>Wed, 21 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/publication/plant-trait-and-vegetation-data-along-a-1314-m-elevation-gradient-with-fire-history-in-puna-grasslands-peru/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NetworkExtinction - An R Package to Simulate Extinction Propagation and Rewiring Potential in Ecological Networks</title>
      <link>https://www.erikkusch.com/publication/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/</link>
      <pubDate>Fri, 02 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/publication/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NetworkExtinction - an R package to simulate extinctionâs propagation and rewiring potential in ecological networks</title>
      <link>https://www.erikkusch.com/publication/in-review/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/</link>
      <pubDate>Mon, 05 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/publication/in-review/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A novel trophic cascade between cougars and feral donkeys shapes desert wetlands</title>
      <link>https://www.erikkusch.com/publication/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/</link>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/publication/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A novel trophic cascade between cougars and feral donkeys shapes desert wetlands</title>
      <link>https://www.erikkusch.com/publication/journal-article/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/</link>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <guid>https://www.erikkusch.com/publication/journal-article/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
