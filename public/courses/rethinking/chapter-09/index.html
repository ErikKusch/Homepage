<!DOCTYPE html><html lang="en-gb" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Erik Kusch">

  
  
  
    
  
  <meta name="description" content="Answers and solutions to the exercises belonging to chapter 9 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.">

  
  <link rel="alternate" hreflang="en-gb" href="https://www.erikkusch.com/courses/rethinking/chapter-09/">

  


  
  
  
  <meta name="theme-color" content="#858383">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Cutive+Mono%7CLora:400,700%7CRoboto:400,700&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-186216138-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-186216138-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu7658c99d512131214e4d6c003a3f85f7_112593_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu7658c99d512131214e4d6c003a3f85f7_112593_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://www.erikkusch.com/courses/rethinking/chapter-09/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ErikKusch">
  <meta property="twitter:creator" content="@ErikKusch">
  
  <meta property="og:site_name" content="Erik Kusch">
  <meta property="og:url" content="https://www.erikkusch.com/courses/rethinking/chapter-09/">
  <meta property="og:title" content="Chapter 09 | Erik Kusch">
  <meta property="og:description" content="Answers and solutions to the exercises belonging to chapter 9 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath."><meta property="og:image" content="https://www.erikkusch.com/img/%C3%A5motdalshytta.jpg">
  <meta property="twitter:image" content="https://www.erikkusch.com/img/%C3%A5motdalshytta.jpg"><meta property="og:locale" content="en-gb">
  
    
      <meta property="article:published_time" content="2021-02-25T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2021-02-25T20:00:00&#43;01:00">
  

  



  


  


  





  <title>Chapter 09 | Erik Kusch</title>

</head>
<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  








  


<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/"><img src="/images/logo_huab2266ff59bbac6a094b6da1268adcf9_208479_0x70_resize_lanczos_2.png" alt="Erik Kusch"></a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/"><img src="/images/logo_huab2266ff59bbac6a094b6da1268adcf9_208479_0x70_resize_lanczos_2.png" alt="Erik Kusch"></a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-center" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/"><span>Home</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Courses & Workshops</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/courses/krigr/"><span>KrigR - State-of-the-Art Climate Data within R</span></a>
            
              <a class="dropdown-item" href="/courses/gbif/"><span>Accessing and Referencing GBIF Data for Research</span></a>
            
              <a class="dropdown-item" href="/courses/rethinking/"><span>Statistical Rethinking - Introduction to Bayesian Statistics</span></a>
            
              <a class="dropdown-item" href="/courses/bayes-nets/"><span>Bayesian Networks - Causality through Bayesian Approaches</span></a>
            
              <a class="dropdown-item" href="/courses/biostat101/"><span>Biostats 101 - An Introduction to Biostatistics</span></a>
            
              <a class="dropdown-item" href="/courses/excursions-into-biostatistics/"><span>Biostats 301 - Excursions into Biostatistics</span></a>
            
              <a class="dropdown-item" href="/courses/bftp-biome-detection/"><span>BFTP - First Steps in Macroecology in R</span></a>
            
          </div>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks"><span>Talks</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/about"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/media/CV_ErikKusch.html" target="_blank" rel="noopener"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





  
    
  




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  

  
  
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/rethinking/">Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/rethinking/chapter-02/">Seminars</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/courses/rethinking/chapter-02/">Chapter 01 &amp; 02</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-03/">Chapter 03</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-04/">Chapter 04</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-04b/">Chapter 04 (Extra Material)</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-05/">Chapter 05</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-06/">Chapter 06</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-07/">Chapter 07</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-08/">Chapter 08</a>
      </li>
      
      <li class="active">
        <a href="/courses/rethinking/chapter-09/">Chapter 09</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-11/">Chapter 10 &amp; 11</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-12/">Chapter 12</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-13/">Chapter 13</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-14/">Chapter 14</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-15/">Chapter 15</a>
      </li>
      
      <li >
        <a href="/courses/rethinking/chapter-16/">Chapter 16</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#material">Material</a></li>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#r-environment"><code>R</code> Environment</a></li>
    <li><a href="#easy-exercises">Easy Exercises</a>
      <ul>
        <li><a href="#practice-e1">Practice E1</a></li>
        <li><a href="#practice-e2">Practice E2</a></li>
        <li><a href="#practice-e3">Practice E3</a></li>
        <li><a href="#practice-e4">Practice E4</a></li>
        <li><a href="#practice-e5">Practice E5</a></li>
        <li><a href="#practice-e6">Practice E6</a></li>
      </ul>
    </li>
    <li><a href="#medium-exercises">Medium Exercises</a>
      <ul>
        <li><a href="#practice-m1">Practice M1</a></li>
        <li><a href="#practice-m2">Practice M2</a></li>
        <li><a href="#practice-m3">Practice M3</a></li>
      </ul>
    </li>
    <li><a href="#hard-exercises">Hard Exercises</a>
      <ul>
        <li><a href="#practice-h1">Practice H1</a></li>
        <li><a href="#practice-h2">Practice H2</a></li>
        <li><a href="#practice-h3">Practice H3</a></li>
        <li><a href="#practice-h4">Practice H4</a></li>
        <li><a href="#practice-h5">Practice H5</a></li>
        <li><a href="#practice-h6">Practice H6</a></li>
      </ul>
    </li>
    <li><a href="#session-info">Session Info</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          <h1>Chapter 09</h1>

          <div class="article-style">
            <h1 id="markov-chain-monte-carlo">Markov Chain Monte Carlo</h1>
<h2 id="material">Material</h2>
<ul>
<li>
<a href="https://htmlpreview.github.io/?https://github.com/ErikKusch/Homepage/blob/master/static/courses/rethinking/10__26-02-2021_SUMMARY_-MCMC.pptx.html" target="_blank" rel="noopener">Slides Chapter 9</a></li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>These are answers and solutions to the exercises at the end of chapter 9 in 
<a href="https://xcelab.net/rm/statistical-rethinking/" target="_blank" rel="noopener">Satistical Rethinking 2</a> by Richard McElreath. I have created these notes as a part of my ongoing involvement in the 
<a href="/project/aubayes/">AU Bayes Study Group</a>. Much of my inspiration for these solutions, where necessary, has been obtained from 
<a href="https://github.com/jffist/statistical-rethinking-solutions/blob/master/ch08_hw.R" target="_blank" rel="noopener">Taras Svirskyi</a>, 
<a href="https://github.com/cavaunpeu/statistical-rethinking/blob/master/chapter-8/homework.R" target="_blank" rel="noopener">William Wolf</a>, and 
<a href="https://www.samples-of-thoughts.com/projects/statistical-rethinking/chapter_8/chp8-ex/" target="_blank" rel="noopener">Corrie Bartelheimer</a> as well as the solutions provided to instructors by Richard McElreath himself.</p>
<h2 id="r-environment"><code>R</code> Environment</h2>
<p>For today&rsquo;s exercise, I load the following packages:</p>
<pre><code class="language-r">library(rethinking)
library(rstan)
library(ggplot2)
library(tidybayes)
</code></pre>
<h2 id="easy-exercises">Easy Exercises</h2>
<h3 id="practice-e1">Practice E1</h3>
<p><strong>Question:</strong> Which of the following is a requirement of the simple Metropolis algorithm?</p>
<ol>
<li>The parameters must be discrete.</li>
<li>The likelihood function must be Gaussian.</li>
<li>The proposal distribution must be symmetric.</li>
</ol>
<p><strong>Answer:</strong></p>
<ol>
<li>Not a requirement. Metropolis can accommodate continuous and discrete parameters.</li>
<li>Not a requirement. Distribution could be any symmetric distribution. Not just Gaussian.</li>
<li>This is a requirement.</li>
</ol>
<h3 id="practice-e2">Practice E2</h3>
<p><strong>Question:</strong> Gibbs sampling is more efficient than the Metropolis algorithm. How does it achieve this extra efficiency? Are there any limitations to the Gibbs sampling strategy?</p>
<p><strong>Answer:</strong> Gibbs uses adaptive proposals when considering which location in the posterior to sample next. This makes it more efficient because less proposed steps are rejected.</p>
<h3 id="practice-e3">Practice E3</h3>
<p><strong>Question:</strong> Which sort of parameters can Hamiltonian Monte Carlo not handle? Can you explain why?</p>
<p><strong>Answer:</strong> Discrete parameters. HMC depends on gradients which to explore using a physics simulation. Discrete parameters would not allow for the construction of any gradients.</p>
<h3 id="practice-e4">Practice E4</h3>
<p><strong>Question:</strong> Explain the difference between the effective number of samples, <code>n_eff</code> as calculated by Stan, and the actual number of samples.</p>
<p><strong>Answer:</strong>  Effective sample number (<code>n_eff</code>) identifies the number of &lsquo;ideal&rsquo; (i.e. uncorrelated) samples. Since MCMC algorithms explore the posterior as a chain of samples, each sample is usually correlated with the previous one to some extent. Conclusively, <code>n_eff</code> identifies the number of samples used for estimating the posterior mean/distribution whereas actual number of samples is simply the number of data points we have.</p>
<p><code>n_eff</code> is usually smaller than the actual number of samples (unless we have anti-correlated MCMC samples).</p>
<h3 id="practice-e5">Practice E5</h3>
<p><strong>Question:</strong> Which value should <code>Rhat</code> approach, when a chain is sampling the posterior distribution correctly?</p>
<p><strong>Answer:</strong> $\hat{R}$ or <code>Rhat</code>, in <code>R</code>, reflects variance within a chain versus variance between chains. If these are the same, $\hat{R}$ will be $1.0$ - i.e.: it does not matter from which chain we would infere parameters and predictions. Values higher than 1.0 can indicate problems in the model. Values much higher than 1 indicate serious issues.</p>
<h3 id="practice-e6">Practice E6</h3>
<p><strong>Question:</strong> Sketch a good trace plot for a Markov chain, one that is effectively sampling from the posterior distribution. What is good about its shape? Then sketch a trace plot for a malfunctioning Markov chain. What about its shape indicates malfunction?</p>
<p><strong>Answer:</strong></p>
<p><em>Good trace plot</em></p>
<pre><code class="language-r">y &lt;- rnorm(1e4, mean = 1, sd = 2)
m.E6Good &lt;- ulam(
  alist(
    y ~ dnorm(mu, sigma),
    mu &lt;- alpha,
    alpha ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 1)
  ),
  data = list(y = y),
  cores = 2,
  chains = 2,
  start = list(
    alpha = 0,
    sigma = 1
  )
)
traceplot(m.E6Good)
</code></pre>
<pre><code>## [1] 1000
## [1] 1
## [1] 1000
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-2-1.png" width="1440" />
These trace plots show that the chains quickly find the region with highest posterior probability and stay there.</p>
<p><em>Bad trace plot</em></p>
<pre><code class="language-r">y &lt;- rnorm(1e4, mean = 1, sd = 2)
m.E6Bad &lt;- ulam(
  alist(
    y ~ dnorm(mu, sigma),
    mu &lt;- a1 + a2,
    a1 ~ dnorm(0, 10),
    a2 ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 1)
  ),
  data = list(y = y),
  chains = 2,
  cores = 2,
  start = list(
    a1 = 0,
    a2 = 0,
    sigma = 1
  ),
)
traceplot(m.E6Bad)
</code></pre>
<pre><code>## [1] 1000
## [1] 1
## [1] 1000
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-3-1.png" width="1440" /></p>
<p>This is a problem of <em>unidentifiable parameters</em> as <code>a1</code> and <code>a2</code> can cancel each other out to arrive at the correct <code>mu</code> and so we see non-stationary behaviour in the trace plots of <code>a1</code> and <code>a2</code> while the trace plot for <code>sigma</code> is doing alright.</p>
<h2 id="medium-exercises">Medium Exercises</h2>
<h3 id="practice-m1">Practice M1</h3>
<p><strong>Question:</strong> Re-estimate the terrain ruggedness model from the chapter, but now using a uniform prior and an exponential prior for the standard deviation, <code>sigma</code>. The uniform prior should be <code>dunif(0,10)</code> and the exponential should be <code>dexp(1)</code>. Do the different priors have any detectable influence on the posterior distribution?</p>
<p><strong>Answer:</strong> The ruggedness model in question is <code>m8.3</code> in the book (or <code>m9.1</code> in <code>ulam()</code> specification). First, I prepare the data like I did 
<a href="post/2021-02-18-statistical-rethinking-chapter-08/index.Rmd">previously</a>.</p>
<pre><code class="language-r">data(rugged)
d &lt;- rugged
d$log_gdp &lt;- log(d$rgdppc_2000)
d &lt;- d[complete.cases(d$rgdppc_2000), ]
d$log_gdp_std &lt;- d$log_gdp / mean(d$log_gdp)
d$rugged_std &lt;- d$rugged / max(d$rugged)
d$cid &lt;- ifelse(d$cont_africa == 1, 1, 2)
dd.trim &lt;- list(
  log_gdp_std = d$log_gdp_std,
  rugged_std = d$rugged_std,
  cid = as.integer(d$cid)
)
</code></pre>
<p>Let&rsquo;s fit that model with the different priors:</p>
<pre><code class="language-r">## Exponential prior for sigma
m.M1Exp &lt;- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu &lt;- a[cid] + b[cid] * (rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ),
  data = dd.trim,
  chains = 4,
  cores = 4,
)
## Uniform prior for sigma
m.M1Uni &lt;- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu &lt;- a[cid] + b[cid] * (rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dnorm(0, 0.3),
    sigma ~ dnorm(0, 10)
  ),
  data = dd.trim,
  chains = 4,
  cores = 4,
)
</code></pre>
<p>Now on to inspect the model. Let&rsquo;s start with the parameter estimates in comparison</p>
<pre><code class="language-r">coeftab(m.M1Exp, m.M1Uni)
</code></pre>
<pre><code>##       m.M1Exp m.M1Uni
## a[1]     0.89    0.89
## a[2]     1.05    1.05
## b[1]     0.13    0.13
## b[2]    -0.14   -0.14
## sigma    0.11    0.11
## nobs      170     170
</code></pre>
<p>These are strikingly the same. What about the individual model outputs in more detail?</p>
<pre><code class="language-r">precis(m.M1Exp, depth = 2)
</code></pre>
<pre><code>##             mean          sd        5.5%       94.5%    n_eff     Rhat4
## a[1]   0.8870817 0.015625699  0.86196179  0.91173540 2453.919 0.9995577
## a[2]   1.0507770 0.009968219  1.03527611  1.06640703 2834.441 0.9988734
## b[1]   0.1344067 0.074307822  0.01486287  0.25218389 2786.188 0.9993677
## b[2]  -0.1413442 0.054855132 -0.22964887 -0.05187494 2324.832 0.9983652
## sigma  0.1117154 0.006171670  0.10228974  0.12208002 2725.266 0.9988256
</code></pre>
<pre><code class="language-r">precis(m.M1Uni, depth = 2)
</code></pre>
<pre><code>##             mean          sd        5.5%       94.5%    n_eff     Rhat4
## a[1]   0.8865936 0.015580736  0.86128553  0.91082334 2489.074 0.9989360
## a[2]   1.0501777 0.010010613  1.03404118  1.06614541 2152.883 1.0007549
## b[1]   0.1312147 0.074609926  0.01239339  0.24998421 2244.528 0.9993558
## b[2]  -0.1420136 0.054996077 -0.22957192 -0.05372842 2023.621 0.9987402
## sigma  0.1115782 0.006224722  0.10188964  0.12166315 3600.101 0.9990594
</code></pre>
<p>Again, these are very similar aside from the effective number of samples (<code>n_eff</code>) which is much higher for all parameter estimates in the model with the exponential prior on <code>sigma</code> (<code>m.M1Exp</code>) except for <code>sigma</code> itself, which boasts a higher <code>n_eff</code> in the uniform-prior model (<code>m.M1Uni</code>). As such, we conclude that while the different priors have an impact on <code>n_eff</code>, they do not change the posterior distributions. Let me visualise this:</p>
<pre><code class="language-r">Plot_df &lt;- data.frame(
  Posteriors = c(
    extract.samples(m.M1Exp, n = 1e4)$sigma,
    extract.samples(m.M1Uni, n = 1e4)$sigma
  ),
  Name = rep(c(&quot;Exp&quot;, &quot;Uni&quot;), each = 1e4),
  Model = rep(c(&quot;m.M1Exp&quot;, &quot;m.M1Uni&quot;), each = 1e4)
)

ggplot(Plot_df, aes(y = Model, x = Posteriors)) +
  stat_halfeye() +
  labs(x = &quot;Parameter Estimate&quot;, y = &quot;Model&quot;) +
  theme_bw()
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-8-1.png" width="1440" />
That really does look the same to me.</p>
<h3 id="practice-m2">Practice M2</h3>
<p><strong>Question:</strong> The Cauchy and exponential priors from the terrain ruggedness model are very weak. They can be made more informative by reducing their scale. Compare the <code>dcauchy</code> and <code>dexp</code> priors for progressively smaller values of the scaling parameter. As these priors become stronger, how does each influence the posterior distribution?</p>
<p><strong>Answer:</strong>  I write a <code>for</code> loop here to minimise code needs:</p>
<pre><code class="language-r">RepTimes &lt;- 4 # how many steps I want to try
ScalingFactor &lt;- 10 # by what factor to make priors stronger
# empty lists to store models in
Explist &lt;- as.list(rep(NA, RepTimes))
Caulist &lt;- as.list(rep(NA, RepTimes))
# Loop over all models
for (Mod_Iter in 0:(RepTimes - 1)) {
  dd.trim$ScalingFactor &lt;- ScalingFactor
  dd.trim$Mod_Iter &lt;- Mod_Iter
  ## Exponential prior for sigma
  m.M2Exp &lt;- ulam(
    alist(
      log_gdp_std ~ dnorm(mu, sigma),
      mu &lt;- a[cid] + b[cid] * (rugged_std - 0.215),
      a[cid] ~ dnorm(1, 0.1),
      b[cid] ~ dnorm(0, 0.3),
      sigma ~ dexp(1 * ScalingFactor^Mod_Iter)
    ),
    data = dd.trim,
    chains = 4,
    cores = 4,
  )
  Explist[[Mod_Iter + 1]] &lt;- m.M2Exp
  ## Cauchy prior for sigma
  m.M2Cau &lt;- ulam(
    alist(
      log_gdp_std ~ dnorm(mu, sigma),
      mu &lt;- a[cid] + b[cid] * (rugged_std - 0.215),
      a[cid] ~ dnorm(1, 0.1),
      b[cid] ~ dnorm(0, 0.3),
      sigma ~ dcauchy(0, 1 / ScalingFactor^Mod_Iter)
    ),
    data = dd.trim,
    chains = 4,
    cores = 4,
  )
  Caulist[[Mod_Iter + 1]] &lt;- m.M2Cau
}
coeftab(Explist[[1]], Explist[[2]], Explist[[3]], Explist[[4]])
</code></pre>
<pre><code>##       Explist[[1]] Explist[[2]] Explist[[3]] Explist[[4]]
## a[1]     0.89         0.89         0.89         0.89     
## a[2]     1.05         1.05         1.05         1.05     
## b[1]     0.13         0.13         0.13         0.13     
## b[2]    -0.14        -0.14        -0.14        -0.15     
## sigma    0.11         0.11         0.11         0.09     
## nobs      170          170          170          170
</code></pre>
<pre><code class="language-r">coeftab(Caulist[[1]], Caulist[[2]], Caulist[[3]], Caulist[[4]])
</code></pre>
<pre><code>##       Caulist[[1]] Caulist[[2]] Caulist[[3]] Caulist[[4]]
## a[1]     0.89         0.89         0.89         0.89     
## a[2]     1.05         1.05         1.05         1.05     
## b[1]     0.14         0.13         0.13         0.13     
## b[2]    -0.14        -0.14        -0.14        -0.14     
## sigma    0.11         0.11         0.11         0.11     
## nobs      170          170          170          170
</code></pre>
<p>The more restrictive exponential priors decrease the estimate for sigma. On the other hand, the more restrictive cauchy priors have no effect, it seems.</p>
<p>Let&rsquo;s explore why this is by looking at the priors themselves:</p>
<pre><code class="language-r">par(mfrow = c(1, 2))
curve(dexp(x, 1),
  from = 0, to = 5, ylab = &quot;Density&quot;, xlab = &quot;sigma&quot;,
  col = &quot;royalblue4&quot;
)
curve(dexp(x, 10), from = 0, to = 5, add = T)
curve(dexp(x, 100), from = 0, to = 5, add = T, col = col.desat(&quot;red&quot;))
curve(dexp(x, 1000), from = 0, to = 5, add = T, col = col.desat(&quot;green&quot;))
mtext(&quot;Exponential Prior&quot;)
legend(&quot;topright&quot;,
  col = c(&quot;royalblue4&quot;, &quot;black&quot;, col.desat(&quot;red&quot;), col.desat(&quot;green&quot;)),
  lty = c(1, 1, 1), legend = c(&quot;Exp(1)&quot;, &quot;Exp(10)&quot;, &quot;Exp(100)&quot;, &quot;Exp(1000)&quot;), bty = &quot;n&quot;
)

curve(2 * dcauchy(x, 0, 1),
  from = 0, to = 5, ylab = &quot;Density&quot;, xlab = &quot;sigma&quot;,
  col = &quot;royalblue4&quot;
)
curve(2 * dcauchy(x, 0, 0.1), from = 0, to = 5, add = T, col = &quot;black&quot;)
curve(2 * dcauchy(x, 0, 0.01), from = 0, to = 5, add = T, col = col.desat(&quot;red&quot;))
curve(2 * dcauchy(x, 0, 0.001), from = 0, to = 5, add = T, col = col.desat(&quot;green&quot;))
mtext(&quot;Cauchy Prior&quot;)
legend(&quot;topright&quot;,
  col = c(&quot;royalblue4&quot;, &quot;black&quot;, col.desat(&quot;red&quot;), col.desat(&quot;green&quot;)),
  lty = c(1, 1, 1), legend = c(&quot;Cauchy(0, 1)&quot;, &quot;Cauchy(0, 0.1)&quot;, &quot;Cauchy(0, 0.01)&quot;, &quot;Cauchy(0, 0.001)&quot;), bty = &quot;n&quot;
)
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-10-1.png" width="1440" /></p>
<p>The cauchy distributions show thicker tails while the exponential distributions quickly concentrate. Hence why a concentrated Cauchy prior allow more flexibility that a concentrated exponential prior.</p>
<h3 id="practice-m3">Practice M3</h3>
<p><strong>Question:</strong> Re-estimate one of the Stan models from the chapter, but at different numbers of <code>warmup</code> iterations. Be sure to use the same number of sampling iterations in each case. Compare the <code>n_eff</code> values.</p>
<p><strong>Answer:</strong> The ruggedness model was fine so far so I continue with that one. Here, I build this model with a fixed run length and fixed starting values for each run with changing warmup values:</p>
<pre><code class="language-r">start &lt;- list(a = c(1, 1), b = c(0, 0), sigma = 1) # use fixed start values for comparability of runs
m.M3 &lt;- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu &lt;- a[cid] + b[cid] * (rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ),
  data = dd.trim,
  start = start,
  chains = 2, cores = 2,
  iter = 100
)
warm_list &lt;- c(5, 10, 100, 500, 1000) # define warmup values to run through
n_eff &lt;- matrix(NA, nrow = length(warm_list), ncol = 5) # first make matrix to hold n_eff results
for (i in 1:length(warm_list)) { # loop over warm_list and collect n_eff
  w &lt;- warm_list[i]
  m_temp &lt;- ulam(m.M3, chains = 2, cores = 2, iter = 1000 + w, warmup = w, start = start)
  n_eff[i, ] &lt;- precis(m_temp, 2)$n_eff
}
colnames(n_eff) &lt;- rownames(precis(m_temp, 2))
rownames(n_eff) &lt;- warm_list
n_eff # columns show parameters, rows show n_eff
</code></pre>
<pre><code>##             a[1]        a[2]        b[1]        b[2]       sigma
## 5       2.314186    1.587251    2.713325    1.270369    1.776862
## 10   2243.084776 2157.086156  737.957589 1010.214712  953.010860
## 100  1725.334719 2294.576251  878.481785 1177.016946 1122.495229
## 500  2999.738299 3282.963810 2292.173710 2737.037252 2200.949134
## 1000 2485.029304 3406.341675 2372.274092 2772.175825 2607.552453
</code></pre>
<p>As we can see, past just 10 warmup samples, <code>n_eff</code> does not change much (in terms of how useful our samples are). In this case, we could be quite happy with a warmup of 10.</p>
<h2 id="hard-exercises">Hard Exercises</h2>
<h3 id="practice-h1">Practice H1</h3>
<p><strong>Question:</strong> Run the model below and then inspect the posterior distribution and explain what it is accomplishing.</p>
<pre><code class="language-r">mp &lt;- map2stan(
  alist(
    a ~ dnorm(0, 1),
    b ~ dcauchy(0, 1)
  ),
  data = list(y = 1),
  start = list(a = 0, b = 0),
  iter = 1e4,
  chains = 2, cores = 2,
  warmup = 100,
  WAIC = FALSE
)
</code></pre>
<p>Compare the samples for the parameters <code>a</code> and <code>b</code>. Can you explain the different trace plots, using what you know about the Cauchy distribution?</p>
<p><strong>Answer:</strong> First of all, let&rsquo;s inspect the posterior:</p>
<pre><code class="language-r">precis(mp)
</code></pre>
<pre><code>##            mean         sd      5.5%    94.5%     n_eff    Rhat4
## a  0.0003388167  0.9988213 -1.601441 1.590561 12762.761 1.000120
## b -0.1918181852 13.8995715 -5.379742 5.346423  3892.011 1.000517
</code></pre>
<p>Oof. Those uncertainties don&rsquo;t look good at all! So what does the model even do? It simply just samples <code>a</code> from a normal distribution with mean 0 and standard deviation 1. <code>b</code> is sampled from a cauchy distribution. Let&rsquo;s look at the traceplot for this:</p>
<pre><code class="language-r">plot(mp, n_cols = 1, col = &quot;royalblue4&quot;)
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-14-1.png" width="1440" /></p>
<p>As we can see, there are quite some outliers in the sampling of the cauchy distribution (<code>b</code>). Why is that? Because the cauchy distribution has very heavy tails thus making it more likely to jump to a value that is far out there in terms of posterior probability. Note that this also decreases <code>n_eff</code>. <code>lp</code> in the above is the log-posterior.</p>
<p>Now let&rsquo;s see how the samples we drew measure up against the underlying functions of <code>a</code> and <code>b</code>, respectively:</p>
<pre><code class="language-r">post &lt;- extract.samples(mp)
par(mfrow = c(1, 2))
dens(post$a)
curve(dnorm(x, 0, 1), from = -4, to = 4, add = T, lty = 2)
legend(&quot;topright&quot;, lty = c(1, 2), legend = c(&quot;Sample&quot;, &quot;Exact density&quot;), bty = &quot;n&quot;)
mtext(&quot;Normal&quot;)
dens(post$b, col = &quot;royalblue4&quot;, xlim = c(-10, 10))
curve(dcauchy(x, 0, 1),
  from = -10, to = 10, add = T, lty = 2,
  col = &quot;royalblue4&quot;
)
mtext(&quot;Cauchy&quot;)
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-15-1.png" width="1440" /></p>
<p>As we can see, the normal distribution has been reconstructed well. The cauchy distributions hasn&rsquo;t.</p>
<h3 id="practice-h2">Practice H2</h3>
<p><strong>Question:</strong> Recall the divorce rate example from Chapter 5. Repeat that analysis, using <code>ulam()</code> this time, fitting models <code>m5.1</code>, <code>m5.2</code>, and <code>m5.3</code>. Use compare to compare the models on the basis of WAIC or PSIS. Explain the results.</p>
<p><strong>Answer:</strong> First, I need to load the data and prepare it for <code>ulam()</code>:</p>
<pre><code class="language-r">data(WaffleDivorce)
d &lt;- WaffleDivorce
d$D &lt;- standardize(d$Divorce)
d$M &lt;- standardize(d$Marriage)
d$A &lt;- standardize(d$MedianAgeMarriage)
d_trim &lt;- list(D = d$D, M = d$M, A = d$A)
</code></pre>
<p>Now I fit the models with <code>ulam()</code>:</p>
<pre><code class="language-r">m5.1_stan &lt;- ulam(
  alist(
    D ~ dnorm(mu, sigma),
    mu &lt;- a + bA * A,
    a ~ dnorm(0, 0.2),
    bA ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = d_trim,
  chains = 4, cores = 4,
  log_lik = TRUE # this is needed to get the terms for calculating PSIS or WAIC
)
m5.2_stan &lt;- ulam(
  alist(
    D ~ dnorm(mu, sigma),
    mu &lt;- a + bM * M,
    a ~ dnorm(0, 0.2),
    bM ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = d_trim,
  chains = 4, cores = 4,
  log_lik = TRUE # this is needed to get the terms for calculating PSIS or WAIC
)
m5.3_stan &lt;- ulam(
  alist(
    D ~ dnorm(mu, sigma),
    mu &lt;- a + bA * A + bM * M,
    a ~ dnorm(0, 0.2),
    bA ~ dnorm(0, 0.5),
    bM ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = d_trim,
  chains = 4, cores = 4,
  log_lik = TRUE # this is needed to get the terms for calculating PSIS or WAIC
)
</code></pre>
<p>Now we compare the models:</p>
<pre><code class="language-r">compare(m5.1_stan, m5.2_stan, m5.3_stan, func = PSIS)
</code></pre>
<pre><code>##               PSIS        SE     dPSIS       dSE    pPSIS       weight
## m5.1_stan 125.7210 12.708327  0.000000        NA 3.630705 0.7253039155
## m5.3_stan 127.6690 12.852350  1.947996 0.6705316 4.773054 0.2738533387
## m5.2_stan 139.2364  9.936093 13.515361 9.1363047 2.923975 0.0008427459
</code></pre>
<pre><code class="language-r">compare(m5.1_stan, m5.2_stan, m5.3_stan, func = WAIC)
</code></pre>
<pre><code>##               WAIC        SE     dWAIC       dSE    pWAIC       weight
## m5.1_stan 125.7778 12.641919  0.000000        NA 3.659072 0.6960655494
## m5.3_stan 127.4407 12.591741  1.662916 0.6770545 4.658881 0.3030766321
## m5.2_stan 139.1754  9.813604 13.397613 9.2109285 2.893468 0.0008578185
</code></pre>
<p>WAIC tells a similar story as PSIS, but the model only containing age (<code>m5.1_stan</code>) wins. The model with both predictors (<code>m5.3_stan</code>) does almost as well. However, their respective PSIS and WAIC values are nearly identical. Furthermore, both models get assigned all of the WAIC weight. Let&rsquo;s call these equal in performance and investigate why:</p>
<pre><code class="language-r">precis(m5.3_stan)
</code></pre>
<pre><code>##                mean         sd       5.5%      94.5%    n_eff     Rhat4
## a     -0.0001904293 0.10140928 -0.1591984  0.1619373 1877.251 1.0002239
## bA    -0.6023698429 0.16025804 -0.8510854 -0.3467602 1085.019 1.0007578
## bM    -0.0550634908 0.16034205 -0.3109204  0.2015101 1187.780 0.9998155
## sigma  0.8275838910 0.08826874  0.7028130  0.9779113 1474.265 1.0028212
</code></pre>
<p>While <code>m5.3_stan</code> contains the marriage predictor, it is very unsure of it&rsquo;s influence. In practical terms, this means that <code>m5.1_stan</code> and <code>m5.3_stan</code> make basically the same predictions</p>
<h3 id="practice-h3">Practice H3</h3>
<p><strong>Question:</strong> Sometimes changing a prior for one parameter has unanticipated effects on other parameters. This is because when a parameter is highly correlated with another parameter in the posterior, the prior influences both parameters. Here’s an example to work and think through.<br>
Go back to the leg length example in Chapter 5. Here is the code again, which simulates height and leg lengths for 100 imagined individuals:</p>
<pre><code class="language-r">N &lt;- 100 # number of individuals
height &lt;- rnorm(N, 10, 2) # sim total height of each
leg_prop &lt;- runif(N, 0.4, 0.5) # leg as proportion of height
leg_left &lt;- leg_prop * height + rnorm(N, 0, 0.02) # sim left leg as proportion + error
leg_right &lt;- leg_prop * height + rnorm(N, 0, 0.02) # sim right leg as proportion + error
d &lt;- data.frame(height, leg_left, leg_right) # combine into data frame
</code></pre>
<p>And below is the model you fit before, resulting in a highly correlated posterior for the two beta parameters. This time, fit the model using <code>ulam()</code>:</p>
<pre><code class="language-r">m5.8s &lt;- ulam(
  alist(
    height ~ dnorm(mu, sigma),
    mu &lt;- a + bl * leg_left + br * leg_right,
    a ~ dnorm(10, 100),
    bl ~ dnorm(2, 10),
    br ~ dnorm(2, 10),
    sigma ~ dexp(1)
  ),
  data = d,
  chains = 4,
  cores = 4,
  start = list(
    a = 10,
    bl = 0,
    br = 0.1,
    sigma = 1
  )
)
</code></pre>
<p>Compare the posterior distribution produced by the code above to the posterior distribution produced when you change the prior for <code>br</code> so that it is strictly positive:</p>
<pre><code class="language-r">m5.8s2 &lt;- ulam(
  alist(
    height ~ dnorm(mu, sigma),
    mu &lt;- a + bl * leg_left + br * leg_right,
    a ~ dnorm(10, 100),
    bl ~ dnorm(2, 10),
    br ~ dnorm(2, 10),
    sigma ~ dexp(1)
  ),
  data = d,
  chains = 4,
  cores = 4,
  constraints = list(br = &quot;lower=0&quot;),
  start = list(
    a = 10,
    bl = 0,
    br = 0.1,
    sigma = 1
  )
)
</code></pre>
<p>Note the constraints list. What this does is constrain the prior distribution of <code>br</code> so that it has positive probability only above zero. In other words, that prior ensures that the posterior distribution for <code>br</code> will have no probability mass below zero.<br>
Compare the two posterior distributions for <code>m5.8s</code> and <code>m5.8s2</code>. What has changed in the posterior distribution of both beta parameters? Can you explain the change induced by the change in prior?</p>
<p><strong>Answer:</strong> It&rsquo;s probably easiest to just look at the posterior distributions of the beta prameters through the <code>pairs()</code> function:</p>
<pre><code class="language-r">pairs(m5.8s, main = &quot;Model 1&quot;)
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-24-1.png" width="1440" /></p>
<pre><code class="language-r">pairs(m5.8s2, main = &quot;Model 2&quot;)
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-24-2.png" width="1440" /></p>
<p>As we can see, the beta distributions have shifted drastically between the different models. Interestingly, <code>bl</code> and <code>br</code> were perfectly symmetric in <code>m5.8s</code>, but are skewed in <code>m5.8s2</code>. Given how the height of a person is approximated in both models (<code>a + bl*leg_left + br*leg_right</code>), the distributions of leg lengths are necessarily negatively correlated (you can be of the same height with a short right leg and long left leg, long left leg and short right leg, or two medium-length legs). Thus, by setting <code>br</code> to be strictly positive in <code>m5.8s2</code> and made it skewed, we have forced <code>bl</code> to be equally skewed in a mirror image of <code>br</code>.</p>
<h3 id="practice-h4">Practice H4</h3>
<p><strong>Question:</strong> For the two models fit in the previous problem, use WAIC or PSIS to compare the effective numbers of parameters for each model. You will need to use <code>log_lik=TRUE</code> to instruct <code>ulam()</code> to compute the terms that both WAIC and PSIS need. Which model has more effective parameters? Why?</p>
<p><strong>Answer:</strong> Let&rsquo;s run the models:</p>
<pre><code class="language-r">m.H4_1 &lt;- ulam(
  alist(
    height ~ dnorm(mu, sigma),
    mu &lt;- a + bl * leg_left + br * leg_right,
    a ~ dnorm(10, 100),
    bl ~ dnorm(2, 10),
    br ~ dnorm(2, 10),
    sigma ~ dexp(1)
  ),
  data = d,
  chains = 4,
  cores = 4,
  start = list(
    a = 10,
    bl = 0,
    br = 0.1,
    sigma = 1
  ),
  log_lik = TRUE
)
m.H4_2 &lt;- ulam(
  alist(
    height ~ dnorm(mu, sigma),
    mu &lt;- a + bl * leg_left + br * leg_right,
    a ~ dnorm(10, 100),
    bl ~ dnorm(2, 10),
    br ~ dnorm(2, 10),
    sigma ~ dexp(1)
  ),
  data = d,
  chains = 4,
  cores = 4,
  constraints = list(br = &quot;lower=0&quot;),
  start = list(
    a = 10,
    bl = 0,
    br = 0.1,
    sigma = 1
  ),
  log_lik = TRUE
)
</code></pre>
<p>Now we compare them with WAIC:</p>
<pre><code class="language-r">compare(m.H4_1, m.H4_2)
</code></pre>
<pre><code>##            WAIC       SE     dWAIC      dSE    pWAIC    weight
## m.H4_1 182.1474 10.21060 0.0000000       NA 2.961292 0.6063273
## m.H4_2 183.0112  9.88398 0.8638001 2.349502 2.382919 0.3936727
</code></pre>
<p>The models are pretty much tied. The model with truncated priors (<code>m.H4_2</code>) is less flexible as indicated by <code>pWAIC</code>. This is because the prior is more informative and the variance in the posterior distribution is smaller as a result.</p>
<h3 id="practice-h5">Practice H5</h3>
<p><strong>Question:</strong> Modify the Metropolis algorithm code from the chapter to handle the case that the island populations have a different distribution than the island labels. This means the island’s number will not be the same as its population.</p>
<p><strong>Answer:</strong> First of all, we need our 10 islands with population sizes of 1-10, but in random order:</p>
<pre><code class="language-r">pop_size &lt;- sample(1:10)
</code></pre>
<p>Now we can use the code from the chapter almost unaltered safe for one exception - we need to use indexing to translate island location into population size:</p>
<pre><code class="language-r">num_weeks &lt;- 1e5
positions &lt;- rep(NA, num_weeks)
current &lt;- 10
for (i in 1:num_weeks) {
  positions[i] &lt;- current # record current position
  proposal &lt;- current + sample(c(-1, 1), size = 1) # flip coin to generate proposal
  # now make sure he loops around the archipelago
  if (proposal &lt; 1) proposal &lt;- 10
  if (proposal &gt; 10) proposal &lt;- 1
  prob_move &lt;- pop_size[proposal] / pop_size[current] # move?
  current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current)
}
</code></pre>
<p>To see if this works, we can plot population size against frequency of visit by the king:</p>
<pre><code class="language-r">f &lt;- table(positions) # compute frequencies
plot(as.vector(f), pop_size,
  type = &quot;n&quot;, # plot frequencies against relative population sizes
  xlab = &quot;frequency&quot;, ylab = &quot;population size&quot;
) # empty plot
text(x = f, y = pop_size, labels = names(f)) # add names of islands / their positions
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-29-1.png" width="1440" /></p>
<h3 id="practice-h6">Practice H6</h3>
<p><strong>Question:</strong> Modify the Metropolis algorithm code from the chapter to write your own simple MCMC estimator for globe tossing data and model from Chapter 2.</p>
<p><strong>Answer:</strong> We want to fit the following model:</p>
<p>$$w∼Binom(θ,n)$$
$$θ∼Unif(0,1)$$
Our Metropolis algorithm looks like this:</p>
<pre><code class="language-r">set.seed(42)
# the globe tossing data
w &lt;- 6
n &lt;- 9
# prior on p
p_prior &lt;- function(p) dunif(p, min = 0, max = 1)
# initializing MCMC
iter &lt;- 1e4
p_sample &lt;- rep(0, iter)
p_current &lt;- 0.5 # start value
for (i in 1:iter) {
  p_sample[i] &lt;- p_current # # record current p
  p_proposal &lt;- runif(1, min = 0, max = 1) # generate proposal
  # compute likelihood for current and proposal
  lkhd_current &lt;- dbinom(w, n, p_current)
  lkhd_proposal &lt;- dbinom(w, n, p_proposal)
  prob_proposal &lt;- lkhd_proposal * p_prior(p_proposal)
  prob_current &lt;- lkhd_current * p_prior(p_current)
  prob_accept &lt;- prob_proposal / prob_current
  p_current &lt;- ifelse(runif(1) &lt; prob_accept, p_proposal, p_current)
}
</code></pre>
<p>Let&rsquo;s visualise what happened here:</p>
<pre><code class="language-r">plot(p_sample, type = &quot;l&quot;, col = &quot;royalblue4&quot;)
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-31-1.png" width="1440" />
Finally, let&rsquo;s plot the posterior distribution:</p>
<pre><code class="language-r">dens(p_sample, col = &quot;royalblue4&quot;, adj = 1)
curve(dbeta(x, w + 1, n - w + 1), from = 0, to = 1, add = T, lty = 2)
abline(v = median(p_sample))
</code></pre>
<p><img src="2021-02-25-statistical-rethinking-chapter-09_files/figure-html/unnamed-chunk-32-1.png" width="1440" /></p>
<h2 id="session-info">Session Info</h2>
<pre><code class="language-r">sessionInfo()
</code></pre>
<pre><code>## R version 4.0.5 (2021-03-31)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19043)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                           
## [5] LC_TIME=English_United Kingdom.1252    
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] tidybayes_2.3.1      rethinking_2.13      rstan_2.21.2         ggplot2_3.3.6        StanHeaders_2.21.0-7
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.7           mvtnorm_1.1-1        lattice_0.20-41      tidyr_1.1.3          prettyunits_1.1.1    ps_1.6.0             assertthat_0.2.1     digest_0.6.27        utf8_1.2.1          
## [10] V8_3.4.1             plyr_1.8.6           R6_2.5.0             backports_1.2.1      stats4_4.0.5         evaluate_0.14        coda_0.19-4          highr_0.9            blogdown_1.3        
## [19] pillar_1.6.0         rlang_0.4.11         curl_4.3.2           callr_3.7.0          jquerylib_0.1.4      R.utils_2.10.1       R.oo_1.24.0          rmarkdown_2.7        styler_1.4.1        
## [28] labeling_0.4.2       stringr_1.4.0        loo_2.4.1            munsell_0.5.0        compiler_4.0.5       xfun_0.22            pkgconfig_2.0.3      pkgbuild_1.2.0       shape_1.4.5         
## [37] htmltools_0.5.1.1    tidyselect_1.1.0     tibble_3.1.1         gridExtra_2.3        bookdown_0.22        arrayhelpers_1.1-0   codetools_0.2-18     matrixStats_0.61.0   fansi_0.4.2         
## [46] crayon_1.4.1         dplyr_1.0.5          withr_2.4.2          MASS_7.3-53.1        R.methodsS3_1.8.1    distributional_0.2.2 ggdist_2.4.0         grid_4.0.5           jsonlite_1.7.2      
## [55] gtable_0.3.0         lifecycle_1.0.0      DBI_1.1.1            magrittr_2.0.1       scales_1.1.1         KernSmooth_2.23-18   RcppParallel_5.1.2   cli_3.0.0            stringi_1.5.3       
## [64] farver_2.1.0         bslib_0.2.4          ellipsis_0.3.2       generics_0.1.0       vctrs_0.3.7          rematch2_2.1.2       forcats_0.5.1        tools_4.0.5          svUnit_1.0.6        
## [73] R.cache_0.14.0       glue_1.4.2           purrr_0.3.4          processx_3.5.1       yaml_2.2.1           inline_0.3.17        colorspace_2.0-0     knitr_1.33           sass_0.3.1
</code></pre>

          </div>

          

<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/statistics/">Statistics</a>
  
  <a class="badge badge-light" href="/tag/bayes/">Bayes</a>
  
  <a class="badge badge-light" href="/tag/bayesian-statistics/">Bayesian Statistics</a>
  
  <a class="badge badge-light" href="/tag/au-bayes-study-group/">AU Bayes Study Group</a>
  
</div>



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/courses/rethinking/chapter-08/" rel="next">Chapter 08</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/courses/rethinking/chapter-11/" rel="prev">Chapter 10 &amp; 11</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on 2021-02-25</p>

          





          


          


  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/courses/rethinking/chapter-16/">Chapter 16</a></li>
      
      <li><a href="/courses/rethinking/chapter-15/">Chapter 15</a></li>
      
      <li><a href="/courses/rethinking/chapter-14/">Chapter 14</a></li>
      
      <li><a href="/courses/rethinking/chapter-13/">Chapter 13</a></li>
      
      <li><a href="/courses/rethinking/chapter-12/">Chapter 12</a></li>
      
    </ul>
  </div>
  



        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    © 2024
  </p>

  
  






  <p class="powered-by">
    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>


      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/latex.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.66c553246b0f279a03be6e5597f72b52.js"></script>

    






  
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
