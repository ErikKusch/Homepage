[{"authors":null,"categories":null,"content":"Hi. I\u0026rsquo;m Erik Kusch, an advisor at CICERO Center for International Climate Research where I work on interdisciplinary research focusing on Climate and Nature Risk. In addition, I also work as a senior engineer at the Natural History Museum of the University of Oslo where I manage research infrastructure for the BioDT project. Using big data and generating novel statistical methodology, I aim to understand how global and local processes and patterns in biological systems come about and are reinforced thus generating knowledge about the resilience of the Earth\u0026rsquo;s ecosystems.\nMy PhD project at Aarhus University focused on ecological interactions and the networks they form at macroecological scales.\nIn my free time, I escape to the mountains and engage in landscape and wildlife photography.\n\r Download my CV or  contact me if you want to know more.\n","date":1730851200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1730851200,"objectID":"6bd5432848a2104ee4011dc2699e9bc5","permalink":"https://www.erikkusch.com/author/erik-kusch/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/erik-kusch/","section":"authors","summary":"Hi. I\u0026rsquo;m Erik Kusch, an advisor at CICERO Center for International Climate Research where I work on interdisciplinary research focusing on Climate and Nature Risk. In addition, I also work as a senior engineer at the Natural History Museum of the University of Oslo where I manage research infrastructure for the BioDT project.","tags":null,"title":"Erik Kusch","type":"authors"},{"authors":["Erik Kusch"],"categories":["GBIF","Biodiversity","Open Science"],"content":"In the age of changes and threat to the Ecosphere at macroecological scales, big data has crystallized as a go-to tool for ecological research. To facilitate the creation of, access to, and referencing of contributors to such big data repositories, the Global Biodiversity Information Facility (GBIF) has established data streams that make readily available a wealth of biodiversity data. Navigating and accessing such large data sets and ensuring fair use and accreditation of observations can seem daunting. In this workshop, we will introduce GBIF, show how to navigate its data portal, demonstrate data streams to obtain and handle data programmatically, and communicate accreditation procedures.\nThroughout this workshop material, I present practical examples for obtaining GBIF data using rgbif. Much of this work has been directly inspired or adapted from the official rgbif website and a previous GBIF workshop.\nLearning Goals Throughout this workshop, you will be introduced to:\n The Global Biodiversity Information Facility (GBIF)   What it is What data it makes available How to navigate the data How to query and obtain specific records What to consider with regards to data content, richness and quality How to reference and accredit GBIF-mediated data  The rgbif package   Functionality for querying, accessing, and handling GBIF data programmatically Data handling practices in R  Study Organism Most of the time, GBIF users query data for individual species so we will establish a comparable use-case here. For most of this material, I will be focussing on Lagopus muta - the rock ptarmigan (see below). I have particularly fond memories of these birds flying alongside an uncle of mine and I on a topptur-ski trip in Lofoten earlier this year. It also lends itself well to a demonstration of rgbif functionality.\nDisclaimer If you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about thing, do not hesitate to contact me.\nAll the best, Erik\n","date":1730851200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1730851200,"objectID":"6490642d8d0e4da061070350a72a5531","permalink":"https://www.erikkusch.com/courses/gbif/","publishdate":"2024-11-06T00:00:00Z","relpermalink":"/courses/gbif/","section":"courses","summary":"Workshop material introducing concepts and giving practical examples for obtaining GBIF data using `rgbif`.","tags":["GBIF","Biodiversity","Open Science"],"title":"Accessing, handling, and referencing open biodiversity data using the Global Biodiversity Information Facility (GBIF)","type":"docs"},{"authors":["Erik Kusch"],"categories":null,"content":"Learning Goals The material presented here is aimed at providing the reader with:\n A solid grasp of basic biostatistics  Have an overview of available methods Be able to judge the applicability of individual methods 2 Basic proficiency in using R Know base commands and how they function Be able to prepare biologically relevant data sets for further analysis Be able to apply basic statistical methods to biologically relevant data sets 3 Research Design Understand how to formulate testable hypotheses Know the importance of proper statistical approaches in research Being able to critically assess statistical methods in research publications    Contents The seminar series covers the following:\n Introduction  An Introduction to Basic Statistics for Biologists Introduction to R   Basic statistical terminology  A primer for Statistical Tests Descriptive Statistics Data Visualisation Inferential Statistics, Hypotheses and our Research Project   Handling Data  Data Handling and Data Mining   Non-parametric tests  Nominal Tests Correlation Tests Ordinal and Metric Tests for two-sample situations Ordinal and Metric Tests for more than two-sample situations   Parametric tests  Simple Parametric Tests   Closing  Summary, Manuscript Workflow and an Outlook on Advanced Statistics    Disclaimer You can also find all of this on GitHub.\nIf you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about thing, do not hesitate to contact me.\nAll the best, Erik\n","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"aec0791dae2bcc3d2da2a5e0aa6fb75a","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/","section":"courses","summary":"This is a series of lectures and seminars designed for B.Sc. students of biology and should serve as an introduction to the basics of biostatistics using R. I taught these topics at the University of Leipzig but invite everyone who stumbles across this page to make use of what I'm presenting here as all of my material has been designed with the students interest in mind and should thus be self-sufficient.","tags":["Statistics"],"title":"An Introduction to Biostatistics","type":"docs"},{"authors":["Erik Kusch"],"categories":null,"content":"Learning Goals The material presented here is aimed at providing the reader with:\n A solid grasp of Bayesian networks  Have an overview of Bayesian principles Be able to formulate Bayesian networks Know how to interpret outputs of Bayesian networks   Ability to execute Bayesian network analyses  Know how to apply the bnlearn package    Contents  We follow the material noted further down under Group Material We prepared ourselves by working through the material noted for each session in the Preparation Column in Proposed Timeline At the start of each session, I quickly presented a summary of the preparation material.  Material  Book “Bayesian Networks With Examples in R” by Marco Scutari \u0026amp; Jean-Baptiste Denis; available here Book “Bayesian Networks in R with Applications in Systems Biology” by Radhakrishnan Nagarajan, Marco Scutari \u0026amp; Sophie Lèbre; available here  Disclaimer If you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about thing, do not hesitate to contact me.\nAll the best, Erik\n","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"811a38ebff851bdff8a0729e2b2dd11b","permalink":"https://www.erikkusch.com/courses/bayes-nets/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/bayes-nets/","section":"courses","summary":"A series of seminars, presentations and solutions to exercise material aimed at providing an introduction to Bayesian Network analysis tools.","tags":["Bayes","Networks","Bayesian Statistics","Statistics","Networks","Biological Networks"],"title":"Bayesian Networks","type":"docs"},{"authors":null,"categories":null,"content":"Learning Goals This is an exercise which is part of the greater Biological Scientific Research in Theory and Practice scheme at Aarhus University. Here, you will learn how to:\n Identify vegetation clusters from space Analyse how those clusters have shifted over time Identify areas that have experienced frequent change of predominant biomes  A few challenges to overcome include:\n Which vegetation index to use? Which measures therein? How to identify clusters? How to validate the accuracy of our cluster products? How to link resilience to shifts in biome states?  Background Biomes are large, somewhat homogeneous biological communities which are usually characterised by one predominant vegetation type. As a consequence of climate change, we expect these to shift poleward leading to a change in landcover classification schemes.\nResilience is a concept/charactersitic of a system which enables it to persist in time and place despite perturbations. Global policy makers have adopted resilience goals.\nDisclaimer This work was inspired heavily by my work on Remote Sensing And Predicting Shifts In Biome Distribution And Resilience Using NDVI Data for my B.Sc. thesis.\nIf you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about thing, do not hesitate to contact me.\nAll the best, Erik\n","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"542222a99d691e7233857e6a5b295847","permalink":"https://www.erikkusch.com/courses/bftp-biome-detection/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/bftp-biome-detection/","section":"courses","summary":"This is a three-part series of exercises for the BFTP (Biological Scientific Research in Theory and Practice) course at Aarhus University. Within these exercises, I walk you through the basics of remote sensing analyses in R as needed for macroecological purposes.","tags":null,"title":"BFTP - Biome Detection through Remote Sensing","type":"docs"},{"authors":["Erik Kusch"],"categories":null,"content":"Learning Goals The material presented here is aimed at providing the reader with:\n A solid grasp of basic biostatistics  Have an overview of available methods Be able to judge the applicability of individual methods 2 Basic proficiency in using R Know base commands and how they function Be able to prepare biologically relevant data sets for further analysis Be able to apply basic statistical methods to biologically relevant data sets 3 Research Design Understand how to formulate testable hypotheses Know the importance of proper statistical approaches in research Being able to critically assess statistical methods in research publications    Contents The seminar series covers the following:\n Introduction  An Introduction to Basic Statistics for Biologists Introduction to R   Basic statistical terminology  A primer for Statistical Tests Descriptive Statistics Data Visualisation Inferential Statistics, Hypotheses and our Research Project   Handling Data  Data Handling and Data Mining   Non-parametric tests  Nominal Tests Correlation Tests Ordinal and Metric Tests for two-sample situations Ordinal and Metric Tests for more than two-sample situations   Parametric tests  Simple Parametric Tests   Closing  Summary, Manuscript Workflow and an Outlook on Advanced Statistics    Feedback \u0026amp; Improvements If you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about thing, do not hesitate to contact me.\nAll the best, Erik\n","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"aab88287552daa23faf08285e8654f16","permalink":"https://www.erikkusch.com/courses/biostat101/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/biostat101/","section":"courses","summary":"This is a series of lectures and seminars designed for B.Sc. students of biology and should serve as an introduction to the basics of biostatistics using R. I taught these topics at the University of Leipzig but invite everyone who stumbles across this page to make use of what I'm presenting here as all of my material has been designed with the students interest in mind and should thus be self-sufficient.","tags":["Statistics"],"title":"BioStat 101 - An Introduction to Biostatistics","type":"docs"},{"authors":null,"categories":null,"content":"Disclaimer You can also find all of this on GitHub.\nIf you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about anything thing, do not hesitate to contact me.\nAll the best, Erik\n","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"9e4f55d40e24d68cbf13747fb1a90530","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/","section":"courses","summary":"A selection of talks related to general topics of biostatistical concern I have given throughout the years.","tags":null,"title":"Excursions into Biostatistics","type":"docs"},{"authors":null,"categories":null,"content":"Learning Goals The material presented here is aimed at providing the reader with:\n A solid grasp of Bayesian statistics  Have an overview of Bayesian principles Be able to formulate Bayesian frameworks Know how to interpret outputs of Bayesian frameworks   Ability to execute Bayesian statistics  Know how to apply the rethinking package Have an initial overview of STAN functionality    Contents  We follow the material noted further down under Group Material We prepared ourselves by working through the material noted for each session in the Preparation Column in Proposed Timeline At the start of each session, I quickly presented a summary of the preparation material.  Material  Lecture Recording “Statistical Rethinking” by Richard McElreath; available here Book “Statistical Rethinking” by Richard McElreath; available here Practical Examples:  Course Material Statistical Rethinking Book “Introduction to WinBUGS for Ecologists” by Marc Kéry; available here Book “Bayesian Population Analysis using WinBUGS” by Marc Kéry and Michael Schaub; available here   Further Input (all prospective)  Disclaimer The material, I have prepared here is now being used for an official PhD-level course.\nIf you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about thing, do not hesitate to contact me.\nAll the best, Erik\n","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"2a55ba3ef9d01f9b19f51df4b2fd9e47","permalink":"https://www.erikkusch.com/courses/rethinking/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/rethinking/","section":"courses","summary":"Summaries and solutions to exercises contained in the Statistical Rethinking material by Richard McElreath.","tags":["Statistics","Bayesian Statistics","Bayes","Rethinking"],"title":"Statistical Rethinking","type":"docs"},{"authors":["Erik Kusch"],"categories":["KrigR","Climate Data"],"content":"\rPlease note that KrigR is currently undergoing major redevelopment with respect to updating functionality to remove deprecated dependencies and to enable operations targeting the new CDS. The workshop material presented here is being redeveloped at the same time. At present, I recommend to use the development version of KrigR - the workshop material detailing setup and quickguide have already been reworked to reference this version of the package which will soon become the new main version of KrigR.\r\r\rThe Copernicus Climate Data Store (CDS) host a variety of data products - like world-leading climate reanalysis products - which provide more accurate environmental information at higher temporal resolution than traditional climate data products used in downstream applications in ecology, anthropology, macroeconomics, epidemeology, and many others.\nThe KrigR R-package reduces barriers for users to (a) download CDS-hosted data (b) aggregate these data to desired temporal resolutions and metrics, (c) acquire and prepare co-variates matching these products, and (d) statistically downscale spatial data using co-variates via kriging which allows for integration of data uncertainty with interpolation uncertainty for improved data reliability indicators.\nThe KrigR workflow allows highly flexible data product creation for unparalleled aligning of data set specifications with research objectives. Climate and weather products obtained through KrigR offer great potential for quantification of exposure to extreme events due to their combinations of high spatial and temporal resolutions. Lastly, KrigR can incorporate third-party data which enables generation of high-resolution, bias-corrected climate projection data allowing for forecasting at high-resolution.\nI have created KrigR for download, temporal aggregation, masking, and statistically interpolating ERA5(-Land) data. We first presented the R-Package (KrigR) itself in Kusch,Davy, 2022. In Davy, Kusch, 2021 published previously my colleague and I demonstrated how data obtained through the KrigR framework relate to previously offered ready-made data sets and why we strongly believe that data handling pipelines (rather than ready-made data sets) are the way forward for downstream analyses.\nThroughout this workshop material, I walk you through the functionality, use-cases, and quality of life aspects with KrigR.\nLearning Goals Throughout this workshop, you will learn how to:\n Query downloads of state-of-the-art climate data using KrigR Use the data processing functionality contained in KrigR to achieve data at desired spatial scales and temporal resolutions Obtain and process covariate data for use in statistical interpolation via kriging Carry out kriging using the KrigR package  Issues \u0026amp; Feature Requests If you run into any error messages, bugs, want to inquire about some KrigR functionality, or request new functionality, please do so by registering an issue on the KrigR GitHub. Please, refrain from sending these via E-mail.\nDisclaimer If you find any typos in my material, are unhappy with some of what or how I am presenting or simply unclear about thing, do not hesitate to contact me.\nAll the best,\nErik\n","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"50cfa4a72fd66312963168c721daa032","permalink":"https://www.erikkusch.com/courses/krigr/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/krigr/","section":"courses","summary":"Workshop material for getting started and becoming adept at using the `R` Package `KrigR`.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"KrigR Workshop","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r\rMaterial Most of the material in these chapters has already been covered in previous material, so the following summary is rather brief:\n \rBayesian Network Inference  Please refer to earlier material for introductions of queries, structure learning, and parameter learning in theory and in R.\nExercises These are answers and solutions to the exercises at the end of chapter 4 in Bayesian Networks in R with Applications in Systems Biology by by Radhakrishnan Nagarajan, Marco Scutari \u0026amp; Sophie Lèbre and Part 4 in Bayesian Networks with Examples in R by M. Scutari and J.-B. Denis. Much of my inspiration for these solutions, where necessary, by consulting the solutions provided by the authors themselves as in the appendix.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(bnlearn)\rlibrary(gRain)\rlibrary(GeneNet)\rlibrary(penalized)\r Nagarajan 4.1  Apply the junction tree algorithm to the validated network structure from Sachs et al. (2005), and draw the resulting undirected triangulated graph.\n Taken directly from the solutions:\nNagarajan 4.2  Consider the Sachs et al. (2005) data used in Sect. 4.2.\n First, let\u0026rsquo;s read the data in like it was done in the book:\nisachs \u0026lt;- read.table(\u0026quot;sachs.interventional.txt\u0026quot;, header = TRUE, colClasses = \u0026quot;factor\u0026quot;)\risachs \u0026lt;- isachs[, 1:11]\rfor (i in names(isachs)) {\rlevels(isachs[, i]) \u0026lt;- c(\u0026quot;LOW\u0026quot;, \u0026quot;AVG\u0026quot;, \u0026quot;HIGH\u0026quot;)\r}\r This .txt file can be downloaded from here.\nPart A  Perform parameter learning with the bn.fit function from bnlearn and the validated network structure. How do the maximum likelihood estimates differ from the Bayesian ones, and how do the latter vary as the imaginary sample size increases?\n sachs_DAG \u0026lt;- model2network(paste0(\r\u0026quot;[PKC][PKA|PKC][praf|PKC:PKA]\u0026quot;,\r\u0026quot;[pmek|PKC:PKA:praf][p44.42|pmek:PKA]\u0026quot;,\r\u0026quot;[pakts473|p44.42:PKA][P38|PKC:PKA]\u0026quot;,\r\u0026quot;[pjnk|PKC:PKA][plcg][PIP3|plcg]\u0026quot;,\r\u0026quot;[PIP2|plcg:PIP3]\u0026quot;\r))\rf4.1_mle \u0026lt;- bn.fit(sachs_DAG, isachs, method = \u0026quot;mle\u0026quot;)\rf4.1_bayes1 \u0026lt;- bn.fit(sachs_DAG, isachs, method = \u0026quot;bayes\u0026quot;, iss = 1)\rf4.1_bayes10 \u0026lt;- bn.fit(sachs_DAG, isachs, method = \u0026quot;bayes\u0026quot;, iss = 10)\rf4.1_bayes100 \u0026lt;- bn.fit(sachs_DAG, isachs, method = \u0026quot;bayes\u0026quot;, iss = 100)\r I omit the outputs of the individual objects created above here for space.\nFrom a theoretical standpoint mle estimates may contain NA values while bayes-inferred estimates do not. That being said, I did not see any NA outputs in the maximum likelihood estimates here.\nAs far as iss is concerned, higher iss values result in smoother estimates.\nPart B  Node PKA is parent of all the nodes in the praf → pmek → p44.42 → pakts473 chain. Use the junction tree algorithm to explore how our beliefs on those nodes change when we have evidence that PKA is “LOW”, and when PKA is “HIGH”.\n mle_jtree \u0026lt;- compile(as.grain(f4.1_mle))\rquery \u0026lt;- c(\u0026quot;praf\u0026quot;, \u0026quot;pmek\u0026quot;, \u0026quot;p44.42\u0026quot;, \u0026quot;pakts473\u0026quot;)\r## baseline query\rquerygrain(mle_jtree, nodes = query)\r ## $pmek\r## pmek\r## LOW AVG HIGH ## 0.5798148 0.3066667 0.1135185 ## ## $praf\r## praf\r## LOW AVG HIGH ## 0.5112963 0.2835185 0.2051852 ## ## $p44.42\r## p44.42\r## LOW AVG HIGH ## 0.1361111 0.6062963 0.2575926 ## ## $pakts473\r## pakts473\r## LOW AVG HIGH ## 0.60944444 0.31037037 0.08018519\r ## low evidence\rmle_jprop \u0026lt;- setFinding(mle_jtree, nodes = \u0026quot;PKA\u0026quot;, states = \u0026quot;LOW\u0026quot;)\rquerygrain(mle_jprop, nodes = query)\r ## $pmek\r## pmek\r## LOW AVG HIGH ## 0.35782443 0.08874046 0.55343511 ## ## $praf\r## praf\r## LOW AVG HIGH ## 0.1145038 0.1746183 0.7108779 ## ## $p44.42\r## p44.42\r## LOW AVG HIGH ## 0.3435115 0.1965649 0.4599237 ## ## $pakts473\r## pakts473\r## LOW AVG HIGH ## 0.2967557 0.2977099 0.4055344\r ## high evidence\rmle_jprop \u0026lt;- setFinding(mle_jtree, nodes = \u0026quot;PKA\u0026quot;, states = \u0026quot;HIGH\u0026quot;)\rquerygrain(mle_jprop, nodes = query)\r ## $pmek\r## pmek\r## LOW AVG HIGH ## 0.981418919 0.016891892 0.001689189 ## ## $praf\r## praf\r## LOW AVG HIGH ## 0.83614865 0.13006757 0.03378378 ## ## $p44.42\r## p44.42\r## LOW AVG HIGH ## 0.07263514 0.68918919 0.23817568 ## ## $pakts473\r## pakts473\r## LOW AVG HIGH ## 0.7652027 0.2347973 0.0000000\r PKA inhibits all other nodes. When PKA is HIGH then the LOW probability of all other nodes increases.\nWhen PKA is HIGH, the activity of all the proteins corresponding to the query nodes is inhibited (the LOW probability increases and the HIGH decreases). When PKA is LOW, the opposite is true (the LOW probability decreases and the HIGH increases).\nPart C  Similarly, explore the effects on pjnk of evidence on PIP2, PIP3, and plcg.\n mle_jprop \u0026lt;- setFinding(mle_jtree,\rnodes = c(\u0026quot;PIP2\u0026quot;, \u0026quot;PIP3\u0026quot;, \u0026quot;plcg\u0026quot;),\rstates = rep(\u0026quot;LOW\u0026quot;, 3)\r)\r## baseline query\rquerygrain(mle_jtree, nodes = \u0026quot;pjnk\u0026quot;)\r ## $pjnk\r## pjnk\r## LOW AVG HIGH ## 0.53944444 0.38277778 0.07777778\r ## low evidence\rquerygrain(mle_jprop, nodes = \u0026quot;pjnk\u0026quot;)\r ## $pjnk\r## pjnk\r## LOW AVG HIGH ## 0.53944444 0.38277778 0.07777778\r Turns out pjnk is unaffected by the others. The DAG shown in the answers to exercise Nagarajan 4.1 supports this.\nNagarajan 4.3  Consider the marks data set analyzed in Sect. 2.3.\n data(marks)\r Part A  Learn both the network structure and the parameters with likelihood based approaches, i.e., BIC or AIC, for structure learning and maximum likelihood estimates for the parameters.\n f4.3_dag \u0026lt;- hc(marks, score = \u0026quot;bic-g\u0026quot;)\rf4.3_dag\r ## ## Bayesian network learned via Score-based methods\r## ## model:\r## [MECH][VECT|MECH][ALG|MECH:VECT][ANL|ALG][STAT|ALG:ANL] ## nodes: 5 ## arcs: 6 ## undirected arcs: 0 ## directed arcs: 6 ## average markov blanket size: 2.40 ## average neighbourhood size: 2.40 ## average branching factor: 1.20 ## ## learning algorithm: Hill-Climbing ## score: BIC (Gauss.) ## penalization coefficient: 2.238668 ## tests used in the learning procedure: 34 ## optimized: TRUE\r f4.3_bn \u0026lt;- bn.fit(f4.3_dag, marks)\rf4.3_bn\r ## ## Bayesian network parameters\r## ## Parameters of node MECH (Gaussian distribution)\r## ## Conditional density: MECH\r## Coefficients:\r## (Intercept) ## 38.95455 ## Standard deviation of the residuals: 17.48622 ## ## Parameters of node VECT (Gaussian distribution)\r## ## Conditional density: VECT | MECH\r## Coefficients:\r## (Intercept) MECH ## 34.3828788 0.4160755 ## Standard deviation of the residuals: 11.01373 ## ## Parameters of node ALG (Gaussian distribution)\r## ## Conditional density: ALG | MECH + VECT\r## Coefficients:\r## (Intercept) MECH VECT ## 25.3619809 0.1833755 0.3577122 ## Standard deviation of the residuals: 8.080725 ## ## Parameters of node ANL (Gaussian distribution)\r## ## Conditional density: ANL | ALG\r## Coefficients:\r## (Intercept) ALG ## -3.574130 0.993156 ## Standard deviation of the residuals: 10.50248 ## ## Parameters of node STAT (Gaussian distribution)\r## ## Conditional density: STAT | ALG + ANL\r## Coefficients:\r## (Intercept) ALG ANL ## -11.1920114 0.7653499 0.3164056 ## Standard deviation of the residuals: 12.60646\r Part B  Query the network learned in the previous point for the probability to have the marks for both STAT and MECH above 60, given evidence that the mark for ALG is at most 60. Are the two variables independent given the evidence on ALG?\n cpquery(f4.3_bn, event = (STAT \u0026gt; 60) \u0026amp; (MECH \u0026gt; 60), evidence = (ALG \u0026lt;= 60), n = 1e7)\r ## [1] 0.009562571\r cpquery(f4.3_bn, event = (STAT \u0026gt; 60), evidence = (ALG \u0026lt;= 60), n = 1e7)\r ## [1] 0.08289571\r cpquery(f4.3_bn, event = (MECH \u0026gt; 60), evidence = (ALG \u0026lt;= 60), n = 1e7)\r ## [1] 0.0683385\r The conditional probability of the two outcomes (0.0095912) is not the same as the product of their corresponding marginal probabilities (0.0056668). Conclusively, we can say that STAT and MECH are not independent conditional on ALG.\nPart C  What is the (conditional) probability of having an average vote (in the [60,70] range) in both VECT and MECH while having an outstanding vote in ALG (at least 90)?\n cpquery(f4.3_bn,\revent = ((MECH \u0026gt;= 60) \u0026amp; (MECH \u0026lt;= 70)) | ((VECT \u0026gt;= 60) \u0026amp; (VECT \u0026lt;= 70)),\revidence = (ALG \u0026gt;= 90),\rn = 1e7\r)\r ## [1] 0.2872254\r Nagarajan 4.4  Using the dynamic Bayesian network dbn2 from Sect. 4.3, investigate the effects of genes 257710_at and 255070_at observed at time t-2 on gene 265768_at at time t.\n This is the network in the chapter according to the errata corrige here:\ndata(arth800)\rsubset \u0026lt;- c(60, 141, 260, 333, 365, 424, 441, 512, 521, 578, 789, 799)\rarth12 \u0026lt;- arth800.expr[, subset]\rx \u0026lt;- arth12[1:(nrow(arth12) - 2), ]\ry \u0026lt;- arth12[-(1:2), \u0026quot;265768_at\u0026quot;]\rlambda \u0026lt;- optL1(response = y, penalized = x, trace = FALSE)$lambda\rlasso.t \u0026lt;- penalized(response = y, penalized = x, lambda1 = lambda, trace = FALSE)\ry \u0026lt;- arth12[-(1:2), \u0026quot;245094_at\u0026quot;]\rcolnames(x)[12] \u0026lt;- \u0026quot;245094_at1\u0026quot;\rlambda \u0026lt;- optL1(response = y, penalized = x, trace = FALSE)$lambda\rlasso.s \u0026lt;- penalized(response = y, penalized = x, lambda1 = lambda, trace = FALSE)\r## errate comes in here\rdbn2 \u0026lt;- empty.graph(c(\r\u0026quot;265768_at\u0026quot;, \u0026quot;245094_at1\u0026quot;,\r\u0026quot;258736_at\u0026quot;, \u0026quot;257710_at\u0026quot;, \u0026quot;255070_at\u0026quot;,\r\u0026quot;245319_at\u0026quot;, \u0026quot;245094_at\u0026quot;\r))\rdbn2 \u0026lt;- set.arc(dbn2, \u0026quot;245094_at\u0026quot;, \u0026quot;265768_at\u0026quot;)\rfor (node in names(coef(lasso.s))[-c(1, 6)]) {\rdbn2 \u0026lt;- set.arc(dbn2, node, \u0026quot;245094_at\u0026quot;)\r}\rdbn2 \u0026lt;- set.arc(dbn2, \u0026quot;245094_at1\u0026quot;, \u0026quot;245094_at\u0026quot;)\rdbn2.data \u0026lt;- as.data.frame(x[, nodes(dbn2)[1:6]])\rdbn2.data[, \u0026quot;245094_at\u0026quot;] \u0026lt;- y\rdbn2.data[, \u0026quot;245094_at1\u0026quot;] \u0026lt;- arth12[2:(nrow(arth12) - 1), \u0026quot;245094_at\u0026quot;]\rdbn2.fit \u0026lt;- bn.fit(dbn2, dbn2.data)\r## errata stops here\rdbn2.fit[[\u0026quot;265768_at\u0026quot;]] \u0026lt;- lasso.t\rdbn2.fit[[\u0026quot;245094_at\u0026quot;]] \u0026lt;- lasso.s\r This is the solution to the exercise:\nset.seed(42)\rcpquery(dbn2.fit, event = (`265768_at` \u0026gt; 8), evidence = (`257710_at` \u0026gt; 8))\r ## [1] 0.3590734\r cpquery(dbn2.fit, event = (`265768_at` \u0026gt; 8), evidence = (`255070_at` \u0026gt; 8))\r ## [1] 0.5753049\r cpquery(dbn2.fit, event = (`265768_at` \u0026gt; 8), evidence = TRUE)\r ## [1] 0.4396\r High expression levels of gene 257710_at at time t −2 reduce the probability of high expression levels of gene 265768_at at time t; the opposite is true for gene 255070_at.\nScutari 4.1  Consider the survey data set from Chapter 1.\n The data can be obtained from here:\nsurvey \u0026lt;- read.table(\u0026quot;survey.txt\u0026quot;, header = TRUE, colClasses = \u0026quot;factor\u0026quot;)\r Remember, this is the corresponding DAG we know to be true:\nPart A  Learn a BN with the IAMB algorithm and the asymptotic mutual information test.\n s4.1_dag \u0026lt;- iamb(survey, test = \u0026quot;mi\u0026quot;)\rs4.1_dag\r ## ## Bayesian network learned via Constraint-based methods\r## ## model:\r## [undirected graph]\r## nodes: 6 ## arcs: 4 ## undirected arcs: 4 ## directed arcs: 0 ## average markov blanket size: 1.33 ## average neighbourhood size: 1.33 ## average branching factor: 0.00 ## ## learning algorithm: IAMB ## conditional independence test: Mutual Information (disc.) ## alpha threshold: 0.05 ## tests used in the learning procedure: 85\r Part B  Learn a second BN with IAMB but using only the first 100 observations of the data set. Is there a significant loss of information in the resulting BN compared to the BN learned from the whole data set?\n s4.1_dagB \u0026lt;- iamb(survey[1:1e2, ], test = \u0026quot;mi\u0026quot;)\rs4.1_dagB\r ## ## Bayesian network learned via Constraint-based methods\r## ## model:\r## [undirected graph]\r## nodes: 6 ## arcs: 1 ## undirected arcs: 1 ## directed arcs: 0 ## average markov blanket size: 0.33 ## average neighbourhood size: 0.33 ## average branching factor: 0.00 ## ## learning algorithm: IAMB ## conditional independence test: Mutual Information (disc.) ## alpha threshold: 0.05 ## tests used in the learning procedure: 42\r We discover far fewer arcs!\nPart C  Repeat the structure learning in the previous point with IAMB and the Monte Carlo and sequential Monte Carlo mutual information tests. How do the resulting networks compare with the BN learned with the asymptotic test? Is the increased execution time justified?\n s4.1_dagC_mcmc \u0026lt;- iamb(survey[1:1e2, ], test = \u0026quot;mc-mi\u0026quot;)\rs4.1_dagC_mcmc\r ## ## Bayesian network learned via Constraint-based methods\r## ## model:\r## [undirected graph]\r## nodes: 6 ## arcs: 1 ## undirected arcs: 1 ## directed arcs: 0 ## average markov blanket size: 0.33 ## average neighbourhood size: 0.33 ## average branching factor: 0.00 ## ## learning algorithm: IAMB ## conditional independence test: Mutual Information (disc., MC) ## alpha threshold: 0.05 ## permutations: 5000 ## tests used in the learning procedure: 38\r s4.1_dagC_smc \u0026lt;- iamb(survey[1:1e2, ], test = \u0026quot;smc-mi\u0026quot;)\rs4.1_dagC_smc\r ## ## Bayesian network learned via Constraint-based methods\r## ## model:\r## [undirected graph]\r## nodes: 6 ## arcs: 1 ## undirected arcs: 1 ## directed arcs: 0 ## average markov blanket size: 0.33 ## average neighbourhood size: 0.33 ## average branching factor: 0.00 ## ## learning algorithm: IAMB ## conditional independence test: Mutual Information (disc., Seq. MC) ## alpha threshold: 0.05 ## permutations: 5000 ## tests used in the learning procedure: 38\r We do not discover more arcs, and the outputs of the two asymptotic tests are equal for this case:\nall.equal(s4.1_dagC_mcmc, s4.1_dagC_smc, s4.1_dagB)\r ## [1] TRUE\r Scutari 4.2  Consider again the survey data set from Chapter 1.\n The data can be obtained from here:\nsurvey \u0026lt;- read.table(\u0026quot;survey.txt\u0026quot;, header = TRUE, colClasses = \u0026quot;factor\u0026quot;)\r Part A  Learn a BN using Bayesian posteriors for both structure and parameter learning, in both cases with iss = 5.\n s4.2_dag \u0026lt;- hc(survey, score = \u0026quot;bde\u0026quot;, iss = 5)\rs4.2_bn \u0026lt;- bn.fit(s4.2_dag, survey, method = \u0026quot;bayes\u0026quot;, iss = 5)\rmodelstring(s4.2_bn)\r ## [1] \u0026quot;[R][E|R][T|R][A|E][O|E][S|E]\u0026quot;\r Part B  Repeat structure learning with hc and 3 random restarts and with tabu. How do the BNs differ? Is there any evidence of numerical or convergence problems?\n s4.2_hc \u0026lt;- hc(survey, score = \u0026quot;bde\u0026quot;, iss = 5, restart = 3)\rmodelstring(s4.2_hc)\r ## [1] \u0026quot;[T][R|T][E|R][A|E][O|E][S|E]\u0026quot;\r s4.2_tabu \u0026lt;- tabu(survey, score = \u0026quot;bde\u0026quot;, iss = 5)\rmodelstring(s4.2_tabu)\r ## [1] \u0026quot;[O][S][E|O:S][A|E][R|E][T|R]\u0026quot;\r The Bayesian networks inferred here differ quite substantially in their DAG structures.\nThe random-start hill-climbing algorithm builds a DAG structure closer to the validated structure which is supported by the score:\nscore(s4.2_hc, survey)\r ## [1] -1998.432\r score(s4.2_tabu, survey)\r ## [1] -1999.733\r Part C  Use increasingly large subsets of the survey data to check empirically that BIC and BDe are asymptotically equivalent.\n set.seed(42)\rbreaks \u0026lt;- seq(from = 10, to = 100, by = 10) # percentage of data\ranalysis_df \u0026lt;- data.frame(\rbde = NA,\rbic = NA,\rbreaks = NA\r)\rfor (k in 1:1e3) {\rbde_vec \u0026lt;- c()\rbic_vec \u0026lt;- c()\rfor (i in breaks) {\rsamp \u0026lt;- sample(1:nrow(survey), nrow(survey) / i)\rsamp \u0026lt;- survey[samp, ]\rs4.2_bde \u0026lt;- hc(samp, score = \u0026quot;bde\u0026quot;, iss = 5)\rs4.2_bic \u0026lt;- hc(samp, score = \u0026quot;bic\u0026quot;)\rbde_vec \u0026lt;- c(bde_vec, score(s4.2_bde, survey))\rbic_vec \u0026lt;- c(bic_vec, score(s4.2_bic, survey))\r}\ranalysis_df \u0026lt;- rbind(\ranalysis_df,\rdata.frame(\rbde = bde_vec,\rbic = bic_vec,\rbreaks = breaks\r)\r)\r}\ranalysis_df \u0026lt;- na.omit(analysis_df)\rplot(\rx = analysis_df$breaks,\ry = abs(analysis_df$bde - analysis_df$bic)\r)\r Scutari 4.3  Consider the marks data set from Section 4.7.\n data(marks)\r Part A  Create a bn object describing the graph in the bottom right panel of Figure 4.5 and call it mdag.\n mdag \u0026lt;- model2network(paste0(\r\u0026quot;[ANL][MECH][LAT|ANL:MECH]\u0026quot;,\r\u0026quot;[VECT|LAT][ALG|LAT][STAT|LAT]\u0026quot;\r))\r Part B  Construct the skeleton, the CPDAG and the moral graph of mdag.\n mdag_skel \u0026lt;- skeleton(mdag)\rmdag_cpdag \u0026lt;- cpdag(mdag)\rmdag_moral \u0026lt;- moral(mdag)\r Part C  Discretise the marks data using \u0026ldquo;interval\u0026rdquo; discretisation with 2, 3 and 4 intervals.\n dmarks_2 \u0026lt;- discretize(marks, \u0026quot;interval\u0026quot;, breaks = 2)\rdmarks_3 \u0026lt;- discretize(marks, \u0026quot;interval\u0026quot;, breaks = 3)\rdmarks_4 \u0026lt;- discretize(marks, \u0026quot;interval\u0026quot;, breaks = 4)\r Part D  Perform structure learning with hc on each of the discretised data sets; how do the resulting DAGs differ?\n hc_2 \u0026lt;- hc(dmarks_2)\rmodelstring(hc_2)\r ## [1] \u0026quot;[MECH][VECT|MECH][ALG|VECT][ANL|ALG][STAT|ALG]\u0026quot;\r hc_3 \u0026lt;- hc(dmarks_3)\rmodelstring(hc_3)\r ## [1] \u0026quot;[MECH][ALG|MECH][ANL|ALG][STAT|ALG][VECT|ANL]\u0026quot;\r hc_4 \u0026lt;- hc(dmarks_4)\rmodelstring(hc_4)\r ## [1] \u0026quot;[MECH][VECT][ALG][ANL|ALG][STAT|ANL]\u0026quot;\r Quite evidently, as we increase the number of intervals, we break conditional relationships so much so that fewer arcs are identified.\nSession Info sessionInfo()\r ## R version 4.2.1 (2022-06-23 ucrt)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19044)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_Germany.utf8 LC_CTYPE=English_Germany.utf8 LC_MONETARY=English_Germany.utf8 LC_NUMERIC=C LC_TIME=English_Germany.utf8 ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] penalized_0.9-52 survival_3.4-0 GeneNet_1.2.16 fdrtool_1.2.17 longitudinal_1.1.13 corpcor_1.6.10 gRain_1.3.11 gRbase_1.8.7 bnlearn_4.8.1 ## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.9 highr_0.9 bslib_0.4.0 compiler_4.2.1 BiocManager_1.30.18 jquerylib_0.1.4 R.methodsS3_1.8.2 R.utils_2.12.0 tools_4.2.1 ## [10] digest_0.6.29 jsonlite_1.8.0 evaluate_0.16 R.cache_0.16.0 lattice_0.20-45 pkgconfig_2.0.3 rlang_1.0.5 igraph_1.3.4 Matrix_1.5-1 ## [19] graph_1.74.0 cli_3.3.0 rstudioapi_0.14 Rgraphviz_2.40.0 yaml_2.3.5 parallel_4.2.1 blogdown_1.13 xfun_0.33 fastmap_1.1.0 ## [28] styler_1.8.0 stringr_1.4.1 knitr_1.40 vctrs_0.4.1 sass_0.4.2 stats4_4.2.1 grid_4.2.1 R6_2.5.1 RBGL_1.72.0 ## [37] rmarkdown_2.16 bookdown_0.29 purrr_0.3.4 magrittr_2.0.3 splines_4.2.1 BiocGenerics_0.42.0 htmltools_0.5.3 stringi_1.7.8 cachem_1.0.6 ## [46] R.oo_1.25.0\r ","date":1667865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667934000,"objectID":"c852b0d1263de0e37fee5b5cdc02d356","permalink":"https://www.erikkusch.com/courses/bayes-nets/inference/","publishdate":"2022-11-08T00:00:00Z","relpermalink":"/courses/bayes-nets/inference/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 4 in [Bayesian Networks in R with Applications in Systems Biology](https://link.springer.com/book/10.1007/978-1-4614-6446-4) by by Radhakrishnan Nagarajan, Marco Scutari \\\u0026 Sophie Lèbre and Part 4 in [Bayesian Networks with Examples in R](https://www.bnlearn.com/book-crc/) by M. Scutari and J.-B. Denis.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Bayesian Network Inference","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r\rMaterial  \rDynamic Bayesian Networks by Gregor Mathes (one of our study group members)  Exercises These are answers and solutions to the exercises at the end of chapter 3 in Bayesian Networks in R with Applications in Systems Biology by by Radhakrishnan Nagarajan, Marco Scutari \u0026amp; Sophie Lèbre. Much of my inspiration for these solutions, where necessary, by consulting the solutions provided by the authors themselves as in the appendix.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(vars)\rlibrary(lars)\rlibrary(GeneNet)\rlibrary(G1DBN) # might have to run remotes::install_version(\u0026quot;G1DBN\u0026quot;, \u0026quot;3.1.1\u0026quot;) first\r Nagarajan 3.1  Consider the Canada data set from the vars package, which we analyzed in Sect. 3.5.1.\n data(Canada)\r Part A  Load the data set from the vars package and investigate its properties using the exploratory analysis techniques covered in Chap. 1.\n str(Canada)\r ## Time-Series [1:84, 1:4] from 1980 to 2001: 930 930 930 931 933 ...\r## - attr(*, \u0026quot;dimnames\u0026quot;)=List of 2\r## ..$ : NULL\r## ..$ : chr [1:4] \u0026quot;e\u0026quot; \u0026quot;prod\u0026quot; \u0026quot;rw\u0026quot; \u0026quot;U\u0026quot;\r summary(Canada)\r ## e prod rw U ## Min. :928.6 Min. :401.3 Min. :386.1 Min. : 6.700 ## 1st Qu.:935.4 1st Qu.:404.8 1st Qu.:423.9 1st Qu.: 7.782 ## Median :946.0 Median :406.5 Median :444.4 Median : 9.450 ## Mean :944.3 Mean :407.8 Mean :440.8 Mean : 9.321 ## 3rd Qu.:950.0 3rd Qu.:410.7 3rd Qu.:461.1 3rd Qu.:10.607 ## Max. :961.8 Max. :418.0 Max. :470.0 Max. :12.770\r Part B  Estimate a VAR(1) process for this data set.\n (var1 \u0026lt;- VAR(Canada, p = 1, type = \u0026quot;const\u0026quot;))\r ## ## VAR Estimation Results:\r## ======================= ## ## Estimated coefficients for equation e: ## ====================================== ## Call:\r## e = e.l1 + prod.l1 + rw.l1 + U.l1 + const ## ## e.l1 prod.l1 rw.l1 U.l1 const ## 1.17353629 0.14479389 -0.07904568 0.52438144 -192.56360758 ## ## ## Estimated coefficients for equation prod: ## ========================================= ## Call:\r## prod = e.l1 + prod.l1 + rw.l1 + U.l1 + const ## ## e.l1 prod.l1 rw.l1 U.l1 const ## 0.08709510 1.01970070 -0.02629309 0.32299246 -81.55109611 ## ## ## Estimated coefficients for equation rw: ## ======================================= ## Call:\r## rw = e.l1 + prod.l1 + rw.l1 + U.l1 + const ## ## e.l1 prod.l1 rw.l1 U.l1 const ## 0.06381103 -0.13551199 0.96872851 -0.19538479 11.61375726 ## ## ## Estimated coefficients for equation U: ## ====================================== ## Call:\r## U = e.l1 + prod.l1 + rw.l1 + U.l1 + const ## ## e.l1 prod.l1 rw.l1 U.l1 const ## -0.19293575 -0.08086896 0.07538624 0.47530976 186.80892410\r Part C  Build the auto-regressive matrix $A$ and the constant matrix $B$ defining the VAR(1) model.\n ## base object creation\rbase_mat \u0026lt;- matrix(0, 4, 5)\rcolnames(base_mat) \u0026lt;- c(\u0026quot;e\u0026quot;, \u0026quot;prod\u0026quot;, \u0026quot;rw\u0026quot;, \u0026quot;U\u0026quot;, \u0026quot;constant\u0026quot;)\rp \u0026lt;- 0.05\r## object filling\rpos \u0026lt;- which(coef(var1)$e[, \u0026quot;Pr(\u0026gt;|t|)\u0026quot;] \u0026lt; p)\rbase_mat[1, pos] \u0026lt;- coef(var1)$e[pos, \u0026quot;Estimate\u0026quot;]\rpos \u0026lt;- which(coef(var1)$prod[, \u0026quot;Pr(\u0026gt;|t|)\u0026quot;] \u0026lt; p)\rbase_mat[2, pos] \u0026lt;- coef(var1)$prod[pos, \u0026quot;Estimate\u0026quot;]\rpos \u0026lt;- which(coef(var1)$rw[, \u0026quot;Pr(\u0026gt;|t|)\u0026quot;] \u0026lt; p)\rbase_mat[3, pos] \u0026lt;- coef(var1)$rw[pos, \u0026quot;Estimate\u0026quot;]\rpos \u0026lt;- which(coef(var1)$U[, \u0026quot;Pr(\u0026gt;|t|)\u0026quot;] \u0026lt; p)\rbase_mat[4, pos] \u0026lt;- coef(var1)$U[pos, \u0026quot;Estimate\u0026quot;]\r## final objects\r(A \u0026lt;- base_mat[, 1:4])\r ## e prod rw U\r## [1,] 1.1735363 0.14479389 -0.07904568 0.5243814\r## [2,] 0.0000000 1.01970070 0.00000000 0.0000000\r## [3,] 0.0000000 -0.13551199 0.96872851 0.0000000\r## [4,] -0.1929358 -0.08086896 0.07538624 0.4753098\r (B \u0026lt;- base_mat[, 5])\r ## [1] -192.5636 0.0000 0.0000 186.8089\r Part D  Compare the results with the LASSO matrix when estimating the L1-penalty with cross-validation.\n ## data preparation\rdata_df \u0026lt;- Canada[-nrow(Canada), ] # remove last row of data\r## Lasso\rLasso_ls \u0026lt;- lapply(colnames(Canada), function(gene) {\ry \u0026lt;- Canada[-1, gene] # remove first row of data, and select only target gene\rlars(y = y, x = data_df, type = \u0026quot;lasso\u0026quot;) # LASSO matrix\r})\r## Cross-validation\rCV_ls \u0026lt;- lapply(1:ncol(Canada), function(gene) {\ry \u0026lt;- Canada[-1, gene] # remove first row of data, and select only target gene\rlasso.cv \u0026lt;- cv.lars(y = y, x = data_df, mode = \u0026quot;fraction\u0026quot;)\rfrac \u0026lt;- lasso.cv$index[which.min(lasso.cv$cv)]\rpredict(Lasso_ls[[gene]], s = frac, type = \u0026quot;coef\u0026quot;, mode = \u0026quot;fraction\u0026quot;)\r})\r## output\rrbind(\rCV_ls[[1]]$coefficients,\rCV_ls[[2]]$coefficients,\rCV_ls[[3]]$coefficients,\rCV_ls[[4]]$coefficients\r)\r ## e prod rw U\r## [1,] 1.17353629 0.14479389 -0.079045685 0.5243814\r## [2,] 0.02570001 1.02314558 -0.004878295 0.1994059\r## [3,] 0.09749788 -0.11991692 0.954389035 -0.1023845\r## [4,] -0.17604953 -0.08192783 0.069502065 0.5086115\r And for comparison the previously identified $A$:\nA\r ## e prod rw U\r## [1,] 1.1735363 0.14479389 -0.07904568 0.5243814\r## [2,] 0.0000000 1.01970070 0.00000000 0.0000000\r## [3,] 0.0000000 -0.13551199 0.96872851 0.0000000\r## [4,] -0.1929358 -0.08086896 0.07538624 0.4753098\r Part E  What can you conclude?\n The whole point of LASSO, as far as I understand it, is to shrink parameter estimates towards 0 often times reaching 0 exactly. In the above this has not happened for many parameters, but is the case with the estimation provided by vars. I assume this might be because there just aren\u0026rsquo;t enough variables and/or observations in time.\nNagarajan 3.2  Consider the arth800 data set from the GeneNet package, which we analyzed in Sects. 3.5.2 and 3.5.3.\n data(arth800)\rdata(arth800.expr)\r Part A  Load the data set from the GeneNet package. The time series expression of the 800 genes is included in a data set called arth800.expr. Investigate its properties using the exploratory analysis techniques covered in Chap. 1.\n str(arth800.expr)\r ## 'longitudinal' num [1:22, 1:800] 10.04 10.11 9.77 10.06 10.02 ...\r## - attr(*, \u0026quot;dimnames\u0026quot;)=List of 2\r## ..$ : chr [1:22] \u0026quot;0-1\u0026quot; \u0026quot;0-2\u0026quot; \u0026quot;1-1\u0026quot; \u0026quot;1-2\u0026quot; ...\r## ..$ : chr [1:800] \u0026quot;AFFX-Athal-GAPDH_3_s_at\u0026quot; \u0026quot;AFFX-Athal-Actin_3_f_at\u0026quot; \u0026quot;267612_at\u0026quot; \u0026quot;267520_at\u0026quot; ...\r## - attr(*, \u0026quot;time\u0026quot;)= num [1:11] 0 1 2 4 8 12 13 14 16 20 ...\r## - attr(*, \u0026quot;repeats\u0026quot;)= num [1:11] 2 2 2 2 2 2 2 2 2 2 ...\r summary(arth800.expr)\r ## Longitudinal data:\r## 800 variables measured at 11 different time points\r## Total number of measurements per variable: 22 ## Repeated measurements: yes ## ## To obtain the measurement design call 'get.time.repeats()'.\r Part B  For this practical exercise, we will work on a subset of variables (one for each gene) having a large variance. Compute the variance of each of the 800 variables, plot the various variance values in decreasing order, and create a data set with the variables greater than 2.\n ## variance calculation\rvariance \u0026lt;- diag(var(arth800.expr))\r## plotting\rplot(sort(variance, decreasing = TRUE), type = \u0026quot;l\u0026quot;, ylab = \u0026quot;Variance\u0026quot;)\rabline(h = 2, lty = 2)\r ## variables with variances greater than 2\rdataVar2 \u0026lt;- arth800.expr[, which(variance \u0026gt; 2)]\rdim(dataVar2)\r ## [1] 22 49\r Part C  Can you fit a VAR process with a usual approach from this data set?\n I don\u0026rsquo;t think so. There are more variables (genes) than there are samples (time steps):\ndim(dataVar2)\r ## [1] 22 49\r Part D  Which alternative approaches can be used to fit a VAR process from this data set?\n The chapter discusses these alternatives:\n LASSO James-Stein Shrinkage Low-order conditional dependency approximation  Part E  Estimate a dynamic Bayesian network with each of the alternative approaches presented in this chapter.\n First, I prepare the data by re-ordering them:\n## make the data sequential for both repetitions\rdataVar2seq \u0026lt;- dataVar2[c(seq(1, 22, by = 2), seq(2, 22, by = 2)), ]\r LASSO with the lars package:\nx \u0026lt;- dataVar2seq[-c(21:22), ] # remove final rows (end of sequences)\rLasso_ls \u0026lt;- lapply(colnames(dataVar2seq), function(gene) {\ry \u0026lt;- dataVar2seq[-(1:2), gene]\rlars(y = y, x = x, type = \u0026quot;lasso\u0026quot;)\r})\rCV_ls \u0026lt;- lapply(1:ncol(dataVar2seq), function(gene) {\ry \u0026lt;- dataVar2seq[-(1:2), gene]\rlasso.cv \u0026lt;- cv.lars(y = y, x = x, mode = \u0026quot;fraction\u0026quot;, plot.it = FALSE)\rfrac \u0026lt;- lasso.cv$index[which.min(lasso.cv$cv)]\rpredict(Lasso_ls[[gene]], s = frac, type = \u0026quot;coef\u0026quot;, mode = \u0026quot;fraction\u0026quot;)\r})\rLasso_mat \u0026lt;- matrix(0, dim(dataVar2seq)[2], dim(dataVar2seq)[2])\rfor (i in 1:dim(Lasso_mat)[1]) {\rLasso_mat[i, ] \u0026lt;- CV_ls[i][[1]]$coefficients\r}\rsum(Lasso_mat != 0) # number of arcs\r ## [1] 456\r plot(sort(abs(Lasso_mat), decr = TRUE)[1:500], type = \u0026quot;l\u0026quot;, ylab = \u0026quot;Absolute coefficients\u0026quot;)\r James-Stein shrinkage with the GeneNet package:\nDBNGeneNet \u0026lt;- ggm.estimate.pcor(dataVar2, method = \u0026quot;dynamic\u0026quot;)\r ## Estimating optimal shrinkage intensity lambda (correlation matrix): 0.0539\r DBNGeneNet.edges \u0026lt;- network.test.edges(DBNGeneNet) # p-values, q-values and posterior probabilities for each potential arc\r ## Estimate (local) false discovery rates (partial correlations):\r## Step 1... determine cutoff point\r## Step 2... estimate parameters of null distribution and eta0\r## Step 3... compute p-values and estimate empirical PDF/CDF\r## Step 4... compute q-values and local fdr\r## Step 5... prepare for plotting\r plot(DBNGeneNet.edges[, \u0026quot;prob\u0026quot;], type = \u0026quot;l\u0026quot;) # arcs probability by decreasing order\r sum(DBNGeneNet.edges$prob \u0026gt; 0.95) # arcs with prob \u0026gt; 0.95\r ## [1] 8\r First-order conditional dependency with the G1DBN package:\nG1DB_BN \u0026lt;- DBNScoreStep1(dataVar2seq, method = \u0026quot;ls\u0026quot;)\r ## Treating 49 vertices:\r## 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%\r G1DB_BN \u0026lt;- DBNScoreStep2(G1DB_BN$S1ls, dataVar2seq, method = \u0026quot;ls\u0026quot;, alpha1 = 0.5)\rplot(sort(G1DB_BN, decreasing = TRUE), type = \u0026quot;l\u0026quot;, ylab = \u0026quot;Arcs’ p-values\u0026quot;)\r Nagarajan 3.3  Consider the dimension reduction approaches used in the previous exercise and the arth800 data set from the GeneNet package.\n data(arth800)\rdata(arth800.expr)\r Part A  For a comparative analysis of the different approaches, select the top 50 arcs for each approach (function BuildEdges from the G1DBN package can be used to that end).\n LASSO\nlasso_tresh \u0026lt;- mean(sort(abs(Lasso_mat), decreasing = TRUE)[50:51]) # Lasso_mat from exercise 3.2\rlasso_50 \u0026lt;- BuildEdges(score = -abs(Lasso_mat), threshold = -lasso_tresh)\r James-Stein shrinkage with the GeneNet package:\nDBNGeneNet_50 \u0026lt;- cbind(DBNGeneNet.edges[1:50, \u0026quot;node1\u0026quot;], DBNGeneNet.edges[1:50, \u0026quot;node2\u0026quot;])\r First-order conditional dependency with the G1DBN package:\nG1DBN_tresh \u0026lt;- mean(sort(G1DB_BN)[50:51])\rG1DBN.edges \u0026lt;- BuildEdges(score = G1DB_BN, threshold = G1DBN_tresh, prec = 3)\r Part B  Plot the four inferred networks with the function plot from package G1DBN.\n Four inferred networks? I assume the exercise so far wanted me to also analyse the data using the LASSO approach with the SIMoNe (simone) package. I will skip over that one and continue with the three I have:\npar(mfrow = c(1, 3))\r## LASSO\rLASSO_plot \u0026lt;- graph.edgelist(cbind(lasso_50[, 1], lasso_50[, 2]))\rLasso_layout \u0026lt;- layout.fruchterman.reingold(LASSO_plot)\rplot(LASSO_plot,\rlayout = Lasso_layout,\redge.arrow.size = 0.5, vertex.size = 10,\rmain = \u0026quot;LASSO\u0026quot;\r)\r## James-Stein\rDBN_plot \u0026lt;- graph.edgelist(DBNGeneNet_50)\r# DBN_layout \u0026lt;- layout.fruchterman.reingold(DBN_plot)\rplot(DBN_plot,\rlayout = Lasso_layout,\redge.arrow.size = 0.5, vertex.size = 10,\rmain = \u0026quot;GeneNet\u0026quot;\r)\r## First-order conditional\rG1DBN_plot \u0026lt;- graph.edgelist(cbind(G1DBN.edges[, 1], G1DBN.edges[, 2]))\r# G1DBN_layout = layout.fruchterman.reingold(G1DBN_plot)\rplot(G1DBN_plot,\rlayout = Lasso_layout,\redge.arrow.size = 0.5, vertex.size = 10,\rmain = \u0026quot;G1DBN\u0026quot;\r)\r Part C  How many arcs are common to the four inferred networks?\n ## extract edges\rLASSO_el \u0026lt;- as_edgelist(LASSO_plot)\rDBN_el \u0026lt;- as_edgelist(DBN_plot)\rG1DBN_el \u0026lt;- as_edgelist(G1DBN_plot)\r## number of repeated edges in pairwise comparisons\rsum(duplicated(rbind(LASSO_el, DBN_el)))\r ## [1] 0\r sum(duplicated(rbind(LASSO_el, G1DBN_el)))\r ## [1] 6\r sum(duplicated(rbind(DBN_el, G1DBN_el)))\r ## [1] 1\r ### all at once\rsum(duplicated(rbind(LASSO_el, DBN_el, G1DBN_el)))\r ## [1] 7\r Part D  Are the top 50 arcs of each inferred network similar? What can you conclude?\n No, they are not. I can conclude that different dimension reductions produce different DAG structures.\nSession Info sessionInfo()\r ## R version 4.2.1 (2022-06-23 ucrt)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19044)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_Germany.utf8 LC_CTYPE=English_Germany.utf8 LC_MONETARY=English_Germany.utf8 LC_NUMERIC=C LC_TIME=English_Germany.utf8 ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] G1DBN_3.1.1 igraph_1.3.4 GeneNet_1.2.16 fdrtool_1.2.17 longitudinal_1.1.13 corpcor_1.6.10 lars_1.3 vars_1.5-6 lmtest_0.9-40 ## [10] urca_1.3-3 strucchange_1.5-3 sandwich_3.0-2 zoo_1.8-10 MASS_7.3-58.1 ## ## loaded via a namespace (and not attached):\r## [1] highr_0.9 bslib_0.4.0 compiler_4.2.1 jquerylib_0.1.4 R.methodsS3_1.8.2 R.utils_2.12.0 tools_4.2.1 digest_0.6.29 jsonlite_1.8.0 evaluate_0.16 ## [11] nlme_3.1-159 R.cache_0.16.0 lattice_0.20-45 pkgconfig_2.0.3 rlang_1.0.5 cli_3.3.0 rstudioapi_0.14 yaml_2.3.5 blogdown_1.13 xfun_0.33 ## [21] fastmap_1.1.0 styler_1.8.0 stringr_1.4.1 knitr_1.40 vctrs_0.4.1 sass_0.4.2 grid_4.2.1 R6_2.5.1 rmarkdown_2.16 bookdown_0.29 ## [31] purrr_0.3.4 magrittr_2.0.3 htmltools_0.5.3 stringi_1.7.8 cachem_1.0.6 R.oo_1.25.0\r ","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667329200,"objectID":"602a3c41fca49c268b9e6d6632ef83d4","permalink":"https://www.erikkusch.com/courses/bayes-nets/dynamic/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/courses/bayes-nets/dynamic/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 3 in [Bayesian Networks in R with Applications in Systems Biology](https://link.springer.com/book/10.1007/978-1-4614-6446-4) by by Radhakrishnan Nagarajan, Marco Scutari \\\u0026 Sophie Lèbre.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Dynamic Bayesian Networks","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r This session of our study group did not include any practical material. For the summary of the theory discussed in this session, please refer to the slides linked below.\nMaterial  \rIntroduction  ","date":1663027200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663095600,"objectID":"90a8a9a528614fd79cdc64345e6790da","permalink":"https://www.erikkusch.com/courses/bayes-nets/introduction/","publishdate":"2022-09-13T00:00:00Z","relpermalink":"/courses/bayes-nets/introduction/","section":"courses","summary":"This is a brief summary of basal knowledge for Bayesian Networks.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Graph Theory \u0026 Bayes","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"Climate Reanalyses Climate reanalyses are the go-to data products for climate scientists and represent the best-in-class approximations of climate characteristics across the Earth.\nThe accuracy of climate reanalyses is largely owed to the number of observations assimilated, the underlying dynamical model, and the data assimilation methodology. Furthermore, climate reanalyses offer access to a vast array of Essential Climate Variables (ECVs) at unparalleled temporal resolutions. Lastly, as reanalyses are created from multiple models (i.e. ensembles), we can obtain data uncertainty for each data record.\nTo our mind, this makes climate reanalyses the gold standard in climate data products for use in macroecological analyses.\nPlease have a look at this presentation for an introduction to climate science: \nThe KrigR Package The KrigR package has been designed to overcome the major stop-gaps in integrating climate reanalyses data into our research frameworks:\n Accessing, downloading, and processing of climate reanalysis data Matching spatial resolutions which downstream applications have become used to  For an introduction to KrigR in presentation form, please have a look at this material: \n","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"efeff5cc6440e1613536e63b3a42dbaf","permalink":"https://www.erikkusch.com/courses/krigr/background/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/background/","section":"courses","summary":"Introduction to the theory and considerations of climate reanalyses and statistical downscaling applications.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"The Theory Behind KrigR","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r\rMaterial  \rMultinomial Bayesian Networks  Exercises These are answers and solutions to the exercises at the end of Part 1 in Bayesian Networks with Examples in R by M. Scutari and J.-B. Denis. I have created these notes as a part of a study-partnership with Frederik Kallesøe. Much of my inspiration for these solutions, where necessary, has been obtained either from chatting with Frederik or by consulting the solutions provided by the authors themselves as in the appendix.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(bnlearn)\rlibrary(gRain)\rlibrary(ggplot2)\rlibrary(lattice)\rlibrary(gridExtra)\r Scutari 1.1  Consider the DAG for the survey studied in this chapter and shown in Figure 1.1.\n Here\u0026rsquo;s the DAG in question:\nPart 1.  List the parents and the children of each node.\n    Node Parent(s) Child(ren)     Age (A) { } E   Sex (S) { } E   Education (E) A, S O, R   Occupation (O) E E   Residence (R) E E   Travel (T) O, R { }    Part 2.  List all the fundamental connections present in the DAG, and classify them as either serial, divergent or convergent.\n Fundamental connections are those paths who contain three vertices/nodes. In directed graphs, they can be classified into three different categories depending on flow of dependencies.\n   Path Classification     A → E ← S Convergent   A → E → O Serial   A → E → R Serial   S → E → O Serial   S → E → R Serial   O ← E → R Divergent   E → O → T Serial   E → R → T Serial   O → T ← R Convergent    Part 3.  Add an arc from Age to Occupation, and another arc from Travel to Education. Is the resulting graph still a valid BN? If not, why?\n Let\u0026rsquo;s take this one arc at a time:\n A → O. Adding this arc does not lead to the introduction of any cycles and so the Bayesian Network (BN) remains valid. I have added this graph to the figure from the book and highlighted it in green just below. T → E. Adding this arc does introduce cyclic paths along T → E → R → T and T → E → O → T thus resulting in a non-valid BN. I have highlighted the added arc in red and shaded the cyclic paths in orange below.  Scutari 1.2  Consider the probability distribution from the survey in Section 1.3.\n The data can be obtained from here:\nsurvey \u0026lt;- read.table(\u0026quot;survey.txt\u0026quot;, header = TRUE, colClasses = \u0026quot;factor\u0026quot;)\rA.lv \u0026lt;- c(\u0026quot;young\u0026quot;, \u0026quot;adult\u0026quot;, \u0026quot;old\u0026quot;)\rS.lv \u0026lt;- c(\u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;)\rE.lv \u0026lt;- c(\u0026quot;high\u0026quot;, \u0026quot;uni\u0026quot;)\rO.lv \u0026lt;- c(\u0026quot;emp\u0026quot;, \u0026quot;self\u0026quot;)\rR.lv \u0026lt;- c(\u0026quot;small\u0026quot;, \u0026quot;big\u0026quot;)\rT.lv \u0026lt;- c(\u0026quot;car\u0026quot;, \u0026quot;train\u0026quot;, \u0026quot;other\u0026quot;)\r Part 1.  Compute the number of configurations of the parents of each node.\n A and S have no parents (refer back to the DAG in exercise 1.1). Therefore, we are only interested in the configurations of parental nodes for E, O, R, and T:\n(E \u0026lt;- length(A.lv) * length(S.lv))\r ## [1] 6\r (O \u0026lt;- length(E.lv))\r ## [1] 2\r (R \u0026lt;- length(E.lv))\r ## [1] 2\r (T \u0026lt;- length(O.lv) * length(R.lv))\r ## [1] 4\r This is a simple exercise of combinatorics. The number of parental configurations is simply the number of states each parental node can be in multiplied by the same for all other parental nodes.\nPart 2.  Compute the number of parameters of the local distributions.\n All of this comes down to how many parameters we need to estimate to accurately represent the probability distributions belonging to each node in our DAG. Since all probabilities per node sum up to 1, we effectively only ever need to estimate a number $n-1$ parameters for each node with $n$ being the number of states said node can be in. Let\u0026rsquo;s walk through this.\nA has 3 states, so need to estimate 2 parameters ($p_A = 2$). S has 2 states hence we need 1 parameter for this node ($p_S = 1$).\nNow we arrive at E and things get more complicated. The probability distribution for E comes in two parts - one for \u0026quot;high\u0026quot; and one for \u0026quot;low\u0026quot; education level. Both of these contain additional probability distributions of combinations of the levels of S and A. To obtain the number of parameters needed to describe this 3-dimensional distribution, we can simply calculate $p_E = n_S * n_A * (n_E-1) = 2 * 3 * 1 = 6$.\nMoving on to O and R. Both of these need 2 parameters ($p_O = p_r = 2$) because of their two-dimensional distributions being made up of two levels of education and two levels occupation and residency respectively ($2 * (2-1) = 2$).\nLastly, we arrive at T which we need 8 parameters for ($p_T = 8$). Holy smokes. Why? Basically, this is a repeat of what we did for E. We have a three-dimensional distribution with three levels in T-Space, two levels in-space, and two more levels in O-Space. To arrive at the number of parameters we simply do $p_T = (n_T-1) * n_o * n_R = 2 * 2 * 2 = 8$.\nPart 3.  Compute the number of parameters of the global distribution.\n We can sum all of the local parameters up to arrive at $p_{total} = p_A + p_S + p_E + p_O + p_R + p_T = 2+1+6+2+2+8 = 21$.\nAnd in R:\n# define DAG structure\rdag \u0026lt;- model2network(\u0026quot;[A][S][E|A:S][O|E][R|E][T|O:R]\u0026quot;)\r# define local distributions\rA.prob \u0026lt;- array(c(0.30, 0.50, 0.20), dim = 3, dimnames = list(A = A.lv))\rS.prob \u0026lt;- array(c(0.60, 0.40), dim = 2, dimnames = list(S = S.lv))\rE.prob \u0026lt;- array(\rc(\r0.75, 0.25, 0.72, 0.28, 0.88, 0.12, 0.64, 0.36, 0.70,\r0.30, 0.90, 0.10\r),\rdim = c(2, 3, 2),\rdimnames = list(E = E.lv, A = A.lv, S = S.lv)\r)\rO.prob \u0026lt;- array(c(0.96, 0.04, 0.92, 0.08),\rdim = c(2, 2),\rdimnames = list(O = O.lv, E = E.lv)\r)\rR.prob \u0026lt;- array(c(0.25, 0.75, 0.20, 0.80),\rdim = c(2, 2),\rdimnames = list(R = R.lv, E = E.lv)\r)\rT.prob \u0026lt;- array(\rc(\r0.48, 0.42, 0.10, 0.56, 0.36, 0.08, 0.58, 0.24, 0.18,\r0.70, 0.21, 0.09\r),\rdim = c(3, 2, 2),\rdimnames = list(T = T.lv, O = O.lv, R = R.lv)\r)\r# define set of local distributions\rcpt \u0026lt;- list(\rA = A.prob, S = S.prob, E = E.prob, O = O.prob,\rR = R.prob, T = T.prob\r)\r# create BN\rbn \u0026lt;- custom.fit(dag, cpt)\r# obtain parameters\rnparams(bn)\r ## [1] 21\r Note that I pulled the probabilities for the distributions from the book and their values are irrelevant to the number of parameters.\nPart 4.  Add an arc from Education to Travel. Recompute the factorisation into local distributions shown in Equation (1.1). How does the number of parameters of each local distribution change?\n Adding E → T to Equation (1.1) results in: $$P(A, S, E, O, R, T) = P(A) P(S) P(E | A, S) P(O | E) P(R | E) P(T | E, O, R)$$\nNow that T is dependant on E as well as the previous parents, the number of free parameters of the local distribution of T increases to 16 ($p_E = 16$). This is because our local distribution of T is now four-dimensional resulting in $p_T = (n_T-1) * n_o * n_R * n_E = 2 * 2 * 2 * 2 = 16$.\nAll other local distributions remain the same.\nScutari 1.3  Consider again the DAG for the survey.\n Part 1.  Create an object of class bn for the DAG.\n Here\u0026rsquo;s the simplest way of doing this by specifying the model string:\n# define DAG structure\rbn \u0026lt;- model2network(\u0026quot;[A][S][E|A:S][O|E][R|E][T|O:R]\u0026quot;)\r Part 2.  Use the functions in bnlearn and the R object created in the previous point to extract the nodes and the arcs of the DAG. Also extract the parents and the children of each node.\n Here we go:\nnodes(bn)\r ## [1] \u0026quot;A\u0026quot; \u0026quot;E\u0026quot; \u0026quot;O\u0026quot; \u0026quot;R\u0026quot; \u0026quot;S\u0026quot; \u0026quot;T\u0026quot;\r arcs(bn)\r ## from to ## [1,] \u0026quot;A\u0026quot; \u0026quot;E\u0026quot;\r## [2,] \u0026quot;S\u0026quot; \u0026quot;E\u0026quot;\r## [3,] \u0026quot;E\u0026quot; \u0026quot;O\u0026quot;\r## [4,] \u0026quot;E\u0026quot; \u0026quot;R\u0026quot;\r## [5,] \u0026quot;O\u0026quot; \u0026quot;T\u0026quot;\r## [6,] \u0026quot;R\u0026quot; \u0026quot;T\u0026quot;\r sapply(X = nodes(bn), FUN = bnlearn::parents, x = bn)\r ## $A\r## character(0)\r## ## $E\r## [1] \u0026quot;A\u0026quot; \u0026quot;S\u0026quot;\r## ## $O\r## [1] \u0026quot;E\u0026quot;\r## ## $R\r## [1] \u0026quot;E\u0026quot;\r## ## $S\r## character(0)\r## ## $T\r## [1] \u0026quot;O\u0026quot; \u0026quot;R\u0026quot;\r sapply(X = nodes(bn), FUN = bnlearn::children, x = bn)\r ## $A\r## [1] \u0026quot;E\u0026quot;\r## ## $E\r## [1] \u0026quot;O\u0026quot; \u0026quot;R\u0026quot;\r## ## $O\r## [1] \u0026quot;T\u0026quot;\r## ## $R\r## [1] \u0026quot;T\u0026quot;\r## ## $S\r## [1] \u0026quot;E\u0026quot;\r## ## $T\r## character(0)\r Part 3.  Print the model formula from bn.\n modelstring(bn)\r ## [1] \u0026quot;[A][S][E|A:S][O|E][R|E][T|O:R]\u0026quot;\r Part 4.  Fit the parameters of the network from the data stored in survey.txt using their Bayesian estimators and save the result into an object of class bn.fit.\n bn_full \u0026lt;- bn.fit(bn, data = survey, method = \u0026quot;bayes\u0026quot;, iss = 10)\rclass(bn_full)\r ## [1] \u0026quot;bn.fit\u0026quot; \u0026quot;bn.fit.dnet\u0026quot;\r Part 5.  Remove the arc from Education to Occupation.\n bn_sparse \u0026lt;- drop.arc(bn, from = \u0026quot;E\u0026quot;, to = \u0026quot;O\u0026quot;)\r Part 6.  Fit the parameters of the modified network. Which local distributions change, and how?\n bn_sparse \u0026lt;- bn.fit(bn_sparse, data = survey, method = \u0026quot;bayes\u0026quot;, iss = 10)\r We already now that the only local distribution which should change is that of O. Let\u0026rsquo;s check that:\ndim(coef(bn_full$O))\r ## [1] 2 2\r dim(coef(bn_sparse$O))\r ## [1] 2\r Quite evidently, the local distribution of O has become much simpler in our sparse Bayesian Network. Why? Because it has no parent node now which would parse additional information and complexity onto it.\nScutari 1.4  Re-create the bn.mle object used in Section 1.4.\n bn.mle \u0026lt;- bn.fit(dag, data = survey, method = \u0026quot;mle\u0026quot;)\r Part 1.  Compare the distribution of Occupation conditional on Age with the corresponding marginal distribution using querygrain.\n ## creating object ready for gRain functions\rjunction \u0026lt;- compile(as.grain(bn.mle))\r## Overall query\rquery_over \u0026lt;- querygrain(junction, nodes = \u0026quot;O\u0026quot;)$O\r## Marginal query when A is young\rjage \u0026lt;- setEvidence(junction, \u0026quot;A\u0026quot;, states = \u0026quot;young\u0026quot;)\rquery_young \u0026lt;- querygrain(jage, nodes = \u0026quot;O\u0026quot;)$O\r## Marginal query when A is adult\rjage \u0026lt;- setEvidence(junction, \u0026quot;A\u0026quot;, states = \u0026quot;adult\u0026quot;)\rquery_adult \u0026lt;- querygrain(jage, nodes = \u0026quot;O\u0026quot;)$O\r## Marginal query when A is old\rjage \u0026lt;- setEvidence(junction, \u0026quot;A\u0026quot;, states = \u0026quot;old\u0026quot;)\rquery_old \u0026lt;- querygrain(jage, nodes = \u0026quot;O\u0026quot;)$O\r## Combining queries\rqueries_df \u0026lt;- rbind(query_over, query_young, query_adult, query_old)\rrownames(queries_df) \u0026lt;- c(\u0026quot;Overall\u0026quot;, \u0026quot;Young\u0026quot;, \u0026quot;Adult\u0026quot;, \u0026quot;Old\u0026quot;)\rqueries_df\r ## emp self\r## Overall 0.9660248 0.03397517\r## Young 0.9644166 0.03558340\r## Adult 0.9636485 0.03635151\r## Old 0.9738915 0.02610849\r As we can see, conditioning on A does not influence the distribution of O that much.\nPart 2.  How many random observations are needed for cpquery to produce estimates of the parameters of these two distributions with a precision of ±0.01?\n I find this question to be difficult to understand. What I assume I am tasked with is to compare the distribution of Occupation conditional on Age (query_over: 0.97, 0.03) with the estimates produced by cpquery given some evidence (i.e. parental node configuration). This would mean comparing each query EXCEPT for query_over to it\u0026rsquo;s counterpart with cpquery(). That\u0026rsquo;s a tad excessive, and so I only compare query_young (0.96, 0.04) from above with the results obtained by cpquery(). What I am looking at is: \u0026ldquo;How high do my sample sizes have to be in cpquery() to be within a ±0.01 margin of query_young.\nLuckily, query_young only has two values and so I can tell cpquery() to only compute one of them as the other follows logically by subtracting the former from 1.\nHere, I want to test this for likelihood weighting (lw) and logic sampling (ls):\n# create test list and test sequence\rprecis_ls \u0026lt;- as.list(c(0, 0))\rnames(precis_ls) \u0026lt;- c(\u0026quot;LW\u0026quot;, \u0026quot;LS\u0026quot;)\rn_seq \u0026lt;- as.integer(seq(from = 1e2, to = 1e5, length.out = 1e2))\r# iterate over our sample sizes\rfor (i in n_seq) {\rprecis_ls$LW \u0026lt;- c(\rprecis_ls$LW,\rcpquery(bn.mle, event = (O == \u0026quot;emp\u0026quot;), evidence = list(A = \u0026quot;young\u0026quot;), method = \u0026quot;lw\u0026quot;, n = i)\r)\rprecis_ls$LS \u0026lt;- c(\rprecis_ls$LS,\rcpquery(bn.mle, event = (O == \u0026quot;emp\u0026quot;), evidence = (A == \u0026quot;young\u0026quot;), method = \u0026quot;ls\u0026quot;, n = i)\r)\r}\r# remove first positions which were blanks\rprecis_ls$LW \u0026lt;- precis_ls$LW[-1]\rprecis_ls$LS \u0026lt;- precis_ls$LS[-1]\r# plotting the results\rplot_df \u0026lt;- data.frame(\rN = c(n_seq, n_seq),\rPrecision = c(\rquery_young[1] - precis_ls$LW,\rquery_young[1] - precis_ls$LS\r),\rMethod = rep(c(\u0026quot;Likelihood Weighting\u0026quot;, \u0026quot;Logical Sampling\u0026quot;), each = length(n_seq))\r)\rggplot(data = plot_df, aes(x = N, y = Precision, col = Method)) +\rgeom_line(size = 1.5) +\rgeom_hline(yintercept = 0.01) +\rgeom_hline(yintercept = -0.01) +\rtheme_bw()\r As is evident from this plot, we do not need much in terms of sample to arrive at highly precise results using cpquery() with either method. Still, to be safe, I would probably always run with n = 1e3 at least.\nPart 3.  Use the functions in bnlearn to extract the DAG from bn.mle.\n dag \u0026lt;- bn.net(bn.mle)\rdag\r ## ## Random/Generated Bayesian network\r## ## model:\r## [A][S][E|A:S][O|E][R|E][T|O:R] ## nodes: 6 ## arcs: 6 ## undirected arcs: 0 ## directed arcs: 6 ## average markov blanket size: 2.67 ## average neighbourhood size: 2.00 ## average branching factor: 1.00 ## ## generation algorithm: Empty\r Part 4.  Which nodes d-separate Age and Occupation?\n sapply(nodes(dag), function(z) dsep(dag, \u0026quot;A\u0026quot;, \u0026quot;O\u0026quot;, z))\r ## A E O R S T ## TRUE TRUE TRUE FALSE FALSE FALSE\r Scutari 1.5  Implement an R function for BN inference via rejection sampling using the description provided in Section 1.4 as a reference.\n From the book:\n \u0026ldquo;In rejection sampling, we generate random independent observations from the BN. Then we count how many match the evidence we are conditioning on and how many of those observations also match the event whose probability we are computing; the estimated conditional probability is the ratio between the latter and the former.\u0026rdquo;\n rejection.sampling \u0026lt;- function(bn, nsim, event.node, event.value, evidence.node, evidence.value) {\rsims \u0026lt;- rbn(x = bn, n = nsim) # random samples for each node from a Bayesian network\rm1 \u0026lt;- sims[sims[, evidence.node] == evidence.value, ] # retain only those samples where our evidence node matches the evidence condition\rm2 \u0026lt;- m1[m1[, event.node] == event.value, ] # retain only those samples where our event node matches the event condition\rreturn(nrow(m2) / nrow(m1)) # how many percent of the evidence samples also return the event state?\r}\rrejection.sampling(\rbn = bn.mle, nsim = 10^4,\revent.node = \u0026quot;O\u0026quot;, event.value = \u0026quot;emp\u0026quot;,\revidence.node = \u0026quot;A\u0026quot;, evidence.value = \u0026quot;young\u0026quot;\r)\r ## [1] 0.9640978\r Scutari 1.6  Using the dag and bn objects from Sections 1.2 and 1.3:\n The DAG in question is the same as dag in these solutions. The BN is the same as bn.mle or bn_full. Since I do this for the Bayesian part of Bayesian networks, I use the latter.\nPart 1.  Plot the DAG using graphviz.plot.\n Easy enough:\ngraphviz.plot(dag)\r Part 2.  Plot the DAG again, highlighting the nodes and the arcs that are part of one or more v-structures.\n A bit meaningless of a plot because all of these nodes are involved in v-structures. However, the paths E → O, and E → R are not highlighted as v-structures. Why? Because they are sequential paths rather than convergent or divergent.\nvs \u0026lt;- vstructs(dag, arcs = TRUE)\rhl \u0026lt;- list(nodes = unique(as.character(vs)), arcs = vs)\rgraphviz.plot(dag, highlight = hl)\r Part 3.  Plot the DAG one more time, highlighting the path leading from Age to Occupation.\n All we need to do is highlight the paths A → E and E → O:\nhl \u0026lt;- matrix(c(\u0026quot;A\u0026quot;, \u0026quot;E\u0026quot;, \u0026quot;E\u0026quot;, \u0026quot;O\u0026quot;), nc = 2, byrow = TRUE)\rgraphviz.plot(bn.mle, highlight = list(arcs = hl))\r Part 4.  Plot the conditional probability table of Education.\n There is a ready-made function for that!\nbn.fit.barchart(bn_full$E)\r Across all age ranges, women are much higher educated (on average) than men.\nPart 5.  Compare graphically the distributions of Education for male and female interviewees.\n Here, we simply need to extract the relevant proportions and need them into a barchart.\njunction \u0026lt;- compile(as.grain(bn.mle))\rjmale \u0026lt;- setEvidence(junction, \u0026quot;S\u0026quot;, states = \u0026quot;M\u0026quot;)\rjfemale \u0026lt;- setEvidence(junction, \u0026quot;S\u0026quot;, states = \u0026quot;F\u0026quot;)\rp1 \u0026lt;- barchart(querygrain(jmale, nodes = \u0026quot;E\u0026quot;)$E, main = \u0026quot;Male\u0026quot;, xlim = c(0, 1))\rp2 \u0026lt;- barchart(querygrain(jfemale, nodes = \u0026quot;E\u0026quot;)$E, main = \u0026quot;Female\u0026quot;, xlim = c(0, 1))\rgrid.arrange(p1, p2, ncol = 2)\r Session Info sessionInfo()\r ## R version 4.2.1 (2022-06-23 ucrt)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19044)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_Germany.utf8 LC_CTYPE=English_Germany.utf8 LC_MONETARY=English_Germany.utf8 LC_NUMERIC=C LC_TIME=English_Germany.utf8 ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] gridExtra_2.3 lattice_0.20-45 ggplot2_3.3.6 gRain_1.3.11 gRbase_1.8.7 bnlearn_4.8.1 ## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.9 assertthat_0.2.1 digest_0.6.29 utf8_1.2.2 R6_2.5.1 stats4_4.2.1 evaluate_0.16 highr_0.9 blogdown_1.13 ## [10] pillar_1.8.1 rlang_1.0.5 rstudioapi_0.14 Rgraphviz_2.40.0 jquerylib_0.1.4 R.utils_2.12.0 R.oo_1.25.0 Matrix_1.5-1 rmarkdown_2.16 ## [19] styler_1.8.0 labeling_0.4.2 stringr_1.4.1 igraph_1.3.4 munsell_0.5.0 compiler_4.2.1 xfun_0.33 pkgconfig_2.0.3 BiocGenerics_0.42.0\r## [28] htmltools_0.5.3 tidyselect_1.1.2 tibble_3.1.8 bookdown_0.29 fansi_1.0.3 dplyr_1.0.9 withr_2.5.0 R.methodsS3_1.8.2 grid_4.2.1 ## [37] RBGL_1.72.0 jsonlite_1.8.0 gtable_0.3.1 lifecycle_1.0.2 DBI_1.1.3 magrittr_2.0.3 scales_1.2.1 graph_1.74.0 cli_3.3.0 ## [46] stringi_1.7.8 cachem_1.0.6 farver_2.1.1 bslib_0.4.0 vctrs_0.4.1 generics_0.1.3 tools_4.2.1 R.cache_0.16.0 glue_1.6.2 ## [55] purrr_0.3.4 parallel_4.2.1 fastmap_1.1.0 yaml_2.3.5 colorspace_2.0-3 BiocManager_1.30.18 knitr_1.40 sass_0.4.2\r ","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618340400,"objectID":"7dc5b4926f495aca5f527b5bbf08d169","permalink":"https://www.erikkusch.com/courses/bayes-nets/part-1/","publishdate":"2021-04-13T00:00:00Z","relpermalink":"/courses/bayes-nets/part-1/","section":"courses","summary":"Answers and solutions to the exercises belonging to Part 1 in [Bayesian Networks with Examples in R](https://www.bnlearn.com/book-crc/) by M. Scutari and J.-B. Denis.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Multinomial Bayesian Networks","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some Lecture Slides  for this session.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"f9ccb71c1e2cea2a49af69cf80be9ea4","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/1_biostatistics-wait.-what/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/1_biostatistics-wait.-what/","section":"courses","summary":"I have prepared some Lecture Slides  for this session.","tags":null,"title":"Biostatistics - Wait... What?!","type":"docs"},{"authors":["Erik Kusch"],"categories":["BFTP Projects"],"content":"Preparing The Work First of all, most .R scripts will follow the same kind of structure:\nHead The Head is used as an information statement at the top of your code document that informs the user of the contents, author, and (sometimes) date of the last edit on said document. This is highly useful when you are intending to give your document to other people at some point. The head for our analysis might look something like this:\n# ####################################################################### #\r# PROJECT: [BFTP] Identifying Biomes And Their Shifts Using Remote Sensing\r# CONTENTS: Functionality to download, aggregate, and crop/mask NDVI data\r# AUTHOR: Erik Kusch\r# EDIT: 09/03/20\r# ####################################################################### #\r Preamble The Preamble is where you set up the most important parameters/guidelines for your coding script. Personally, I highly recommend to make your first line in the preamble read rm(list=ls()). This nifty line of code clears your entire working environment in R meaning that you work from a clean slate thus eliminating all possible interference of previous work. If your code works as intended after this line, it means that your project is internally consistent and self-contained which makes your analysis reproducible (we want that!).\nAfterwards, I like to establish a directory (i.e. \u0026ldquo;folder\u0026rdquo;) structure. After all, no one likes a cluttered folder on their hard drive.Therefore, we identify our current working directory (wd) with getwd() and save it as an object in R which we call Dir.Base. This is the folder in which our document is located and where R is looking for and saving files to. We don\u0026rsquo;t want to dump everything there. Conclusively, we need to create our own folders within our project folder. We would like to call these folders \u0026ldquo;Data\u0026rdquo; and \u0026ldquo;Plots\u0026rdquo; (the purpose of these folders should be obvious from their names). To actually create these folders on your hard drive, we must first establish the folder paths. We do so by using the paste() command in R which combines objects and writes the sep argument between the combined objects. Here, we take the path to our project folder (Dir.Base ) and combine it with the name of the folder we want (e.g. \u0026ldquo;Data\u0026rdquo;) while using the backslash (\u0026quot;/\u0026quot;) between these two objects as it indicates the jump in a folder hierarchy. The folder is then created using the dir.create() function.\nOur preamble then looks like this:\nrm(list=ls()) # clearing the entire environment\rDir.Base \u0026lt;- getwd() # identifying the current directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # generating the folder path for data folder\rdir.create(Dir.Data) # creating the data folder\rDir.Plots \u0026lt;- paste(Dir.Base, \u0026quot;Plots\u0026quot;, sep=\u0026quot;/\u0026quot;) # generating the folder path for figures folder\rdir.create(Dir.Plots) # creating the figures folder\r Usually, this is also where we load packages for more functionality of our analyses. However, this time, we will do so when they are necessary to give you a better overview and explanation what they do.\nCoding All of the important Coding happens after the head and the preamble are written and run in R. Basically, this is the rest of this document.\nDownloading NDVI Data First of all, we need to download the NDVI data that we are interested in. One particularly useful repository for this is the Global Inventory Modelling and Mapping Studies (GIMMS) 3g v.1 data set obtained via the Advanced Very High Resolution Radiometer (AVHRR). This time series goes back all the way to January 1982 and contains bi-weekly, global projects of NDVI values.\nPackages Firstly, we need some packages:\n gimms is a package which enables us to download the GIMMS 3g v.1 data set directly through R raster is a package which allows us to establish, handle, and save spatial gridded products of any variable we want (NDVI in this case)\nWe install and load our packages as follows:  install.packages(\u0026quot;gimms\u0026quot;) # for GIMMS NDVI data download\rlibrary(gimms)\rinstall.packages(\u0026quot;raster\u0026quot;) # for spatial raster format\rlibrary(raster)\r Downloading Let\u0026rsquo;s download the GIMMS 3g v.1 NDVI data for the entire year of 1982:\ngimms_files \u0026lt;- downloadGimms(x = as.Date(\u0026quot;1982-01-01\u0026quot;), # download from January 1982\ry = as.Date(\u0026quot;1982-12-31\u0026quot;), # download to December 1982\rdsn = Dir.Data, # save downloads in data folder\rquiet = FALSE # show download progress\r)\r Now, we want to turn our downloaded data into a raster so we can do spatial analyses with it:\ngimms_raster \u0026lt;- rasterizeGimms(x = gimms_files, # the data we rasterize\rremove_header = TRUE # we don't need the header of the data\r)\rgimms_raster # some information about the raster stack we created here\r ## class : RasterStack ## dimensions : 2160, 4320, 9331200, 24 (nrow, ncol, ncell, nlayers)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -180, 180, -90, 90 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## names : ndvi.1.1, ndvi.2.1, ndvi.3.1, ndvi.4.1, ndvi.5.1, ndvi.6.1, ndvi.7.1, ndvi.8.1, ndvi.9.1, ndvi.10.1, ndvi.11.1, ndvi.12.1, ndvi.1.2, ndvi.2.2, ndvi.3.2, ... ## min values : -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, ... ## max values : 0.99, 0.99, 1.00, 0.99, 0.99, 0.99, 1.00, 1.00, 0.99, 0.99, 1.00, 1.00, 1.00, 1.00, 1.00, ...\r Here, you can see that we have successfully created a RasterStack with 24 layers (two for each month because measurements were bi-weekly), for the entire earth (extent of -180, 180, -90, 90). We can also see that there are some values below 0 which we don\u0026rsquo;t expect for the NDVI and we will fix this in a second. For now, just notice that we have successfully downloaded the data.\nAggregating NDVI Data With our data successfully downloaded, it is now time to prepare the data further for our analysis.\nComposites Firstly, we want to deal with monthly NDVI values. To do so, we want to build monthly maximum composites. Luckily, the gimms package has just the right option for us:\nindices \u0026lt;- monthlyIndices(gimms_files) # generate month indices from the data\rgimms_raster_mvc \u0026lt;- monthlyComposite(gimms_raster, # the data\rindices = indices # the indices\r)\rgimms_raster_mvc # some information about our monthly composite raster stack\r ## class : RasterStack ## dimensions : 2160, 4320, 9331200, 12 (nrow, ncol, ncell, nlayers)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -180, 180, -90, 90 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## names : index_1.1, index_1.2, index_1.3, index_1.4, index_1.5, index_1.6, index_1.7, index_1.8, index_1.9, index_1.10, index_1.11, index_1.12 ## min values : -0.30, -0.30, -0.30, -0.29, -0.30, -0.30, -0.30, -0.30, -0.30, -0.30, -0.30, -0.30 ## max values : 0.99, 1.00, 0.99, 1.00, 0.99, 1.00, 1.00, 1.00, 1.00, 1.00, 0.99, 0.99\r As you can see above, our new raster stack has the same dimensions, resolution, coordinate reference system (crs), and extent as the previous one. However, we have reduced the number of layers to 12 (one for each month).\nSince there are still negative values present (an artifact of how NASA stores the data or cloud cover), we simply set these to 0:\nNegatives \u0026lt;- which(values(gimms_raster_mvc) \u0026lt; 0) # identify all negative values\rvalues(gimms_raster_mvc)[Negatives] \u0026lt;- 0 # set threshold for barren land (NDVI\u0026lt;0)\rgimms_raster_mvc\r ## class : RasterBrick ## dimensions : 2160, 4320, 9331200, 12 (nrow, ncol, ncell, nlayers)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -180, 180, -90, 90 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : index_1.1, index_1.2, index_1.3, index_1.4, index_1.5, index_1.6, index_1.7, index_1.8, index_1.9, index_1.10, index_1.11, index_1.12 ## min values : 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ## max values : 0.99, 1.00, 0.99, 1.00, 0.99, 1.00, 1.00, 1.00, 1.00, 1.00, 0.99, 0.99\r See how all of the min values are now on 0!\nLastly, we want to see what our data looks like (visual inspection is an important step to sanity check your work). We do so as follows:\nplot(gimms_raster_mvc)\r What a beautiful seasonal trend of greening we can observe (I\u0026rsquo;ll stop nerding out here before it get\u0026rsquo;s out of hand, don\u0026rsquo;t worry)!\nAnnual Values Lastly, we may wish (and in fact, you will have to) aggregate our data to annual and even more-than-annual means and seasonality measures.\nMean Values To establish annual mean values, we simply take the mean for each cell in our raster stack for all the layers as such:\ngimms_annual \u0026lt;- calc(gimms_raster_mvc, # data from which to calculate\rfun=mean, # function which to calculate with\rna.rm = TRUE # ignore NAs\r)\r Seasonality Values Measures of seasonality are defined as the span between the maximum value of a cell and the minimum value of the same cell. So, we calculate a maximum raster and a minimum raster and then simply subtract the minimum from the maximum as follows:\nmaxi \u0026lt;- calc(gimms_raster_mvc, fun=max)\rmini \u0026lt;- calc(gimms_raster_mvc, fun=min)\rgimms_seasonality \u0026lt;- maxi-mini\r \\pagebreak\nPlots Let\u0026rsquo;s have a look at our annual mean and seasonality:\nplot(gimms_annual, main = \u0026quot;Mean\u0026quot;)\r plot(gimms_seasonality, main = \u0026quot;Seasonality\u0026quot;)\r Cropping NDVI Data Our data is still on a global scale. We are only interested in data across Alaska, though. Let\u0026rsquo;s deal with that.\nPackages \u0026amp; Data Again, we have to install some packages and load them.\ninstall.packages(\u0026quot;sp\u0026quot;) # for spatialpolygons format\rlibrary(sp)\rinstall.packages(\u0026quot;rgdal\u0026quot;) # for shapefiles\rlibrary(rgdal)\r Secondly, we require the actual shape files. Personally, I am a big fan of the Natural Earth Shape files (\\url{http://www.naturalearthdata.com/downloads/10m-cultural-vectors/}) because of all the different shape files I can get there. Here, we are interested in states/provinces and so want to download the data from here: \\url{https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_1_states_provinces.zip}. Thankfully, Rlet\u0026rsquo;s us do the downloading as well as the unpacking of archived (.zip) data:\n# Downloading\rdownload.file(\u0026quot;https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_1_states_provinces.zip\u0026quot;,\rdestfile = paste(Dir.Data, \u0026quot;Shapes.zip\u0026quot;, sep=\u0026quot;/\u0026quot;)) # destination file\r# Unzipping\runzip(paste(Dir.Data, \u0026quot;Shapes.zip\u0026quot;, sep=\u0026quot;/\u0026quot;), # which file to unzip\rexdir = Dir.Data) # where to unzip to\r Finally, we want to load our shape files into R. We do this using the readOGR() function in R:\nShapes \u0026lt;- readOGR(Dir.Data, # where to look for the file\r\u0026quot;ne_10m_admin_1_states_provinces\u0026quot;, # the file name\rverbose = FALSE) # we don't want an overview of the loaded data\r Crop \u0026amp; Mask Now, we are ready to use our shape file for Alaska. First, we have to find out which of our shape files is for Alaska:\nPosition \u0026lt;- which(Shapes$name_en == \u0026quot;Alaska\u0026quot;) # find the english name that's \u0026quot;Alaska\u0026quot; in our shapefiles\rAlaska_Shp \u0026lt;- Shapes[Position,] # extract the Alaska shapefile\rplot(Alaska_Shp) # plot it for inspection\r We really don\u0026rsquo;t care much about that island chain all the way to the right in our plot.\nThis is likely to be an extent-caused issue and we should crop our shape file extent to the easternmost point of Alaska on the continent:\nextent(Alaska_Shp) # extent clearly shows the super-eastern coordinates\r ## class : Extent ## xmin : -179 ## xmax : 180 ## ymin : 51 ## ymax : 71\r # Crop\rAlaska_Shp \u0026lt;- crop(Alaska_Shp, # what to crop\rextent(-190, -130, 51, 71)) # which extent to crop to\rplot(Alaska_Shp) # visualising the cropped product\r Lovely. That resolved the issue. We are ready for final cropping of our data and saving of the cropped data.\nMean Values Let\u0026rsquo;s deal with the annual mean for 1982:\n# Crop\rgimms_annual \u0026lt;- crop(gimms_annual, # mean annual data\rextent(Alaska_Shp)) # cropped Alaska extent\r# Mask (this keeps only cells that fall into our shapefile)\rgimms_annual \u0026lt;- mask(gimms_annual, # cropped annual means\rAlaska_Shp) # cropped Alaska shapefile\rplot(gimms_annual, main =\u0026quot;Annual Mean 1982\u0026quot;) # inspection time!\r # Save data\rwriteRaster(x = gimms_annual, # which raster to save\rfile = paste(Dir.Data, \u0026quot;1982Mean\u0026quot;, sep=\u0026quot;/\u0026quot;), # which file to save to\rformat = \u0026quot;CDF\u0026quot;, overwrite = TRUE) # which format to use and whether to overwrite\r ## class : RasterLayer ## dimensions : 237, 590, 139830 (nrow, ncol, ncell)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -179, -130, 51, 71 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : 1982Mean.nc ## names : layer ## values : 0, 0.84 (min, max)\r## zvar : layer\r Seasonality Values # Crop\rgimms_seasonality \u0026lt;- crop(gimms_seasonality, # mean seasonality data\rextent(Alaska_Shp)) # cropped Alaska extent\r# Mask (this keeps only cells that fall into our shapefile)\rgimms_seasonality \u0026lt;- mask(gimms_seasonality, # cropped seasonality data\rAlaska_Shp) # cropped Alaska shapefile\rplot(gimms_seasonality, main = \u0026quot;Seasonality 1982\u0026quot;) # inspection time!\r # Save data\rwriteRaster(x = gimms_seasonality, # which raster to save\rfile = paste(Dir.Data, \u0026quot;1982Season\u0026quot;, sep=\u0026quot;/\u0026quot;), # which file to save to\rformat = \u0026quot;CDF\u0026quot;, overwrite = TRUE) # which format to use and whether to overwrite\r ## class : RasterLayer ## dimensions : 237, 590, 139830 (nrow, ncol, ncell)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -179, -130, 51, 71 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : 1982Season.nc ## names : layer ## values : 0, 1 (min, max)\r## zvar : layer\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"d2abe6853bcadae69dd2e4d1dd3edc9d","permalink":"https://www.erikkusch.com/courses/bftp-biome-detection/data-allocation/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/bftp-biome-detection/data-allocation/","section":"courses","summary":"Preparing The Work First of all, most .R scripts will follow the same kind of structure:\nHead The Head is used as an information statement at the top of your code document that informs the user of the contents, author, and (sometimes) date of the last edit on said document.","tags":["R","Statistics","Remote Sensing"],"title":"","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some Lecture Slides  for this session.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"060d60483c0bc810df2b6f59ff4a15f8","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/01-an-introduction-to-basic-statistics-for-biologists/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/01-an-introduction-to-basic-statistics-for-biologists/","section":"courses","summary":"I have prepared some Lecture Slides  for this session.","tags":null,"title":"Basic Statistics for Biologists","type":"docs"},{"authors":null,"categories":["BioStat101"],"content":"\r\rTheory slides for this session.\rClick the outline of the presentation below to get to the HTML version of the slides for this session.\r  \r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cf8e0c8a64da4d700d7e94739473ed6b","permalink":"https://www.erikkusch.com/courses/biostat101/01-an-introduction-to-basic-statistics-for-biologists/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/biostat101/01-an-introduction-to-basic-statistics-for-biologists/","section":"courses","summary":"\r\rTheory slides for this session.\rClick the outline of the presentation below to get to the HTML version of the slides for this session.\r  \r\r","tags":null,"title":"Basic Statistics for Biologists","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r Material  \rNetworks in R  Exercises These are answers and solutions to the exercises at the end of chapter 1 in Bayesian Networks in R with Applications in Systems Biology by Radhakrishnan Nagarajan, Marco Scutari \u0026amp; Sophie Lèbre. Much of my inspiration for these solutions, where necessary, by consulting the solutions provided by the authors themselves as in the appendix.\nNagarajan 1.1  1.1. Consider a directed acyclic graph with n nodes.\n  (a) Show that at least one node must not have any incoming arc, i.e., the graph must contain at least one root node.\n A graph without a root node violates the premise of acyclicity inherent to Bayesian Networks.\nAssuming our graph is directed with G = (V, A), and assuming that there is no root node present, for any vertex $V_i$ that we chose of the set V, we can find a path that $V_i \\rightarrow \u0026hellip; \\rightarrow V_n$ which spans all nodes in V. However, $V_n$ must have an outgoing arc ($V_n \\rightarrow \u0026hellip;$) which must connect to any of the nodes already on the path between $V_i$ and $V_n$ thereby incurring a loop or cycle.\n (b) Show that such a graph can have at most n(n−1) arcs.\n This can be explained as an iterative process. Starting with any node $V_1 \\in \\boldsymbol V$, not violating the prerequisite for acyclicity, $V_1$ may only contain $n-1$ outgoing arcs (an arc linking to itself would create a cycle). Continuing now to another node $V_2 \\in \\boldsymbol V$ and $V_2 \\neq V_1$, this node may only contain $n-2$ outgoing arcs as any arc linking to itself or $V_1$ would introduce a cycle or loop.\nContinuing this process to its logical conclusion of $V_n$, we can summarise the number of possible outgoing arcs thusly:\n\\begin{equation} A \\leq (n-1) + (n-2) + \u0026hellip; + (1) = \\left( n\\atop{2} \\right) = \\frac{n(n-1)}{2} \\end{equation}\n (c) Show that a path can span at most n−1 arcs.\n Any arc contains two nodes - one tail and one head. Therefore, a path spanning n arcs would have to contain n+1 vertices, thus passing trough one vertex twice and introducing a cycle.\n (d) Describe an algorithm to determine the topological ordering of the graph.\n Two prominent examples are breadth-first (BF) and depth-first (DF) algorithms.\nThe former (BF) attempts to locate a node that satisfies a certain query conditions by exploring a graph from a root node and subsequently evaluating nodes which are equidistant to the root (at a distance of one arc). If none of these nodes satisfies the search criteria, the distance to root node is increased by an additional arc distance.\nDF, on the other hand, starts at a root node and fully explores a randomly chosen path until either a node satisfying the search criteria is reached or the path has ended in which case a new path is explored starting at the root node.\nNagarajan 1.2  1.2. Consider the graphs shown in Fig. 1.1.\n  (a) Obtain the skeleton of the partially directed and directed graphs.\n I start by loading the visNetwork R package. I chose this package simply because I like how it creates interactive visualisations - try it out! Click some of the vertices below or try and drag them around.\nI also load additional html libraries with which I can include the thml outputs produced by visNetwork in this blog:\nlibrary(visNetwork)\rlibrary(htmlwidgets)\rlibrary(htmltools)\r Next, I register the node set as well as the two arc sets we are working with:\nV \u0026lt;- data.frame(\rid = c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;E\u0026quot;),\rlabel = c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;E\u0026quot;)\r)\rA_directed \u0026lt;- data.frame(\rfrom = c(\u0026quot;C\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;A\u0026quot;),\rto = c(\u0026quot;E\u0026quot;, \u0026quot;A\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;B\u0026quot;)\r)\rA_partial \u0026lt;- data.frame(\rfrom = c(\u0026quot;E\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;A\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;C\u0026quot;),\rto = c(\u0026quot;B\u0026quot;, \u0026quot;E\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;A\u0026quot;)\r)\r Note that I still have to register a direction even for undirected edges.\nNow, to visualise the skeletons, we simply plot the graphs without any edge directionality:\n\rClick here for the plotting call of the skeleton of the directed graph:\r## skeleton of directed graph\rNagara1.2aD \u0026lt;- visNetwork(\rnodes = V,\redges = A_directed\r) %\u0026gt;%\rvisNodes(\rshape = \u0026quot;circle\u0026quot;,\rfont = list(size = 40, color = \u0026quot;white\u0026quot;),\rcolor = list(\rbackground = \u0026quot;darkgrey\u0026quot;,\rborder = \u0026quot;black\u0026quot;,\rhighlight = \u0026quot;orange\u0026quot;\r),\rshadow = list(enabled = TRUE, size = 10)\r) %\u0026gt;%\rvisEdges(color = list(\rcolor = \u0026quot;green\u0026quot;,\rhighlight = \u0026quot;red\u0026quot;\r)) %\u0026gt;%\rvisLayout(randomSeed = 42)\rsaveWidget(Nagara1.2aD, \u0026quot;Nagara1.2aD.html\u0026quot;)\r \r\r\rClick here for the plotting call of the skeleton of the partially directed graph:\r## skeleton of partially directed graph\rNagara1.2aP \u0026lt;- visNetwork(\rnodes = V,\redges = A_partial\r) %\u0026gt;%\rvisNodes(\rshape = \u0026quot;circle\u0026quot;,\rfont = list(size = 40, color = \u0026quot;white\u0026quot;),\rcolor = list(\rbackground = \u0026quot;darkgrey\u0026quot;,\rborder = \u0026quot;black\u0026quot;,\rhighlight = \u0026quot;orange\u0026quot;\r),\rshadow = list(enabled = TRUE, size = 10)\r) %\u0026gt;%\rvisEdges(color = list(\rcolor = \u0026quot;green\u0026quot;,\rhighlight = \u0026quot;red\u0026quot;\r)) %\u0026gt;%\rvisLayout(randomSeed = 42)\rsaveWidget(Nagara1.2aP, \u0026quot;Nagara1.2aP.html\u0026quot;)\r \r\r (b) Enumerate the acyclic graphs that can be obtained by orienting the undirected arcs of the partially directed graph.\n Right. Sorting this out using visNetwork would be a royal pain. So I instead opt for using igraph for this exercise.\nFirst, I load the necessary R package:\nlibrary(igraph)\r Next, I consider the edge and node set of the partially directed graph:\nV \u0026lt;- data.frame(id = c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;E\u0026quot;))\rA_partial \u0026lt;- data.frame(\rfrom = c(\u0026quot;E\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;A\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;C\u0026quot;),\rto = c(\u0026quot;B\u0026quot;, \u0026quot;E\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;D\u0026quot;, \u0026quot;A\u0026quot;)\r)\r To enumerate all DAGs from these sets, I may only change the directions of the last three edges listed in my edge set.\nObjectively, this exercise could be solved by simply thinking about the different constellations. However, I code for a living. One may argue that thinking is not necessarily in my wheelhouse (on may also claim the opposite). Hence, I will automate the procedure.\nTo do so, I will need to create all possible combinations of directions of currently undirected edges in the graph in question and check whether they create cycles or not.\nTo do so, I load the bnlearn package as it comes with an error message when trying to assign an arc set that introduces cycles. I also register a base graph consisting of only our vertex set:\nlibrary(bnlearn)\rbase_bn \u0026lt;- empty.graph(nodes = V$id)\r Now, I simply loop over my three arcs in question and alternate which direction they are pointing. At the deepest level of this monstrosity, I am then assingning the final arcs to the base graph and only retain it if the cyclicity error has not been thrown:\nA_iter \u0026lt;- A_partial\rA_ls \u0026lt;- list()\rcounter \u0026lt;- 1\rfor (AD in 1:2) {\rA_iter[3, ] \u0026lt;- if (AD == 1) {\rA_partial[3, ]\r} else {\rrev(A_partial[3, ])\r}\rfor (CD in 1:2) {\rA_iter[4, ] \u0026lt;- if (CD == 1) {\rA_partial[4, ]\r} else {\rrev(A_partial[4, ])\r}\rfor (CA in 1:2) {\rA_iter[5, ] \u0026lt;- if (CA == 1) {\rA_partial[5, ]\r} else {\rrev(A_partial[5, ])\r}\rA_check \u0026lt;- tryCatch(\r{\rarcs(base_bn) \u0026lt;- A_iter\r},\rerror = function(e) {\r\u0026quot;error\u0026quot;\r}\r)\rif (all(A_check != \u0026quot;error\u0026quot;)) {\rA_ls[[counter]] \u0026lt;- base_bn\rcounter \u0026lt;- counter + 1\r}\r}\r}\r}\r How many valid DAGs did this result in?\nlength(A_ls)\r ## [1] 6\r Let\u0026rsquo;s plot these out and be done with it:\npar(mfrow = c(2, 3))\rfor (plot_iter in A_ls) {\rdag_igraph \u0026lt;- graph_from_edgelist(arcs(plot_iter))\rplot(dag_igraph,\rlayout = layout.circle,\rvertex.size = 30\r)\r}\r  (c) List the arcs that can be reversed (i.e., turned in the opposite direction), one at a time, without introducing cycles in the directed graph.\n All arcs of the directed graph can be reversed without introducing cycles.\nNagarajan 1.3  1.3. The (famous) iris data set reports the measurements in centimeters of the sepal length and width and the petal length and width for 50 flowers from each of 3 species of iris (“setosa,” “versicolor,” and “virginica”).\n  (a) Load the iris data set (it is included in the datasets package, which is part of the base R distribution and does not need to be loaded explicitly) and read its manual page.\n data(iris)\r ?iris\r  (b) Investigate the structure of the data set.\n str(iris)\r ## 'data.frame':\t150 obs. of 5 variables:\r## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\r## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\r## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\r## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\r## $ Species : Factor w/ 3 levels \u0026quot;setosa\u0026quot;,\u0026quot;versicolor\u0026quot;,..: 1 1 1 1 1 1 1 1 1 1 ...\r  (c) Compare the sepal length among the three species by plotting histograms side by side.\n library(ggplot2)\rggplot(iris, aes(x = Sepal.Length)) +\rgeom_histogram() +\rfacet_wrap(~Species) +\rtheme_bw()\r  (d) Repeat the previous point using boxplots.\n library(ggplot2)\rggplot(iris, aes(x = Species, y = Sepal.Length)) +\rgeom_boxplot() +\rtheme_bw()\r Nagarajan 1.4  1.4. Consider again the iris data set from Exercise 1.3.\n  (a) Write the data frame holding iris data frame into a space-separated text file named “iris.txt,” and read it back into a second data frame called iris2.\n write.table(iris, file = \u0026quot;iris.txt\u0026quot;, row.names = FALSE)\riris2 \u0026lt;- read.table(\u0026quot;iris.txt\u0026quot;, header = TRUE)\r  (b) Check that iris and iris2 are identical.\n identical(iris, iris2)\r ## [1] FALSE\r Why are they not identical? That\u0026rsquo;s because iris stores Species as a factor. Information which is lost when writing to a .txt file. Let\u0026rsquo;s reformat this and check again:\niris2$Species \u0026lt;- factor(iris2$Species)\ridentical(iris, iris2)\r ## [1] TRUE\r  (c) Repeat the previous two steps with a file compressed with bzip2 named “iris.txt.bz2.”\n bzfd \u0026lt;- bzfile(\u0026quot;iris.txt.bz2\u0026quot;, open = \u0026quot;w\u0026quot;)\rwrite.table(iris, file = bzfd, row.names = FALSE)\rclose(bzfd)\rbzfd \u0026lt;- bzfile(\u0026quot;iris.txt.bz2\u0026quot;, open = \u0026quot;r\u0026quot;)\riris2 \u0026lt;- read.table(bzfd, header = TRUE)\rclose(bzfd)\riris2$Species \u0026lt;- factor(iris2$Species)\ridentical(iris, iris2)\r ## [1] TRUE\r  (d) Save iris directly (e.g., without converting it to a text table) into a file called “iris.rda,” and read it back.\n save(iris, file = \u0026quot;iris.rda\u0026quot;)\rload(\u0026quot;iris.rda\u0026quot;)\r  (e) List all R objects in the global environment and remove all of them apart from iris.\n ls()\r ## [1] \u0026quot;A_check\u0026quot; \u0026quot;A_directed\u0026quot; \u0026quot;A_iter\u0026quot; \u0026quot;A_ls\u0026quot; \u0026quot;A_partial\u0026quot; \u0026quot;AD\u0026quot; \u0026quot;base_bn\u0026quot; \u0026quot;bzfd\u0026quot; \u0026quot;CA\u0026quot; \u0026quot;CD\u0026quot; \u0026quot;counter\u0026quot; \u0026quot;dag_igraph\u0026quot; \u0026quot;iris\u0026quot; \u0026quot;iris2\u0026quot; ## [15] \u0026quot;Nagara1.2aD\u0026quot; \u0026quot;Nagara1.2aP\u0026quot; \u0026quot;plot_iter\u0026quot; \u0026quot;V\u0026quot;\r l \u0026lt;- ls()\rrm(list = l[l != \u0026quot;iris\u0026quot;])\r  (f) Exit the R saving the contents of the current session.\n quit(save = \u0026quot;yes\u0026quot;)\r Nagarajan 1.5  1.5. Consider the gaussian.test data set included in bnlearn.\n  (a) Print the column names.\n colnames(gaussian.test)\r ## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot; \u0026quot;D\u0026quot; \u0026quot;E\u0026quot; \u0026quot;F\u0026quot; \u0026quot;G\u0026quot;\r  (b) Print the range and the quartiles of each variable.\n ## range\rfor (var in names(gaussian.test)) {\rprint(range(gaussian.test[, var]))\r}\r ## [1] -2.246520 4.847388\r## [1] -10.09456 14.21538\r## [1] -15.80996 32.44077\r## [1] -9.043796 26.977326\r## [1] -3.558768 11.494383\r## [1] -1.170247 45.849594\r## [1] -1.365823 12.409607\r ## quantiles\rfor (var in names(gaussian.test)) {\rprint(quantile(gaussian.test[, var]))\r}\r ## 0% 25% 50% 75% 100% ## -2.2465197 0.3240041 0.9836491 1.6896519 4.8473877 ## 0% 25% 50% 75% 100% ## -10.09455807 -0.01751825 2.00025495 4.07692065 14.21537969 ## 0% 25% 50% 75% 100% ## -15.809961 3.718150 8.056369 12.373614 32.440769 ## 0% 25% 50% 75% 100% ## -9.043796 5.984274 8.994232 12.164417 26.977326 ## 0% 25% 50% 75% 100% ## -3.558768 2.095676 3.508567 4.873497 11.494383 ## 0% 25% 50% 75% 100% ## -1.170247 17.916175 21.982997 26.330886 45.849594 ## 0% 25% 50% 75% 100% ## -1.365823 3.738940 5.028420 6.344179 12.409607\r  (c) Print all the observations for which A falls in the interval [3,4] and B in (−∞,−5]∪[10,∞).\n TestA \u0026lt;- (gaussian.test[, \u0026quot;A\u0026quot;] \u0026gt;= 3) \u0026amp; (gaussian.test[, \u0026quot;A\u0026quot;] \u0026lt;= 4)\rTestB \u0026lt;- (gaussian.test[, \u0026quot;B\u0026quot;] \u0026lt;= -4) | (gaussian.test[, \u0026quot;B\u0026quot;] \u0026gt;= 4)\rgaussian.test[TestA \u0026amp; TestB, ]\r ## A B C D E F G\r## 134 3.000115 5.677259 19.6165914 13.90710134 1.2399546 29.66208 6.1184117\r## 171 3.912097 5.000325 19.5261459 13.31373543 0.2807556 32.51754 7.3699037\r## 954 3.735995 4.052434 18.1856087 12.09431457 3.7080579 26.97241 3.0517690\r## 1034 3.317637 4.837303 18.1044125 13.32279487 2.9563555 28.40041 3.9876290\r## 1042 3.372036 4.197395 17.6533233 12.52777893 4.8983597 31.08633 3.7283984\r## 1078 3.157623 5.184670 19.0430676 13.89072391 3.2572347 37.08646 8.9429136\r## 1127 3.141251 4.269507 17.1939411 12.42629251 2.6622288 29.53266 4.4132469\r## 1237 3.031727 4.341881 17.6020776 12.43625964 2.7949498 27.74622 5.4084005\r## 1755 3.052266 4.612071 18.1180989 13.19968750 5.6471997 27.78189 1.5129846\r## 1819 3.290631 7.143942 22.6867359 16.14048867 4.8648686 37.51501 8.0241134\r## 2030 3.289162 5.787095 20.0194963 14.52479092 5.2423368 37.46786 7.6643575\r## 2153 3.037955 4.797399 17.1331929 13.58727751 2.7524554 31.84176 5.5202624\r## 2179 3.114916 5.414628 19.3677155 14.14501162 3.4438786 31.06106 3.8799064\r## 2576 3.458761 4.471637 18.1722539 13.36940122 2.3688318 23.60165 0.7689322\r## 2865 3.140513 7.269383 22.5686681 16.86773531 4.0260061 36.17848 6.1028714\r## 3035 3.476832 4.109519 17.0599625 11.55995675 4.4027366 29.83397 3.6381844\r## 3133 3.667252 4.953129 19.6575484 13.31833594 5.0080665 31.78321 3.9031780\r## 3434 3.418895 6.412021 21.8072576 15.48090391 5.6847825 29.41806 1.3941551\r## 3481 3.050811 6.203747 21.1427355 15.39309314 4.2068982 33.79386 5.1348785\r## 3573 3.612315 4.741220 18.4841065 13.08992732 5.4532191 31.22224 3.3986084\r## 3695 3.284053 4.899003 17.7691812 13.73467842 4.5814578 39.96773 9.5808916\r## 3893 3.070645 6.111989 20.6963754 15.34110860 2.0329921 29.92680 4.1352188\r## 3999 3.493238 5.307218 19.1502279 14.10123450 4.8567953 35.69970 5.8485995\r## 4144 3.045976 4.925688 18.8388604 13.28690773 7.3473994 34.12657 4.0527848\r## 4164 3.624343 5.411443 20.3400016 13.35879870 7.4107565 32.20646 2.5717899\r## 4220 3.133246 4.950543 17.9604182 13.91087282 4.2105519 30.01146 3.7960603\r## 4229 3.119493 7.255816 22.4329800 16.59886045 2.4893039 33.62491 5.0819631\r## 4258 3.777205 7.189762 23.9019969 16.75321069 4.0727603 37.66095 6.6653238\r## 4671 3.455920 -4.198865 0.1452861 -0.27503006 1.9954874 16.60534 4.7261660\r## 4703 3.301100 -4.109750 0.2244686 -0.07441052 6.2531813 23.58530 6.4627941\r## 4739 3.010097 9.775164 28.1861733 20.54659992 5.1594216 40.50032 5.8467280\r## 4779 3.215547 6.393758 20.7043512 15.59370075 3.2628127 33.35600 5.8151547\r## 4866 3.873728 -4.257339 0.8213114 -0.31665717 0.2758219 14.94325 5.4011586\r## 4987 3.058566 8.128704 24.9419446 18.56396890 5.8402279 35.29171 4.4032448\r  (d) Sample 50 rows without replacement.\n I\u0026rsquo;m leaving out the output to save some space.\nset.seed(42)\rgaussian.test[sample(50, replace = FALSE), ]\r  (e) Draw a bootstrap sample (e.g., sample 5,000 observations with replacement) and compute the mean of each variable.\n colMeans(gaussian.test[sample(5000, replace = TRUE), ])\r ## A B C D E F G ## 1.007428 2.076592 8.157574 9.101292 3.532690 22.160643 4.998093\r  (f) Standardize each variable.\n I\u0026rsquo;m leaving out the oputput to save some space.\nscale(gaussian.test)\r Nagarajan 1.6  1.6. Generate a data frame with 100 observations for the following variables:\n  (a) A categorical variable with two levels, low and high. The first 50 observations should be set to low, the others to high.\n A \u0026lt;- factor(c(rep(\u0026quot;low\u0026quot;, 50), rep(\u0026quot;high\u0026quot;, 50)), levels = c(\u0026quot;low\u0026quot;, \u0026quot;high\u0026quot;))\r  (b) A categorical variable with two levels, good and bad, nested within the first variable, i.e., the first 25 observations should be set to good, the second 25 to bad, and so on.\n nesting \u0026lt;- c(rep(\u0026quot;good\u0026quot;, 25), rep(\u0026quot;bad\u0026quot;, 25))\rB \u0026lt;- factor(rep(nesting, 2), levels = c(\u0026quot;good\u0026quot;, \u0026quot;bad\u0026quot;))\r  (c) A continuous, numerical variable following a Gaussian distribution with mean 2 and variance 4 when the first variable is equal to low and with mean 4 and variance 1 if the first variable is equal to high. In addition, compute the standard deviation of the last variable for each configuration of the first two variables.\n set.seed(42)\rC \u0026lt;- c(rnorm(50, mean = 2, sd = 2), rnorm(50, mean = 4, sd = 1))\rdata \u0026lt;- data.frame(A = A, B = B, C = C)\raggregate(C ~ A + B, data = data, FUN = sd)\r ## A B C\r## 1 low good 2.6127294\r## 2 high good 0.9712271\r## 3 low bad 1.8938398\r## 4 high bad 0.8943556\r One essential task in any analysis is to import and export the R objects describing models from different packages. This is all the more true in the case of BN modelling, as no package implements all of structure learning, parameter learning and inference. --\r1. Create the dag.bnlearn object from Section 5.1.1. --\r2. Export it to deal. --\r3. Import the result back into bnlearn. --\r4. Export dag.bnlearn to catnet and import it back in bnlearn. --\r5. Perform parameter learning using the discretised dmarks and dag.bnlearn and export it to a DSC file, which can be read in Hugin and GeNIe. --\rLearn a GBN from the marks data (without the LAT variable) using pcalg and a custom test that defines dependence as significant if the corresponding partial correlation is greater than 0.50. --\rReproduce the example of structure learning from Section 5.1.1 using deal, but set the imaginary sample size to 20. How does the resulting network change? --\r","date":1664236800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664305200,"objectID":"29059f6803e3d2d243cc01414456d5b6","permalink":"https://www.erikkusch.com/courses/bayes-nets/networksr/","publishdate":"2022-09-27T00:00:00Z","relpermalink":"/courses/bayes-nets/networksr/","section":"courses","summary":"Here, we lay the foundation for registering networks and their structure in `R` and show how to visualise them.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"(Bayesian) Networks \u0026 R","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"Installing KrigR First of all, we need to install KrigR.\n\r\u0026ndash;\u0026gt; Until we have implemented our development ideas and goals, KrigR will not be submitted to CRAN to avoid the hassle of updating an already accepted package. For the time being, KrigR is only available through the associated GitHub repository.\n\r--\rInstallation of an R-Package from GitHub is facilitated via the devtools package and its install_github() function. Thus, KrigR can be installed and loaded as follows:\n\rAs KrigR is currently undergoing substantial development in response to the establishment of a new CDS and deprecation of previous dependency packages, you have to install the latest development version.\r\r\rdevtools::install_github(\u0026quot;https://github.com/ErikKusch/KrigR\u0026quot;, ref = \u0026quot;Development\u0026quot;)\rlibrary(KrigR)\r CDS API Access \rIf you have used KrigR or CDS services before 2024-09-16, please be advised that a new CDS has been established and you will need to create a new account and register your new user credentials with KrigR to ensure continued use of it.\r\r\rBefore you can access Climate Data Store (CDS) products through KrigR, you need to register an account at CDS. Don\u0026rsquo;t forget to accept the terms and conditions:\nOnce you have created your account, you can find your API credentials on your personal page (which you access by clicking your name in the top-right corner of the webpage) on the CDS webpage:\nOnce you have done so, we recommend you register the user ID and API Key as characters as seen below (this will match the naming scheme in our workshop material):\nAPI_User \u0026lt;- \u0026quot;youremail@somethingortheother\u0026quot;\rAPI_Key \u0026lt;- \u0026quot;YourApiKeyGoesHereAsACharacterString\u0026quot;\r \rYou are now ready for KrigR.\r\r\rIf this is your first contact with KrigR, we recommend strongly you follow the workshop material in order. If you return to KrigR with specific questions or ideas, we recommend you make use of the search function at the top left of this page. If you are short on time, the quick start guide will be useful to you.\n","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"a66f930857b804207fc0d087d1626c71","permalink":"https://www.erikkusch.com/courses/krigr/setup/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/setup/","section":"courses","summary":"Set-up instructions for `KrigR` and preparations for the workshop.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Setting up KrigR","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r\rMaterial  \rGaussian Bayesian Networks  Exercises These are answers and solutions to the exercises at the end of Part 2 in Bayesian Networks with Examples in R by M. Scutari and J.-B. Denis. Much of my inspiration for these solutions, where necessary, by consulting the solutions provided by the authors themselves as in the appendix.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(bnlearn)\rlibrary(ggplot2)\rlibrary(tidyr)\rlibrary(tidybayes)\r Scutari 2.1  Prove that Equation (2.2) implies Equation (2.3).\n Equation 2.2 reads:\n$$f(C | G = g) \\neq f(C)$$\nEquation 2.3 reads:\n$$f(G | C = c) \\neq f(G)$$\nSo how do we go about demonstrating that the first implies the latter? Well, we are using Bayesian theory here so why not use the Bayes' theorem? So let\u0026rsquo;s start by rewriting equation 2.2:\n$$f(C | G) = \\frac{f(C, G)}{f(G)} = \\frac{f(G | C) f(C)}{f(G)}$$ So how does this relate to the question that equation 2.2 implies equation 2.3? Well, if $f(C|G) = f(C)$ then this equation would reveal that $f(G|C) = f(G)$ (so that the $f(G)$ terms factor out). Our proof stipulates that these statements aren\u0026rsquo;t true, but one still implies the other and we land of quod erat demonstrandum.\nScutari 2.2  Within the context of the DAG shown in Figure 2.1, prove that Equation (2.5) is true using Equation (2.6).\n This is the DAG in question:\nThe equation to prove (2.5) is:\n$$f(N, W | V = v) = f(N | V = v) f(W | V = v)$$\nand we use this equation (2.6) for our proof:\n$$f(G, E, V, N, W, C) = f(G) f(E) f(V | G, E) f(N | V) f(W | V) f(C | N, W)$$\nLet\u0026rsquo;s start the proof by integrating over all variables that aren\u0026rsquo;t $N$, $W$, and $V$ (the variables contained in the equation we are tasked to prove):\n$$f(V, W, N) = \\int_G \\int_E \\int_Cf(G,E,V,N,W,C)$$\nWe do this to remove all but the variables we are after from our equation so let\u0026rsquo;s follow this rationale:\n$$ \\begin{aligned} \\int_G \\int_E \\int_Cf(G,E,V,N,W,C) = \u0026amp;f(V) f(N|V) f(W|V) \\newline \u0026amp;\\times \\left( \\int_G \\int_E f(G) f(E) f(V|G,E) \\right) \\newline \u0026amp;\\left( \\int_C f(C|N,W) \\right) \\end{aligned} $$\nSimplifying this mess, we arrive at:\n$$f(V, W, N) = f(V) f(N|V) f(W|V)$$\nFinally, we can obtain our original formula:\n$$f(W,N|V) = \\frac{f(V,W,N)}{f(V)} = \\frac{f(V) f(N|V) f(W|V)}{f(V)} = f(N|V) f(W|N)$$\nAnother case of the quod erat demonstrandums.\nScutari 2.3  Compute the marginal variance of the two nodes with two parents from the local distributions proposed in Table 2.1. Why is it much more complicated for C than for V?\n Table 2.1 is hardly a table at all, but I did locate it. Basically, it is an amalgamation of the probability distributions proposed for the DAG from the previous exercise:\nNote that the parameter $07v$ in the second-to-last row should read $0.7v$.\nThe two nodes we are after are $V$ and $C$. Since the task already tells us that the computation of the marginal variance for $V$ is easier than for $C$, I start with this one.\n Computation for $V$  Simply translating the probability distribution into a linear model, we receive:\n$$V = -10.35534 + 0.5G + 0.70711E + \\epsilon_V$$\nwith the variances of our independent variables $G$, $E$, and $\\epsilon_V$ being $10^2$, $10^2$, and $5^2$ respectively. Consequently the variance of $V$ can be calculated as follows:\n$$VAR(V) = 0.5^2VAR(G) + 0.70711^2VAR(E) + VAR(\\epsilon_V)$$ $$VAR(V) = 0.5^210^2+0.70711^210^2+5^2 = 10$$\nComputation for $C$  For $C$, we can transform our portability distribution into a linear model again:\n$$C = 0.3N+0.7W+\\epsilon_C$$\nthis time, however the predictors variables are not independent since they share node $V$ as their parent. Consequently, we have to compute their covariance:\n$$COV(N,W) = COV(0.1V, 0.7V) = 0.1 * 0.7 * Var(V) = 0.1 * 0.7 * 10^2$$\nSo we actually needed to calculate the variance for $V$ to even be able to calculate the variance for $C$. Let\u0026rsquo;s round this out now, then:\n$$ \\begin{aligned} Var(C) \u0026amp;= 0.3^2 * VAR(N) + 0.7^2VAR(W) \\newline \u0026amp;+ VAR(\\epsilon_C) + 2 * 0.3 * 0.7 * COV(N,W) \\end{aligned} $$\nNow, I simply plug the values into the formula and arrive at:\n$$ \\begin{aligned} Var(C) \u0026amp;= 0.3^2 * 9.949874^2+0.7^2 * 7.141428 \\newline \u0026amp;+6.25^2+2 * 0.3 * 0.7 * 0.1 * 0.7 * 10^2 \\newline \u0026amp; = 54.4118 \\end{aligned} $$\nCuriously, the book suggest this as the solution:\n$$Var(C) = (0.3^2+0.7^2+0.3 * 0.7 * 0.14)10^2+6.25^2 = 100.0024$$\nI am not sure where the values for VAR(N) and VAR(W) have gone here. If anyone who is reading this knows the answer to it, please contact me and let me know as well.\nScutari 2.4  Write an R script using only the rnorm and cbind functions to create a 100 × 6 matrix of 100 observations simulated from the BN defined in Table 2.1. Compare the result with those produced by a call to cpdist function.\n To simulate a table of observation using the formulae in the probability distribution collection from the previous question (Table 1), we simply select random values for all parent nodes according to their distributions and let the distributions for all offspring nodes do the rest. One important note here, is that the rnorm() function in R takes as an argument of variation the standard deviation $\\sigma$ rather than the variance $\\sigma^2$:\nset.seed(42) # making things reproducible\rn \u0026lt;- 1e2 # number of replicates\rG \u0026lt;- rnorm(n, 50, 10)\rE \u0026lt;- rnorm(n, 50, 10)\rV \u0026lt;- rnorm(n, -10.35534 + 0.5 * G + 0.70711 * E, 5)\rN \u0026lt;- rnorm(n, 45 + 0.1 * V, 9.949874)\rW \u0026lt;- rnorm(n, 15 + 0.7 * V, 7.141428)\rC \u0026lt;- rnorm(n, 0.3 * N + 0.7 * W, 6.25)\rsim1 \u0026lt;- data.frame(cbind(G, E, V, N, W, C))\r Now we do this using the cpdist() function. To do so, we first have to create our Bayesian Network:\ndag.bnlearn \u0026lt;- model2network(\u0026quot;[G][E][V|G:E][N|V][W|V][C|N:W]\u0026quot;)\rdisE \u0026lt;- list(coef = c(\u0026quot;(Intercept)\u0026quot; = 50), sd = 10)\rdisG \u0026lt;- list(coef = c(\u0026quot;(Intercept)\u0026quot; = 50), sd = 10)\rdisV \u0026lt;- list(coef = c(\u0026quot;(Intercept)\u0026quot; = -10.35534, E = 0.70711, G = 0.5), sd = 5)\rdisN \u0026lt;- list(coef = c(\u0026quot;(Intercept)\u0026quot; = 45, V = 0.1), sd = 9.949874)\rdisW \u0026lt;- list(coef = c(\u0026quot;(Intercept)\u0026quot; = 15, V = 0.7), sd = 7.141428)\rdisC \u0026lt;- list(coef = c(\u0026quot;(Intercept)\u0026quot; = 0, N = 0.3, W = 0.7), sd = 6.25)\rdis.list \u0026lt;- list(E = disE, G = disG, V = disV, N = disN, W = disW, C = disC)\rgbn.bnlearn \u0026lt;- custom.fit(dag.bnlearn, dist = dis.list)\rsim2 \u0026lt;- data.frame(cpdist(gbn.bnlearn, nodes = nodes(gbn.bnlearn), evidence = TRUE))\r this is pretty much exactly what is done in the chapter.\nSo let\u0026rsquo;s compare these simulation outputs:\n# preparing all data together in one data frame for plotting\rsim1$sim \u0026lt;- 1\rsim2$sim \u0026lt;- 2\rPlot_df \u0026lt;- rbind(sim1, sim2[, match(colnames(sim1), colnames(sim2))])\rPlot_df \u0026lt;- gather(data = Plot_df, key = \u0026quot;node\u0026quot;, value = \u0026quot;value\u0026quot;, G:C)\rPlot_df$sim \u0026lt;- as.factor(Plot_df$sim)\r## plotting\rggplot(Plot_df, aes(x = value, y = sim)) +\rstat_halfeye() +\rfacet_wrap(~node, scales = \u0026quot;free\u0026quot;) +\rtheme_bw()\r As is apparent from this, all results fall close to the expected values of roughly 50. There are noticeable differences between the simulations. I would suggest that these are due to the fairly low sample size for sim1.\nScutari 2.5  Imagine two ways other than changing the size of the points (as in Section 2.7.2) to introduce a third variable in the plot.\n The plot in question is this one:\nthis plot is aimed at showing the distribution of $C$ when both $E$ and $V$ vary. Here, the variation in $V$ is shown along the x-axis, while the variation of $E$ is contained within the sizes of the circles. The y-axis represents the values of $C$ according to its distributions.\nSo how else could we add information of $E$ to a plot of $V$ and $C$? I reckon we could:\n Make three scatter plots. One for each pairing of our variables. Represent the values of $E$ with a colour saturation gradient.  Scutari 2.6  Can GBNs be extended to log-normal distributions? If so how, if not, why?\n GBNs are Gaussian Bayesian Networks - Bayesian Networks where each node follows a Gaussian distribution.\nYes, absolutely they can! We can simply take the logarithm of all initial variables and apply the GBN right away. Of course, all values that shall be transformed using the logarithm have to be positive.\nScutari 2.7  How can we generalise GBNs as defined in Section 2.3 in order to make each node’s variance depend on the node’s parents?\n I see absolutely no problem here. Let\u0026rsquo;s say we have two nodes:\n $A$; parent node with a constant variance $B$; child node with a variance dependant the parent node  Then we can easily define the variance of $B$ given $A$ ($VAR(B|A)$) as follows:\n$$VAR(B|A) = \\left(A-E(A)\\right)^2 * \\sigma^2_B$$\nScutari 2.8  From the first three lines of Table 2.1, prove that the joint distribution of E, G and V is trivariate normal.\n This one is a doozy and I really needed to consult the solutions in the book for this one. Let\u0026rsquo;s first remind ourselves of the first lines of said table:\nTo approach this problem it is useful to point out that the logarithm of the density of a multivariate normal distribution is defined as such:\n$$f(x) \\propto -\\frac{1}{2}(x-\\mu)^T\\sum^{-2}(x-\\mu)$$\nwith $x$ being a random vector and $\\mu$ denoting our expectation. $\\sum$ identifies the covariance matrix.\nSimplifying this, we can transform our variables $G$, $E$, and $V$ to give them a zero marginal expectation and a unity marginal variance. That is a very long-winded way of saying: we normalise our variables:\n$$\\overline G = \\frac{G-E(G)}{\\sqrt{VAR(G)}} = \\frac{G-50}{10} \\sim Normal(0, 1)$$ $$\\overline E = \\frac{E-E(E)}{\\sqrt{VAR(E)}} = \\frac{E-50}{10} \\sim Normal(0, 1)$$ $$\\overline V = \\frac{V-E(V)}{\\sqrt{VAR(V)}} = \\frac{V-50}{10}$$ Solving for $\\overline V | \\overline G, \\overline E$, we obtain:\n\\begin{equation} \\overline V | \\overline G, \\overline E = Normal\\left(\\frac{1}{2} \\overline G + \\sqrt{\\frac{1}{2}} \\overline E , (\\frac{1}{2})^2 \\right) \\end{equation}\nI have to honestly that I don\u0026rsquo;t quite understand how this happened and if anyone reading this has intuition for this solution, please let me know.\nNow, we can compute the joint density distribution of these three normalised variables:\n$$\\begin{eqnarray} f(\\overline G, \\overline E, \\overline V) \u0026amp;\\propto\u0026amp; f(\\overline G)+f(\\overline E)+f(\\overline V | \\overline G, \\overline E) \\newline \u0026amp;=\u0026amp; -\\frac{g^2}{2}-\\frac{e^2}{2}-2 \\left( v- \\frac{1}{2}g - \\sqrt{\\frac{1}{2}}e \\right)^2 \\newline \u0026amp;=\u0026amp; -\\begin{bmatrix} g \\newline e \\newline v\\end{bmatrix}^T \\begin{bmatrix} 1 \u0026amp; \\frac{\\sqrt{2}}{2} \u0026amp; -1\\newline \\frac{\\sqrt{2}}{2} \u0026amp; \\frac{3}{2} \u0026amp; -\\sqrt{2} \\newline -1 \u0026amp; -\\sqrt{2} \u0026amp; 2 \\end{bmatrix} \\begin{bmatrix} g \\newline e \\newline v\\end{bmatrix} \\newline \u0026amp;=\u0026amp; -\\frac{1}{2} \\begin{bmatrix} g \\newline e \\newline v\\end{bmatrix}^T \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; \\frac{1}{2}\\newline 0 \u0026amp; 1 \u0026amp; \\frac{1}{2} \\newline \\frac{1}{2} \u0026amp; \\sqrt{\\frac{1}{2}} \u0026amp; 1 \\end{bmatrix} \\begin{bmatrix} g \\newline e \\newline v\\end{bmatrix} \\newline \\end{eqnarray}$$\nI have to admit that most of this is, as of right now, beyond me as I came to this book for the \u0026ldquo;applications in R\u0026rdquo; in the first place. The book concludes that this results in:\n$$VAR \\left( \\begin{bmatrix} \\overline G \\newline \\overline E \\newline \\overline V\\end{bmatrix} \\right) = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; \\frac{1}{2}\\newline 0 \u0026amp; 1 \u0026amp; \\frac{1}{2} \\newline \\frac{1}{2} \u0026amp; \\sqrt{\\frac{1}{2}} \u0026amp; 1 \\end{bmatrix} $$\nwhich results in our proof.\nSession Info sessionInfo()\r ## R version 4.2.1 (2022-06-23 ucrt)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19044)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_Germany.utf8 LC_CTYPE=English_Germany.utf8 LC_MONETARY=English_Germany.utf8 LC_NUMERIC=C LC_TIME=English_Germany.utf8 ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] tidybayes_3.0.2 tidyr_1.2.0 ggplot2_3.3.6 bnlearn_4.8.1 ## ## loaded via a namespace (and not attached):\r## [1] styler_1.8.0 tidyselect_1.1.2 xfun_0.33 bslib_0.4.0 purrr_0.3.4 lattice_0.20-45 colorspace_2.0-3 vctrs_0.4.1 generics_0.1.3 ## [10] htmltools_0.5.3 yaml_2.3.5 utf8_1.2.2 rlang_1.0.5 R.oo_1.25.0 jquerylib_0.1.4 pillar_1.8.1 glue_1.6.2 withr_2.5.0 ## [19] DBI_1.1.3 R.utils_2.12.0 distributional_0.3.1 R.cache_0.16.0 lifecycle_1.0.2 stringr_1.4.1 posterior_1.3.1 munsell_0.5.0 blogdown_1.13 ## [28] gtable_0.3.1 R.methodsS3_1.8.2 coda_0.19-4 evaluate_0.16 labeling_0.4.2 knitr_1.40 fastmap_1.1.0 parallel_4.2.1 fansi_1.0.3 ## [37] highr_0.9 arrayhelpers_1.1-0 backports_1.4.1 checkmate_2.1.0 scales_1.2.1 cachem_1.0.6 jsonlite_1.8.0 abind_1.4-5 farver_2.1.1 ## [46] tensorA_0.36.2 digest_0.6.29 svUnit_1.0.6 stringi_1.7.8 bookdown_0.29 dplyr_1.0.9 grid_4.2.1 ggdist_3.2.0 cli_3.3.0 ## [55] tools_4.2.1 magrittr_2.0.3 sass_0.4.2 tibble_3.1.8 pkgconfig_2.0.3 ellipsis_0.3.2 assertthat_0.2.1 rmarkdown_2.16 rstudioapi_0.14 ## [64] R6_2.5.1 compiler_4.2.1\r ","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622574000,"objectID":"63e930fdd40377ce5617fa845a2d3e93","permalink":"https://www.erikkusch.com/courses/bayes-nets/part-2/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/courses/bayes-nets/part-2/","section":"courses","summary":"Answers and solutions to the exercises belonging to Part 2 in [Bayesian Networks with Examples in R](https://www.bnlearn.com/book-crc/) by M. Scutari and J.-B. Denis.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Gaussian Bayesian Networks","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Small Worlds in Large Worlds Material  \rSlides Chapter 1 \rSlides Chapter 2  Introduction These are answers and solutions to the exercises at the end of chapter 2 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Taras Svirskyi and Jeffrey Girard.\nEasy Exercises Practice E1 Question: Which of the expressions below correspond to the statement: the probability of rain on Monday?\n $Pr(rain)$ $Pr(rain|Monday)$ $Pr(Monday|rain)$ $\\frac{Pr(rain,Monday)}{Pr(Monday)}$  Answer:\n 2, $Pr(rain|Monday)$ - reads as \u0026ldquo;the probability of rain, given that it is Monday\u0026rdquo;. 4, $\\frac{Pr(rain|Monday)}{Pr(Monday)}$ - reads as \u0026ldquo;the probability that is raining and a Monday, divided by the probability of it being a Monday\u0026rdquo; which is the same as \u0026ldquo;the probability of rain, given that it is Monday. This is simply just the Bayes theorem in action.  Practice E2 Question: Which of the following statements corresponds to the expression: $Pr(Monday|rain)$?\n The probability of rain on Monday. The probability of rain, given that it is Monday. The probability that it is Monday, given that it is raining. The probability that it is Monday and that it is raining.  Answer:\n 3, The probability that it is Monday, given that it is raining.  Practice E3 Question: Which of the expressions below correspond to the statement: the probability that it is Monday, given that it is raining?\n $Pr(Monday|rain)$ $Pr(rain|Monday)$ $Pr(rain|Monday)Pr(Monday)$ $\\frac{Pr(rain|Monday)Pr(Monday)}{Pr(rain)}$ $\\frac{Pr(Monday|rain)Pr(rain)}{Pr(Monday)}$  Answer:\n 1, $Pr(Monday|rain)$ 4, $\\frac{Pr(rain|Monday)Pr(Monday)}{Pr(rain)}$  Practice E4 Question: The Bayesian statistician Bruno de Finetti (1906-1985) began his book on probability theory with the declaration: “PROBABILITY DOES NOT EXIST.” The capitals appeared in the original, so I imagine de Finetti wanted us to shout the statement. What he meant is that probability is a device for describing uncertainty from the perspective of an observer with limited knowledge; it has no objective reality. Discuss the globe tossing example from the chapter, in light of this statement. What does it mean to say “the probability of water is 0.7”?\nAnswer:\n Completely uninformed and looking only at random samples, we would come to the conclusion that 70% of the Earth are covered by water. However, this estimate could be heavily biased once confounding factors are taken into account. Factors such as inaccuracy of the globe model we are tossing when compared to the real globe (i.e. the model is perfectly spherical, but the Earth itself is a flattened ellipsoid).  Medium Exercises This is where we get into R application of Bayes. Here, I load a few packages to make my outputs a bit nicer to look at:\nrm(list = ls())\rlibrary(ggplot2)\rlibrary(cowplot)\r Practice M1 \u0026amp; M2 Question: Recall the globe tossing model from the chapter. Compute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for p.\n W,W,W W,W,W,L L,W,W,L,W,W,W  Now assume a prior for p that is equal to zero when p\u0026lt;0.5 and is a positive constant when p≥0.5. Again compute and plot the grid approximate posterior distribution for each of the sets of observations in the problem just above.\nAnswer:\n# Register the data we observed\rdata1 \u0026lt;- c(\u0026quot;W\u0026quot;, \u0026quot;W\u0026quot;, \u0026quot;W\u0026quot;)\rdata2 \u0026lt;- c(\u0026quot;W\u0026quot;, \u0026quot;W\u0026quot;, \u0026quot;W\u0026quot;, \u0026quot;L\u0026quot;)\rdata3 \u0026lt;- c(\u0026quot;L\u0026quot;, \u0026quot;W\u0026quot;, \u0026quot;W\u0026quot;, \u0026quot;L\u0026quot;, \u0026quot;W\u0026quot;, \u0026quot;W\u0026quot;, \u0026quot;W\u0026quot;)\rdata_ls \u0026lt;- list(data1, data2, data3)\rnames(data_ls) \u0026lt;- c(paste(data1, collapse = \u0026quot;\u0026quot;), paste(data2, collapse = \u0026quot;\u0026quot;), paste(data3, collapse = \u0026quot;\u0026quot;))\r# Define grid to sample\rp_grid \u0026lt;- seq(0, 1, length.out = 25)\rng \u0026lt;- length(p_grid)\r# Register the priors\rpriors_ls \u0026lt;- list(NA, NA)\rnames(priors_ls) \u0026lt;- c(\u0026quot;uniform prior (M1)\u0026quot;, \u0026quot;disjunct prior (M2)\u0026quot;)\rpriors_ls[[1]] \u0026lt;- rep(1, ng)\rpriors_ls[[2]] \u0026lt;- ifelse(p_grid \u0026lt; 0.5, 0, 1)\r# Generate a list within which to store plots for later output all together\rplot_ls \u0026lt;- as.list(rep(NA, length(data_ls) * length(priors_ls)))\rcounter \u0026lt;- 1\r# Calculate Posteriors\rfor (i in 1:length(data_ls)) { # loop over data sets\rdata \u0026lt;- data_ls[[i]] # extract data from list\rn \u0026lt;- length(data) # number of observations\rw \u0026lt;- sum(data == \u0026quot;W\u0026quot;) # number of observed water\rfor (k in 1:length(priors_ls)) { # loop over priors\rprior \u0026lt;- priors_ls[[k]] # extract prior\rlikelihood \u0026lt;- dbinom(w, n, p_grid) # calculate likelihood of water in grid\rposterior \u0026lt;- likelihood * prior # compute posterior\rposterior \u0026lt;- posterior / sum(posterior) # standardise posterior\r# save data to data frame for ggplot\rdf \u0026lt;- data.frame(\rparam = p_grid,\rprob = posterior,\rptype = rep(\u0026quot;posterior\u0026quot;, ng)\r)\r# ggplotting to plot list\rplot_ls[[counter]] \u0026lt;- ggplot(df, aes(x = param, y = prob)) +\rgeom_line() +\rgeom_point() +\rtheme_bw() +\rlabs(title = paste(names(data_ls)[i], names(priors_ls)[k], sep = \u0026quot; \u0026quot;))\rcounter \u0026lt;- counter + 1\r} # end of priors loop\r} # end of data set loop\rplot_grid(plotlist = plot_ls, ncol = 2, labels = \u0026quot;AUTO\u0026quot;)\r Practice M3 Question: Suppose there are two globes, one for Earth and one for Mars. The Earth globe is 70% covered in water. The Mars globe is 100% land. Further suppose that one of these globes–you don’t know which–was tossed in the air and produces a “land” observation. Assume that each globe was equally likely to be tossed. Show that the posterior probability that the globe was the Earth, conditional on seeing “land” ($Pr(Earth|land)$), is 0.23.\nAnswer:\nFrom the question, we know that:\n $P(land|Earth) = 1-0.7 = 0.3$ $P(land|Mars) = 1$ $P(Earth) = P(Mars) = .5$  According to Bayes' theorem, we know that:\n$P(Earth|Land) = \\frac{P(land|Earth)P(Earth)}{P(land)}$\nConclusively, we are only missing $P(land)$ which we can calculate from:\n$P(land) = P(land|Earth)P(Earth)+P(land|Mars)Pr(Mars)$\n$= 0.30.5+10.5=0.65$\nFinally, we plug all these values into the above Bayes' theorem and obtain: $P(Earth|Land) = \\frac{0.3*0.5}{0.65} = 0.2307692$\nIn R, we can do this:\n(p_e_l \u0026lt;- (1 - 0.7) * 0.5 / ((1 - 0.7) * 0.5 + 1. * 0.5))\r ## [1] 0.2307692\r Practice M4 Question: Suppose you have a deck with only three cards. Each card has two sides, and each side is either black or white. One card has two black sides. The second card has one black and one white side. The third card has two white sides. Now suppose all three cards are placed in a bag and shuffled. Someone reaches into the bag and pulls out a card and places it flat on a table. A black side is shown facing up, but you don’t know the colour of the side facing down. Show that the probability that the other side is also black is 2/3. Use the counting method (Section 2 of the chapter) to approach this problem. This means counting up the ways that each card could produce the observed data (a black card facing up on the table).\nAnswer:\nI made a small visualisation of this here: By Counting:\nAs you can see, out of all draws that start with a black side facing up on the first draw (3 total paths), only two conclude to the other side also being black. Thus, the probability is two thirds.\nBayes' Theorem:\n$P(Second = B|First = B) = \\frac{P(Second = B, First = B)}{P(First = B)} = \\frac{P(BB)}{P(BB)+P(WB)*P(First = B|WB)}$ $= \\frac{1/3}{(1/3 + 1/3 * 1/2)} = 2/3$\nVia R:\nbb.ways \u0026lt;- 2\rwb.ways \u0026lt;- 1\rww.ways \u0026lt;- 0\rlikelihood \u0026lt;- c(bb.ways, wb.ways, ww.ways)\rprior \u0026lt;- c(1, 1, 1)\rposterior \u0026lt;- prior * likelihood\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1] == 2 / 3\r ## [1] TRUE\r Practice M5 Question: Now suppose there are four cards: BB, BW, WW, and another BB. Again suppose a card is drawn from the bag and a black side appears face up. Again calculate the probability that the other side is black.\nAnswer:\nHere\u0026rsquo;s an update of my previous visualisation for this: By Counting:\nAs you can see, out of all draws that start with a black side facing up on the first draw (5 total paths), four conclude to the other side also being black. Thus, the probability is 4/5 which is 0.8.\nBayes' Theorem:\n$P(Second = B|First = B) = \\frac{P(Second = B, First = B)}{P(First = B)} = \\frac{P(BB)}{P(BB)+P(WB)*P(First = B|WB)}$ $=\\frac{1/2}{(1/2 + 1/4 * 1/2)} = 4/5$\nVia R:\nbb.ways \u0026lt;- 2\rwb.ways \u0026lt;- 1\rww.ways \u0026lt;- 0\rlikelihood \u0026lt;- c(bb.ways, wb.ways, ww.ways)\rprior \u0026lt;- c(2, 1, 1)\rposterior \u0026lt;- prior * likelihood\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1] == 4 / 5\r ## [1] TRUE\r Practice M6 Question: Imagine that black ink is heavy, and so cards with black sides are heavier than cards with white sides. As a result, it’s less likely that a card with black sides is pulled from the bag. So again assume that there are three cards: BB, BW, and WW. After experimenting a number of times, you conclude that for every way to pull the BB card from the bag, there are 2 ways to pull the BW card and 3 ways to pull the WW card. Again suppose that a card is pulled and a black side appears face up. Show that the probability the other side is black is now 0.5. Use the counting method, as before.\nAnswer:\nHere\u0026rsquo;s an update of my previous visualisation for this: By Counting:\nOut of all draws that start with a black side facing up on the first draw (4 total paths), only 2 now conclude to the other side also being black. Thus, the probability is 1/2 which is 0.5.\nBayes' Theorem:\n$P(Second = B|First = B) = \\frac{P(Second = B, First = B)}{P(First = B)} = \\frac{P(BB)}{P(BB)+P(WB)*P(First = B|WB)}$ $= \\frac{1/6}{(1/6 + 2/6 * 1/2)} = 1/2$\nVia R:\nbb.ways \u0026lt;- 2\rwb.ways \u0026lt;- 1\rww.ways \u0026lt;- 0\rlikelihood \u0026lt;- c(bb.ways, wb.ways, ww.ways)\rprior \u0026lt;- c(1, 2, 3)\rposterior \u0026lt;- prior * likelihood\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1] == 0.5\r ## [1] TRUE\r Practice M7 Question: Assume again the original card problem, with a single card showing a black side face up. Before looking at the other side, we draw another card from the bag and lay it face up on the table. The face that is shown on the new card is white. Show that the probability that the first card, the one showing a black side, has black on its other side is now 0.75. Use the counting method, if you can. Hint: Treat this like the sequence of globe tosses, counting all the ways to see each observation, for each possible first card.\nAnswer:\nHere\u0026rsquo;s an update of my previous visualisation for this: By Counting:\nOut of all draws that start with a black side facing up on the first draw (12 total paths), 8 now conclude to the next card being places white-side facing up. Thus, the probability is 8/12 which is 0.75.\nVia R:\ncard.bb.likelihood \u0026lt;- 2 * 3 # bb pulled first (either side), next card is ww (either side) or wb (white-side up)\rcard.wb.likelihood \u0026lt;- 1 * 2 # wb pulled black side up, next card is ww (either side)\rcard.ww.likelihood \u0026lt;- 0\rlikelihood \u0026lt;- c(card.bb.likelihood, card.wb.likelihood, card.ww.likelihood)\rprior \u0026lt;- c(1, 1, 1)\rposterior \u0026lt;- prior * likelihood\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1] == 0.75\r ## [1] TRUE\r Hard Exercises Practice H1 Question: Suppose there are two species of panda bear. Both are equally common in the wild and live in the same place. They look exactly alike and eat the same food, and there is yet no genetic assay capable of telling them apart. They differ however in family sizes. Species A gives birth to twins 10% of the time, otherwise birthing a single infant. Species B births twins 20% of the time, otherwise birthing singleton infants. Assume these numbers are known with certainty, from many years of field research. Now suppose you are managing a captive panda breeding program. You have a new female panda of unknown species, and she has just given birth to twins. What is the probability that her next birth will also be twins?\nAnswer:\nBy Hand:\nFrom the question, we know that:\n $Pr(twins|A)=0.1$ $Pr(twins|B)=0.2$ $Pr(A)=0.5$ $Pr(B)=0.5$  We know want to calculate $Pr(twins)$ which is given as:\n$Pr(twins)=Pr(twins|A)Pr(A)+Pr(twins|B)Pr(B)$\nFor this, however, we need to know the probability of our individual belonging to species A or B, respectively. For this, we will use the Bayes' Theorem:\n$Pr(A|twins)=\\frac{Pr(twins|A)Pr(A)}{Pr(twins)}=\\frac{0.1*(0.5)}{0.15}=1/3$\n$Pr(B|twins)=\\frac{Pr(twins|B)Pr(B)}{Pr(twins)}=\\frac{0.2*(0.5)}{0.15}=2/3$\nThese values can be used as $Pr(A)$ and $Pr(B)$ respectively in the formula to compute $Pr(twins)$ above as such:\n$Pr(twins) = 0.11/3 + 0.22/3 = 1/6$\nIn R:\np_twins_A \u0026lt;- 0.1\rp_twins_B \u0026lt;- 0.2\rlikelihood \u0026lt;- c(p_twins_A, p_twins_B)\rprior \u0026lt;- c(1, 1)\rposterior \u0026lt;- prior * likelihood\rposterior \u0026lt;- posterior / sum(posterior)\rsum(posterior * likelihood) == 1 / 6\r ## [1] TRUE\r Practice H2 Question: Recall all the facts from the problem above. Now compute the probability that the panda we have is from species A, assuming we have observed only the first birth and that it was twins.\nAnswer: We already now from our answer above that it is 1/3.\nBy Hand:\n$Pr(A|twins)=\\frac{Pr(twins|A)Pr(A)}{Pr(twins)}=\\frac{0.1*(0.5)}{0.15}=1/3$\nIn R:\np_twins_A \u0026lt;- 0.1\rp_twins_B \u0026lt;- 0.2\rlikelihood \u0026lt;- c(p_twins_A, p_twins_B)\rprior \u0026lt;- c(1, 1)\rposterior \u0026lt;- prior * likelihood\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1] # 0.33\r ## [1] 0.3333333\r Practice H3 Question: Continuing on from the previous problem, suppose the same panda mother has a second birth and that it is not twins, but a singleton infant. Compute the posterior probability that this panda is species A.\nAnswer:\nBy Hand:\nThe probability of birthing singleton infants given a certain species-membership is given by:\n$Pr(single|A)=1–Pr(twins|A)=1–0.1=0.9$\n$Pr(single|B)=1–Pr(twins|B)=1–0.2=0.8$\nWe already know species membership probability given the first birth having been a twin-birth:\n$Pr(A)=1/3$\n$Pr(B)=2/3$\nNext, we require the probability of a singleton birth overall, which we calculate as follows:\n$Pr(single)=Pr(single|A)Pr(A)+Pr(single|B)Pr(B)$\n$=0.9(1/3)+0.8(2/3)=5/6$\nFinally, we are ready to use the Bayes' Theorem:\n$Pr(A|single)=\\frac{Pr(single|A)Pr(A)}{Pr(single)}=\\frac{0.9(1/3)}{5/6}=0.36$\nIn R:\n## TWO STEPS WITH UPDATING\rp_twins_A \u0026lt;- 0.1\rp_twins_B \u0026lt;- 0.2\r# first Bayesian update\rlikelihood_twins \u0026lt;- c(p_twins_A, p_twins_B)\rprior \u0026lt;- c(1, 1)\rposterior \u0026lt;- prior * likelihood_twins\rposterior \u0026lt;- posterior / sum(posterior)\r# second Bayesian update\rlikelihood_single \u0026lt;- c(1 - p_twins_A, 1 - p_twins_B)\rprior \u0026lt;- posterior\rposterior \u0026lt;- prior * likelihood_single\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1] == 0.36\r ## [1] FALSE\r ## IN ONE STEP\rp_twins_A \u0026lt;- 0.1\rp_twins_B \u0026lt;- 0.2\r# likelihood of two events (p(twins_step1 \u0026amp; single_step2|species=X))\rlikelihood_twins_single \u0026lt;- c(\rp_twins_A * (1 - p_twins_A),\rp_twins_B * (1 - p_twins_B)\r)\rprior \u0026lt;- c(1, 1)\rposterior \u0026lt;- prior * likelihood_twins_single\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1] == 0.36\r ## [1] TRUE\r Practice H4 Question: A common boast of Bayesian statisticians is that Bayesian inferences makes it easy to use all of the data, even if the data are of different types. So suppose now that a veterinarian comes along who has a new genetic test that she claims can identify the species of our mother panda. But the test, like all tests, is imperfect. This is the information you have about the test:\n The probability it correctly identifies a species A panda is 0.8. The probability it correctly identifies a species B panda is 0.65.  The vet administers the test to your panda and tells you that the test is positive for species A. First ignore your previous information from the births and compute the posterior probability that your panda is species A. Then redo your calculation, now using the birth data as well.\nAnswer:\nBy Hand:\nAgain, the question hands us some information:\n $Pr(+A|A)=0.8$ $Pr(+A|B)=1 − 0.65 = 0.35$  Importantly here, the test was positive for species A. I had previously overlooked this. Thanks to Aramis Farias for pointing this out to me!\nCurrently, we have to assume that both species are equally likely here:\n $Pr(A)=0.5$ $Pr(B)=0.5$  Now, to calculate $Pr(A|+)$, we require $Pr(+)$:\n$Pr(+)=Pr(+|A)Pr(A)+Pr(+|B)Pr(B)$\n$=0.8(0.5)+0.35(0.5)=0.575$\nFinally, we calculate $Pr(A|+)$: $Pr(A|+)=\\frac{Pr(+A|A)Pr(A)}{Pr(+)}=\\frac{0.8(0.5)}{0.575}\\sim 0.6987$\nTaking into account our previous knowledge on births, we have to set:\n $Pr(A)=0.36$ $Pr(B)=1-Pr(A)=0.64$  We plug these values into the formulae above and obtain:\n$Pr(+)=Pr(+|A)Pr(A)+Pr(+|B)Pr(B)$\n$=0.8(0.36)+0.35(0.64)=0.512$\nFinally, we calculate $Pr(A|+)$: $Pr(A|+)=\\frac{Pr(+A|A)Pr(A)}{Pr(+)}=\\frac{0.8(0.36)}{0.512}=0.5625$\nGiven our test alone, we are probably overestimating assignment to species A, here.\nIn R:\n# WITHOUT BIRTH-INFORMATION\rlikelihood_test \u0026lt;- c(0.8, 0.35)\rprior \u0026lt;- c(1, 1)\rposterior_vet \u0026lt;- prior * likelihood_test\rposterior_vet \u0026lt;- posterior_vet / sum(posterior_vet)\rposterior_vet[1]\r ## [1] 0.6956522\r # WITH BIRT-INFORMATION\rp_twins_A \u0026lt;- 0.1\rp_twins_B \u0026lt;- 0.2\r# likelihood of two events (p(twins_step1 \u0026amp; single_step2|species=X))\rlikelihood_twins_single \u0026lt;- c(\rp_twins_A * (1 - p_twins_A),\rp_twins_B * (1 - p_twins_B)\r)\rprior \u0026lt;- posterior_vet\rposterior \u0026lt;- prior * likelihood_twins_single\rposterior \u0026lt;- posterior / sum(posterior)\rposterior[1]\r ## [1] 0.5625\r Session Info sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] cowplot_1.1.1 ggplot2_3.4.1\r## ## loaded via a namespace (and not attached):\r## [1] highr_0.10 bslib_0.4.2 compiler_4.2.3 pillar_1.8.1 jquerylib_0.1.4 R.methodsS3_1.8.2 R.utils_2.12.2 tools_4.2.3 digest_0.6.31 jsonlite_1.8.4 ## [11] evaluate_0.20 lifecycle_1.0.3 tibble_3.2.1 gtable_0.3.1 R.cache_0.16.0 pkgconfig_2.0.3 rlang_1.1.0 cli_3.6.0 rstudioapi_0.14 yaml_2.3.7 ## [21] blogdown_1.16 xfun_0.37 fastmap_1.1.1 withr_2.5.0 dplyr_1.1.0 styler_1.9.1 knitr_1.42 generics_0.1.3 vctrs_0.6.1 sass_0.4.5 ## [31] tidyselect_1.2.0 grid_4.2.3 glue_1.6.2 R6_2.5.1 fansi_1.0.4 rmarkdown_2.20 bookdown_0.33 farver_2.1.1 purrr_1.0.1 magrittr_2.0.3 ## [41] scales_1.2.1 htmltools_0.5.4 colorspace_2.1-0 labeling_0.4.2 utf8_1.2.3 munsell_0.5.0 cachem_1.0.7 R.oo_1.25.0\r ","date":1609804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609860360,"objectID":"eaceaca8f9aea494769157f35e88504b","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-02/","publishdate":"2021-01-05T00:00:00Z","relpermalink":"/courses/rethinking/chapter-02/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 2 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 01 \u0026 02","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some Lecture Slides  for this session.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"31fb6ddf82646e18ec228710c5676a8c","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/2_statistical-terminology-the-basics-misconceptions-and-pedantics/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/2_statistical-terminology-the-basics-misconceptions-and-pedantics/","section":"courses","summary":"I have prepared some Lecture Slides  for this session.","tags":null,"title":"Statistical Terminology","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory These are the solutions to the exercises contained within the handout to Introduction to R which walks you through the basics of the R machinery. R is a coding language that can be highly individualised and hence there are often multiple solutions to the same problem. Within these solutions, I shall only present you with one solution for every given task. However, do keep in mind that there is probably a myriad of other ways to achieve your goal.\nI have prepared some Lecture Slides  for this session.\nCreating and Inspecting Objects Vector  A vector reading: \u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;  Letters_vec \u0026lt;- c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;)\rLetters_vec\r ## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r length(Letters_vec)\r ## [1] 3\r  A vector reading: 1, 2, 3  Numbers_vec \u0026lt;- c(1, 2, 3)\rNumbers_vec\r ## [1] 1 2 3\r length(Numbers_vec)\r ## [1] 3\r  A vector reading: TRUE, FALSE  Logic_vec \u0026lt;- c(TRUE, FALSE)\rLogic_vec\r ## [1] TRUE FALSE\r length(Logic_vec)\r ## [1] 2\r  A vector of the elements of the first three vectors  Big_vec \u0026lt;- c(Letters_vec, Numbers_vec, Logic_vec)\rBig_vec\r ## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot; \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;3\u0026quot; \u0026quot;TRUE\u0026quot; \u0026quot;FALSE\u0026quot;\r length(Big_vec)\r ## [1] 8\r  A vector reading as a sequence of full numbers from 1 to 20  Seq_vec \u0026lt;- c(1:20)\rSeq_vec\r ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\r length(Seq_vec)\r ## [1] 20\r Factor  A factor reading: \u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;  Letters_fac \u0026lt;- factor(x = c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;))\rLetters_fac\r ## [1] A B C\r## Levels: A B C\r length(Letters_fac)\r ## [1] 3\r  A factor reading: 1, 2, 3  Numbers_fac \u0026lt;- factor(x = c(1, 2, 3))\rNumbers_fac\r ## [1] 1 2 3\r## Levels: 1 2 3\r length(Numbers_fac)\r ## [1] 3\r  A factor reading: 1, 2, 3 but only levels 1 and 2 are allowed  Constrained_fac \u0026lt;- factor(x = c(1, 2, 3), levels = c(1, 2))\rConstrained_fac\r ## [1] 1 2 \u0026lt;NA\u0026gt;\r## Levels: 1 2\r length(Constrained_fac)\r ## [1] 3\r  A factor reading: 1, 2, 3 levels 1 - 4 are allowed  Expanded_fac \u0026lt;- factor(x = c(1, 2, 3), levels = c(1, 2, 3, 4))\rExpanded_fac\r ## [1] 1 2 3\r## Levels: 1 2 3 4\r length(Expanded_fac)\r ## [1] 3\r Matrix  The first two vectors we established in distinct columns of a matrix  Combine_mat \u0026lt;- matrix(data = c(Numbers_vec, Letters_vec), ncol = 2)\rCombine_mat\r ## [,1] [,2]\r## [1,] \u0026quot;1\u0026quot; \u0026quot;A\u0026quot; ## [2,] \u0026quot;2\u0026quot; \u0026quot;B\u0026quot; ## [3,] \u0026quot;3\u0026quot; \u0026quot;C\u0026quot;\r dim(Combine_mat)\r ## [1] 3 2\r  The first two vectors we established in distinct rows of a matrix  Pivot_mat \u0026lt;- matrix(data = c(Numbers_vec, Letters_vec), nrow = 2, byrow = TRUE)\rPivot_mat\r ## [,1] [,2] [,3]\r## [1,] \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;3\u0026quot; ## [2,] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r dim(Pivot_mat)\r ## [1] 2 3\r  The above matrix with meaningful names  Names_mat \u0026lt;- Pivot_mat\rdimnames(Names_mat) \u0026lt;- list(c(\u0026quot;Numbers\u0026quot;, \u0026quot;Letters\u0026quot;))\rNames_mat\r ## [,1] [,2] [,3]\r## Numbers \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;3\u0026quot; ## Letters \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r dim(Names_mat)\r ## [1] 2 3\r Data Frame  The first matrix we established as a data frame  Combine_df \u0026lt;- data.frame(Combine_mat)\rCombine_df\r ## X1 X2\r## 1 1 A\r## 2 2 B\r## 3 3 C\r dim(Combine_df)\r ## [1] 3 2\r  The previous data frame with meaningful names  Names_df \u0026lt;- Combine_df\rcolnames(Names_df) \u0026lt;- c(\u0026quot;Numbers\u0026quot;, \u0026quot;Letters\u0026quot;)\rNames_df\r ## Numbers Letters\r## 1 1 A\r## 2 2 B\r## 3 3 C\r dim(Names_df)\r ## [1] 3 2\r List  The first two vectors we created  Vectors_ls \u0026lt;- list(Numbers_vec, Letters_vec)\rVectors_ls\r ## [[1]]\r## [1] 1 2 3\r## ## [[2]]\r## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r length(Vectors_ls)\r ## [1] 2\r Statements and Loops Statements  Numbers_vec contains more elements than Letters_fac?  length(Numbers_vec) \u0026gt; length(Letters_fac)\r ## [1] FALSE\r  The first column of Combine_df is shorter than Vectors_ls?  length(Combine_df[, 1]) \u0026lt; length(Vectors_ls)\r ## [1] FALSE\r  The elements of Letters_vec are the same as the elements of Letters_fac?  Letters_vec == Letters_fac\r ## [1] TRUE TRUE TRUE\r Loops  Print each element of Vectors_ls  for (i in 1:length(Vectors_ls)) {\rprint(Vectors_ls[[i]])\r}\r ## [1] 1 2 3\r## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r  Print each element of Numbers_vec + 1  Numbers_veca \u0026lt;- Numbers_vec + 1\rfor (i in 1:length(Numbers_veca)) {\rprint(Numbers_veca[i])\r}\r ## [1] 2\r## [1] 3\r## [1] 4\r  Subtract 1 from each element of the first column of Combine_mat and print each element separately  Mat_column \u0026lt;- Combine_mat[, 1] # extract data\rMat_column \u0026lt;- as.numeric(Mat_column) # convert to numeric\rMat_column \u0026lt;- Mat_column - 1 # substract 1\rfor (i in 1:length(Mat_column)) {\rprint(Mat_column[i])\r}\r ## [1] 0\r## [1] 1\r## [1] 2\r Useful Commands  Read out your current working directory (not showing you the result as it is different on every machine, it should start like this \u0026ldquo;C:/Users/\u0026hellip;.\u0026quot;)  getwd()\r  Inspect the Vectors_ls object using the View() function (again, I am not showing you the result as this only works directly in R or Rstudio)  View(Vectors_ls)\r  Inspect the Combine_df object using the View() function (again, I am not showing you the result as this only works directly in R or Rstudio)  View(Combine_df)\r  Get the help documentation for the as.matrix() function (again, I am not showing you the result as this only works directly in R or Rstudio)  `?`(as.matrix)\r  Install and load the dplyr package  install.packages(\u0026quot;dplyr\u0026quot;)\rlibrary(dplyr)\r  Remove the Logic_vec object from your working environment  rm(Logic_vec)\r  Clear your entire working environment  ls() # this command shows you all the object in the environment\r ## [1] \u0026quot;Big_vec\u0026quot; \u0026quot;Combine_df\u0026quot; \u0026quot;Combine_mat\u0026quot; \u0026quot;Constrained_fac\u0026quot;\r## [5] \u0026quot;Expanded_fac\u0026quot; \u0026quot;i\u0026quot; \u0026quot;Letters_fac\u0026quot; \u0026quot;Letters_vec\u0026quot; ## [9] \u0026quot;Mat_column\u0026quot; \u0026quot;Names_df\u0026quot; \u0026quot;Names_mat\u0026quot; \u0026quot;Numbers_fac\u0026quot; ## [13] \u0026quot;Numbers_vec\u0026quot; \u0026quot;Numbers_veca\u0026quot; \u0026quot;Pivot_mat\u0026quot; \u0026quot;Seq_vec\u0026quot; ## [17] \u0026quot;Vectors_ls\u0026quot;\r rm(list = ls())\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"d61ca3d6408c0793f558365f4e4847b9","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/introduction-to-r/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/introduction-to-r/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to Introduction to R which walks you through the basics of the `R` machinery. `R` is a coding language that can be highly individualised and hence there are often multiple solutions to the same problem. Within these solutions, I shall only present you with one solution for every given task. However, do keep in mind that there is probably a myriad of other ways to achieve your goal.","tags":["R","Statistics"],"title":"Introduction to R","type":"docs"},{"authors":null,"categories":["BioStat101"],"content":"Theory These are the solutions to the exercises contained within the handout to Introduction to R which walks you through the basics of the R machinery. R is a coding language that can be highly individualised and hence there are often multiple solutions to the same problem. Within these solutions, I shall only present you with one solution for every given task. However, do keep in mind that there is probably a myriad of other ways to achieve your goal.\n\r\rTheory slides for this session.\rClick the outline of the presentation below to get to the HTML version of the slides for this session.\r  \r\rCreating and Inspecting Objects Vector  A vector reading: \u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;  Letters_vec \u0026lt;- c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;)\rLetters_vec\r ## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r length(Letters_vec)\r ## [1] 3\r  A vector reading: 1, 2, 3  Numbers_vec \u0026lt;- c(1, 2, 3)\rNumbers_vec\r ## [1] 1 2 3\r length(Numbers_vec)\r ## [1] 3\r  A vector reading: TRUE, FALSE  Logic_vec \u0026lt;- c(TRUE, FALSE)\rLogic_vec\r ## [1] TRUE FALSE\r length(Logic_vec)\r ## [1] 2\r  A vector of the elements of the first three vectors  Big_vec \u0026lt;- c(Letters_vec, Numbers_vec, Logic_vec)\rBig_vec\r ## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot; \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;3\u0026quot; \u0026quot;TRUE\u0026quot; \u0026quot;FALSE\u0026quot;\r length(Big_vec)\r ## [1] 8\r  A vector reading as a sequence of full numbers from 1 to 20  Seq_vec \u0026lt;- c(1:20)\rSeq_vec\r ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\r length(Seq_vec)\r ## [1] 20\r Factor  A factor reading: \u0026ldquo;A\u0026rdquo;, \u0026ldquo;B\u0026rdquo;, \u0026ldquo;C\u0026rdquo;  Letters_fac \u0026lt;- factor(x = c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;))\rLetters_fac\r ## [1] A B C\r## Levels: A B C\r length(Letters_fac)\r ## [1] 3\r  A factor reading: 1, 2, 3  Numbers_fac \u0026lt;- factor(x = c(1, 2, 3))\rNumbers_fac\r ## [1] 1 2 3\r## Levels: 1 2 3\r length(Numbers_fac)\r ## [1] 3\r  A factor reading: 1, 2, 3 but only levels 1 and 2 are allowed  Constrained_fac \u0026lt;- factor(x = c(1, 2, 3), levels = c(1, 2))\rConstrained_fac\r ## [1] 1 2 \u0026lt;NA\u0026gt;\r## Levels: 1 2\r length(Constrained_fac)\r ## [1] 3\r  A factor reading: 1, 2, 3 levels 1 - 4 are allowed  Expanded_fac \u0026lt;- factor(x = c(1, 2, 3), levels = c(1, 2, 3, 4))\rExpanded_fac\r ## [1] 1 2 3\r## Levels: 1 2 3 4\r length(Expanded_fac)\r ## [1] 3\r Matrix  The first two vectors we established in distinct columns of a matrix  Combine_mat \u0026lt;- matrix(data = c(Numbers_vec, Letters_vec), ncol = 2)\rCombine_mat\r ## [,1] [,2]\r## [1,] \u0026quot;1\u0026quot; \u0026quot;A\u0026quot; ## [2,] \u0026quot;2\u0026quot; \u0026quot;B\u0026quot; ## [3,] \u0026quot;3\u0026quot; \u0026quot;C\u0026quot;\r dim(Combine_mat)\r ## [1] 3 2\r  The first two vectors we established in distinct rows of a matrix  Pivot_mat \u0026lt;- matrix(data = c(Numbers_vec, Letters_vec), nrow = 2, byrow = TRUE)\rPivot_mat\r ## [,1] [,2] [,3]\r## [1,] \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;3\u0026quot; ## [2,] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r dim(Pivot_mat)\r ## [1] 2 3\r  The above matrix with meaningful names  Names_mat \u0026lt;- Pivot_mat\rdimnames(Names_mat) \u0026lt;- list(c(\u0026quot;Numbers\u0026quot;, \u0026quot;Letters\u0026quot;))\rNames_mat\r ## [,1] [,2] [,3]\r## Numbers \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;3\u0026quot; ## Letters \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r dim(Names_mat)\r ## [1] 2 3\r Data Frame  The first matrix we established as a data frame  Combine_df \u0026lt;- data.frame(Combine_mat)\rCombine_df\r ## X1 X2\r## 1 1 A\r## 2 2 B\r## 3 3 C\r dim(Combine_df)\r ## [1] 3 2\r  The previous data frame with meaningful names  Names_df \u0026lt;- Combine_df\rcolnames(Names_df) \u0026lt;- c(\u0026quot;Numbers\u0026quot;, \u0026quot;Letters\u0026quot;)\rNames_df\r ## Numbers Letters\r## 1 1 A\r## 2 2 B\r## 3 3 C\r dim(Names_df)\r ## [1] 3 2\r List  The first two vectors we created  Vectors_ls \u0026lt;- list(Numbers_vec, Letters_vec)\rVectors_ls\r ## [[1]]\r## [1] 1 2 3\r## ## [[2]]\r## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r length(Vectors_ls)\r ## [1] 2\r Statements and Loops Statements  Numbers_vec contains more elements than Letters_fac?  length(Numbers_vec) \u0026gt; length(Letters_fac)\r ## [1] FALSE\r  The first column of Combine_df is shorter than Vectors_ls?  length(Combine_df[, 1]) \u0026lt; length(Vectors_ls)\r ## [1] FALSE\r  The elements of Letters_vec are the same as the elements of Letters_fac?  Letters_vec == Letters_fac\r ## [1] TRUE TRUE TRUE\r Loops  Print each element of Vectors_ls  for (i in 1:length(Vectors_ls)) {\rprint(Vectors_ls[[i]])\r}\r ## [1] 1 2 3\r## [1] \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;\r  Print each element of Numbers_vec + 1  Numbers_veca \u0026lt;- Numbers_vec + 1\rfor (i in 1:length(Numbers_veca)) {\rprint(Numbers_veca[i])\r}\r ## [1] 2\r## [1] 3\r## [1] 4\r  Subtract 1 from each element of the first column of Combine_mat and print each element separately  Mat_column \u0026lt;- Combine_mat[, 1] # extract data\rMat_column \u0026lt;- as.numeric(Mat_column) # convert to numeric\rMat_column \u0026lt;- Mat_column - 1 # substract 1\rfor (i in 1:length(Mat_column)) {\rprint(Mat_column[i])\r}\r ## [1] 0\r## [1] 1\r## [1] 2\r Useful Commands  Read out your current working directory (not showing you the result as it is different on every machine, it should start like this \u0026ldquo;C:/Users/\u0026hellip;.\u0026quot;)  getwd()\r  Inspect the Vectors_ls object using the View() function (again, I am not showing you the result as this only works directly in R or Rstudio)  View(Vectors_ls)\r  Inspect the Combine_df object using the View() function (again, I am not showing you the result as this only works directly in R or Rstudio)  View(Combine_df)\r  Get the help documentation for the as.matrix() function (again, I am not showing you the result as this only works directly in R or Rstudio)  `?`(as.matrix)\r  Install and load the dplyr package  install.packages(\u0026quot;dplyr\u0026quot;)\rlibrary(dplyr)\r  Remove the Logic_vec object from your working environment  rm(Logic_vec)\r  Clear your entire working environment  ls() # this command shows you all the object in the environment\r ## [1] \u0026quot;Big_vec\u0026quot; \u0026quot;Combine_df\u0026quot; \u0026quot;Combine_mat\u0026quot; \u0026quot;Constrained_fac\u0026quot;\r## [5] \u0026quot;Expanded_fac\u0026quot; \u0026quot;i\u0026quot; \u0026quot;Letters_fac\u0026quot; \u0026quot;Letters_vec\u0026quot; ## [9] \u0026quot;Mat_column\u0026quot; \u0026quot;Names_df\u0026quot; \u0026quot;Names_mat\u0026quot; \u0026quot;Numbers_fac\u0026quot; ## [13] \u0026quot;Numbers_vec\u0026quot; \u0026quot;Numbers_veca\u0026quot; \u0026quot;Pivot_mat\u0026quot; \u0026quot;Seq_vec\u0026quot; ## [17] \u0026quot;Vectors_ls\u0026quot;\r rm(list = ls())\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"24e35befc1c16ad08acb7adb6efcb08c","permalink":"https://www.erikkusch.com/courses/biostat101/introduction-to-r/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/introduction-to-r/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to Introduction to R which walks you through the basics of the `R` machinery. `R` is a coding language that can be highly individualised and hence there are often multiple solutions to the same problem. Within these solutions, I shall only present you with one solution for every given task. However, do keep in mind that there is probably a myriad of other ways to achieve your goal.","tags":["R","Statistics"],"title":"Introduction to R","type":"docs"},{"authors":["Erik Kusch"],"categories":["BFTP Projects"],"content":"Preparing The Work Let\u0026rsquo;s create our basic structure for this document:\nHead Not much has changed in the head when compared to our last exercise. We merely change the contents and and the edit tag, since the rest stays the same for the entire project.\n# ####################################################################### #\r# PROJECT: [BFTP] Identifying Biomes And Their Shifts Using Remote Sensing\r# CONTENTS: Functionality to identify clusters of NDVI mean and seasonality\r# AUTHOR: Erik Kusch\r# EDIT: 18/03/20\r# ####################################################################### #\r Preamble I am keeping the same preamble as last time because we will need to index the data and the plot directory in this exercise. Our preamble then looks like this:\nrm(list=ls()) # clearing the entire environment\rDir.Base \u0026lt;- getwd() # identifying the current directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # generating the folder path for data folder\rDir.Plots \u0026lt;- paste(Dir.Base, \u0026quot;Plots\u0026quot;, sep=\u0026quot;/\u0026quot;) # generating the folder path for figures folder\r Notice, that we do not call the function dir.create() this time. We don\u0026rsquo;t need to do so, because we already created the two directories established above in our last exercise. Usually, we would create this entire analysis of your BFTP project in one R code script. In this case, we would only have one preamble which defines and creates directories instead of doing this step for every single sub-part of the analysis. Alas, we want to break this down for you. Therefore, you see this preamble here and will again in the next exercise.\nAgain, this is where would load packages, but I am going to install and load the necessary packages when needed to show you what they are good for. Personally, I recommend you always load all necessary packages at the beginning of your code file and leave comments as to what you load them for. This will make it easier to remove packages you don\u0026rsquo;t need anymore when you change things.\nCoding Again, all of the important Coding happens after the head and the preamble are written and run in R. Basically, this is the rest of this document once more.\nCluster Analysis Cluster analyses come in many forms. Here, we are interested in a k-means clustering approach. These approaches identify $k$ (a number) clusters. One of the most prominent ways to do this in R is undoubtedly the mclust R package. Clusters can be thought of as groupings of data in multi-dimensional space. The number of dimensions is equal to the number of clustering components. In the mclust R package, the characteristics of these clusters (orientation, volume, shape) are, if not specified otherwise, estimated from the data.\nmclust provides the user with a very autonomous process of model calculation and selection. First, if not specified otherwise, mclust calculates all available models for a range of cluster component numbers (by default one to nine clusters). Secondly, once the models are established, mclust selects the most appropriate of the models according to their respective Bayesian Information Criterion (BIC) value. The BIC is an indicator of model quality: the lower the BIC, the better the model fits the data. Conclusively, mclust chooses the model with the lowest BIC available for clustering the data.\nLoading Data Before we can get started with our analysis, we have to load our NDVI mean and seasonality data (see last exercise) back into R, we do this as follows:\nlibrary(raster) # the raster package for rasters\rMean1982_ras \u0026lt;- raster(paste(Dir.Data, \u0026quot;1982Mean.nc\u0026quot;, sep=\u0026quot;/\u0026quot;)) # loading means\rSeason1982_ras \u0026lt;- raster(paste(Dir.Data, \u0026quot;1982Season.nc\u0026quot;, sep=\u0026quot;/\u0026quot;)) # loading seasonalities\r Now that we have loaded the data into R, it is time to introduce you to another useful feature of the raster package - the stack. With a stack of rasters, you can do exactly what the name suggests, stack rasters of the same resolution, and extent into one R object. You do this by calling the stack()function in R:\nAll1982_ras \u0026lt;- stack(Mean1982_ras, Season1982_ras) # creating a stack\rnames(All1982_ras) \u0026lt;- c(\u0026quot;Mean\u0026quot;, \u0026quot;Seasonality\u0026quot;) # assign names to stack layers\rAll1982_ras\r ## class : RasterStack ## dimensions : 237, 590, 139830, 2 (nrow, ncol, ncell, nlayers)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -179, -130, 51, 71 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## names : Mean, Seasonality ## min values : 0, 0 ## max values : 0.84, 1.00\r As you can see, this object contains both rasters as layers which we have already assigned names to.\nNow let\u0026rsquo;s see how plotting works with this. This time, I am adding a couple of arguments to the plot() function to make the plots nicer than before:\nplot(All1982_ras, # what to plot\rcolNA = \u0026quot;black\u0026quot;, # which colour to assign to NA values\rlegend.shrink=1, # vertical size of legend\rlegend.width=2 # horizontal size of legend\r)\r Using stacks makes plotting easier in R if you want to plot more than one raster at a time.\nData Extraction We\u0026rsquo;re now ready to extract data from our data sets. mclust let\u0026rsquo;s us assess multi-dimensional clusters but wants the data to be handed over in one file - as a matrix, to be precise. Let\u0026rsquo;s see what happens when we just look the first few (head()) values (values()) of our raster stack:\nhead(values(All1982_ras))\r ## Mean Seasonality\r## [1,] NA NA\r## [2,] NA NA\r## [3,] NA NA\r## [4,] NA NA\r## [5,] NA NA\r## [6,] NA NA\r As you can see, the data gets extracted but there are NA values here. This is because the top-left corner of our rasters (which is where values start) contains a lot of NA cells.\nLet\u0026rsquo;s see what kind of object this is:\nclass(values(All1982_ras))\r ## [1] \u0026quot;matrix\u0026quot; \u0026quot;array\u0026quot;\r It is a matrix! Just what mclust wants! Let\u0026rsquo;s actually create that as an object:\nVals1982_mat \u0026lt;- values(All1982_ras)\rrownames(Vals1982_mat) \u0026lt;- 1:dim(Vals1982_mat)[1] # rownames to index raster cell number\r Finally, let\u0026rsquo;s carry out a sanity check to make sure that we really have ported all values from both source rasters to our matrix. For this to be the case, the rownumber of our matrix (dim()[1]) needs to be the same as the amount (length()) of values (values()) in our rasters:\ndim(Vals1982_mat)[1] == length(values(Mean1982_ras)) \u0026amp; dim(Vals1982_mat)[1] == length(values(Season1982_ras))\r ## [1] TRUE\r This checks out!\nData Prepartion As you remember, there were plenty of NA values in our data set. No cluster algorithm can handle these. Therefore, we need to get rid of them. This is done as follows:\nVals1982_mat \u0026lt;- na.omit(Vals1982_mat) # omit all rows which contain at least one NA record\rdim(Vals1982_mat) # new dimensions of our matrix\r ## [1] 39460 2\r This seriously cut our data down and will speed up our clustering approach a lot.\nCluster Identification Let\u0026rsquo;s install and load the mclust package.\ninstall.packages(\u0026quot;mclust\u0026quot;)\rlibrary(mclust)\r Cluster Model Selection Let\u0026rsquo;s start with the mclust functionality to identify the best fitting clustering with a range of 1 to 9 clusters. To do so, we first need to identify the BIC fit for all of our possible cluster models. mclust does this automatically:\ndataBIC \u0026lt;- mclustBIC(Vals1982_mat) # identify BICs for different models\rprint(summary(dataBIC)) # show summary of top-ranking models\r ## Best BIC values:\r## EVV,8 EVV,9 EVE,8\r## BIC 136809 136800.2 135504\r## BIC diff 0 -8.6 -1304\r The output above tells us that the best performing model was of type EVV (ellipsoidal distribution, equal volume, variable shape, and variable orientation of clusters) identifying 9 clusters.\nLet\u0026rsquo;s see a visual overview of this:\nplot(dataBIC)\r Here, you can see different models compared to each other given certain numbers of clusters that have been considered.\nNow we can build our model:\nmod \u0026lt;- Mclust(Vals1982_mat, # data for the cluster model\rG = 7 # BIC index for model to be built\r)\r We now have our full model! How many clusters did it identify?\nmod$G # number of groups/clusters in model\r ## [1] 7\r No surprises here, we\u0026rsquo;ve got 7 clusters.\nNow let\u0026rsquo;s look at the mean values of the clusters:\nmod[[\u0026quot;parameters\u0026quot;]][[\u0026quot;mean\u0026quot;]] # mean values of clusters\r ## [,1] [,2] [,3] [,4] [,5] [,6] [,7]\r## Mean 0.36 0.53 0.67 0.081 0.44 0.26 0.21\r## Seasonality 0.76 0.56 0.35 0.269 0.72 0.64 0.59\r These can be interpreted biologically, but I will leave that to you.\nNow let\u0026rsquo;s see how well these clusters distinguish the mean-seasonality space:\nplot(mod, what = \u0026quot;uncertainty\u0026quot;)\r How do we map this? We predict our clusters for our initial data as follows:\nModPred \u0026lt;- predict.Mclust(mod, Vals1982_mat) # prediction\rPred_ras \u0026lt;- Mean1982_ras # establishing a rediction raster\rvalues(Pred_ras) \u0026lt;- NA # set everything to NA\r# set values of prediction raster to corresponding classification according to rowname\rvalues(Pred_ras)[as.numeric(rownames(Vals1982_mat))] \u0026lt;- as.vector(ModPred$classification)\rPred_ras\r ## class : RasterLayer ## dimensions : 237, 590, 139830 (nrow, ncol, ncell)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -179, -130, 51, 71 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : layer ## values : 1, 7 (min, max)\r As you can see, this has the same extent and resolution as our source rasters but the values range from 1 to 7. These are our cluster assignments.\nNow let\u0026rsquo;s plot this:\ncolours \u0026lt;- rainbow(mod$G) # define 7 colours\rplot(Pred_ras, # what to plot\rcol = colours, # colours for groups\rcolNA = \u0026quot;black\u0026quot;, # which colour to assign to NA values\rlegend.shrink=1, # vertical size of legend\rlegend.width=2 # horizontal size of legend\r)\r How often do we observe which assignment?\ntable(values(Pred_ras))\r ## ## 1 2 3 4 5 6 7 ## 13101 1902 1118 2939 5608 8047 6745\r Pre-Defined Number As biologists, we have got decades of work already present concerning biome distributions across the Earth. One such classification are the Terrestrial Ecoregions of the World (\\url{https://www.worldwildlife.org/publications/terrestrial-ecoregions-of-the-world}). We want to identify how many biomes this data set identifies across Australia.\nFirstly, we download the data and unpack it:\n# downloading Terrestrial Ecoregion Shapefile as zip\rdownload.file(\u0026quot;http://assets.worldwildlife.org/publications/15/files/original/official_teow.zip\u0026quot;,\rdestfile = file.path(Dir.Data, \u0026quot;wwf_ecoregions.zip\u0026quot;)\r)\r# unpacking the zip\runzip(file.path(Dir.Data, \u0026quot;wwf_ecoregions.zip\u0026quot;), exdir = file.path(Dir.Data, \u0026quot;WWF_ecoregions\u0026quot;)\r)\r Secondly, we load the data into R:\n# loading shapefile for biomes\rwwf \u0026lt;- readOGR(file.path(Dir.Data, \u0026quot;WWF_ecoregions\u0026quot;, \u0026quot;official\u0026quot;, \u0026quot;wwf_terr_ecos.shp\u0026quot;),\rverbose = FALSE)\r Thirdly, we need to limit the global terrestrial ecoregion shapefile to the state of Alaska and need our Alaska shapefile for this:\nShapes \u0026lt;- readOGR(Dir.Data, # where to look for the file\r\u0026quot;ne_10m_admin_1_states_provinces\u0026quot;, # the file name\rverbose = FALSE) # we don't want an overview of the loaded data\rPosition \u0026lt;- which(Shapes$name_en == \u0026quot;Alaska\u0026quot;) # find the english name that's \u0026quot;Alaska\u0026quot;\rAlaska_Shp \u0026lt;- Shapes[Position,] # extract the Alaska shapefile\rAlaska_Shp \u0026lt;- crop(Alaska_Shp, # what to crop\rextent(-190, -130, 51, 71)) # which extent to crop to\r Now, we need to limit the global biome shapefile to the shape of Alaska:\nwwf_ready \u0026lt;- crop(wwf, extent(Alaska_Shp)) # cropping to Alaska extent\rwwf_ready \u0026lt;- intersect(Alaska_Shp, wwf) # masking of two shapefiles\rplot(wwf_ready, # plotting final shape\rcol = wwf_ready@data[[\u0026quot;BIOME\u0026quot;]] # use BIOME specification for colours\r)\r We first identify the BICs:\n# identify BICs for different models\rdataBIC2 \u0026lt;- mclustBIC(Vals1982_mat, G = length(unique(wwf_ready@data[[\u0026quot;G200_BIOME\u0026quot;]]))) print(summary(dataBIC2)) # show summary of top-ranking models\r ## Best BIC values:\r## EVV,4 VVE,4 EVE,4\r## BIC 133035 132345 125463\r## BIC diff 0 -690 -7572\r As you can see, the shapefile gives us 4 clusters across Alaska even though the map only shows 3. The fourth biome is only represented by a single polygon across all of Alaska and we might want to reduce the set to 3.\nFor now, we are running with the idea of 4 clusters:\nmod2 \u0026lt;- Mclust(Vals1982_mat, # data for the cluster model\rG = 4 # BIC index for model to be built\r)\r We now have our full model!\nNow let\u0026rsquo;s look at the mean values of the clusters:\nmod2[[\u0026quot;parameters\u0026quot;]][[\u0026quot;mean\u0026quot;]] # mean values of clusters\r ## [,1] [,2] [,3] [,4]\r## Mean 0.41 0.13 0.60 0.27\r## Seasonality 0.73 0.39 0.44 0.67\r Again, I leave the biological interpretation to you.\nFinally, we will plot our assignments in mean-seasonality space:\nplot(mod2, what = \u0026quot;uncertainty\u0026quot;)\r Again, let\u0026rsquo;s predict our clusters for our initial data as follows:\nModPred2 \u0026lt;- predict.Mclust(mod2, Vals1982_mat) # prediction\rPred2_ras \u0026lt;- Mean1982_ras # establishing a rediction raster\rvalues(Pred2_ras) \u0026lt;- NA # set everything to NA\r# set values of prediction raster to corresponding classification according to rowname\rvalues(Pred2_ras)[as.numeric(rownames(Vals1982_mat))] \u0026lt;- as.vector(ModPred2$classification)\rPred2_ras\r ## class : RasterLayer ## dimensions : 237, 590, 139830 (nrow, ncol, ncell)\r## resolution : 0.083, 0.083 (x, y)\r## extent : -179, -130, 51, 71 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : layer ## values : 1, 4 (min, max)\r As you can see, this has the same extent and resolution as our source rasters but the values range from 1 to 4. These are our cluster assignments.\nNow let\u0026rsquo;s plot this:\ncolours \u0026lt;- rainbow(mod2$G) # define 4 colours\rplot(Pred2_ras, # what to plot\rcol = colours, # colours for groups\rcolNA = \u0026quot;black\u0026quot;, # which colour to assign to NA values\rlegend.shrink=1, # vertical size of legend\rlegend.width=2 # horizontal size of legend\r)\r How often do we observe which assignment?\ntable(values(Pred2_ras))\r ## ## 1 2 3 4 ## 12223 4066 2327 20844\r Saving Workspace What Is It And Why Do We Do It? The workspace records all of our elements in R. Since we want to pick up from this point in our next exercise, we want to save the workspace and restore it at a later point to assess all of our elements again.\nSaving And Loading The Workspace Saving a workspace goes as follows:\n# save workspace\rsave.image(file = (paste(Dir.Base, \u0026quot;Workspace.RData\u0026quot;, sep=\u0026quot;/\u0026quot;)))\r Now let\u0026rsquo;s load it again:\nrm(list=ls()) # clean workspace\rload(file = \u0026quot;Workspace.RData\u0026quot;) # load workspace\rls() # list elements in workspace\r ## [1] \u0026quot;Alaska_Shp\u0026quot; \u0026quot;All1982_ras\u0026quot; \u0026quot;colours\u0026quot; ## [4] \u0026quot;dataBIC\u0026quot; \u0026quot;dataBIC2\u0026quot; \u0026quot;Dir.Base\u0026quot; ## [7] \u0026quot;Dir.Data\u0026quot; \u0026quot;Dir.Plots\u0026quot; \u0026quot;Mean1982_ras\u0026quot; ## [10] \u0026quot;mod\u0026quot; \u0026quot;mod2\u0026quot; \u0026quot;ModPred\u0026quot; ## [13] \u0026quot;ModPred2\u0026quot; \u0026quot;Position\u0026quot; \u0026quot;Pred_ras\u0026quot; ## [16] \u0026quot;Pred2_ras\u0026quot; \u0026quot;Season1982_ras\u0026quot; \u0026quot;Shapes\u0026quot; ## [19] \u0026quot;Vals1982_mat\u0026quot; \u0026quot;wwf\u0026quot; \u0026quot;wwf_ready\u0026quot;\r All our files are back!\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"bc731ece56a5bf68073518e074060000","permalink":"https://www.erikkusch.com/courses/bftp-biome-detection/cluster-analysis/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/bftp-biome-detection/cluster-analysis/","section":"courses","summary":"Preparing The Work Let\u0026rsquo;s create our basic structure for this document:\nHead Not much has changed in the head when compared to our last exercise. We merely change the contents and and the edit tag, since the rest stays the same for the entire project.","tags":["R","Statistics","Remote Sensing"],"title":"Cluster Analysis","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"\rThis part of the workshop is meant to give a very brief introduction to KrigR and I highly recommend you peruse the rest of the content, too. If you are already committed to going through the more thorough workshop material in the Workshop tab on the left, I would recommend skipping this quickstart guide as you will gain more knowledge at a more approachable pace in that more exhaustive part of the material.\r\r\r\r\u0026ndash;\u0026gt;\n\r--\rPre-KrigR Housekeeping Before we can commence the quick start guide, I want to set up a directory structure and prepare some plotting functions to make the rest of the guide run more smoothly.\nCDS API Credentials As explained in the KrigR setup, please register your CDS API credentials into your R session like so:\nAPI_User \u0026lt;- \u0026quot;youremail@somethingortheother\u0026quot;\rAPI_Key \u0026lt;- \u0026quot;YourApiKeyGoesHereAsACharacterString\u0026quot;\r Setting up Directories For this guide to run in a structured way, we create a folder/directory structure. We create the following directories:\n A Data directory for all of our data downloads A Covariate directory for all of our covariate data An Exports directory for all of our Kriging outputs  Dir.Base \u0026lt;- getwd() # identifying the current directory\rDir.Data \u0026lt;- file.path(Dir.Base, \u0026quot;Data\u0026quot;) # folder path for data\rDir.Covariates \u0026lt;- file.path(Dir.Base, \u0026quot;Covariates\u0026quot;) # folder path for covariates\rDir.Exports \u0026lt;- file.path(Dir.Base, \u0026quot;Exports\u0026quot;) # folder path for exports\r## create directories, if they don't exist yet\rDirs \u0026lt;- sapply(\rc(Dir.Data, Dir.Covariates, Dir.Exports),\rfunction(x) if (!dir.exists(x)) dir.create(x)\r)\rrm(Dirs) # we don't need to keep the response to directory creation\r Using KrigR Before we start these exercises, we need to load KrigR:\nlibrary(KrigR)\r Since KrigR works with terra objects to handle raster data, we may also want to load the terra package at this point:\nlibrary(terra)\r KrigR is conceptualised around a three-step progression through its functionality using the three core functions CDownloadS(), CovariateSetup(), and Kriging():\nData Retrieval \u0026amp; Handling - CDownloadS() Using the CDownloadS() function, you gain access to a number of CDS-hosted data products. More details on how you can find out which data products are supported and how to query them, refer to the Finding CDS-Hosted Data Products section. For the sake of this quickstart overview of KrigR capabilities, we will execute a very simple call to CDownloadS(). For a deeper understanding of the capabilities of KrigR for CDS-data download and processing, please refer to the Data Retrieval \u0026amp; Handling\nThe most simple way in which you can run the functions of the KrigR package is by specifying a rectangular bounding box (i.e., an SpatExtent) to specify your study region(s). For this quickstart, we focus on an area covering southern and central Norway:\nExtent_ext \u0026lt;- ext(c(4.05, 12.95, 58.05, 63.55))\rExtent_ext\r ## SpatExtent : 4.05, 12.95, 58.05, 63.55 (xmin, xmax, ymin, ymax)\r Next, you specify, which variable, from which data product, for which time-window you want to obtain and at which temporal resolution. For this part of the workshop, we download air temperature for a three-day interval around 2022-08-18 - when I camped on a mountain flank below Hurrungane facing Fannaråki - the mountain that inspired my relocation to Norway. Loaded with this information, CDownloadS() then executes preliminary checks of validity of your data request, breaks the request into separate chunks if it is too big to be handled by CDS all at once, hands the request to CDS, waits for request completion on CDS followed by data download, spatial limiting, temporal aggregation, and finally, saving of the resulting file to your hard drive.\n\rNotice that the downloading of CDS-hosted data may take a short while to start as the download request gets queued with CDS before it is executed. An overview of your CDS requests can be seen here.\r\r\r\rYou need to accept the required licences for each data product before download queries are accepted by CDS. You only have to do this once per data product. If licenses haven\u0026rsquo;t been accepted yet, CDownloadS() terminates with an error message containing the URL to the data product page where you will find a \u0026ldquo;Terms of use\u0026rdquo; section under which you need to accept the required license(s).\r\r\r## Note that I have already downloaded the QuickStart raw data and CDownloadS() is simply loading this from the disk for me here. Your console output while CDownloadS() is being executed will look differently.\rQuickStart_Raw \u0026lt;- CDownloadS(\r## Variable and Data Product\rVariable = \u0026quot;2m_temperature\u0026quot;, # this is air temperature\rDataSet = \u0026quot;reanalysis-era5-land\u0026quot;, # data product from which we want to download\r## Time-Window\rDateStart = \u0026quot;2022-08-17\u0026quot;, # date at which time window opens\rDateStop = \u0026quot;2022-08-19\u0026quot;, # date at which time window terminates\rTZone = \u0026quot;CET\u0026quot;, # European Central Time to align with our study region\r## Temporal Aggregation\rTResolution = \u0026quot;day\u0026quot;, # we want daily aggregates\rTStep = 1, # we want aggregates of 1 day each\r## Spatial Limiting\rExtent = Extent_ext, # our rectangular bounding box\r## File Storing\rDir = Dir.Data, # where to store the data\rFileName = \u0026quot;QuickStart_Raw\u0026quot;, # what to call the resulting file\r## API User Credentials\rAPI_User = API_User,\rAPI_Key = API_Key\r)\r ## ###### CDS Request \u0026amp; Data Download\r ## [1] \u0026quot;Building request\u0026quot;\r## [1] \u0026quot;Checking request validity\u0026quot;\r## [1] \u0026quot;A file with the name QuickStart_Raw.nc already exists in C:/Users/erikkus/Documents/Homepage/content/courses/krigr/Data.\u0026quot;\r## [1] \u0026quot;Loading this file for you from the disk.\u0026quot;\r QuickStart_Raw\r ## class : SpatRaster ## dimensions : 55, 88, 3 (nrow, ncol, nlyr)\r## resolution : 0.1, 0.1 (x, y)\r## extent : 4.1, 12.9, 58.1, 63.6 (xmin, xmax, ymin, ymax)\r## coord. ref. : lon/lat Coordinate System imported from GRIB file ## source : QuickStart_Raw.nc ## names : QuickStart_Raw_1, QuickStart_Raw_2, QuickStart_Raw_3 ## time : 2022-08-16 to 2022-08-18 CEST\r See how we have obtained a SpatRaster corresponding the three dates we indicated to CDownloadS()? Great! The raw, hourly ERA5-Land data we queried has been aggregated to daily intervals as specified by us. You may also notice that the SpatRaster we obtained has a slightly different extent than what we queried. This is because CDS aligns the data with a data product specific grid. If in doubt on this, simply specify a slightly larger extent than you ultimately need for your study.\nUsing the KrigR function Plot.SpatRast(), we can easily visualise the data we just obtained.\nPlot.SpatRast(QuickStart_Raw)\r As you can see the CDownloadS() function updates you on what it is currently working on at each major step. I implemented this to make sure people don\u0026rsquo;t get too anxious staring at an empty console in R. If this feature is not appealing to you, you can turn this progress tracking off by setting verbose = FALSE in the function call to CDownloadS().\nCDownloadS() also saves metadata pertaining to your download \u0026amp; handling query directly to the final output. While we store all settings of your function call (sans your API credentials), the most relevant metadata appended to your files obtained with CDownloadS() will most likely be the citation command by which to reference this data in your subsequent research outputs. You can retrieve this information as follows:\nmetags(QuickStart_Raw)[\u0026quot;Citation\u0026quot;]\r ## Citation ## \u0026quot;reanalysis-era5-land data (DOI:10.24381/cds.e2161bac) obtained with KrigR (DOI:10.1088/1748-9326/ac48b3) on 2024-10-04 14:29:18.291047\u0026quot;\r \rMore detailed instructions on how to make the most effective use of the CDownloadS() function and ensure you receive the data you require can be found here.\r\r\rKeep in mind that every function within the KrigR package produces NetCDF (.nc) or TIFF (.tif) files (depending on your specification of the FileExtension argument in CDownloadS()) in the specified directory (Dir argument in the function call) to allow for further manipulation outside of R if necessary (for example, using Panoply).\nDownscaling Covariates - CovariateSetup() Next, we use the CovariateSetup() function which comes with KrigR to obtain elevation data as our covariate of choice. This produces two SpatRasters:\n A raster of training resolution which matches the input data in all attributes except for the data in each cell. A raster of target resolution which matches the input data as closely as possible in all attributes except for the resolution (which is specified by the user).  Both of these products are bundled into a list where the first element corresponds to the training resolution and the second element contains the target resolution covariate data. Here, we specify a target resolution of .02.\n\rAlternatively to specifying a target resolution, you can specify a different SpatRaster which should be matched in all attributes by the raster at target resolution.\n\r\r## Note that I have already downloaded the global GMTED2010 data with this function prior, your output will show the download itself as well\rCovs_ls \u0026lt;- CovariateSetup(\rTraining = QuickStart_Raw,\rTarget = .02,\rDir = Dir.Covariates,\rKeep_Global = TRUE\r)\r ## [1] \u0026quot;GMTED2010 covariate data already downloaded.\u0026quot;\r Covs_ls\r ## $Training\r## class : SpatRaster ## dimensions : 55, 88, 1 (nrow, ncol, nlyr)\r## resolution : 0.1, 0.1 (x, y)\r## extent : 4.1, 12.9, 58.1, 63.6 (xmin, xmax, ymin, ymax)\r## coord. ref. : lon/lat WGS 84 (EPSG:4326) ## source : Covariates_Train.nc ## name : GMTED2010 ## ## $Target\r## class : SpatRaster ## dimensions : 330, 528, 1 (nrow, ncol, nlyr)\r## resolution : 0.01666667, 0.01666667 (x, y)\r## extent : 4.09986, 12.89986, 58.09986, 63.59986 (xmin, xmax, ymin, ymax)\r## coord. ref. : lon/lat WGS 84 (EPSG:4326) ## source : Covariates_Target.nc ## name : GMTED2010\r Again, we can use a KrigR plotting function to easily visualise this data:\nPlot.Covariates(Covs_ls)\r \rThe CovariateSetup() function can also be used to prepare raster data you already have at hand for use in subsequent Kriging.\r\r\rStatistical Downscaling - Kriging() Now let\u0026rsquo;s statistically downscale the data we just obtained with the covariates we just prepared. We do so using the Kriging() function:\nQuickStart_Krig \u0026lt;- Kriging(\rData = QuickStart_Raw, # data we want to krig as a raster object\rCovariates_training = Covs_ls[[1]], # training covariate as a raster object\rCovariates_target = Covs_ls[[2]], # target covariate as a raster object\rEquation = \u0026quot;GMTED2010\u0026quot;, # the covariate(s) we want to use\rnmax = 40, # degree of localisation\rCores = 3, # we want to krig using three cores to speed this process up\rFileName = \u0026quot;QuickStart_Krig\u0026quot;, # the file name for our full kriging output\rDir = Dir.Exports # which directory to save our final input in\r)\rQuickStart_Krig\r ## $Prediction\r## class : SpatRaster ## dimensions : 330, 528, 3 (nrow, ncol, nlyr)\r## resolution : 0.01666667, 0.01666667 (x, y)\r## extent : 4.09986, 12.89986, 58.09986, 63.59986 (xmin, xmax, ymin, ymax)\r## coord. ref. : lon/lat Coordinate System imported from GRIB file ## source : QuickStart_Krig_Kriged.nc ## varname : QuickStart_Raw ## names : QuickStart~g_Kriged_1, QuickStart~g_Kriged_2, QuickStart~g_Kriged_3 ## time : 2022-08-16 to 2022-08-18 CEST ## ## $StDev\r## class : SpatRaster ## dimensions : 330, 528, 3 (nrow, ncol, nlyr)\r## resolution : 0.01666667, 0.01666667 (x, y)\r## extent : 4.09986, 12.89986, 58.09986, 63.59986 (xmin, xmax, ymin, ymax)\r## coord. ref. : lon/lat Coordinate System imported from GRIB file ## source : QuickStart_Krig_STDev.nc ## varname : QuickStart_Raw ## names : QuickStart~ig_STDev_1, QuickStart~ig_STDev_2, QuickStart~ig_STDev_3 ## time : 2022-08-16 to 2022-08-18 CEST\r This operation took 2 seconds on my machine (this may vary drastically on other devices). There we go. All the data has been downscaled and we do have uncertainties recorded for all of our outputs. Let\u0026rsquo;s visualise this again with a KrigR function - Plot.Kriged():\nPlot.Kriged(QuickStart_Krig)\r As you can see, the elevation patterns show up clearly in our kriged air temperature output. Seems like Norway got warmer the day I left camp on August of 2022 - I do remember the night from the 18th to the 19th being the first clear night after a few days of constant cloud cover and it did get cold in my tent that night, but the heat during daytime thereafter seems to have balanced that out and swung the daily average into being a warmer day. Furthermore, you can see that our certainty of Kriging predictions steadily increases towards the 2022-08-18 in comparison to the preceding days. However, do keep in mind that a maximum standard error of 2.84, 1.89, 1.5 (for each layer of our output respectively, and across the sea at that, where there are no topographical variations we can exploit for kriging) on a total range of data of 15.31, 14.8, 14.73 (again, for each layer in the output respectively) is evident of a downscaling result we can be confident in.\n\rMore detailed instructions on how to make the most effective use of the krigR() function can be found here.\r\r\r\rThis concludes the quick start tutorial for KrigR. For more effective use of the KrigR toolbox, I suggest you peruse the rest of the workshop material or use the search function if you have specific queries.\r\r\rSession Info sessionInfo()\r ## R version 4.4.0 (2024-04-24 ucrt)\r## Platform: x86_64-w64-mingw32/x64\r## Running under: Windows 11 x64 (build 22631)\r## ## Matrix products: default\r## ## ## locale:\r## [1] C\r## ## time zone: Europe/Oslo\r## tzcode source: internal\r## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] terra_1.7-78 KrigR_0.4.0 ## ## loaded via a namespace (and not attached):\r## [1] tidyselect_1.2.1 viridisLite_0.4.2 dplyr_1.1.4 farver_2.1.2 ## [5] viridis_0.6.5 R.utils_2.12.3 fastmap_1.2.0 reshape_0.8.9 ## [9] blogdown_1.19 digest_0.6.37 timechange_0.3.0 lifecycle_1.0.4 ## [13] sf_1.0-17 magrittr_2.0.3 compiler_4.4.0 rlang_1.1.4 ## [17] sass_0.4.9 progress_1.2.3 doSNOW_1.0.20 tools_4.4.0 ## [21] utf8_1.2.4 yaml_2.3.10 knitr_1.48 FNN_1.1.4.1 ## [25] prettyunits_1.2.0 labeling_0.4.3 sp_2.1-4 classInt_0.4-10 ## [29] plyr_1.8.9 abind_1.4-8 KernSmooth_2.23-22 R.cache_0.16.0 ## [33] withr_3.0.1 purrr_1.0.2 R.oo_1.26.0 grid_4.4.0 ## [37] fansi_1.0.6 xts_0.14.0 e1071_1.7-16 colorspace_2.1-1 ## [41] ggplot2_3.5.1 scales_1.3.0 iterators_1.0.14 cli_3.6.3 ## [45] rmarkdown_2.28 crayon_1.5.3 intervals_0.15.5 generics_0.1.3 ## [49] httr_1.4.7 ncdf4_1.23 DBI_1.2.3 pbapply_1.7-2 ## [53] cachem_1.1.0 proxy_0.4-27 ecmwfr_2.0.2 stringr_1.5.1 ## [57] stars_0.6-6 parallel_4.4.0 vctrs_0.6.5 jsonlite_1.8.8 ## [61] bookdown_0.40 hms_1.1.3 foreach_1.5.2 jquerylib_0.1.4 ## [65] tidyr_1.3.1 units_0.8-5 snow_0.4-4 glue_1.7.0 ## [69] codetools_0.2-20 cowplot_1.1.3 gstat_2.1-2 lubridate_1.9.3 ## [73] stringi_1.8.4 gtable_0.3.5 munsell_0.5.1 tibble_3.2.1 ## [77] styler_1.10.3 pillar_1.9.0 htmltools_0.5.8.1 R6_2.5.1 ## [81] automap_1.1-12 evaluate_0.24.0 lattice_0.22-6 highr_0.11 ## [85] R.methodsS3_1.8.2 memoise_2.0.1 bslib_0.8.0 class_7.3-22 ## [89] Rcpp_1.0.13 gridExtra_2.3 spacetime_1.3-2 xfun_0.47 ## [93] zoo_1.8-12 pkgconfig_2.0.3\r ","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"ee815ac975003d1b5f7a3102e7ba95ec","permalink":"https://www.erikkusch.com/courses/krigr/quickstart/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/quickstart/","section":"courses","summary":"This part of the workshop is meant to give a very brief introduction to KrigR and I highly recommend you peruse the rest of the content, too. If you are already committed to going through the more thorough workshop material in the Workshop tab on the left, I would recommend skipping this quickstart guide as you will gain more knowledge at a more approachable pace in that more exhaustive part of the material.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Quick Guide","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r\rMaterial  \rHybrid Bayesian Networks \rHybrid Bayesian Networks by Ariel Saffer (one of our study group members)  Exercises These are answers and solutions to the exercises at the end of Part 3 in Bayesian Networks with Examples in R by M. Scutari and J.-B. Denis. Much of my inspiration for these solutions, where necessary, by consulting the solutions provided by the authors themselves as in the appendix.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(bnlearn)\rlibrary(rjags)\r Scutari 3.1  Explain why it is logical to get a three-step function for the discretised approach in Figure 3.2.\n Figure 3.2 shows this discretisation:\nthe reason we obtain a three-step function here is down to the intervals that were chosen to bin the continuous diametre data into discrete categories:\n$$\u0026lt;6.16$$ $$[6.16; 6.19]$$ $$\u0026gt;6.19$$\nOwing to these intervals, we fit all of our continuous data into three categories which mirror the three-step function portrayed in the above figure.\nScutari 3.2  Starting from the BUGS model in Section 3.1.1, write another BUGSmodel for the discretised model proposed in Section 3.1.2. The functions required for this task are described in the JAGS manual.\n The model for the hybrid case (which we are to adapt to the discretised approach) reads as such:\nmodel{ csup ~ dcat(sp); cdiam ~ dnorm(mu[csup], 1/sigma^2);\r}\r To adapt it for discretised data, I simply change the outcome distribution for cdiam to also be categorical:\nmodel{ csup ~ dcat(sp); cdiam ~ dcat(Diams[, csup]);\r}\r where Diams is a matrix that contains probabilities for the different diameters (rows) for suppliers (columns).\nScutari 3.3  Let d = 6.0, 6.1, 6.2, 6.4.\n   Using the BUGS model proposed in Section 3.1.1, write the R script to estimate $P(S = s1 | D = d)$ for the continuous approach demonstrated in the same section.   I start by simply repeating the code in section 3.1.1:\nsp \u0026lt;- c(0.5, 0.5)\rmu \u0026lt;- c(6.1, 6.25)\rsigma \u0026lt;- 0.05\r From here, I take inspiration from the book in the later section on the crop model and write a sampling loop for which to retain samples. First, I create some objects to store data and outputs as well as do some housekeeping:\n## house-keeping\rset.seed(42) # there are random processes here\r## object creation\rdiameters_vec \u0026lt;- c(6.0, 6.1, 6.2, 6.4)\rprob_vec \u0026lt;- rep(NA, length(diameters_vec))\rnames(prob_vec) \u0026lt;- diameters_vec\r Next, I greatly dislike the reliance on model files that the book insists on and so I register my JAGS model code as an active text connection in R:\njags_mod \u0026lt;- textConnection(\u0026quot;model{\rcsup ~ dcat(sp);\rcdiam ~ dnorm(mu[csup], 1/sigma^2);\r}\u0026quot;)\r Finally, I am ready to estimate $P(S = s1 | D = d)$:\nfor (samp_iter in seq(length(diameters_vec))) {\r# create data list\rjags.data \u0026lt;- list(sp = sp, mu = mu, sigma = sigma, cdiam = diameters_vec[samp_iter])\r# compile model\rmodel \u0026lt;- jags.model(file = jags_mod, data = jags.data, quiet = TRUE)\rupdate(model, n.iter = 1e4)\r# sample model and retrieve vector of supplier identity (containing values 1 and 2)\rsimu \u0026lt;- coda.samples(model = model, variable.names = \u0026quot;csup\u0026quot;, n.iter = 2e4, thin = 20)[[1]]\r# compute probability of supplier 1\rprob_vec[samp_iter] \u0026lt;- sum(simu == 1) / length(simu)\r}\rprob_vec\r ## 6 6.1 6.2 6.4 ## 1.000 0.982 0.197 0.000\r  Using the BUGS model obtained in Exercise 3.2, write the R script to estimate $P(S = s1 | D = d)$ for the discretised approach suggested in Section 3.1.2.   Again, I start by typing out important parameters from the book:\nsp \u0026lt;- c(0.5, 0.5)\rDiams \u0026lt;- matrix(c(0.88493, 0.07914, 0.03593, 0.03593, 0.07914, 0.88493), 3)\rDiams\r ## [,1] [,2]\r## [1,] 0.88493 0.03593\r## [2,] 0.07914 0.07914\r## [3,] 0.03593 0.88493\r Once more, I perform housekeeping and object creation prior to sampling. This time, however, I create a probability matrix to store the probability of each rod diametre in each diametre class belonging to supplier 1:\n## house-keeping\rset.seed(42) # there are random processes here\r## object creation\rdiameters_vec \u0026lt;- c(6.0, 6.1, 6.2, 6.4)\rcdiam_vec \u0026lt;- 1:3\rdimnames \u0026lt;- list(\rpaste(\u0026quot;cdiam\u0026quot;, cdiam_vec, sep = \u0026quot;_\u0026quot;),\rdiameters_vec\r)\rprob_mat \u0026lt;- matrix(rep(NA, 12), ncol = 4)\rdimnames(prob_mat) \u0026lt;- dimnames\r And there\u0026rsquo;s our model:\njags_mod \u0026lt;- textConnection(\u0026quot;model{\rcsup ~ dcat(sp);\rcdiam ~ dcat(Diams[, csup]);\r}\u0026quot;)\r Finally, I am ready to estimate $P(S = s1 | D = d)$:\nfor (samp_iter in seq(length(cdiam_vec))) {\r# create data list\rjags.data \u0026lt;- list(sp = sp, Diams = Diams, cdiam = cdiam_vec[samp_iter])\r# compile model\rmodel \u0026lt;- jags.model(file = jags_mod, data = jags.data, quiet = TRUE)\rupdate(model, n.iter = 1e4)\r# sample model and retrieve vector of supplier identity (containing values 1 and 2)\rsimu \u0026lt;- coda.samples(model = model, variable.names = \u0026quot;csup\u0026quot;, n.iter = 2e4, thin = 20)[[1]]\r# compute probability of supplier 1\rprob_mat[samp_iter, ] \u0026lt;- sum(simu == 1) / length(simu)\r}\rprob_mat\r ## 6 6.1 6.2 6.4\r## cdiam_1 0.966 0.966 0.966 0.966\r## cdiam_2 0.490 0.490 0.490 0.490\r## cdiam_3 0.035 0.035 0.035 0.035\r  And check the results with Figure 3.2.\n Looking at figure 3.2, I\u0026rsquo;d argue the above probabilities align with the figure:\nScutari 3.4  In Section 3.1.1, the probability that the supplier is s1 knowing that the diameter is 6.2 was estimated to be 0.1824 which is not identical to the value obtained with JAGS.\n   Explain why the calculation with the R function dnorm is right and why the value 0.1824 is correct. Can you explain why the JAGS result is not exact? Propose a way to improve it.   Since either function relies on random processes, differences in seeds may explain the difference in inference. To improve the accuracy of the JAGS result, I would suggest increasing the sample size that led to its creation.\n Would this value be different if we modify the marginal distribution for the two suppliers?   Yes. Marginal distributions are essential to the Bayes' Theorem and a change thereof would necessitate a change in inference.\nScutari 3.5  Revisiting the discretisation in Section 3.1.2, compute the conditional probability tables for $ D | S $ and $ S | D $ when the interval boundaries are set to $ (6.10, 6.18) $ instead of $ (6.16, 6.19)$ . Compared to the results presented in Section 3.1.2, what is your conclusion?\n Let\u0026rsquo;s start by repeating book code and updating the intervals to obtain $D | S$:\nmu \u0026lt;- c(6.1, 6.25)\rsigma \u0026lt;- 0.05\rlimits \u0026lt;- c(6.10, 6.18)\rdsd \u0026lt;- matrix(\rc(\rdiff(c(0, pnorm(limits, mu[1], sigma), 1)),\rdiff(c(0, pnorm(limits, mu[2], sigma), 1))\r),\r3, 2\r)\rdimnames(dsd) \u0026lt;- list(D = c(\u0026quot;thin\u0026quot;, \u0026quot;average\u0026quot;, \u0026quot;thick\u0026quot;), S = c(\u0026quot;s1\u0026quot;, \u0026quot;s2\u0026quot;))\rdsd\r ## S\r## D s1 s2\r## thin 0.50000000 0.001349898\r## average 0.44520071 0.079406761\r## thick 0.05479929 0.919243341\r To obtain $ S | D $, we apply Bayes' Theorem:\njointd \u0026lt;- dsd / 2 # dive by 2 to get joint distribution over suppliers of which we have 2\rmardd \u0026lt;- rowSums(jointd) # marginal distribution of diametre class irrespective of supplier\rdds \u0026lt;- t(jointd / mardd) # find conditional probabilites\rdds\r ## D\r## S thin average thick\r## s1 0.997307473 0.8486359 0.05625964\r## s2 0.002692527 0.1513641 0.94374036\r One of our new limits in in fact the mean diametre supplied by supplier 1. That is clearly not a helpful limit as it simply shifts probability to supplier 1.\nSession Info sessionInfo()\r ## R version 4.2.1 (2022-06-23 ucrt)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19044)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_Germany.utf8 LC_CTYPE=English_Germany.utf8 LC_MONETARY=English_Germany.utf8 LC_NUMERIC=C LC_TIME=English_Germany.utf8 ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] rjags_4-13 coda_0.19-4 bnlearn_4.8.1\r## ## loaded via a namespace (and not attached):\r## [1] bslib_0.4.0 compiler_4.2.1 pillar_1.8.1 jquerylib_0.1.4 R.methodsS3_1.8.2 R.utils_2.12.0 tools_4.2.1 digest_0.6.29 jsonlite_1.8.0 evaluate_0.16 ## [11] lifecycle_1.0.2 R.cache_0.16.0 lattice_0.20-45 rlang_1.0.5 cli_3.3.0 rstudioapi_0.14 yaml_2.3.5 parallel_4.2.1 blogdown_1.13 xfun_0.33 ## [21] fastmap_1.1.0 styler_1.8.0 stringr_1.4.1 knitr_1.40 vctrs_0.4.1 sass_0.4.2 grid_4.2.1 glue_1.6.2 R6_2.5.1 fansi_1.0.3 ## [31] rmarkdown_2.16 bookdown_0.29 purrr_0.3.4 magrittr_2.0.3 htmltools_0.5.3 utf8_1.2.2 stringi_1.7.8 cachem_1.0.6 R.oo_1.25.0\r ","date":1623110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623178800,"objectID":"72e481f04175777817d040596d877b4c","permalink":"https://www.erikkusch.com/courses/bayes-nets/part-3/","publishdate":"2021-06-08T00:00:00Z","relpermalink":"/courses/bayes-nets/part-3/","section":"courses","summary":"Answers and solutions to the exercises belonging to Part 3 in [Bayesian Networks with Examples in R](https://www.bnlearn.com/book-crc/) by M. Scutari and J.-B. Denis.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Hybrid Bayesian Networks","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Sampling the Imaginary Material  \rSlides Chapter 3  Introduction These are answers and solutions to the exercises at the end of chapter 3 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Jeffrey Girard.\nLoading rethinking package for visualisations:\nrm(list = ls())\rlibrary(rethinking)\r Easy Exercises These problems use the samples from the posterior distribution for the globe tossing example. This code will give you a specific set of samples, so that you can check your answers exactly. Use the values in samples to answer the questions that follow.\np_grid \u0026lt;- seq(from = 0, to = 1, length.out = 1000)\rprior \u0026lt;- rep(1, 1000)\rlikelihood \u0026lt;- dbinom(6, size = 9, prob = p_grid)\rposterior \u0026lt;- likelihood * prior\rposterior \u0026lt;- posterior / sum(posterior)\rset.seed(100)\rsamples \u0026lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\rhist(samples)\r Practice E1 Question: How much posterior probability lies below $p=0.2$?\nAnswer:\n# how the book did it\rsum(samples \u0026lt; .2) / length(samples)\r ## [1] 4e-04\r # easier way\rmean(samples \u0026lt; 0.2)\r ## [1] 4e-04\r Practice E2 Question: How much posterior probability lies above $p=0.8$?\nAnswer:\nmean(samples \u0026gt; 0.8)\r ## [1] 0.1116\r Practice E3 Question: How much posterior probability lies between $p=0.2$ and $p=0.8$?\nAnswer:\nmean(samples \u0026gt; 0.2 \u0026amp; samples \u0026lt; 0.8)\r ## [1] 0.888\r Practice E4 Question: 20% of the posterior probability lies below which value of $p$?\nAnswer:\nquantile(samples, 0.2)\r ## 20% ## 0.5185185\r Practice E5 Question: 20% of the posterior probability lies above which value of $p$?\nAnswer:\nquantile(samples, 0.8)\r ## 80% ## 0.7557558\r Practice E6 Question: Which values of $p$ contain the narrowest interval equal to 66% of the posterior probability?\nAnswer:\nHPDI(samples, prob = 0.66)\r ## |0.66 0.66| ## 0.5085085 0.7737738\r Practice E7 Question: Which values of p contain 66% of the posterior probability, assuming equal posterior probability both below and above the interval?\nAnswer:\nPI(samples, prob = 0.66)\r ## 17% 83% ## 0.5025025 0.7697698\r Medium Exercises Practice M1 Question: Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.\nAnswer:\np_grid \u0026lt;- seq(from = 0, to = 1, length.out = 1000)\rprior \u0026lt;- rep(1, 1000)\rlikelihood \u0026lt;- dbinom(8, size = 15, prob = p_grid)\rposterior \u0026lt;- likelihood * prior\rposterior \u0026lt;- posterior / sum(posterior)\rplot(p_grid, posterior, type = \u0026quot;l\u0026quot;)\r p_grid[which.max(posterior)]\r ## [1] 0.5335335\r Practice M2 Question: Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for $p$.\nAnswer:\nset.seed(42)\rsamples \u0026lt;- sample(p_grid, prob = posterior, replace = TRUE, size = 1e+4)\rhist(samples)\r HPDI(samples, prob = .9)\r ## |0.9 0.9| ## 0.3393393 0.7267267\r mean(samples)\r ## [1] 0.5295147\r median(samples)\r ## [1] 0.5305305\r Practice M3 Question: Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in $p$. What is the probability of observing 8 water in 15 tosses?\nAnswer:\nn \u0026lt;- 15\rset.seed(42)\rdumdata \u0026lt;- rbinom(10000, size = n, prob = samples)\rsimplehist(dumdata)\r mean(dumdata == 8)\r ## [1] 0.1419\r Practice M4 Question: Using the posterior distribution constructed from the new (8/15) data, now calculate the probability of observing 6 water in 9 tosses.\nAnswer:\nlikelihood_6of9 \u0026lt;- dbinom(6, size = 9, prob = p_grid)\rprior_6of9 \u0026lt;- posterior\r(p_6of9 \u0026lt;- sum(likelihood_6of9 * prior_6of9))\r ## [1] 0.1763898\r ## Alternatively, we can generate the data using the same seed as above:\rset.seed(100)\rdumdata_6of9 \u0026lt;- rbinom(10000, size = 9, prob = samples)\rsimplehist(dumdata_6of9)\r mean(dumdata_6of9 == 6)\r ## [1] 0.1765\r Practice M5 Question: Start over at 3M1, but now use a prior that is zero below $p=0.5$ and a constant above $p=0.5$. This corresponds to prior information that a majority of the Earth’s surface is water. Repeat each problem above and compare the inferences. What difference does the better prior make? If it helps, compare inferences (using both priors) to the true value $p=0.7$.\nPart A Question: Construct the posterior distribution, using grid approximation.\nAnswer:\np_grid \u0026lt;- seq(from = 0, to = 1, length.out = 1000)\rprior \u0026lt;- ifelse(p_grid \u0026lt; 0.5, 0, 0.5)\rlikelihood \u0026lt;- dbinom(8, size = 15, prob = p_grid)\rposterior \u0026lt;- likelihood * prior\rposterior \u0026lt;- posterior / sum(posterior)\rplot(p_grid, posterior, type = \u0026quot;l\u0026quot;)\r p_grid[which.max(posterior)]\r ## [1] 0.5335335\r Part B Question: Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for $p$\nAnswer:\nset.seed(42)\rsamples \u0026lt;- sample(p_grid, prob = posterior, replace = TRUE, size = 1e+4)\rhist(samples)\r HPDI(samples, prob = .9)\r ## |0.9 0.9| ## 0.5005005 0.7117117\r mean(samples)\r ## [1] 0.6067921\r median(samples)\r ## [1] 0.5945946\r Part C Question: What is the probability of observing 8 water in 15 tosses?\nAnswer:\nn \u0026lt;- 15\rset.seed(42)\rdumdata \u0026lt;- rbinom(10000, size = n, prob = samples)\rsimplehist(dumdata)\r mean(dumdata == 8)\r ## [1] 0.1516\r table(dumdata) / 1e+4\r ## dumdata\r## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## 0.0002 0.0004 0.0038 0.0125 0.0329 0.0671 0.1188 0.1516 0.1734 0.1712 0.1276 0.0823 0.0398 0.0157 0.0027\r Part D Question: Using the posterior distribution constructed from the new (8/15) data, now calculate the probability of observing 6 water in 9 tosses.\nAnswer:\nlikelihood_6of9 \u0026lt;- dbinom(6, size = 9, prob = p_grid)\rprior_6of9 \u0026lt;- posterior\r(p_6of9 \u0026lt;- sum(likelihood_6of9 * prior_6of9))\r ## [1] 0.2323071\r ## Alternatively, we can generate the data using the same seed as above:\rset.seed(100)\rdumdata_6of9 \u0026lt;- rbinom(10000, size = 9, prob = samples)\rsimplehist(dumdata_6of9)\r mean(dumdata_6of9 == 6)\r ## [1] 0.2321\r Practice M6 Question: Suppose you want to estimate the Earth’s proportion of water very precisely. Specifically, you want the 99% percentile interval of the posterior distribution of $p$ to be only 0.05 wide. This means the distance between the upper and lower bound of the interval should be 0.05. How many times will you have to toss the globe to do this?\nAnswer: Solution taken from Richard McElreath and altered by myself.\nf \u0026lt;- function(N) {\rp_true \u0026lt;- 0.7\rW \u0026lt;- rbinom(1, size = N, prob = p_true)\rprob_grid \u0026lt;- seq(0, 1, length.out = 1000)\rprior \u0026lt;- rep(1, 1000)\rprob_data \u0026lt;- dbinom(W, size = N, prob = prob_grid)\rposterior \u0026lt;- prob_data * prior\rposterior \u0026lt;- posterior / sum(posterior)\rsamples \u0026lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\rPI99 \u0026lt;- PI(samples, .99)\ras.numeric(PI99[2] - PI99[1])\r}\rNlist \u0026lt;- c(20, 50, 100, 200, 500, 1000, 2000)\rNlist \u0026lt;- rep(Nlist, each = 100)\rwidth \u0026lt;- sapply(Nlist, f)\rplot(Nlist, width)\rabline(h = 0.05, col = \u0026quot;red\u0026quot;)\r Hard Exercises data(homeworkch3)\r Practice H1 Question: Using grid approximation, compute the posterior distribution for the probability of a birth being a boy. Assume a uniform prior probability. Which parameter value maximizes the posterior probability?\nAnswer:\nn_boys \u0026lt;- sum(c(birth1, birth2))\rn_ttl \u0026lt;- length(birth1) + length(birth2)\rn_pgrid \u0026lt;- 1000\rp_grid \u0026lt;- seq(0, 1, length.out = n_pgrid)\rprior \u0026lt;- rep(1, n_pgrid)\rlikelihood \u0026lt;- dbinom(n_boys, size = n_ttl, prob = p_grid)\rposterior \u0026lt;- likelihood * prior\rposterior \u0026lt;- posterior / sum(posterior)\rplot(p_grid, posterior, type = \u0026quot;l\u0026quot;)\r p_grid[which.max(posterior)]\r ## [1] 0.5545546\r Practice H2 Question: Using the $sample()$ function, draw 10000 random parameter values from the posterior distribution you calculated above. Use these samples to estimate the 50%, 89% and 97% highest posterior density intervals.\nAnswer:\nn_ptrials \u0026lt;- 1e4\rp_samples \u0026lt;- sample(p_grid, size = n_ptrials, prob = posterior, replace = TRUE)\r(hpi_50 \u0026lt;- HPDI(p_samples, .5))\r ## |0.5 0.5| ## 0.5265265 0.5735736\r (hpi_89 \u0026lt;- HPDI(p_samples, .89))\r ## |0.89 0.89| ## 0.4964965 0.6076076\r (hpi_97 \u0026lt;- HPDI(p_samples, .97))\r ## |0.97 0.97| ## 0.4784785 0.6276276\r for (w in c(.5, .89, .97)) {\rhpi \u0026lt;- HPDI(p_samples, w)\rprint(sprintf(\u0026quot;HPDI %d%% [%f, %f]\u0026quot;, w * 100, hpi[1], hpi[2]))\r}\r ## [1] \u0026quot;HPDI 50% [0.526527, 0.573574]\u0026quot;\r## [1] \u0026quot;HPDI 89% [0.496496, 0.607608]\u0026quot;\r## [1] \u0026quot;HPDI 97% [0.478478, 0.627628]\u0026quot;\r mean(p_samples)\r ## [1] 0.5545528\r median(p_samples)\r ## [1] 0.5545546\r Practice H3 Question: Use rbinom() to simulate 10000 replicates of 200 births. You should end up with 10000 numbers, each one a count of boys out of 200 births. Compare the distribution of predicted numbers of boys to the actual count in the data (111 boys out of 200 births). There are many good ways to visualize the simulations, but the dens() command (part of the rethinking package) is probably the easiest way in this case. Does it look like the model fits the data well? That is, does the distribution of predictions include the actual observation as a central, likely outcome?\nAnswer:\nn_btrials \u0026lt;- 1e4 # birth observations\rset.seed(42)\rb_sample \u0026lt;- rbinom(n_btrials, size = n_ttl, prob = p_samples)\rsimplehist(b_sample)\r mean(b_sample)\r ## [1] 110.9792\r median(b_sample)\r ## [1] 111\r dens(b_sample)\rabline(v = n_boys, col = \u0026quot;red\u0026quot;)\r Practice H4 Question: Now compare 10000 counts of boys from 100 simulated first-borns only to the number of boys in the first births, birth1. How does the model look in this light?\nAnswer:\nn_boys_b1 \u0026lt;- sum(birth1)\rn_ttl_b1 \u0026lt;- length(birth1)\rn_btrials \u0026lt;- 1e4 # birth observations\rlikelihood \u0026lt;- dbinom(sum(birth1), size = length(birth1), prob = p_grid)\rposterior \u0026lt;- likelihood * prior\rposterior \u0026lt;- posterior / sum(posterior)\rsamples \u0026lt;- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)\rset.seed(42)\rb_sample \u0026lt;- rbinom(n_btrials, size = n_ttl_b1, prob = samples)\rsimplehist(b_sample)\rabline(v = n_boys_b1, col = \u0026quot;red\u0026quot;)\r mean(b_sample)\r ## [1] 51.0102\r median(b_sample)\r ## [1] 51\r dens(b_sample)\rabline(v = n_boys_b1, col = \u0026quot;red\u0026quot;)\r Practice H5 Question: The model assumes that sex of first and second births are independent. To check this assumption, focus now on second births that followed female first-borns. Compare 10,000 simulated counts of boys to only those second births that followed girls. To do this correctly, you need to count the number of first-borns who were girls and simulate that many births, 10,000 times. Compare the counts of boys in your simulations to the actual observed count of boys following girls. How does the model look in this light? Any guesses what is going on in these data?\nAnswer:\nn_ttl_g1 \u0026lt;- sum(birth1 == 0)\rn_ttl_g1b2 \u0026lt;- sum(birth2[birth1 == 0])\rprint(sprintf(\u0026quot;there were %d boys born after first girl. There were ttl %d cases\u0026quot;, n_ttl_g1b2, n_ttl_g1))\r ## [1] \u0026quot;there were 39 boys born after first girl. There were ttl 49 cases\u0026quot;\r n_btrials \u0026lt;- 1e4 # birth observations\rb_sample \u0026lt;- rbinom(n_btrials, size = n_ttl_g1, prob = p_samples)\rmean(b_sample)\r ## [1] 27.1431\r median(b_sample)\r ## [1] 27\r simplehist(b_sample)\rabline(v = n_ttl_g1b2, col = \u0026quot;red\u0026quot;)\r The model underestimates number of boys for the second child after the first girl. Gender of the second child is not independent from the first one.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] rethinking_2.13 rstan_2.21.2 ggplot2_3.3.3 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 R6_2.5.0 ## [11] backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 ## [21] jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 ## [31] pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 codetools_0.2-18 matrixStats_0.61.0\r## [41] fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 lifecycle_1.0.0 ## [51] DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.7 ## [61] rematch2_2.1.2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 ## [71] sass_0.3.1\r ","date":1609977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610002800,"objectID":"b70e96efa9e41c4224535792e35d43de","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-03/","publishdate":"2021-01-07T00:00:00Z","relpermalink":"/courses/rethinking/chapter-03/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 3 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 03","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some Lecture Slides  for this session. I also provide the code structure  I propose during the talk with useful helper functions.\nAn older version of the lecture slides from previous talks on the same subject can be found here  and are much text-heavier.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"0219ee030fe0b3ce6cad690462d2dc42","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/3_coding-practices-life-with-r/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/3_coding-practices-life-with-r/","section":"courses","summary":"I have prepared some Lecture Slides  for this session. I also provide the code structure  I propose during the talk with useful helper functions.\nAn older version of the lecture slides from previous talks on the same subject can be found here  and are much text-heavier.","tags":null,"title":"Coding Practices - Life with R","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory These are the solutions to the exercises contained within the handout to A Primer For Statistical Tests which walks you through the basics of variables, their scales and distributions. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.\nI have prepared some I have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here.\nLoading the R Environment Object load(\u0026quot;Data/Primer.RData\u0026quot;) # load data file from Data folder\r Variables Finding Variables ls() # list all elements in working environment\r ## [1] \u0026quot;Colour\u0026quot; \u0026quot;Depth\u0026quot; \u0026quot;IndividualsPassingBy\u0026quot;\r## [4] \u0026quot;Length\u0026quot; \u0026quot;Reproducing\u0026quot; \u0026quot;Sex\u0026quot; ## [7] \u0026quot;Size\u0026quot; \u0026quot;Temperature\u0026quot;\r Colour class(Colour) # mode\r ## [1] \u0026quot;character\u0026quot;\r barplot(table(Colour)) # fitting?\r    Question Answer     Mode? character   Which scale? Nominal   What\u0026rsquo;s implied? Categorical data that can\u0026rsquo;t be ordered   Does data fit scale? Yes    Depth class(Depth) # mode\r ## [1] \u0026quot;numeric\u0026quot;\r barplot(Depth) # fitting?\r    Question Answer     Mode? numeric   Which scale? Interval/Discrete   What\u0026rsquo;s implied? Continuous data with a non-absence point of origin   Does data fit scale? Debatable (is 0 depth absence of depth?)    IndividualsPassingBy class(IndividualsPassingBy) # mode\r ## [1] \u0026quot;integer\u0026quot;\r barplot(IndividualsPassingBy) # fitting?\r    Question Answer     Mode? integer   Which scale? Integer   What\u0026rsquo;s implied? Only integer numbers with an absence point of origin   Does data fit scale? Yes    Length class(Length) # mode\r ## [1] \u0026quot;numeric\u0026quot;\r barplot(Length) # fitting?\r    Question Answer     Mode? numeric   Which scale? Relation/Ratio   What\u0026rsquo;s implied? Continuous data with an absence point of origin   Does data fit scale? Yes    Reproducing class(Reproducing) # mode\r ## [1] \u0026quot;integer\u0026quot;\r barplot(Reproducing) # fitting?\r    Question Answer     Mode? integer   Which scale? Integer   What\u0026rsquo;s implied? Only integer numbers with an absence point of origin   Does data fit scale? Yes    Sex class(Sex) # mode\r ## [1] \u0026quot;factor\u0026quot;\r barplot(table(Sex)) # fitting?\r    Question Answer     Mode? factor   Which scale? Binary   What\u0026rsquo;s implied? Only two possible outcomes   Does data fit scale? Yes    Size class(Size) # mode\r ## [1] \u0026quot;character\u0026quot;\r barplot(table(Size)) # fitting?\r    Question Answer     Mode? character   Which scale? Ordinal   What\u0026rsquo;s implied? Categorical data that can be ordered   Does data fit scale? Yes    Temperature class(Temperature) # mode\r ## [1] \u0026quot;numeric\u0026quot;\r barplot(Temperature) # fitting?\r    Question Answer     Mode? numeric   Which scale? Interval/Discrete   What\u0026rsquo;s implied? Continuous data with a non-absence point of origin   Does data fit scale? Yes (the data is clearly recorded in degree Celsius)    Distributions Length plot(density(Length)) # distribution plot\r shapiro.test(Length) # normality check\r ## ## Shapiro-Wilk normality test\r## ## data: Length\r## W = 0.99496, p-value = 0.4331\r The data is normal distributed.\nReproducing plot(density(Reproducing)) # distribution\r shapiro.test(Reproducing) # normality check\r ## ## Shapiro-Wilk normality test\r## ## data: Reproducing\r## W = 0.98444, p-value = 0.2889\r The data is binomial distributed (i.e. \u0026ldquo;How many individuals manage to reproduce\u0026rdquo;) but looks normal distributed. The normal distribution doesn\u0026rsquo;t make sense here because it implies continuity whilst the data only comes in integers.\nIndividualsPassingBy plot(density(IndividualsPassingBy)) # distribution\r shapiro.test(IndividualsPassingBy) # normality check\r ## ## Shapiro-Wilk normality test\r## ## data: IndividualsPassingBy\r## W = 0.96905, p-value = 0.0187\r The data is poisson distributed (i.e. \u0026ldquo;How many individuals pass by an observer in a given time frame?\u0026quot;).\nDepth plot(density(Depth)) # distribution\r The data is uniform distributed. You don\u0026rsquo;t know this distribution class from the lectures and I only wanted to confuse you with this to show you that there\u0026rsquo;s much more out there than I can show in our lectures.\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"9ffb32ff6eeee114ae491cc10d8319ee","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/a-primer-for-statistical-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/a-primer-for-statistical-tests/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to A Primer For Statistical Tests which walks you through the basics of variables, their scales and distributions. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.","tags":["R","Statistics"],"title":"A Primer For Statistical Tests","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory These are the solutions to the exercises contained within the handout to A Primer For Statistical Tests which walks you through the basics of variables, their scales and distributions. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.\n\r\rTheory slides for this session.\rClick the outline of the presentation below to get to the HTML version of the slides for this session.\r\r \r\rData Find the data for this exercise here.\nLoading the R Environment Object load(\u0026quot;Data/Primer.RData\u0026quot;) # load data file from Data folder\r Variables Finding Variables ls() # list all elements in working environment\r ## [1] \u0026quot;Colour\u0026quot; \u0026quot;Depth\u0026quot; \u0026quot;IndividualsPassingBy\u0026quot;\r## [4] \u0026quot;Length\u0026quot; \u0026quot;Reproducing\u0026quot; \u0026quot;Sex\u0026quot; ## [7] \u0026quot;Size\u0026quot; \u0026quot;Temperature\u0026quot;\r Colour class(Colour) # mode\r ## [1] \u0026quot;character\u0026quot;\r barplot(table(Colour)) # fitting?\r    Question Answer     Mode? character   Which scale? Nominal   What\u0026rsquo;s implied? Categorical data that can\u0026rsquo;t be ordered   Does data fit scale? Yes    Depth class(Depth) # mode\r ## [1] \u0026quot;numeric\u0026quot;\r barplot(Depth) # fitting?\r    Question Answer     Mode? numeric   Which scale? Interval/Discrete   What\u0026rsquo;s implied? Continuous data with a non-absence point of origin   Does data fit scale? Debatable (is 0 depth absence of depth?)    IndividualsPassingBy class(IndividualsPassingBy) # mode\r ## [1] \u0026quot;integer\u0026quot;\r barplot(IndividualsPassingBy) # fitting?\r    Question Answer     Mode? integer   Which scale? Integer   What\u0026rsquo;s implied? Only integer numbers with an absence point of origin   Does data fit scale? Yes    Length class(Length) # mode\r ## [1] \u0026quot;numeric\u0026quot;\r barplot(Length) # fitting?\r    Question Answer     Mode? numeric   Which scale? Relation/Ratio   What\u0026rsquo;s implied? Continuous data with an absence point of origin   Does data fit scale? Yes    Reproducing class(Reproducing) # mode\r ## [1] \u0026quot;integer\u0026quot;\r barplot(Reproducing) # fitting?\r    Question Answer     Mode? integer   Which scale? Integer   What\u0026rsquo;s implied? Only integer numbers with an absence point of origin   Does data fit scale? Yes    Sex class(Sex) # mode\r ## [1] \u0026quot;factor\u0026quot;\r barplot(table(Sex)) # fitting?\r    Question Answer     Mode? factor   Which scale? Binary   What\u0026rsquo;s implied? Only two possible outcomes   Does data fit scale? Yes    Size class(Size) # mode\r ## [1] \u0026quot;character\u0026quot;\r barplot(table(Size)) # fitting?\r    Question Answer     Mode? character   Which scale? Ordinal   What\u0026rsquo;s implied? Categorical data that can be ordered   Does data fit scale? Yes    Temperature class(Temperature) # mode\r ## [1] \u0026quot;numeric\u0026quot;\r barplot(Temperature) # fitting?\r    Question Answer     Mode? numeric   Which scale? Interval/Discrete   What\u0026rsquo;s implied? Continuous data with a non-absence point of origin   Does data fit scale? Yes (the data is clearly recorded in degree Celsius)    Distributions Length plot(density(Length)) # distribution plot\r shapiro.test(Length) # normality check\r ## ## Shapiro-Wilk normality test\r## ## data: Length\r## W = 0.99496, p-value = 0.4331\r The data is normal distributed.\nReproducing plot(density(Reproducing)) # distribution\r shapiro.test(Reproducing) # normality check\r ## ## Shapiro-Wilk normality test\r## ## data: Reproducing\r## W = 0.98444, p-value = 0.2889\r The data is binomial distributed (i.e. \u0026ldquo;How many individuals manage to reproduce\u0026rdquo;) but looks normal distributed. The normal distribution doesn\u0026rsquo;t make sense here because it implies continuity whilst the data only comes in integers.\nIndividualsPassingBy plot(density(IndividualsPassingBy)) # distribution\r shapiro.test(IndividualsPassingBy) # normality check\r ## ## Shapiro-Wilk normality test\r## ## data: IndividualsPassingBy\r## W = 0.96905, p-value = 0.0187\r The data is poisson distributed (i.e. \u0026ldquo;How many individuals pass by an observer in a given time frame?\u0026quot;).\nDepth plot(density(Depth)) # distribution\r The data is uniform distributed. You don\u0026rsquo;t know this distribution class from the lectures and I only wanted to confuse you with this to show you that there\u0026rsquo;s much more out there than I can show in our lectures.\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"27d88087bc392c222cdc534b7d542053","permalink":"https://www.erikkusch.com/courses/biostat101/a-primer-for-statistical-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/a-primer-for-statistical-tests/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to A Primer For Statistical Tests which walks you through the basics of variables, their scales and distributions. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.","tags":["R","Statistics"],"title":"A Primer For Statistical Tests","type":"docs"},{"authors":["Erik Kusch"],"categories":["BFTP Projects"],"content":"Preparing The Work Let\u0026rsquo;s create our basic structure for this document:\nHead Not much has changed in the head when compared to our last exercise. We merely change the contents and and the edit tag, since the rest stays the same for the entire project.\n# ####################################################################### #\r# PROJECT: [BFTP] Identifying Biomes And Their Shifts Using Remote Sensing\r# CONTENTS: Functionality to identify and analyse changes in spatial cluster distributions\r# AUTHOR: Erik Kusch\r# EDIT: 19/03/20\r# ####################################################################### #\r Preamble I am keeping the same preamble as last time because we will need to index the data and the plot directory in this exercise. Our preamble then looks like this:\nrm(list=ls()) # clearing the entire environment\rDir.Base \u0026lt;- getwd() # identifying the current directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # generating the folder path for data folder\rDir.Plots \u0026lt;- paste(Dir.Base, \u0026quot;Plots\u0026quot;, sep=\u0026quot;/\u0026quot;) # generating the folder path for figures folder\r Notice, that we do not call the function dir.create() this time. We don\u0026rsquo;t need to do so, because we already created the two directories established above in our last exercise. Usually, we would create this entire analysis of your BFTP project in one R code script. In this case, we would only have one preamble which defines and creates directories instead of doing this step for every single sub-part of the analysis. Alas, we want to break this down for you. Therefore, you see this preamble here and will again in the next exercise.\nThis time, we actually do load packages here as we really only need the raster package. By now, I am assuming you know what we use it for:\nlibrary(raster) # the raster package for rasters\r Additionally, we reload our .RData workspace from the last exercise to gain back our mclust model objects in particular.\nload(file = \u0026quot;Workspace.RData\u0026quot;) # load workspace\r Coding Again, all of the important Coding happens after the head and the preamble are written and run in R. Basically, this is the rest of this document once more.\nChange Analysis Loading Data Firstly, we need the raw NDVI mean and seasonality data for the time frames we want to compare. Let\u0026rsquo;s deal with that right quick.\n1982 Let\u0026rsquo;s load our 1982 NDVI mean and seasonality data:\nMean1982_ras \u0026lt;- raster(paste(Dir.Data, \u0026quot;1982Mean.nc\u0026quot;, sep=\u0026quot;/\u0026quot;)) # loading means\rSeason1982_ras \u0026lt;- raster(paste(Dir.Data, \u0026quot;1982Season.nc\u0026quot;, sep=\u0026quot;/\u0026quot;)) # loading seasonalities\rAll1982_ras \u0026lt;- stack(Mean1982_ras, Season1982_ras) # creating a stack\rnames(All1982_ras) \u0026lt;- c(\u0026quot;Mean\u0026quot;, \u0026quot;Seasonality\u0026quot;) # assign names to stack layers\rVals1982_mat \u0026lt;- values(All1982_ras) # extract data\rrownames(Vals1982_mat) \u0026lt;- 1:dim(Vals1982_mat)[1] # rownames to index raster cell number\rVals1982_mat \u0026lt;- na.omit(Vals1982_mat) # omit all rows which contain at least one NA record\rsummary(Vals1982_mat) # a summary of the data\r ## Mean Seasonality ## Min. :0.00 Min. :0.00 ## 1st Qu.:0.22 1st Qu.:0.55 ## Median :0.33 Median :0.67 ## Mean :0.32 Mean :0.64 ## 3rd Qu.:0.41 3rd Qu.:0.76 ## Max. :0.84 Max. :1.00\r 2015 In order to assess how biome distributions have changed, we need another time frame to compare our 1982 data to. For this, I have re-run the code from our first BFTP exercise for the year 2015. We now load that data into R:\nMean2015_ras \u0026lt;- raster(paste(Dir.Data, \u0026quot;2015Mean.nc\u0026quot;, sep=\u0026quot;/\u0026quot;)) # loading means\rSeason2015_ras \u0026lt;- raster(paste(Dir.Data, \u0026quot;2015Season.nc\u0026quot;, sep=\u0026quot;/\u0026quot;)) # loading seasonalities\rAll2015_ras \u0026lt;- stack(Mean2015_ras, Season2015_ras) # creating a stack\rnames(All2015_ras) \u0026lt;- c(\u0026quot;Mean\u0026quot;, \u0026quot;Seasonality\u0026quot;) # assign names to stack layers\rVals2015_mat \u0026lt;- values(All2015_ras) # extract data\rrownames(Vals2015_mat) \u0026lt;- 1:dim(Vals2015_mat)[1] # rownames to index raster cell number\rVals2015_mat \u0026lt;- na.omit(Vals2015_mat) # omit all rows which contain at least one NA record\rsummary(Vals2015_mat) # a summary of the data\r ## Mean Seasonality ## Min. :0.00 Min. :0.00 ## 1st Qu.:0.25 1st Qu.:0.56 ## Median :0.33 Median :0.67 ## Mean :0.34 Mean :0.64 ## 3rd Qu.:0.43 3rd Qu.:0.77 ## Max. :0.83 Max. :1.00\r Notice, that the output of the summary() function is different for both matrices built from raster data values. This is important to ensure that our analysis actually references different time frames.\n\\newpage\nPredictions Secondly, we want to compare cluster assignments. To do so, we need to use our mclust models to predict cluster assignments for each cell in our target region raster using the NDVI mean and seasonality data that we loaded previously.\n1982 Let\u0026rsquo;s deal with the 1982 data first. mod2 is the mclust model object for 4 clusters from our last exercise. Here, we predict clusters and place them on a raster:\nModPred1982 \u0026lt;- predict.Mclust(mod2, Vals1982_mat) # prediction\rPred1982_ras \u0026lt;- Mean1982_ras # establishing a rediction raster\rvalues(Pred1982_ras) \u0026lt;- NA # set everything to NA\r# set values of prediction raster to corresponding classification according to rowname\rvalues(Pred1982_ras)[as.numeric(rownames(Vals1982_mat))] \u0026lt;- as.vector(ModPred1982$classification)\rcolours \u0026lt;- rainbow(mod2$G) # define 4 colours\rplot(Pred1982_ras, # what to plot\rcol = colours, # colours for groups\rcolNA = \u0026quot;black\u0026quot;, # which colour to assign to NA values\rlegend.shrink=1, # vertical size of legend\rlegend.width=2 # horizontal size of legend\r)\r \\newpage\n2015 Now, we deal with the 2015 time frame. Notice, that we are using the mod2 mclust model which was established for 1982 in our last exercise. It is important that we use the same model when predicting our classes between time frames to ensure comparability. After all, we want to make sure that cluster 1 is the same in 1982 as 2015. It is debatable whether we should use a cluster model built from just one year of data or even from the same time frame as one of the the time frames which are to be compared. In fact, I would argue that we should establish a mclust model for the mean annual NDVI and mean annual seasonality of NDVI across the entire time for which data is available. For now, we simply use the 1982-reliant model:\nModPred2015 \u0026lt;- predict.Mclust(mod2, Vals2015_mat) # prediction\rPred2015_ras \u0026lt;- Mean2015_ras # establishing a rediction raster\rvalues(Pred2015_ras) \u0026lt;- NA # set everything to NA\r# set values of prediction raster to corresponding classification according to rowname\rvalues(Pred2015_ras)[as.numeric(rownames(Vals2015_mat))] \u0026lt;- as.vector(ModPred2015$classification)\rcolours \u0026lt;- rainbow(mod2$G) # define 4 colours\rplot(Pred2015_ras, # what to plot\rcol = colours, # colours for groups\rcolNA = \u0026quot;black\u0026quot;, # which colour to assign to NA values\rlegend.shrink=1, # vertical size of legend\rlegend.width=2 # horizontal size of legend\r)\r You can already see some cluster assignment changes on Nunivak island.\n\\newpage\nInitial Assesment Let\u0026rsquo;s first assess how many raster cells have changed cluster assignment between our two time frames:\n# identify how many cell assignments don't match between rasters\rChange \u0026lt;- sum(ModPred1982$classification != ModPred2015$classification)\r# divide number of mismatches by number of all cells\rChange/length(ModPred2015$classification)\r ## [1] 0.22\r As you can see, there is a proportion of 0.22 raster cells which have changed cluster assignment between the two time frames. Now, let\u0026rsquo;s put this on a map:\nPredChange_ras \u0026lt;- Mean2015_ras # establishing a rediction raster\rvalues(PredChange_ras) \u0026lt;- NA # set everything to NA\r# set values of prediction raster to corresponding classification according to rowname\rvalues(PredChange_ras)[as.numeric(rownames(Vals2015_mat))] \u0026lt;- ModPred1982$classification != ModPred2015$classification\rcolours \u0026lt;- c(\u0026quot;green\u0026quot;, \u0026quot;red\u0026quot;) # define 2 colours\rplot(PredChange_ras, col = colours, colNA = \u0026quot;black\u0026quot;,\rlegend.shrink=1, legend.width=2)\r I leave it to you to interpret these patterns (there actually is an interpretation to be had here).\n\\newpage\nIn-Depth Assesment I\u0026rsquo;d argue that a simple understanding whether things have changed won\u0026rsquo;t be what we want to report. What we want, is to know which cluster took over the cells of which raster. I.e., I\u0026rsquo;d like to answer the question: \u0026ldquo;Which clusters take over the regions of other clusters and which ones?\u0026rdquo;. I hope you\u0026rsquo;re interested in this, too. Here\u0026rsquo;s how we can analyse this: For each cluster assignment we:\n Identify the cells corresponding to it in 1982/the past Count how many of these cells are classified as the same cluster in 2015/the present Repeat the above for all combinations of cluster assignments imaginable  NClusters \u0026lt;- mod2$G # identify the number of clusters\rpresent \u0026lt;- as.vector(Pred2015_ras) # assignments in 2015\rpast \u0026lt;- as.vector(Pred1982_ras) # assignments in 1982\r# this matrix will hold the data, rows will show past state, columns will show present state\rchangematrix \u0026lt;- matrix(rep(NA, NClusters^2), nrow=NClusters, ncol=NClusters)\rchangevec \u0026lt;- rep(NA, NClusters) # this vector will fill rows in our matrix\rfor(k in 1:NClusters){ # loop over clusters in past\rchangerun \u0026lt;- changevec changeperc \u0026lt;- changevec\rfor(m in 1:NClusters){ # loop over clusters in present\rpresentcells \u0026lt;- which(present==m) # figure out which cells hold value m\rpastcells \u0026lt;- which(past==k) # figure out which cells hold value k\r# figure out how many of the cell denominators are shared by the two vectors\rrate \u0026lt;- length(Reduce(intersect, list(pastcells,presentcells))) changerun[m] \u0026lt;- rate # save rate to changerun in place m\r} # end of present-loop\rchangematrix[k,] \u0026lt;- changerun # save changerun to k row in matrix\rfor(n in 1:NClusters){ # turn rates into portions\r# divide number of in a cell by total number of cells in its row\rchangeperc[n] \u0026lt;- changematrix[k,n] / sum(changematrix[k,])\r} # end of percentages\rchangematrix[k,] \u0026lt;- changeperc # save changeperc to row k\r} # end of past-loop\rchangematrix \u0026lt;- changematrix*100 # turn everything into percentages\rrownames(changematrix) \u0026lt;- paste0(\u0026quot;Past\u0026quot;, 1:NClusters)\rcolnames(changematrix) \u0026lt;- paste0(\u0026quot;Present\u0026quot;, 1:NClusters)\rchangematrix # show the matrix\r ## Present1 Present2 Present3 Present4\r## Past1 82.0 0.84 4.459 13\r## Past2 3.5 60.35 0.074 36\r## Past3 23.8 0.00 76.235 0\r## Past4 16.9 3.01 0.029 80\r As you can see, there\u0026rsquo;s quite a bit going on here. Let me explain how to read this. From past (1982) to present (2015), 82.03% of raster cells assigned to cluster 1 in 1982 are assigned to cluster 1 in 2015 as well. 0.84% of raster cells previously assigned to cluster 1 are classified as cluster 2 in 2015. Notice, how all rows sum up to 100% each. Representing the total of assigned raster cells in the 1982 record.\nGiven the biological counterparts of the clusters, how would you interpret these shifts?\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"64f241fe0e79cd04fee7f8ebe7552b7e","permalink":"https://www.erikkusch.com/courses/bftp-biome-detection/change-analysis/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/bftp-biome-detection/change-analysis/","section":"courses","summary":"Preparing The Work Let\u0026rsquo;s create our basic structure for this document:\nHead Not much has changed in the head when compared to our last exercise. We merely change the contents and and the edit tag, since the rest stays the same for the entire project.","tags":["R","Statistics","Remote Sensing"],"title":"Change Analysis","type":"docs"},{"authors":[],"categories":["Bayesian Networks"],"content":"\rblockquote{\rcolor:#633a00;\r}\r\rMaterial  \rStatic Bayesian Networks by Felipe Sanchez (one of our study group members)  For detailed summary slides, please consult the separate sections on Multinomial, Gaussian, and Hybrid Bayesian Networks.\nExercises These are answers and solutions to the exercises at the end of chapter 2 in Bayesian Networks in R with Applications in Systems Biology by by Radhakrishnan Nagarajan, Marco Scutari \u0026amp; Sophie Lèbre. Much of my inspiration for these solutions, where necessary, by consulting the solutions provided by the authors themselves as in the appendix.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(bnlearn)\rlibrary(igraph)\r Nagarajan 2.1  Consider the asia synthetic data set from Lauritzen and Spiegelhalter (1988), which describes the diagnosis of a patient at a chest clinic who has just come back from a trip to Asia and is showing dyspnea.\n Part A  Load the data set from the bnlearn package and investigate its characteristics using the exploratory analysis techniques covered in Chap. 1.\n data(asia)\rstr(asia)\r ## 'data.frame':\t5000 obs. of 8 variables:\r## $ A: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 1 1 1 1 1 1 1 1 1 1 ...\r## $ S: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 2 2 1 1 1 2 1 2 2 2 ...\r## $ T: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 1 1 2 1 1 1 1 1 1 1 ...\r## $ L: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 1 1 1 1 1 1 1 1 1 1 ...\r## $ B: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 2 1 1 2 1 1 1 2 2 2 ...\r## $ E: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 1 1 2 1 1 1 1 1 1 1 ...\r## $ X: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 1 1 2 1 1 1 1 1 1 1 ...\r## $ D: Factor w/ 2 levels \u0026quot;no\u0026quot;,\u0026quot;yes\u0026quot;: 2 1 2 2 2 2 1 2 2 2 ...\r summary(asia)\r ## A S T L B E X D ## no :4958 no :2485 no :4956 no :4670 no :2451 no :4630 no :4431 no :2650 ## yes: 42 yes:2515 yes: 44 yes: 330 yes:2549 yes: 370 yes: 569 yes:2350\r Part B  Create a bn object with the network structure described in the manual page of asia.\n dag_2.1 \u0026lt;- model2network(\u0026quot;[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]\u0026quot;)\r Part C  Derive the skeleton, the moral graph, and the CPDAG representing the equivalence class of the network. Plot them using graphviz.plot.\n # object creation\rskel_2.1 \u0026lt;- skeleton(dag_2.1)\rmoral_2.1 \u0026lt;- moral(dag_2.1)\requclass_2.1 \u0026lt;- cpdag(dag_2.1)\r# plotting\rpar(mfrow = c(1, 3))\rgraphviz.plot(skel_2.1, main = \u0026quot;Skeleton\u0026quot;)\rgraphviz.plot(moral_2.1, main = \u0026quot;Moral\u0026quot;)\rgraphviz.plot(equclass_2.1, main = \u0026quot;Equivalence Class\u0026quot;)\r Part D  Identify the parents, the children, the neighbors, and the Markov blanket of each node.\n # parents\rsapply(nodes(dag_2.1), bnlearn::parents, x = dag_2.1)\r ## $A\r## character(0)\r## ## $B\r## [1] \u0026quot;S\u0026quot;\r## ## $D\r## [1] \u0026quot;B\u0026quot; \u0026quot;E\u0026quot;\r## ## $E\r## [1] \u0026quot;L\u0026quot; \u0026quot;T\u0026quot;\r## ## $L\r## [1] \u0026quot;S\u0026quot;\r## ## $S\r## character(0)\r## ## $T\r## [1] \u0026quot;A\u0026quot;\r## ## $X\r## [1] \u0026quot;E\u0026quot;\r # children\rsapply(nodes(dag_2.1), bnlearn::children, x = dag_2.1)\r ## $A\r## [1] \u0026quot;T\u0026quot;\r## ## $B\r## [1] \u0026quot;D\u0026quot;\r## ## $D\r## character(0)\r## ## $E\r## [1] \u0026quot;D\u0026quot; \u0026quot;X\u0026quot;\r## ## $L\r## [1] \u0026quot;E\u0026quot;\r## ## $S\r## [1] \u0026quot;B\u0026quot; \u0026quot;L\u0026quot;\r## ## $T\r## [1] \u0026quot;E\u0026quot;\r## ## $X\r## character(0)\r # neighbors\rsapply(nodes(dag_2.1), bnlearn::nbr, x = dag_2.1)\r ## $A\r## [1] \u0026quot;T\u0026quot;\r## ## $B\r## [1] \u0026quot;D\u0026quot; \u0026quot;S\u0026quot;\r## ## $D\r## [1] \u0026quot;B\u0026quot; \u0026quot;E\u0026quot;\r## ## $E\r## [1] \u0026quot;D\u0026quot; \u0026quot;L\u0026quot; \u0026quot;T\u0026quot; \u0026quot;X\u0026quot;\r## ## $L\r## [1] \u0026quot;E\u0026quot; \u0026quot;S\u0026quot;\r## ## $S\r## [1] \u0026quot;B\u0026quot; \u0026quot;L\u0026quot;\r## ## $T\r## [1] \u0026quot;A\u0026quot; \u0026quot;E\u0026quot;\r## ## $X\r## [1] \u0026quot;E\u0026quot;\r # markov blanket\rsapply(nodes(dag_2.1), bnlearn::mb, x = dag_2.1)\r ## $A\r## [1] \u0026quot;T\u0026quot;\r## ## $B\r## [1] \u0026quot;D\u0026quot; \u0026quot;E\u0026quot; \u0026quot;S\u0026quot;\r## ## $D\r## [1] \u0026quot;B\u0026quot; \u0026quot;E\u0026quot;\r## ## $E\r## [1] \u0026quot;B\u0026quot; \u0026quot;D\u0026quot; \u0026quot;L\u0026quot; \u0026quot;T\u0026quot; \u0026quot;X\u0026quot;\r## ## $L\r## [1] \u0026quot;E\u0026quot; \u0026quot;S\u0026quot; \u0026quot;T\u0026quot;\r## ## $S\r## [1] \u0026quot;B\u0026quot; \u0026quot;L\u0026quot;\r## ## $T\r## [1] \u0026quot;A\u0026quot; \u0026quot;E\u0026quot; \u0026quot;L\u0026quot;\r## ## $X\r## [1] \u0026quot;E\u0026quot;\r Nagarajan 2.2  Using the network structures created in Exercise 2.1 for the asia data set, produce the following plots with graphviz.plot:\n Part A  A plot of the CPDAG of the equivalence class in which the arcs belonging to a v-structure are highlighted (either with a different color or using a thicker line width).\n graphviz.plot(equclass_2.1,\rhighlight = list(arcs = vstructs(equclass_2.1, arcs = TRUE), lwd = 2, col = \u0026quot;red\u0026quot;)\r)\r Part B  Fill the nodes with different colors according to their role in the diagnostic process: causes (“visit to Asia” and “smoking”), effects (“tuberculosis,” “lung cancer,” and “bronchitis”), and the diagnosis proper (“chest X-ray,” “dyspnea,” and “either tuberculosis or lung cancer/bronchitis”).\n No clue on how to do this with graphviz.plot and the solution provided in the book results in an error message. Instead, I use igraph for plotting:\n# create igraph object\requclass_igraph \u0026lt;- graph_from_edgelist(arcs(equclass_2.1))\r# assign colours, effects = red; causes = green; diagnosis = blue\rV(equclass_igraph)$color \u0026lt;- c(\u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;green\u0026quot;)\rV(equclass_igraph)$name \u0026lt;- c(\u0026quot;Visit to Asia\u0026quot;, \u0026quot;Tubercolosis\u0026quot;, \u0026quot;Bronchitis\u0026quot;, \u0026quot;Dyspnoea\u0026quot;, \u0026quot;Smoking\u0026quot;, \u0026quot;Tuberculosis vs Cancer\u0026quot;, \u0026quot;X-Ray\u0026quot;, \u0026quot;Lung Cancer\u0026quot;)\r# plotting\rplot(equclass_igraph,\rlayout = layout.circle,\rvertex.size = 30,\rvertex.label.color = \u0026quot;black\u0026quot;\r)\r Part C  Explore different layouts by changing the layout and shape arguments.\n par(mfrow = c(2, 5))\rlayout \u0026lt;- c(\u0026quot;dot\u0026quot;, \u0026quot;neato\u0026quot;, \u0026quot;twopi\u0026quot;, \u0026quot;circo\u0026quot;, \u0026quot;fdp\u0026quot;)\rshape \u0026lt;- c(\u0026quot;ellipse\u0026quot;, \u0026quot;circle\u0026quot;)\rfor (l in layout) {\rfor (s in shape) {\rgraphviz.plot(equclass_2.1, shape = s, layout = l, main = paste(l, s))\r}\r}\r Nagarajan 2.3  Consider the marks data set analyzed in Sect. 2.3.\n data(marks)\r Part A  Discretize the data using a quantile transform and different numbers of intervals (say, from 2 to 5). How does the network structure learned from the resulting data sets change as the number of intervals increases?\n intervals \u0026lt;- 2:5\rpar(mfrow = c(1, length(intervals)))\rfor (int in intervals) {\rdisc_data \u0026lt;- discretize(marks, breaks = int, method = \u0026quot;quantile\u0026quot;)\rgraphviz.plot(hc(disc_data), main = int)\r}\r The network structure becomes flatter. I reckon this is caused by the loss of information as the number of intervals is increased and variables are discretised with no regard for joint distributions.\nPart B  Repeat the discretization using interval discretization using up to 5 intervals, and compare the resulting networks with the ones obtained previously with quantile discretization.\n intervals \u0026lt;- 2:5\rpar(mfrow = c(1, length(intervals)))\rfor (int in intervals) {\rdisc_data \u0026lt;- discretize(marks, breaks = int, method = \u0026quot;interval\u0026quot;)\rgraphviz.plot(hc(disc_data), main = int)\r}\r Although the specific placement of the nodes changes between the two discretisation approaches, the general pattern of loss of arcs as number of intervals increases stays constant.\nPart C  Does Hartemink’s discretization algorithm perform better than either quantile or interval discretization? How does its behavior depend on the number of initial breaks?\n intervals \u0026lt;- 2:5\rpar(mfrow = c(1, length(intervals)))\rfor (int in intervals) {\rdisc_data \u0026lt;- discretize(marks, breaks = int, method = \u0026quot;hartemink\u0026quot;, ibreaks = 50, idisc = \u0026quot;interval\u0026quot;)\rgraphviz.plot(hc(disc_data), main = int)\r}\r This form of discretisation seems more robust when assessing how accurately the DAG structure is learned when number of intervals is increased.\nNagarajan 2.4  The ALARM network (Beinlich et al. 1989) is a Bayesian network designed to provide an alarm message system for patients hospitalized in intensive care units (ICU). Since ALARM is commonly used as a benchmark in literature, a synthetic data set of 5000 observations generated from this network is available from bnlearn as alarm.\n data(alarm)\r Part A  Create a bn object for the “true” structure of the network using the model string provided in its manual page.\n true_bn \u0026lt;- model2network(paste(\u0026quot;[HIST|LVF][CVP|LVV]\u0026quot;, \u0026quot;[PCWP|LVV][HYP][LVV|HYP:LVF][LVF]\u0026quot;,\r\u0026quot;[STKV|HYP:LVF][ERLO][HRBP|ERLO:HR]\u0026quot;, \u0026quot;[HREK|ERCA:HR][ERCA][HRSA|ERCA:HR][ANES]\u0026quot;,\r\u0026quot;[APL][TPR|APL][ECO2|ACO2:VLNG][KINK]\u0026quot;, \u0026quot;[MINV|INT:VLNG][FIO2][PVS|FIO2:VALV]\u0026quot;,\r\u0026quot;[SAO2|PVS:SHNT][PAP|PMB][PMB][SHNT|INT:PMB]\u0026quot;, \u0026quot;[INT][PRSS|INT:KINK:VTUB][DISC][MVS]\u0026quot;,\r\u0026quot;[VMCH|MVS][VTUB|DISC:VMCH]\u0026quot;, \u0026quot;[VLNG|INT:KINK:VTUB][VALV|INT:VLNG]\u0026quot;,\r\u0026quot;[ACO2|VALV][CCHL|ACO2:ANES:SAO2:TPR]\u0026quot;, \u0026quot;[HR|CCHL][CO|HR:STKV][BP|CO:TPR]\u0026quot;,\rsep = \u0026quot;\u0026quot;\r))\r Part B  Compare the networks learned with different constraint-based algorithms with the true one, both in terms of structural differences and using either BIC or BDe.\n # learning\rbn.gs \u0026lt;- gs(alarm)\rbn.iamb \u0026lt;- iamb(alarm)\rbn.inter \u0026lt;- inter.iamb(alarm)\r# plotting\rpar(mfrow = c(2, 2))\rgraphviz.plot(true_bn, main = \u0026quot;True Structure\u0026quot;)\rgraphviz.plot(bn.gs, main = \u0026quot;Grow-Shrink\u0026quot;)\rgraphviz.plot(bn.iamb, main = \u0026quot;IAMB\u0026quot;)\rgraphviz.plot(bn.inter, main = \u0026quot;Inter-IAMB\u0026quot;)\r # comparisons\runlist(bnlearn::compare(true_bn, bn.gs))\r ## tp fp fn ## 5 14 41\r unlist(bnlearn::compare(true_bn, bn.iamb))\r ## tp fp fn ## 16 18 30\r unlist(bnlearn::compare(true_bn, bn.inter))\r ## tp fp fn ## 27 11 19\r # Scores\rscore(cextend(true_bn), alarm, type = \u0026quot;bde\u0026quot;)\r ## [1] -218063\r score(cextend(bn.gs), alarm, type = \u0026quot;bde\u0026quot;)\r ## [1] -337116.1\r score(cextend(bn.iamb), alarm, type = \u0026quot;bde\u0026quot;)\r ## [1] -263670.8\r score(cextend(bn.inter), alarm, type = \u0026quot;bde\u0026quot;)\r ## [1] -259922.1\r Part C  The overall performance of constraint-based algorithms suggests that the asymptotic $\\chi^2$ conditional independence tests may not be appropriate for analyzing alarm. Are permutation or shrinkage tests better choices?\n This should improve the performance drastically. However, computational time is so high that I refuse to run this code. Even the first call to gs() below takes more than 12 hours to run. I don\u0026rsquo;t know what the authors of the exercise material had envisioned the learning outcome of this to be.\nbn.gs2 \u0026lt;- gs(alarm, test = \u0026quot;smc-x2\u0026quot;)\rbn.iamb2 \u0026lt;- iamb(alarm, test = \u0026quot;smc-x2\u0026quot;)\rbn.inter2 \u0026lt;- inter.iamb(alarm, test = \u0026quot;smc-x2\u0026quot;)\runlist(compare(true_bn, bn.gs2))\runlist(compare(true_bn, bn.iamb2))\runlist(compare(true_bn, bn.inter2))\r Part D  How are the above learning strategies affected by changes to alpha?\n Shrinkage should also improves structure learning performance, but computational time should be much lower than it is with permutation tests. Much like with the previous exercise, however, the code below just takes too long for my liking to finish running.\nbn.gs3 \u0026lt;- gs(alarm, test = \u0026quot;smc-x2\u0026quot;, alpha = 0.01)\rbn.iamb3 \u0026lt;- iamb(alarm, test = \u0026quot;smc-x2\u0026quot;, alpha = 0.01)\rbn.inter3 \u0026lt;- inter.iamb(alarm, test = \u0026quot;smc-x2\u0026quot;, alpha = 0.01)\runlist(compare(true, bn.gs3))\runlist(compare(true, bn.iamb3))\runlist(compare(true, bn.inter3))\r Nagarajan 2.5  Consider again the alarm network used in Exercise 2.4.\n Part A  Learn its structure with hill-climbing and tabu search, using the posterior density BDe as a score function. How does the network structure change with the imaginary sample size iss?\n par(mfrow = c(2, 5))\rfor (iss in c(1, 5, 10, 20, 50)) {\rbn \u0026lt;- hc(alarm, score = \u0026quot;bde\u0026quot;, iss = iss)\rmain \u0026lt;- paste(\u0026quot;hc(..., iss = \u0026quot;, iss, \u0026quot;)\u0026quot;, sep = \u0026quot;\u0026quot;)\rsub \u0026lt;- paste(narcs(bn), \u0026quot;arcs\u0026quot;)\rgraphviz.plot(bn, main = main, sub = sub)\r}\rfor (iss in c(1, 5, 10, 20, 50)) {\rbn \u0026lt;- tabu(alarm, score = \u0026quot;bde\u0026quot;, iss = iss)\rmain \u0026lt;- paste(\u0026quot;tabu(..., iss = \u0026quot;, iss, \u0026quot;)\u0026quot;, sep = \u0026quot;\u0026quot;)\rsub \u0026lt;- paste(narcs(bn), \u0026quot;arcs\u0026quot;)\rgraphviz.plot(bn, main = main, sub = sub)\r}\r The number of arcs increases with iss. Large values of iss over-smooth the data and thus result in networks with similar scores and therefore allow for many arcs to be included in the final networks.\nPart B  Does the length of the tabu list have a significant impact on the network structures learned with tabu?\n par(mfrow = c(1, 5))\rfor (n in c(10, 15, 20, 50, 100)) {\rbn \u0026lt;- tabu(alarm, score = \u0026quot;bde\u0026quot;, tabu = n)\rbde \u0026lt;- score(bn, alarm, type = \u0026quot;bde\u0026quot;)\rmain \u0026lt;- paste(\u0026quot;tabu(..., tabu = \u0026quot;, n, \u0026quot;)\u0026quot;, sep = \u0026quot;\u0026quot;)\rsub \u0026lt;- paste(ntests(bn), \u0026quot;steps, score\u0026quot;, bde)\rgraphviz.plot(bn, main = main, sub = sub)\r}\r Increasing the tabu length severely affects the learned structure of the final network. Firstly, it does so by increasing the raw number of network structures explored by tabu. Secondly, getting stuck in local maxima becomes increasingly unlikely.\nPart C  How does the BIC score compare with BDe at different sample sizes in terms of structure and score of the learned network?\n par(mfrow = c(2, 6))\rfor (n in c(100, 200, 500, 1000, 2000, 5000)) {\rbn.bde \u0026lt;- hc(alarm[1:n, ], score = \u0026quot;bde\u0026quot;)\rbn.bic \u0026lt;- hc(alarm[1:n, ], score = \u0026quot;bic\u0026quot;)\rbde \u0026lt;- score(bn.bde, alarm, type = \u0026quot;bde\u0026quot;)\rbic \u0026lt;- score(bn.bic, alarm, type = \u0026quot;bic\u0026quot;)\rmain \u0026lt;- paste(\u0026quot;BDe, sample size\u0026quot;, n)\rsub \u0026lt;- paste(ntests(bn.bde), \u0026quot;steps, score\u0026quot;, bde)\rgraphviz.plot(bn.bde, main = main, sub = sub)\rmain \u0026lt;- paste(\u0026quot;BIC, sample size\u0026quot;, n)\rsub \u0026lt;- paste(ntests(bn.bic), \u0026quot;steps, score\u0026quot;, bic)\rgraphviz.plot(bn.bic, main = main, sub = sub)\r}\r The networks become more similar as sample size increases. At small sample sizes, BIC results in sparser networks than BDe.\nNagarajan 2.6  Consider the observational data set from Sachs et al. (2005) used in Sect. 2.5.1 (the original data set, not the discretized one).\n Part A  Evaluate the networks learned by hill-climbing with BIC and BGe using cross-validation and the log-likelihood loss function.\n The sachs data file is available\rhere.\nsachs \u0026lt;- read.table(\u0026quot;sachs.data.txt\u0026quot;, header = TRUE)\rbn.bic \u0026lt;- hc(sachs, score = \u0026quot;bic-g\u0026quot;)\rbn.cv(bn.bic, data = sachs)\r ## ## k-fold cross-validation for Bayesian networks\r## ## target network structure:\r## [praf][PIP2][p44.42][PKC][pmek|praf][PIP3|PIP2][pakts473|p44.42][P38|PKC][plcg|PIP3][PKA|p44.42:pakts473][pjnk|PKC:P38] ## number of folds: 10 ## loss function: Log-Likelihood Loss (Gauss.) ## expected loss: 65.48251\r bn.bge \u0026lt;- hc(sachs, score = \u0026quot;bge\u0026quot;)\rbn.cv(bn.bge, data = sachs)\r ## ## k-fold cross-validation for Bayesian networks\r## ## target network structure:\r## [praf][plcg][PIP2][p44.42][PKC][pmek|praf][PIP3|PIP2][pakts473|p44.42][P38|PKC][PKA|p44.42:pakts473][pjnk|PKC:P38] ## number of folds: 10 ## loss function: Log-Likelihood Loss (Gauss.) ## expected loss: 65.3477\r The BGe network fits the data slightly better than the BIC-network.\nPart B  Use bootstrap resampling to evaluate the distribution of the number of arcs present in each of the networks learned in the previous point. Do they differ significantly?\n set.seed(42)\rnarcs.bic \u0026lt;- bn.boot(sachs, algorithm = \u0026quot;hc\u0026quot;, algorithm.args = list(score = \u0026quot;bic-g\u0026quot;), statistic = narcs)\rnarcs.bge \u0026lt;- bn.boot(sachs, algorithm = \u0026quot;hc\u0026quot;, algorithm.args = list(score = \u0026quot;bge\u0026quot;), statistic = narcs)\rnarcs.bic \u0026lt;- unlist(narcs.bic)\rnarcs.bge \u0026lt;- unlist(narcs.bge)\rpar(mfrow = c(1, 2))\rhist(narcs.bic, main = \u0026quot;BIC\u0026quot;, freq = FALSE)\rcurve(dnorm(x, mean = mean(narcs.bic), sd = sd(narcs.bic)), add = TRUE, col = 2)\rhist(narcs.bge, main = \u0026quot;BGe\u0026quot;, freq = FALSE)\rcurve(dnorm(x, mean = mean(narcs.bge), sd = sd(narcs.bge)), add = TRUE, col = 2)\r Number-of-arc-distributions are markedly different between BIC and BGe networks.\nPart C  Compute the averaged network structure for sachs using hill-climbing with BGe and different imaginary sample sizes. How does the value of the significance threshold change as iss increases?\n set.seed(42)\rt \u0026lt;- c()\riss \u0026lt;- c(5, 10, 20, 50, 100)\rfor (i in iss) {\rs \u0026lt;- boot.strength(sachs,\ralgorithm = \u0026quot;hc\u0026quot;,\ralgorithm.args = list(score = \u0026quot;bge\u0026quot;, iss = i)\r)\rt \u0026lt;- c(t, attr(s, \u0026quot;threshold\u0026quot;))\r}\rt\r ## [1] 0.780 0.415 0.430 0.380 0.440\r Session Info sessionInfo()\r ## R version 4.2.1 (2022-06-23 ucrt)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19044)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_Germany.utf8 LC_CTYPE=English_Germany.utf8 LC_MONETARY=English_Germany.utf8 LC_NUMERIC=C LC_TIME=English_Germany.utf8 ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] igraph_1.3.4 bnlearn_4.8.1\r## ## loaded via a namespace (and not attached):\r## [1] highr_0.9 bslib_0.4.0 compiler_4.2.1 jquerylib_0.1.4 R.methodsS3_1.8.2 R.utils_2.12.0 tools_4.2.1 digest_0.6.29 jsonlite_1.8.0 ## [10] evaluate_0.16 R.cache_0.16.0 pkgconfig_2.0.3 rlang_1.0.5 graph_1.74.0 cli_3.3.0 rstudioapi_0.14 Rgraphviz_2.40.0 yaml_2.3.5 ## [19] parallel_4.2.1 blogdown_1.13 xfun_0.33 fastmap_1.1.0 styler_1.8.0 stringr_1.4.1 knitr_1.40 sass_0.4.2 vctrs_0.4.1 ## [28] grid_4.2.1 stats4_4.2.1 R6_2.5.1 rmarkdown_2.16 bookdown_0.29 purrr_0.3.4 magrittr_2.0.3 htmltools_0.5.3 BiocGenerics_0.42.0\r## [37] stringi_1.7.8 cachem_1.0.6 R.oo_1.25.0\r ","date":1666656000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666724400,"objectID":"1484d9af7bae634e71d5fa30198a354d","permalink":"https://www.erikkusch.com/courses/bayes-nets/static/","publishdate":"2022-10-25T00:00:00Z","relpermalink":"/courses/bayes-nets/static/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 2 in [Bayesian Networks in R with Applications in Systems Biology](https://link.springer.com/book/10.1007/978-1-4614-6446-4) by by Radhakrishnan Nagarajan, Marco Scutari \\\u0026 Sophie Lèbre.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Additional Static Exercises","type":"docs"},{"authors":["Erik Kusch"],"categories":["Excursion into Biostatistics"],"content":"Our Resarch Project Here (and over the next few exercises in this \u0026ldquo;course\u0026rdquo;), we are looking at a big (and entirely fictional) data base of the common house sparrow (Passer domesticus). In particular, we are interested in the Evolution of Passer domesticus in Response to Climate Change.\nThe Data I have created a large data set for this exercise which is available in a cleaned and properly handled version here.\nReading the Data into R Let\u0026rsquo;s start by reading the data into R and taking an initial look at it:\nSparrows_df \u0026lt;- readRDS(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowData.rds\u0026quot;))\rSparrows_df \u0026lt;- Sparrows_df[!is.na(Sparrows_df$Weight), ]\rhead(Sparrows_df)\r ## Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type\r## 1 SI 60 100 Continental Native 34.05 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 2 SI 60 100 Continental Native 34.86 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 3 SI 60 100 Continental Native 32.34 12.66 6.64 Black Female Shrub 35.60 1 3.21 C Large Yes Avian\r## 4 SI 60 100 Continental Native 34.78 15.09 7.00 Brown Female Shrub 47.75 0 NA E Large Yes Avian\r## 5 SI 60 100 Continental Native 35.01 13.82 6.81 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 6 SI 60 100 Continental Native 32.36 12.67 6.64 Brown Female Shrub 32.47 1 3.17 E Large Yes Avian\r Variables When building models or trying to explain anything about our data set, we need to consider all the different variables and the information contained therein. In this data set, we have access to:\n Index [Factor] - an abbreviation of Site records Latitude [Numeric] - an identifier of where specific sparrow measurements where taken Longitude [Numeric] - an identifier of where specific sparrow measurements where taken Climate [Factor] - local climate types that sparrows are subjected to (e.g. coastal, continental, and semi-coastal) Population.Status [Factor] - population status (e.g. native or introduced) Weight [Numeric] - sparrow weight [g]; Range: 13-40g Height [Numeric] - sparrow height/length [cm]; Range: 10-22cm Wing.Chord [Numeric] - wing length [cm]; Range: 6-10cm Colour [Factor] - main plumage colour (e.g. brown, grey, and black) Sex [Factor] - sparrow sex Nesting.Site [Factor] - nesting conditions, only recorded for females (e.g. tree or shrub) Nesting.Height [Numeric] - nest elevation above ground level, only recorded for females Number.of.Eggs [Numeric] - number of eggs per nest, only recorded for females Egg.Weight [Numeric] - mean weight of eggs per nest, only recorded for females Flock [Factor] - which flock at each location each sparrow belongs to Home.Range [Factor] - size of home range of each flock (e.g. Small, Medium, and Large) Predator.Presence [Factor] - if a predator is present at a station (e.g. No or Yes) Predator.Type [Factor] - what kind of predator is present (e.g. Avian, Non-Avian, or None)  Note that the variables Longitude and Latitude may be used to retrieve climate data variables from a host of data sources.\nLocations Looking at our data, we notice that it comes at distinct stations. Let\u0026rsquo;s visualise where they are:\nlibrary(\u0026quot;leaflet\u0026quot;)\rPlot_df \u0026lt;- Sparrows_df[, c(\u0026quot;Longitude\u0026quot;, \u0026quot;Latitude\u0026quot;, \u0026quot;Index\u0026quot;, \u0026quot;Climate\u0026quot;, \u0026quot;Population.Status\u0026quot;)]\rPlot_df \u0026lt;- unique(Plot_df)\rm \u0026lt;- leaflet()\rm \u0026lt;- addTiles(m)\rm \u0026lt;- addMarkers(m,\rlng = Plot_df$Longitude,\rlat = Plot_df$Latitude,\rlabel = Plot_df$Index,\rpopup = paste(Plot_df$Population.Status, Plot_df$Climate, sep = \u0026quot;;\u0026quot;)\r)\rm\r \u0026lt;div class=\u0026quot;leaflet html-widget html-fill-item-overflow-hidden html-fill-item\u0026quot; id=\u0026quot;htmlwidget-9aac1c390aadeb1fd4f9\u0026quot; style=\u0026quot;width:1440px;height:768px;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\r\u0026lt;script type=\u0026quot;application/json\u0026quot; data-for=\u0026quot;htmlwidget-9aac1c390aadeb1fd4f9\u0026quot;\u0026gt;{\u0026quot;x\u0026quot;:{\u0026quot;options\u0026quot;:{\u0026quot;crs\u0026quot;:{\u0026quot;crsClass\u0026quot;:\u0026quot;L.CRS.EPSG3857\u0026quot;,\u0026quot;code\u0026quot;:null,\u0026quot;proj4def\u0026quot;:null,\u0026quot;projectedBounds\u0026quot;:null,\u0026quot;options\u0026quot;:{}}},\u0026quot;calls\u0026quot;:[{\u0026quot;method\u0026quot;:\u0026quot;addTiles\u0026quot;,\u0026quot;args\u0026quot;:[\u0026quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\u0026quot;,null,null,{\u0026quot;minZoom\u0026quot;:0,\u0026quot;maxZoom\u0026quot;:18,\u0026quot;tileSize\u0026quot;:256,\u0026quot;subdomains\u0026quot;:\u0026quot;abc\u0026quot;,\u0026quot;errorTileUrl\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;tms\u0026quot;:false,\u0026quot;noWrap\u0026quot;:false,\u0026quot;zoomOffset\u0026quot;:0,\u0026quot;zoomReverse\u0026quot;:false,\u0026quot;opacity\u0026quot;:1,\u0026quot;zIndex\u0026quot;:1,\u0026quot;detectRetina\u0026quot;:false,\u0026quot;attribution\u0026quot;:\u0026quot;\u0026amp;copy; \u0026lt;a href=\\\u0026quot;https://openstreetmap.org\\\u0026quot;\u0026gt;OpenStreetMap\u0026lt;\\/a\u0026gt; contributors, \u0026lt;a href=\\\u0026quot;https://creativecommons.org/licenses/by-sa/2.0/\\\u0026quot;\u0026gt;CC-BY-SA\u0026lt;\\/a\u0026gt;\u0026quot;}]},{\u0026quot;method\u0026quot;:\u0026quot;addMarkers\u0026quot;,\u0026quot;args\u0026quot;:[[60,54,-25,-21.1,70,55,31,17.25,4,10.5,-51.75],[100,-2,135,55.6,-90,-97,-92,-88.75,-53,-67,-59.17],null,null,null,{\u0026quot;interactive\u0026quot;:true,\u0026quot;draggable\u0026quot;:false,\u0026quot;keyboard\u0026quot;:true,\u0026quot;title\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;alt\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;zIndexOffset\u0026quot;:0,\u0026quot;opacity\u0026quot;:1,\u0026quot;riseOnHover\u0026quot;:false,\u0026quot;riseOffset\u0026quot;:250},[\u0026quot;Native;Continental\u0026quot;,\u0026quot;Native;Coastal\u0026quot;,\u0026quot;Introduced;Continental\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Semi-Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;],null,null,null,[\u0026quot;SI\u0026quot;,\u0026quot;UK\u0026quot;,\u0026quot;AU\u0026quot;,\u0026quot;RE\u0026quot;,\u0026quot;NU\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;LO\u0026quot;,\u0026quot;BE\u0026quot;,\u0026quot;FG\u0026quot;,\u0026quot;SA\u0026quot;,\u0026quot;FI\u0026quot;],{\u0026quot;interactive\u0026quot;:false,\u0026quot;permanent\u0026quot;:false,\u0026quot;direction\u0026quot;:\u0026quot;auto\u0026quot;,\u0026quot;opacity\u0026quot;:1,\u0026quot;offset\u0026quot;:[0,0],\u0026quot;textsize\u0026quot;:\u0026quot;10px\u0026quot;,\u0026quot;textOnly\u0026quot;:false,\u0026quot;className\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;sticky\u0026quot;:true},null]}],\u0026quot;limits\u0026quot;:{\u0026quot;lat\u0026quot;:[-51.75,70],\u0026quot;lng\u0026quot;:[-97,135]}},\u0026quot;evals\u0026quot;:[],\u0026quot;jsHooks\u0026quot;:[]}\u0026lt;/script\u0026gt;\r Note that you can zoom and drag the above map as well as click the station markers for some additional information.\nAdding Information How do we get the data for this? Well, I wrote an R-Package that does exactly that.\nFirst, said package needs to be installed from my GitHub repository for it. Subsequently, we need to set API Key and User number obtained at the Climate Data Store. I have already baked these into my material, so I don\u0026rsquo;t set them here, but include lines of code that ask you for your credentials when copy \u0026amp; pasted over:\nif (\u0026quot;KrigR\u0026quot; %in% rownames(installed.packages()) == FALSE) { # KrigR check\rSys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS = \u0026quot;true\u0026quot;)\rdevtools::install_github(\u0026quot;https://github.com/ErikKusch/KrigR\u0026quot;)\r}\rlibrary(KrigR)\r#### CDS API (needed for ERA5-Land downloads)\rif (!exists(\u0026quot;API_Key\u0026quot;) | !exists(\u0026quot;API_User\u0026quot;)) { # CS API check: if CDS API credentials have not been specified elsewhere\rAPI_User \u0026lt;- readline(prompt = \u0026quot;Please enter your Climate Data Store API user number and hit ENTER.\u0026quot;)\rAPI_Key \u0026lt;- readline(prompt = \u0026quot;Please enter your Climate Data Store API key number and hit ENTER.\u0026quot;)\r} # end of CDS API check\r#### NUMBER OF CORES\rif (!exists(\u0026quot;numberOfCores\u0026quot;)) { # Core check: if number of cores for parallel processing has not been set yet\rnumberOfCores \u0026lt;- readline(prompt = paste(\u0026quot;How many cores do you want to allocate to these processes? Your machine has\u0026quot;, parallel::detectCores()))\r} # end of Core check\r Now that we have the package, we can download some state-of-the-art climate data. I have already prepared all of this in the data directory you downloaded earlier so this step will automatically be skipped:\nif (!file.exists(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))) {\rcolnames(Plot_df)[1:3] \u0026lt;- c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;, \u0026quot;ID\u0026quot;) # set column names to be in line with what KrigR wants\rPoints_Raw \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5\u0026quot;,\rDateStart = \u0026quot;1982-01-01\u0026quot;,\rDateStop = \u0026quot;2012-12-31\u0026quot;,\rTResolution = \u0026quot;month\u0026quot;,\rTStep = 1,\rExtent = Plot_df, # the point data with Lon and Lat columns\rBuffer = 0.5, # a 0.5 degree buffer should be drawn around each point\rID = \u0026quot;ID\u0026quot;, # this is the column which holds point IDs\rAPI_User = API_User,\rAPI_Key = API_Key,\rDir = file.path(getwd(), \u0026quot;Data\u0026quot;),\rFileName = \u0026quot;AT_Climatology.nc\u0026quot;\r)\rPoints_mean \u0026lt;- calc(Points_Raw, fun = mean)\rPoints_sd \u0026lt;- calc(Points_Raw, fun = sd)\rSparrows_df$TAvg \u0026lt;- as.numeric(extract(x = Points_mean, y = Sparrows_df[, c(\u0026quot;Longitude\u0026quot;, \u0026quot;Latitude\u0026quot;)], buffer = 0.3))\rSparrows_df$TSD \u0026lt;- as.numeric(extract(x = Points_sd, y = Sparrows_df[, c(\u0026quot;Longitude\u0026quot;, \u0026quot;Latitude\u0026quot;)], buffer = 0.3))\rsaveRDS(Sparrows_df, file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))\r} else {\rSparrows_df \u0026lt;- readRDS(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))\r}\r We have now effectively added two more variables to the data set:\nTAvg [Numeric] - Average air temperature for a 30-year time-period TSD [Numeric] - Standard deviation of mean monthly air temperature for a 30-year time-period  Now we have the data set we will look at for the rest of the exercises in this seminar series. But how did we get here? Find the answer here.\nHypotheses Let\u0026rsquo;s consider the following two hypotheses for our exercises for this simulated research project:\n Sparrow Morphology is determined by:\nA. Climate Conditions with sparrows in stable, warm environments fairing better than those in colder, less stable ones.\nB. Competition with sparrows in small flocks doing better than those in big flocks.\nC. Predation with sparrows under pressure of predation doing worse than those without. Sites accurately represent sparrow morphology. This may mean:\nA. Population status as inferred through morphology.\nB. Site index as inferred through morphology.\nC. Climate as inferred through morphology.  We try to answer these over the next few sessions.\nSessionInfo sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] KrigR_0.1.2 terra_1.7-21 httr_1.4.5 stars_0.6-0 abind_1.4-5 fasterize_1.0.4 sf_1.0-12 lubridate_1.9.2 automap_1.1-9 doSNOW_1.0.20 ## [11] snow_0.4-4 doParallel_1.0.17 iterators_1.0.14 foreach_1.5.2 rgdal_1.6-5 raster_3.6-20 sp_1.6-0 stringr_1.5.0 keyring_1.3.1 ecmwfr_1.5.0 ## [21] ncdf4_1.21 leaflet_2.1.2 ## ## loaded via a namespace (and not attached):\r## [1] xts_0.13.0 R.cache_0.16.0 tools_4.2.3 bslib_0.4.2 utf8_1.2.3 R6_2.5.1 KernSmooth_2.23-20 DBI_1.1.3 colorspace_2.1-0 tidyselect_1.2.0 ## [11] compiler_4.2.3 cli_3.6.0 gstat_2.1-0 bookdown_0.33 sass_0.4.5 scales_1.2.1 classInt_0.4-9 proxy_0.4-27 digest_0.6.31 rmarkdown_2.20 ## [21] R.utils_2.12.2 pkgconfig_2.0.3 htmltools_0.5.4 styler_1.9.1 fastmap_1.1.1 htmlwidgets_1.6.1 rlang_1.0.6 rstudioapi_0.14 FNN_1.1.3.2 jquerylib_0.1.4 ## [31] generics_0.1.3 zoo_1.8-11 jsonlite_1.8.4 crosstalk_1.2.0 dplyr_1.1.0 R.oo_1.25.0 magrittr_2.0.3 Rcpp_1.0.10 munsell_0.5.0 fansi_1.0.4 ## [41] lifecycle_1.0.3 R.methodsS3_1.8.2 stringi_1.7.12 yaml_2.3.7 plyr_1.8.8 grid_4.2.3 lattice_0.20-45 knitr_1.42 pillar_1.8.1 spacetime_1.2-8 ## [51] codetools_0.2-19 glue_1.6.2 evaluate_0.20 blogdown_1.16 vctrs_0.5.2 gtable_0.3.1 purrr_1.0.1 reshape_0.8.9 assertthat_0.2.1 cachem_1.0.7 ## [61] ggplot2_3.4.1 xfun_0.37 lwgeom_0.2-11 e1071_1.7-13 class_7.3-21 tibble_3.2.0 intervals_0.15.3 memoise_2.0.1 units_0.8-1 timechange_0.2.0 ## [71] ellipsis_0.3.2\r ","date":1614384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"c76f9089a16c19d223d611feb94ad95e","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/","publishdate":"2021-02-27T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/research-project/","section":"courses","summary":"This is a quick documentation of a mock research project used throughout all `R` exercises during this seminar series.","tags":["R","Statistics"],"title":"Research Project","type":"docs"},{"authors":["Erik Kusch"],"categories":["Excursion into Biostatistics"],"content":"Our Resarch Project Here (and over the next few exercises in this \u0026ldquo;course\u0026rdquo;), we are looking at a big (and entirely fictional) data base of the common house sparrow (Passer domesticus). In particular, we are interested in the Evolution of Passer domesticus in Response to Climate Change.\nThe Data I have created a large data set for this exercise which is available in a cleaned and properly handled version here.\nReading the Data into R Let\u0026rsquo;s start by reading the data into R and taking an initial look at it:\nSparrows_df \u0026lt;- readRDS(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowData.rds\u0026quot;))\rSparrows_df \u0026lt;- Sparrows_df[!is.na(Sparrows_df$Weight), ]\rhead(Sparrows_df)\r ## Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type\r## 1 SI 60 100 Continental Native 34.05 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 2 SI 60 100 Continental Native 34.86 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 3 SI 60 100 Continental Native 32.34 12.66 6.64 Black Female Shrub 35.60 1 3.21 C Large Yes Avian\r## 4 SI 60 100 Continental Native 34.78 15.09 7.00 Brown Female Shrub 47.75 0 NA E Large Yes Avian\r## 5 SI 60 100 Continental Native 35.01 13.82 6.81 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 6 SI 60 100 Continental Native 32.36 12.67 6.64 Brown Female Shrub 32.47 1 3.17 E Large Yes Avian\r Variables When building models or trying to explain anything about our data set, we need to consider all the different variables and the information contained therein. In this data set, we have access to:\n Index [Factor] - an abbreviation of Site records Latitude [Numeric] - an identifier of where specific sparrow measurements where taken Longitude [Numeric] - an identifier of where specific sparrow measurements where taken Climate [Factor] - local climate types that sparrows are subjected to (e.g. coastal, continental, and semi-coastal) Population.Status [Factor] - population status (e.g. native or introduced) Weight [Numeric] - sparrow weight [g]; Range: 13-40g Height [Numeric] - sparrow height/length [cm]; Range: 10-22cm Wing.Chord [Numeric] - wing length [cm]; Range: 6-10cm Colour [Factor] - main plumage colour (e.g. brown, grey, and black) Sex [Factor] - sparrow sex Nesting.Site [Factor] - nesting conditions, only recorded for females (e.g. tree or shrub) Nesting.Height [Numeric] - nest elevation above ground level, only recorded for females Number.of.Eggs [Numeric] - number of eggs per nest, only recorded for females Egg.Weight [Numeric] - mean weight of eggs per nest, only recorded for females Flock [Factor] - which flock at each location each sparrow belongs to Home.Range [Factor] - size of home range of each flock (e.g. Small, Medium, and Large) Predator.Presence [Factor] - if a predator is present at a station (e.g. No or Yes) Predator.Type [Factor] - what kind of predator is present (e.g. Avian, Non-Avian, or None)  Note that the variables Longitude and Latitude may be used to retrieve climate data variables from a host of data sources.\nLocations Looking at our data, we notice that it comes at distinct stations. Let\u0026rsquo;s visualise where they are:\nlibrary(\u0026quot;leaflet\u0026quot;)\rPlot_df \u0026lt;- Sparrows_df[, c(\u0026quot;Longitude\u0026quot;, \u0026quot;Latitude\u0026quot;, \u0026quot;Index\u0026quot;, \u0026quot;Climate\u0026quot;, \u0026quot;Population.Status\u0026quot;)]\rPlot_df \u0026lt;- unique(Plot_df)\rm \u0026lt;- leaflet()\rm \u0026lt;- addTiles(m)\rm \u0026lt;- addMarkers(m,\rlng = Plot_df$Longitude,\rlat = Plot_df$Latitude,\rlabel = Plot_df$Index,\rpopup = paste(Plot_df$Population.Status, Plot_df$Climate, sep = \u0026quot;;\u0026quot;)\r)\rm\r \u0026lt;div class=\u0026quot;leaflet html-widget html-fill-item-overflow-hidden html-fill-item\u0026quot; id=\u0026quot;htmlwidget-198293ac646900c5a74e\u0026quot; style=\u0026quot;width:1440px;height:768px;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\r\u0026lt;script type=\u0026quot;application/json\u0026quot; data-for=\u0026quot;htmlwidget-198293ac646900c5a74e\u0026quot;\u0026gt;{\u0026quot;x\u0026quot;:{\u0026quot;options\u0026quot;:{\u0026quot;crs\u0026quot;:{\u0026quot;crsClass\u0026quot;:\u0026quot;L.CRS.EPSG3857\u0026quot;,\u0026quot;code\u0026quot;:null,\u0026quot;proj4def\u0026quot;:null,\u0026quot;projectedBounds\u0026quot;:null,\u0026quot;options\u0026quot;:{}}},\u0026quot;calls\u0026quot;:[{\u0026quot;method\u0026quot;:\u0026quot;addTiles\u0026quot;,\u0026quot;args\u0026quot;:[\u0026quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\u0026quot;,null,null,{\u0026quot;minZoom\u0026quot;:0,\u0026quot;maxZoom\u0026quot;:18,\u0026quot;tileSize\u0026quot;:256,\u0026quot;subdomains\u0026quot;:\u0026quot;abc\u0026quot;,\u0026quot;errorTileUrl\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;tms\u0026quot;:false,\u0026quot;noWrap\u0026quot;:false,\u0026quot;zoomOffset\u0026quot;:0,\u0026quot;zoomReverse\u0026quot;:false,\u0026quot;opacity\u0026quot;:1,\u0026quot;zIndex\u0026quot;:1,\u0026quot;detectRetina\u0026quot;:false,\u0026quot;attribution\u0026quot;:\u0026quot;\u0026amp;copy; \u0026lt;a href=\\\u0026quot;https://openstreetmap.org\\\u0026quot;\u0026gt;OpenStreetMap\u0026lt;\\/a\u0026gt; contributors, \u0026lt;a href=\\\u0026quot;https://creativecommons.org/licenses/by-sa/2.0/\\\u0026quot;\u0026gt;CC-BY-SA\u0026lt;\\/a\u0026gt;\u0026quot;}]},{\u0026quot;method\u0026quot;:\u0026quot;addMarkers\u0026quot;,\u0026quot;args\u0026quot;:[[60,54,-25,-21.1,70,55,31,17.25,4,10.5,-51.75],[100,-2,135,55.6,-90,-97,-92,-88.75,-53,-67,-59.17],null,null,null,{\u0026quot;interactive\u0026quot;:true,\u0026quot;draggable\u0026quot;:false,\u0026quot;keyboard\u0026quot;:true,\u0026quot;title\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;alt\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;zIndexOffset\u0026quot;:0,\u0026quot;opacity\u0026quot;:1,\u0026quot;riseOnHover\u0026quot;:false,\u0026quot;riseOffset\u0026quot;:250},[\u0026quot;Native;Continental\u0026quot;,\u0026quot;Native;Coastal\u0026quot;,\u0026quot;Introduced;Continental\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Semi-Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;,\u0026quot;Introduced;Coastal\u0026quot;],null,null,null,[\u0026quot;SI\u0026quot;,\u0026quot;UK\u0026quot;,\u0026quot;AU\u0026quot;,\u0026quot;RE\u0026quot;,\u0026quot;NU\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;LO\u0026quot;,\u0026quot;BE\u0026quot;,\u0026quot;FG\u0026quot;,\u0026quot;SA\u0026quot;,\u0026quot;FI\u0026quot;],{\u0026quot;interactive\u0026quot;:false,\u0026quot;permanent\u0026quot;:false,\u0026quot;direction\u0026quot;:\u0026quot;auto\u0026quot;,\u0026quot;opacity\u0026quot;:1,\u0026quot;offset\u0026quot;:[0,0],\u0026quot;textsize\u0026quot;:\u0026quot;10px\u0026quot;,\u0026quot;textOnly\u0026quot;:false,\u0026quot;className\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;sticky\u0026quot;:true},null]}],\u0026quot;limits\u0026quot;:{\u0026quot;lat\u0026quot;:[-51.75,70],\u0026quot;lng\u0026quot;:[-97,135]}},\u0026quot;evals\u0026quot;:[],\u0026quot;jsHooks\u0026quot;:[]}\u0026lt;/script\u0026gt;\r Note that you can zoom and drag the above map as well as click the station markers for some additional information.\nAdding Information How do we get the data for this? Well, I wrote an R-Package that does exactly that.\nFirst, said package needs to be installed from my GitHub repository for it. Subsequently, we need to set API Key and User number obtained at the Climate Data Store. I have already baked these into my material, so I don\u0026rsquo;t set them here, but include lines of code that ask you for your credentials when copy \u0026amp; pasted over:\nif (\u0026quot;KrigR\u0026quot; %in% rownames(installed.packages()) == FALSE) { # KrigR check\rSys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS = \u0026quot;true\u0026quot;)\rdevtools::install_github(\u0026quot;https://github.com/ErikKusch/KrigR\u0026quot;)\r}\rlibrary(KrigR)\r#### CDS API (needed for ERA5-Land downloads)\rif (!exists(\u0026quot;API_Key\u0026quot;) | !exists(\u0026quot;API_User\u0026quot;)) { # CS API check: if CDS API credentials have not been specified elsewhere\rAPI_User \u0026lt;- readline(prompt = \u0026quot;Please enter your Climate Data Store API user number and hit ENTER.\u0026quot;)\rAPI_Key \u0026lt;- readline(prompt = \u0026quot;Please enter your Climate Data Store API key number and hit ENTER.\u0026quot;)\r} # end of CDS API check\r#### NUMBER OF CORES\rif (!exists(\u0026quot;numberOfCores\u0026quot;)) { # Core check: if number of cores for parallel processing has not been set yet\rnumberOfCores \u0026lt;- readline(prompt = paste(\u0026quot;How many cores do you want to allocate to these processes? Your machine has\u0026quot;, parallel::detectCores()))\r} # end of Core check\r Now that we have the package, we can download some state-of-the-art climate data. I have already prepared all of this in the data directory you downloaded earlier so this step will automatically be skipped:\nif (!file.exists(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))) {\rcolnames(Plot_df)[1:3] \u0026lt;- c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;, \u0026quot;ID\u0026quot;) # set column names to be in line with what KrigR wants\rPoints_Raw \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5\u0026quot;,\rDateStart = \u0026quot;1982-01-01\u0026quot;,\rDateStop = \u0026quot;2012-12-31\u0026quot;,\rTResolution = \u0026quot;month\u0026quot;,\rTStep = 1,\rExtent = Plot_df, # the point data with Lon and Lat columns\rBuffer = 0.5, # a 0.5 degree buffer should be drawn around each point\rID = \u0026quot;ID\u0026quot;, # this is the column which holds point IDs\rAPI_User = API_User,\rAPI_Key = API_Key,\rDir = file.path(getwd(), \u0026quot;Data\u0026quot;),\rFileName = \u0026quot;AT_Climatology.nc\u0026quot;\r)\rPoints_mean \u0026lt;- calc(Points_Raw, fun = mean)\rPoints_sd \u0026lt;- calc(Points_Raw, fun = sd)\rSparrows_df$TAvg \u0026lt;- as.numeric(extract(x = Points_mean, y = Sparrows_df[, c(\u0026quot;Longitude\u0026quot;, \u0026quot;Latitude\u0026quot;)], buffer = 0.3))\rSparrows_df$TSD \u0026lt;- as.numeric(extract(x = Points_sd, y = Sparrows_df[, c(\u0026quot;Longitude\u0026quot;, \u0026quot;Latitude\u0026quot;)], buffer = 0.3))\rsaveRDS(Sparrows_df, file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))\r} else {\rSparrows_df \u0026lt;- readRDS(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))\r}\r We have now effectively added two more variables to the data set:\nTAvg [Numeric] - Average air temperature for a 30-year time-period TSD [Numeric] - Standard deviation of mean monthly air temperature for a 30-year time-period  Now we have the data set we will look at for the rest of the exercises in this seminar series. But how did we get here? Find the answer here.\nHypotheses Let\u0026rsquo;s consider the following two hypotheses for our exercises for this simulated research project:\n Sparrow Morphology is determined by:\nA. Climate Conditions with sparrows in stable, warm environments fairing better than those in colder, less stable ones.\nB. Competition with sparrows in small flocks doing better than those in big flocks.\nC. Predation with sparrows under pressure of predation doing worse than those without. Sites accurately represent sparrow morphology. This may mean:\nA. Population status as inferred through morphology.\nB. Site index as inferred through morphology.\nC. Climate as inferred through morphology.  We try to answer these over the next few sessions.\nSessionInfo sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] KrigR_0.1.2 terra_1.7-21 httr_1.4.5 stars_0.6-0 abind_1.4-5 fasterize_1.0.4 sf_1.0-12 lubridate_1.9.2 automap_1.1-9 doSNOW_1.0.20 ## [11] snow_0.4-4 doParallel_1.0.17 iterators_1.0.14 foreach_1.5.2 rgdal_1.6-5 raster_3.6-20 sp_1.6-0 stringr_1.5.0 keyring_1.3.1 ecmwfr_1.5.0 ## [21] ncdf4_1.21 leaflet_2.1.2 ## ## loaded via a namespace (and not attached):\r## [1] xts_0.13.0 R.cache_0.16.0 tools_4.2.3 bslib_0.4.2 utf8_1.2.3 R6_2.5.1 KernSmooth_2.23-20 DBI_1.1.3 colorspace_2.1-0 tidyselect_1.2.0 ## [11] compiler_4.2.3 cli_3.6.0 gstat_2.1-0 bookdown_0.33 sass_0.4.5 scales_1.2.1 classInt_0.4-9 proxy_0.4-27 digest_0.6.31 rmarkdown_2.20 ## [21] R.utils_2.12.2 pkgconfig_2.0.3 htmltools_0.5.4 styler_1.9.1 fastmap_1.1.1 htmlwidgets_1.6.1 rlang_1.0.6 rstudioapi_0.14 FNN_1.1.3.2 jquerylib_0.1.4 ## [31] generics_0.1.3 zoo_1.8-11 jsonlite_1.8.4 crosstalk_1.2.0 dplyr_1.1.0 R.oo_1.25.0 magrittr_2.0.3 Rcpp_1.0.10 munsell_0.5.0 fansi_1.0.4 ## [41] lifecycle_1.0.3 R.methodsS3_1.8.2 stringi_1.7.12 yaml_2.3.7 plyr_1.8.8 grid_4.2.3 lattice_0.20-45 knitr_1.42 pillar_1.8.1 spacetime_1.2-8 ## [51] codetools_0.2-19 glue_1.6.2 evaluate_0.20 blogdown_1.16 vctrs_0.5.2 gtable_0.3.1 purrr_1.0.1 reshape_0.8.9 assertthat_0.2.1 cachem_1.0.7 ## [61] ggplot2_3.4.1 xfun_0.37 lwgeom_0.2-11 e1071_1.7-13 class_7.3-21 tibble_3.2.0 intervals_0.15.3 memoise_2.0.1 units_0.8-1 timechange_0.2.0 ## [71] ellipsis_0.3.2\r ","date":1614384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"a7dcc0f6ad6555d8ce8659b1e77e4049","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/research-project/","publishdate":"2021-02-27T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/research-project/","section":"courses","summary":"This is a quick documentation of a mock research project used throughout all `R` exercises during this seminar series.","tags":["R","Statistics"],"title":"Research Project","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Geocentric Models Material  \rSlides Chapter 4  Introduction These are answers and solutions to the exercises at the end of chapter 4 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Jeffrey Girard.\nEasy Exercises Practice E1 Question: In the model definition below, which line is the likelihood?\n $y_i \\sim Normal(\\mu, \\sigma)$ $\\mu \\sim Normal(0, 10)$ $\\sigma \\sim Uniform(0, 10)$  Answer: 1, $y_i \\sim Normal(\\mu, \\sigma)$ - This is the likelihood specification (see also page 84 in the book). Everything else is a specification of priors.\nPractice E2 Question: In the model definition just above, how many parameters are in the posterior distribution?\nAnswer: $y_i$ is not to be estimated, but represents the data we have at hand and want to understand through parameters. Both $\\mu$ and $\\sigma$ are parameters which we attempt to estimate.\nPractice E3 Question: Using the model definition above, write down the appropriate form of Bayes’ theorem that includes the proper likelihood and priors.\nAnswer: Following the specification in the \u0026ldquo;Overthinking\u0026rdquo; box on page 87, we can write the Bayes' Theorem for the model above as:\n$Pr(\\mu, \\sigma | y) = \\frac{\\prod_i Normal(y_i| \\mu, \\sigma) Normal(\\mu| 0, 10) Uniform(\\sigma | 0, 10)}{\\int\\int\\prod_i Normal(y_i| \\mu, \\sigma) Normal(\\mu| 0, 10) Uniform(\\sigma | 0, 10) d\\mu d\\sigma}$\nPractice E4 Question: In the model definition below, which line is the linear model?\n $y_i \\sim Normal(\\mu, \\sigma)$ $\\mu_i=\\alpha+\\beta x_i$ $\\alpha \\sim Normal(0,10)$ $\\beta \\sim Normal(0,1)$ $\\sigma \\sim Uniform(0,10)$  Answer: The linear model is deterministic in nature (i.e. the parameters determine the value of the response variable). This is identified with the mathematical notation of $=$. Therefore, line 2. $\\mu_i=\\alpha+\\beta x_i$ is the linear model. All other specifications are stochastic links (identified with $\\sim$).\nPractice E5 Question: In the model definition just above, how many parameters are in the posterior distribution?\nAnswer: Three. $\\alpha$, $\\beta$, and $\\sigma$ are the parameters we estimate. $y_i \\sim Normal(\\mu, \\sigma)$ is the likelihood.\nMedium Exercises This is where we get into R applications.\nrm(list = ls())\rlibrary(rethinking)\r Practice M1 Question: For the model definition below, simulate observed heights from the prior (not the posterior).\n $y_i \\sim Normal(\\mu, \\sigma)$ $\\mu \\sim Normal(0, 10)$ $\\sigma \\sim Uniform(0, 10)$  Answer:\nset.seed(42)\rsample_mu \u0026lt;- rnorm(1e4, 0, 10)\rsample_sigma \u0026lt;- runif(1e4, 0, 10)\rprior_y \u0026lt;- rnorm(1e4, sample_mu, sample_sigma)\rdens(prior_y)\r Practice M2 Question: Translate the model just above into a quap() formula.\nAnswer:\nformula \u0026lt;- alist(\ry ~ dnorm(mu, sigma),\rmu ~ dnorm(0, 10),\rsigma ~ dunif(0, 10)\r)\rformula\r ## [[1]]\r## y ~ dnorm(mu, sigma)\r## ## [[2]]\r## mu ~ dnorm(0, 10)\r## ## [[3]]\r## sigma ~ dunif(0, 10)\r Practice M3 Question: Translate the quap() model formula below into a mathematical model definition.\nflist \u0026lt;- alist(\ry ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * x,\ra ~ dnorm(0, 50),\rb ~ dunif(0, 10),\rsigma ~ dunif(0, 50)\r)\r Answer:\n $y_i \\sim Normal(\\mu, \\sigma)$ $\\mu_i=\\alpha+\\beta x_i$ $\\alpha \\sim Normal(0,50)$ $\\beta \\sim Uniform(0,10)$ $\\sigma \\sim Uniform(0,50)$  Practice M4 Question: A sample of students is measured for height each year for 3 years. After the third year, you want to fit a linear regression predicting height using year as a predictor. Write down the mathematical model definition for this regression, using any variable names and priors you choose. Be prepared to defend you choice of priors.\nAnswer: Firstly, I start by identifying the likelihood of heights $h$. I assume these to be normally distributed around some mean $\\mu$, with a standard deviation of $\\sigma$:\n$h_i = Normal(\\mu, \\sigma)$\n$\\mu$ is the mean of heights and can be obtained as follows:\n$\\mu_i = \\alpha + \\beta x_i$\nSetting aside the issue of independence here - each student shows up in the data multiple times, thus making the time-series of heights dependent and potentially autocorrelated - no age range has been specified for our students in question. This leaves us with little information regarding potential priors (elementary school students are much smaller than university students). Therefore, I chose a weak prior with a large range. I call this prior for the height intercept $\\alpha$ and assume a normal distribution with a wide range:\n$\\alpha \\sim Normal(150,25)$\nset.seed(42)\rdens(rnorm(1e4, 150, 25))\r $\\beta$ represents the average increase of in height for each year. Again, the potentially large age range means we have to use a somewhat uninformative prior because people grow very differently at different ages. The distribution here could be argued to be uniform or normal. I am going with normal because it emphasises a much more peaked distribution of growth rates with an emphasis for the mean:\n$\\beta \\sim Normal(4,1)$\nset.seed(42)\rdens(rnorm(1e4, 4, 2))\r As you can see, this choice of prior for $\\alpha$ would allow for negative growth rates which might be an issue.\nFinally, we need to identify our $\\sigma$ where I specify a uniform range that covers the full range of heights when given a large range of students (in age, that is):\n$\\sigma \\sim Uniform(0,30)$\nPlugging this one into our height simulation, we get a wide but overall sensible range:\nset.seed(42)\rdens(rnorm(1e4, 150, 30))\r Personally, I think a second-order polynomial regression could be sensible here to account for the change in growth rate over time, but I assume a latter question will deal with that.\nPractice M5 Question: Now suppose I remind you that every student got taller each year. Does this information lead you to change your choice of priors? How?\nAnswer: Yes, I can change my prior for $\\beta$ to always be positive by using a log-normal distribution:\n$\\beta \\sim LogNormal(2,0.5)$\nset.seed(42)\rdens(rlnorm(1e4, 2, .5))\r Now this makes much more sense!\nPractice M6 Question: Now suppose I tell you that the variance among heights for students of the same age is never more than 64 cm. How does this lead you to revise your priors?\nAnswer: The variance is the square product of $\\sigma$, so we know that $\\sigma$ never exceeds $\\sqrt(64) = 8$ and can update our prior accordingly:\n$\\sigma \\sim Uniform(0,8)$\nset.seed(42)\rdens(runif(1e4, 0, 8))\r Hard Exercises Practice H1 Question: The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals. That is, fill in the table below, using model-based predictions.\n   Individual weight expected height 89% interval     1 46.95     2 43.72     3 64.78     4 32.59     5 54.63      Answer:\ndata(\u0026quot;Howell1\u0026quot;)\rd \u0026lt;- Howell1\rformula \u0026lt;- alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * weight,\ra ~ dnorm(150, 30), # a relatively short height with a large SD to account for large age spread in data set and the overall smaller stature of the peoples in the !Kung census\rb ~ dlnorm(0, 1), # I want strictly positive weight-height relationships\rsigma ~ dunif(0, 50) # rather large SD\r)\r(m \u0026lt;- quap(formula, data = d))\r ## ## Quadratic approximate posterior distribution\r## ## Formula:\r## height ~ dnorm(mu, sigma)\r## mu \u0026lt;- a + b * weight\r## a ~ dnorm(150, 30)\r## b ~ dlnorm(0, 1)\r## sigma ~ dunif(0, 50)\r## ## Posterior means:\r## a b sigma ## 75.550586 1.761449 9.345982 ## ## Log-likelihood: -1987.71\r Now, we can obtain the posterior distributions for our weight values in the table:\nnew_weight \u0026lt;- c(46.95, 43.72, 64.78, 32.59, 54.63)\rpred_height \u0026lt;- link(m, data = data.frame(weight = new_weight))\rexpected \u0026lt;- apply(pred_height, 2, mean)\rinterval \u0026lt;- apply(pred_height, 2, HPDI, prob = 0.89)\r Finally, we merge this into a data frame:\ndata.frame(\rindividual = 1:5,\rweight = new_weight,\rexpected = expected,\rlower = interval[1, ],\rupper = interval[2, ]\r)\r ## individual weight expected lower upper\r## 1 1 46.95 158.2948 157.4868 159.1242\r## 2 2 43.72 152.6012 151.9167 153.3826\r## 3 3 64.78 189.7242 188.3729 191.2549\r## 4 4 32.59 132.9821 132.3565 133.6889\r## 5 5 54.63 171.8326 170.9136 173.0242\r Practice H2 Question: Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right, you should end up with a new data frame with 192 rows in it.\nAnswer:\nd2 \u0026lt;- Howell1[Howell1$age \u0026lt; 18, ]\rweight_bar \u0026lt;- mean(d2$weight)\rnrow(d2)\r ## [1] 192\r Part A Question: Fit a linear regression to these data, using quap(). Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets?\nAnswer:\nformula \u0026lt;- alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * (weight - weight_bar),\ra ~ dnorm(110, 30),\rb ~ dlnorm(0, 1),\rsigma ~ dunif(0, 60)\r)\rm \u0026lt;- quap(formula, data = d2)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a 108.319563 0.6087746 107.346624 109.292503\r## b 2.716656 0.0683154 2.607475 2.825838\r## sigma 8.437165 0.4305635 7.749042 9.125289\r For a 10-unit increase in weight, we see a 27.17cm increase in height.\nPart B Question: Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Superimpose the MAP regression line and 89% HPDI for the mean. Also superimpose the 89% HPDI for predicted heights.\nAnswer:\n# Data for plot\rweight.seq \u0026lt;- seq(from = min(d2$weight), to = max(d2$weight), by = 1) # sequence to do predictions for\rmu \u0026lt;- link(m, data = data.frame(weight = weight.seq)) # do predictions\rmu.mean \u0026lt;- apply(mu, 2, mean) # calculate mean\rmu.HPDI \u0026lt;- apply(mu, 2, HPDI, prob = 0.89) # identify interval\rsim.height \u0026lt;- sim(m, data = list(weight = weight.seq)) # simulate full predictions\rheight.HPDI \u0026lt;- apply(sim.height, 2, HPDI, prob = 0.89) # identify interval\r# Plotting\rplot(height ~ weight, data = d2, col = col.alpha(rangi2, 0.7)) # base plot\rlines(weight.seq, mu.mean) # add mean line\rshade(mu.HPDI, weight.seq) # add hdpi interval\rshade(height.HPDI, weight.seq) # add full-hdpi interval\r Part C Question: What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don’t have to write any new code. Just explain what the model appears to be doing a bad job of, and what you hypothesize would be a better model.\nAnswer: The model woefully overpredicts height at the low-weight end of the spectrum as well as the upper end of the weight spectrum. At the mid-range of the weight spectrum, our model underpredicts height. It looks as though the data fall onto a curve and so we could potentially do better with a polynomial model.\nPractice H3 Question: Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body weight that scales with height!” Let’s take your colleague’s advice and see what happens.\nPart A Question: Model the relationship between height (cm) and the natural logarithm of weight (log-kg). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Fit this model, using the quadratic approximation:\n$h_i ∼ Normal(\\mu_i, \\sigma)$\n$\\mu_i = \\alpha + \\beta log(w_i)$\n$\\alpha ∼ Normal(178, 20)$\n$\\beta ∼ LogNormal(0, 1)$\n$\\sigma ∼ Uniform(0, 50)$\nwhere $h_i$ is the height of individual $i$ and $w_i$ is the weight (in kg) of individual $i$. The function for computing a natural log in R is just log(). Can you interpret the resulting estimates?\nAnswer:\nd \u0026lt;- Howell1\rformula \u0026lt;- alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * log(weight),\ra ~ dnorm(178, 20),\rb ~ dlnorm(0, 1),\rsigma ~ dunif(0, 50)\r)\rm \u0026lt;- quap(formula, data = d)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a -22.874329 1.3343120 -25.006817 -20.741840\r## b 46.817801 0.3823300 46.206764 47.428838\r## sigma 5.137168 0.1558908 4.888025 5.386312\r Our $\\alpha$ estimate seems to be out-of-line at -22.87. This is simply the predicted height when the weight is 0 log-kg and thus somewhat uninformative. $\\beta$ tells us that our individual grow, on average, by 46.82cm per increase in log-kg by 1. The standard deviation around our height predictions is 5.14.\nTransforming a variable makes interpreting diffuclt.\nPart B Question: Begin with this plot: plot(height ~ weight, data = Howell1), col = col.alpha(rangi2, 0.4)). Then use samples from the quadratic approximate posterior of the model in (a) to superimpose on the plot: (1) the predicted mean height as a function of weight, (2) the 97% HPDI for the mean, and (3) the 97% HPDI for predicted heights.\nAnswer:\nplot(height ~ weight, data = d, col = col.alpha(rangi2, 0.4))\r# Estimate and plot the quap regression line and 97% HPDI for the mean\rweight.seq \u0026lt;- seq(from = min(d$weight), to = max(d$weight), by = 1)\rmu \u0026lt;- link(m, data = data.frame(weight = weight.seq))\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.HPDI \u0026lt;- apply(mu, 2, HPDI, prob = 0.97)\rlines(weight.seq, mu.mean)\rshade(mu.HPDI, weight.seq)\r# Estimate and plot the 97% HPDI for the predicted heights\rsim.height \u0026lt;- sim(m, data = list(weight = weight.seq))\rheight.HPDI \u0026lt;- apply(sim.height, 2, HPDI, prob = 0.97)\rshade(height.HPDI, weight.seq)\r Yup, this does fit much more neatly.\nPractice H4 Question: Plot the prior predictive distribution for the polynomial regression model in the chapter. You can modify the code that plots the linear regression prior predictive distribution. Can you modify the prior distributions of $\\alpha$, $\\beta_1$, and $\\beta_2$ so that the prior predictions stay within the biologically reasonable outcome space? That is to say: Do not try to fit the data by hand. But do try to keep the curves consistent with what you know about height and weight, before seeing these exact data.\nAnswer:\ndata(\u0026quot;Howell1\u0026quot;)\rd \u0026lt;- Howell1\r# standardising weight\rd$weight_s \u0026lt;- with(d, (weight - mean(weight)) / sd(weight))\r# quadratic weight\rd$weight_s2 \u0026lt;- d$weight_s^2\r# MODEL\rM_Poly \u0026lt;- quap(\ralist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b1 * weight_s + b2 * weight_s2,\ra ~ dnorm(178, 20),\rb1 ~ dlnorm(0, 1),\rb2 ~ dnorm(0, 1),\rsigma ~ dunif(0, 50)\r),\rdata = d\r)\rprecis(M_Poly)\r ## mean sd 5.5% 94.5%\r## a 146.054799 0.3689900 145.465082 146.644517\r## b1 21.734548 0.2888949 21.272839 22.196258\r## b2 -7.800570 0.2742037 -8.238800 -7.362339\r## sigma 5.774487 0.1764685 5.492456 6.056517\r The prior prediction can be obtained using extract.prior(). The obtained sample can then be passed on to the link() function for the weight space in question. Since we want to try multiple priors, I use a function that takes the alist object as well as the number of predicted curves as arguments. This function-idea has been adapted from Gregor Mathes solution which is based on the use of tidyverse:\nlibrary(tidyr) # we don't get around using the function pivot_longer()\rlibrary(ggplot2)\rmodify_prior_poly \u0026lt;- function(my_alist, N) {\r# set seed for reproducibility\rset.seed(42)\r# fit model\rm_poly \u0026lt;- quap(my_alist, data = d)\r# make weight sequence with both standardised weight and the square of it\rweight_seq \u0026lt;- seq(from = min(d$weight), to = max(d$weight), by = 1)\rweight_seq \u0026lt;- data.frame(\rweight = weight_seq,\rweight_s = (weight_seq - mean(weight_seq)) / sd(weight_seq),\rweight_s2 = ((weight_seq - mean(weight_seq)) / sd(weight_seq))^2\r)\r# extract samples from the prior\rm_poly_prior \u0026lt;- extract.prior(m_poly, n = N)\r# now apply the polynomial equation to the priors to get predicted heights\rm_poly_mu \u0026lt;- link(\rm_poly,\rpost = m_poly_prior,\rdata = list(\rweight_s = weight_seq$weight_s,\rweight_s2 = weight_seq$weight_s2\r)\r)\rm_poly_mu \u0026lt;- as.data.frame(m_poly_mu)\rm_poly_mu \u0026lt;- as.data.frame(pivot_longer(m_poly_mu, cols = everything(), values_to = \u0026quot;height\u0026quot;))\rm_poly_mu$weight \u0026lt;- rep(weight_seq$weight, N)\rm_poly_mu$type \u0026lt;- rep(as.character(1:N), each = length(weight_seq$weight))\r# plot it\rggplot(m_poly_mu) +\rgeom_line(aes(x = weight, y = height, group = type), alpha = 0.5) +\rgeom_hline(yintercept = c(0, 272), colour = \u0026quot;steelblue4\u0026quot;) +\rannotate(\rgeom = \u0026quot;text\u0026quot;,\rx = c(6, 12),\ry = c(11, 285),\rlabel = c(\u0026quot;Embryo\u0026quot;, \u0026quot;World's tallest person\u0026quot;),\rcolour = c(rep(\u0026quot;steelblue4\u0026quot;, 2))\r) +\rlabs(x = \u0026quot;Weight in kg\u0026quot;, y = \u0026quot;Height in cm\u0026quot;) +\rtheme_minimal()\r}\r Let\u0026rsquo;s run this for our initial model specification:\nmodify_prior_poly(\rmy_alist = alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b1 * weight_s + b2 * weight_s2,\ra ~ dnorm(178, 20),\rb1 ~ dlnorm(0, 1),\rb2 ~ dnorm(0, 1),\rsigma ~ dunif(0, 50)\r),\rN = 40\r)\r The priors should cover the whole biologically sensible space (unless we have some really strong indication for this not being the case). Let\u0026rsquo;s start by decreasing the mean for $\\alpha$ and increasing its standard deviation:\nmodify_prior_poly(\rmy_alist = alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b1 * weight_s + b2 * weight_s2,\ra ~ dnorm(130, 35), # decrease mean and increase sd\rb1 ~ dlnorm(0, 1),\rb2 ~ dnorm(0, 1),\rsigma ~ dunif(0, 50)\r),\rN = 40\r)\r Better, but not quite there yet. The lines themselves could do with stronger positive relationship here between weight and height. We know this relationship to be stronger:\nmodify_prior_poly(\rmy_alist = alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b1 * weight_s + b2 * weight_s2,\ra ~ dnorm(130, 35),\rb1 ~ dlnorm(1, 1), # increase mean, but not sd (we don't want negative relationships)\rb2 ~ dnorm(0, 1),\rsigma ~ dunif(0, 50)\r),\rN = 40\r)\r I am already happy with this. However, we can see some downward curving weight-height relationships here. That\u0026rsquo;s probably not what we find in the real-world and so we might want to force these relationships to always curve upwards, by having a positive $\\beta_2$ with a narrow log-normal distribution:\nmodify_prior_poly(\rmy_alist = alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b1 * weight_s + b2 * weight_s2,\ra ~ dnorm(130, 35),\rb1 ~ dlnorm(1, 1),\rb2 ~ dlnorm(0, .05), # force positive parameter\rsigma ~ dunif(0, 50)\r),\rN = 40\r)\r Phew. I can\u0026rsquo;t think of more, to be honest. This looks good to me.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] tidyr_1.1.3 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.3 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 R6_2.5.0 ## [11] backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 ## [21] jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 labeling_0.4.2 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 ## [31] xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 codetools_0.2-18 ## [41] matrixStats_0.61.0 fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 ## [51] lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 farver_2.1.0 bslib_0.2.4 ellipsis_0.3.2 ## [61] generics_0.1.0 vctrs_0.3.7 rematch2_2.1.2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 ## [71] colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1610064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610092800,"objectID":"d80304da13b9d3c7411c03dce6058394","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-04/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/courses/rethinking/chapter-04/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 4 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayesian Statistics","Bayes","AU Bayes Study Group"],"title":"Chapter 04","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory These are the solutions to the exercises contained within the handout to Descriptive Statistics which walks you through the basics of descriptive statistics and its parameters. The analyses presented here are using data from the StarWars data set supplied through the dplyr package that have been saved as a .csv file. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.\nI have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here.\nPackages As you will remember from our lecture slides, the calculation of the mode in R can either be achieved through some intense coding or simply by using the mlv(..., method=\u0026quot;mfv\u0026quot;) function contained within the modeest package (unfortunately, this package is out of date and can sometimes be challenging to install).\nConclusively, it is now time for you to get familiar with how packages work in R. Packages are the way by which R is supplied with user-created and moderator-mediated functionality that exceeds the base applicability of R. Many things you will want to accomplish in more advanced statistics is impossible without such packages and even basic tasks such as data visualisation (dealt with in our next seminar) are reliant on R packages.\nIf you want to get a package and its functions into R there are two ways we will discuss in the following. In general, it pays to load all packages at the beginning of a coding document before any actual analyses happen (in the preamble) so you get a good overview of what the program is calling upon.\nBasic Preamble This is the most basic version of getting packages into R and is widely practised and taught. Unsurprisingly, I am not a big fan of it.\nFirst, you use function install.packages() to download the desired package off dedicated servers (usually CRAN-mirrors) to your machine where it is then unpacked into a library (a folder that\u0026rsquo;s located in your documents section by default). Secondly, you need to invoke the library() function to load the R package you need into your active R session. In our case of the package modeest it would look something like this:\ninstall.packages(\u0026quot;modeest\u0026quot;)\rlibrary(modeest)\r The reason I am not overly fond of this procedure is that it is clunky, can break easily through spelling mistakes and starts cluttering your preamble super fast if the analyses you are wanting to perform require excessive amounts of packages. Additionally, when you are some place with a bad internet connection you might not want to re-download packages that are already contained on your hard drive.\nAdvanced Preamble There is a myriad of different preamble styles (just as there are tons of different, personalised coding styles). I am left with presenting my preamble of choice here but I do not claim that this is the most sophisticated one out there.\nThe way this preamble works is that it is structured around a user-defined function (something we will touch on later in our seminar series) which first checks whether a package is already downloaded and then installs (if necessary) and/or loads it into R. This function is called install.load.package() and you can see its specification down below (don\u0026rsquo;t worry if it doesn\u0026rsquo;t make sense to you yet - it is not supposed to at this point). Unfortunately, it can only ever be applied to one package at a time and so we need a workaround to make it work on multiple packages at once. This can be achieved by establishing a vector of all desired package names (package_vec) and then applying (sapply()) the install.load.package() function to every item of the package name vector iteratively as follows:\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE)) install.packages(x)\rrequire(x, character.only = TRUE)\r}\r# packages to load/install if necessary\rpackage_vec \u0026lt;- c(\u0026quot;modeest\u0026quot;)\r# applying function install.load.package to all packages specified in package_vec\rsapply(package_vec, install.load.package)\r ## Loading required package: modeest\r ## modeest ## TRUE\r Why do I prefer this? Firstly, it is way shorter than the basic method when dealing with many packages (which you will get into fast, I promise), reduces the chance for typos by 50% and does not override already installed packages hence speeding up your processing time.\nLoading the Excel data into R Our data is located in the Data folder and is called DescriptiveData.csv. Since it is a .csv file, we can simply use the R in-built function read.csv() to load the data by combining the former two identifiers into one long string with a backslash separating the two (the backslash indicates a step down in the folder hierarchy). Given this argument, read.csv() will produce an object of type data.frame in R which we want to keep in our environment and hence need to assign a name to. In our case, let that name be Data_df (I recommend using endings to your data object names that indicate their type for easier coding without constant type checking):\nData_df \u0026lt;- read.csv(\u0026quot;Data/DescriptiveData.csv\u0026quot;) # load data file from Data folder\r What\u0026rsquo;s contained within our data? Now that our data set is finally loaded into R, we can finally get to trying to make sense of it. Usually, this shouldn\u0026rsquo;t ever be something one has to do in R but should be manageable through a project-/data-specific README file (we will cover this in our seminar on hypotheses testing and project planning) but for now we are stuck with pure exploration of our data set. Get your goggles on and let\u0026rsquo;s dive in!\nFirstly, it always pays to asses the basic attributes of any data object (remember the Introduction to R seminar):\n Name - we know the name (it is Data_df) since we named it that Type - we already know that it is a data.frame because we created it using the read.csv function Mode - this is an interesting one as it means having to subset our data frame Dimensions - a crucial information about how many observations and variables are contained within our data set  Dimensions Let\u0026rsquo;s start with the dimensions because these will tell us how many modes (these are object attribute modes and not descriptive parameter modes) to asses:\ndim(Data_df)\r ## [1] 87 8\r Using the dim() function, we arrive at the conclusion that our Data_df contains 87 rows and 8 columns. Since data frames are usually ordered as observations $\\times$ variables, we can conclude that we have 87 observations and 8 variables at our hands.\nYou can arrive at the same point by using the function View() in R. I\u0026rsquo;m not showing this here because it does not translate well to paper and would make whoever chooses to print this waste paper.\nModes Now it\u0026rsquo;s time to get a hang of the modes of the variable records within our data set. To do so, we have two choices, we can either subset the data frame by columns and apply the class() function to each column subset or simply apply the str() function to the data frame object. The reason str() may be favourable in this case is due to the fact that str() automatically breaks down the structure of R-internal objects and hence saves us the sub-setting:\nstr(Data_df)\r ## 'data.frame':\t87 obs. of 8 variables:\r## $ name : chr \u0026quot;Luke Skywalker\u0026quot; \u0026quot;C-3PO\u0026quot; \u0026quot;R2-D2\u0026quot; \u0026quot;Darth Vader\u0026quot; ...\r## $ height : int 172 167 96 202 150 178 165 97 183 182 ...\r## $ mass : num 77 75 32 136 49 120 75 32 84 77 ...\r## $ hair_color: chr \u0026quot;blond\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;none\u0026quot; ...\r## $ skin_color: chr \u0026quot;fair\u0026quot; \u0026quot;gold\u0026quot; \u0026quot;white, blue\u0026quot; \u0026quot;white\u0026quot; ...\r## $ eye_color : chr \u0026quot;blue\u0026quot; \u0026quot;yellow\u0026quot; \u0026quot;red\u0026quot; \u0026quot;yellow\u0026quot; ...\r## $ birth_year: num 19 112 33 41.9 19 52 47 NA 24 57 ...\r## $ gender : chr \u0026quot;male\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;male\u0026quot; ...\r As it turns out, our data frame knows the 8 variables of name, height, mass, hair_color, skin_color, eye_color, birth_year, gender which range from integer to numeric and factor modes.\nData Content So what does our data actually tell us? Answering this question usually comes down to some analyses but for now we are only really interested in what kind of information our data frame is storing.\nAgain, this would be easiest to asses using a README file or the View() function in R. However, for the sake of brevity we can make due with the following to commands which present the user with the first and last five rows of any respective data frame:\nhead(Data_df)\r ## name height mass hair_color skin_color eye_color birth_year\r## 1 Luke Skywalker 172 77 blond fair blue 19.0\r## 2 C-3PO 167 75 gold yellow 112.0\r## 3 R2-D2 96 32 white, blue red 33.0\r## 4 Darth Vader 202 136 none white yellow 41.9\r## 5 Leia Organa 150 49 brown light brown 19.0\r## 6 Owen Lars 178 120 brown, grey light blue 52.0\r## gender\r## 1 male\r## 2 ## 3 ## 4 male\r## 5 female\r## 6 male\r tail(Data_df)\r ## name height mass hair_color skin_color eye_color birth_year gender\r## 82 Finn NA NA black dark dark NA male\r## 83 Rey NA NA brown light hazel NA female\r## 84 Poe Dameron NA NA brown light brown NA male\r## 85 BB8 NA NA none none black NA none\r## 86 Captain Phasma NA NA unknown unknown unknown NA female\r## 87 Padmé Amidala 165 45 brown light brown 46 female\r The avid reader will surely have picked up on the fact that all the records in the name column of Data_df belong to characters from the Star Wars universe. In fact, this data set is a modified version of the StarWars data set supplied by the dplyr package and contains information of many of the important cast members of the Star Wars movie universe.\nParameters of descriptive statistics Names As it turns out (and should\u0026rsquo;ve been obvious from the onset if we\u0026rsquo;re honest), every major character in the cinematic Star Wars Universe has a unique name to themselves. Conclusively, the calculation of any parameters of descriptive statistics makes no sense with the names of our characters for the two following reasons:\n The name variable is of mode character/factor and only allows for the calculation of the mode Since every name only appears once, there is no mode  As long as the calculation of descriptive parameters of the name variable of our data set is concerned, Admiral Ackbar said it best: \u0026ldquo;It\u0026rsquo;s a trap\u0026rdquo;.\nHeight Let\u0026rsquo;s get started on figuring out some parameters of descriptive statistics for the height variable of our Star Wars characters.\nSubsetting First, we need to extract the data in question from our big data frame object. This can be achieved by indexing through the column name as follows:\nHeight \u0026lt;- Data_df$height\r Location Parameters Now, with our Height vector being the numeric height records of the Star Wars characters in our data set, we are primed to calculate location parameters as follows:\nmean \u0026lt;- mean(Height, na.rm = TRUE)\rmedian \u0026lt;- median(Height, na.rm = TRUE)\rmode \u0026lt;- mlv(na.omit(Height), method = \u0026quot;mfv\u0026quot;)\rmin \u0026lt;- min(Height, na.rm = TRUE)\rmax \u0026lt;- max(Height, na.rm = TRUE)\rrange \u0026lt;- max - min\r# Combining all location parameters into one vector for easier viewing\rLocPars_vec \u0026lt;- c(mean, median, mode, min, max, range)\rnames(LocPars_vec) \u0026lt;- c(\u0026quot;mean\u0026quot;, \u0026quot;median\u0026quot;, \u0026quot;mode\u0026quot;, \u0026quot;minimum\u0026quot;, \u0026quot;maximum\u0026quot;, \u0026quot;range\u0026quot;)\rLocPars_vec\r ## mean median mode minimum maximum range ## 174.358 180.000 183.000 66.000 264.000 198.000\r As you can clearly see, there is a big range in the heights of our respective Star Wars characters with mean and median being fairly disjunct due to the outliers in height on especially either end.\nDistribution Parameters Now that we are aware of the location parameters of the Star Wars height records, we can move on to the distribution parameters/parameters of spread. Those can be calculated in R as follows:\nvar \u0026lt;- var(Height, na.rm = TRUE)\rsd \u0026lt;- sd(Height, na.rm = TRUE)\rquantiles \u0026lt;- quantile(Height, na.rm = TRUE)\r# Combining all location parameters into one vector for easier viewing\rDisPars_vec \u0026lt;- c(var, sd, quantiles)\rnames(DisPars_vec) \u0026lt;- c(\u0026quot;var\u0026quot;, \u0026quot;sd\u0026quot;, \u0026quot;0%\u0026quot;, \u0026quot;25%\u0026quot;, \u0026quot;50%\u0026quot;, \u0026quot;75%\u0026quot;, \u0026quot;100%\u0026quot;)\rDisPars_vec\r ## var sd 0% 25% 50% 75% 100% ## 1208.98272 34.77043 66.00000 167.00000 180.00000 191.00000 264.00000\r Notice how some of the quantiles (actually quartiles in this case) link up with some of the parameters of central tendency.\nSummary Just to round this off, have a look at what the summary() function in R supplies you with:\nsummary \u0026lt;- summary(na.omit(Height))\rsummary\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 66.0 167.0 180.0 174.4 191.0 264.0\r This is a nice assortment of location and dispersion parameters.\nMass Now let\u0026rsquo;s focus on the weight of our Star Wars characters.\nSubsetting Again, we need to extract our data from the data frame. For the sake of brevity, I will refrain from showing you the rest of the analysis and only present its results to save some space.\nMass \u0026lt;- Data_df$mass\r Location Parameters ## mean median mode minimum maximum range ## 97.31186 79.00000 80.00000 15.00000 1358.00000 1343.00000\r As you can see, there is a huge range in weight records of Star Wars characters and especially the outlier on the upper end (1358kg) push the mean towards the upper end of the weight range and away from the median. We\u0026rsquo;ve got Jabba Desilijic Tiure to thank for that.\nDistribution Parameters ## var sd 0% 25% 50% 75% 100% ## 28715.7300 169.4572 15.0000 55.6000 79.0000 84.5000 1358.0000\r Quite obviously, the wide range of weight records also prompts a large variance and standard deviation.\nHair Color Hair colour in our data set is saved in column 4 of our data set and so when sub-setting the data frame to obtain information about a characters hair colour, instead of calling on Data_df$hair_color we can also do so as follows:\nHCs \u0026lt;- Data_df[, 4]\r Of course, hair colour is not a numeric variable and much better represent by being of mode factor. Therefore, we are unable to obtain most parameters of descriptive statistics but we can show a frequency count as follows which allows for the calculation of the mode:\ntable(HCs)\r ## HCs\r## auburn auburn, grey auburn, white black ## 5 1 1 1 13 ## blond blonde brown brown, grey grey ## 3 1 18 1 1 ## none unknown white ## 37 1 4\r Eye Colour Eye colour is another factor mode variable:\nECs \u0026lt;- Data_df$eye_color\r We can only calculate the mode by looking for the maximum in our table() output:\ntable(ECs)\r ## ECs\r## black blue blue-gray brown dark ## 10 19 1 21 1 ## gold green, yellow hazel orange pink ## 1 1 3 8 1 ## red red, blue unknown white yellow ## 5 1 3 1 11\r Birth Year Subsetting As another numeric variable, birth year allows for the calculation of the full range of parameters of descriptive statistics:\nBY \u0026lt;- Data_df$birth_year\r Keep in mind that StarWars operates on a different time reference scale than we do.\nLocation Parameters ## mean median mode minimum maximum range ## 87.56512 52.00000 19.00000 8.00000 896.00000 888.00000\r Again, there is a big disparity here between mean and median which stems from extreme outliers on both ends of the age spectrum (Yoda and Wicket Systri Warrick, respectively).\nDistribution Parameters ## var sd 0% 25% 50% 75% 100% ## 23929.4414 154.6914 8.0000 35.0000 52.0000 72.0000 896.0000\r Unsurprisingly, there is a big variance and standard deviation for the observed birth year/age records.\nGender Gender is another factor mode variable (obviously):\nGender \u0026lt;- Data_df$gender\r We can, again, only judge the mode of our data from the output of the table() function:\ntable(Gender)\r ## Gender\r## female hermaphrodite male none ## 3 19 1 62 2\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"8857b254d261ab17a04bc86fba376044","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/descriptive-statistics/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/descriptive-statistics/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to Descriptive Statistics which walks you through the basics of descriptive statistics and its parameters. The analyses presented here are using data from the `StarWars` data set supplied through the `dplyr` package that have been saved as a .csv file.","tags":["R","Statistics"],"title":"Descriptive Statistics","type":"docs"},{"authors":["Erik Kusch"],"categories":["BioStat101","An Introduction to Biostatistics"],"content":"Theory These are the solutions to the exercises contained within the handout to Descriptive Statistics which walks you through the basics of descriptive statistics and its parameters. The analyses presented here are using data from the StarWars data set supplied through the dplyr package that have been saved as a .csv file. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions. I have prepared some slides for this session: \nData Find the data for this exercise here. Do not worry about downloading it for now.\nPackages As you will remember from our lecture slides, the calculation of the mode in R can either be achieved through some intense coding or simply by using the mlv(..., method=\u0026quot;mfv\u0026quot;) function contained within the modeest package (unfortunately, this package is out of date and can sometimes be challenging to install).\nConclusively, it is now time for you to get familiar with how packages work in R. Packages are the way by which R is supplied with user-created and moderator-mediated functionality that exceeds the base applicability of R. Many things you will want to accomplish in more advanced statistics is impossible without such packages and even basic tasks such as data visualisation (dealt with in our next seminar) are reliant on R packages.\nIf you want to get a package and its functions into R there are two ways we will discuss in the following. In general, it pays to load all packages at the beginning of a coding document before any actual analyses happen (in the preamble) so you get a good overview of what the program is calling upon.\nBasic Preamble This is the most basic version of getting packages into R and is widely practised and taught. Unsurprisingly, I am not a big fan of it.\nFirst, you use function install.packages() to download the desired package off dedicated servers (usually CRAN-mirrors) to your machine where it is then unpacked into a library (a folder that\u0026rsquo;s located in your documents section by default). Secondly, you need to invoke the library() function to load the R package you need into your active R session. In our case of the package modeest it would look something like this:\ninstall.packages(\u0026quot;modeest\u0026quot;)\rlibrary(modeest)\r The reason I am not overly fond of this procedure is that it is clunky, can break easily through spelling mistakes and starts cluttering your preamble super fast if the analyses you are wanting to perform require excessive amounts of packages. Additionally, when you are some place with a bad internet connection you might not want to re-download packages that are already contained on your hard drive.\nAdvanced Preamble There is a myriad of different preamble styles (just as there are tons of different, personalised coding styles). I am left with presenting my preamble of choice here but I do not claim that this is the most sophisticated one out there.\nThe way this preamble works is that it is structured around a user-defined function (something we will touch on later in our seminar series) which first checks whether a package is already downloaded and then installs (if necessary) and/or loads it into R. This function is called install.load.package() and you can see its specification down below (don\u0026rsquo;t worry if it doesn\u0026rsquo;t make sense to you yet - it is not supposed to at this point). Unfortunately, it can only ever be applied to one package at a time and so we need a workaround to make it work on multiple packages at once. This can be achieved by establishing a vector of all desired package names (package_vec) and then applying (sapply()) the install.load.package() function to every item of the package name vector iteratively as follows:\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\r# packages to load/install if necessary\rpackage_vec \u0026lt;- c(\u0026quot;modeest\u0026quot;)\r# applying function install.load.package to all packages specified in\r# package_vec\rsapply(package_vec, install.load.package)\r ## Loading required package: modeest\r ## modeest ## TRUE\r Why do I prefer this? Firstly, it is way shorter than the basic method when dealing with many packages (which you will get into fast, I promise), reduces the chance for typos by 50% and does not override already installed packages hence speeding up your processing time.\nLoading the Excel data into R Our data is located in the Data folder and is called DescriptiveData.csv. Since it is a .csv file, we can simply use the R in-built function read.csv() to load the data by combining the former two identifiers into one long string with a backslash separating the two (the backslash indicates a step down in the folder hierarchy). Given this argument, read.csv() will produce an object of type data.frame in R which we want to keep in our environment and hence need to assign a name to. In our case, let that name be Data_df (I recommend using endings to your data object names that indicate their type for easier coding without constant type checking):\n# Data_df \u0026lt;- read.csv('Data/DescriptiveData.csv') # load data file from Data\r# folder if you downloaded the data as a .csv alternatively, read the csv\r# directly from the url\rData_df \u0026lt;- read.csv(\u0026quot;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/DescriptiveData.csv\u0026quot;)\r What\u0026rsquo;s contained within our data? Now that our data set is finally loaded into R, we can finally get to trying to make sense of it. Usually, this shouldn\u0026rsquo;t ever be something one has to do in R but should be manageable through a project-/data-specific README file (we will cover this in our seminar on hypotheses testing and project planning) but for now we are stuck with pure exploration of our data set. Get your goggles on and let\u0026rsquo;s dive in!\nFirstly, it always pays to asses the basic attributes of any data object (remember the Introduction to R seminar):\n Name - we know the name (it is Data_df) since we named it that Type - we already know that it is a data.frame because we created it using the read.csv function Mode - this is an interesting one as it means having to subset our data frame Dimensions - a crucial information about how many observations and variables are contained within our data set  Dimensions Let\u0026rsquo;s start with the dimensions because these will tell us how many modes (these are object attribute modes and not descriptive parameter modes) to asses:\ndim(Data_df)\r ## [1] 87 8\r Using the dim() function, we arrive at the conclusion that our Data_df contains 87 rows and 8 columns. Since data frames are usually ordered as observations $\\times$ variables, we can conclude that we have 87 observations and 8 variables at our hands.\nYou can arrive at the same point by using the function View() in R. I\u0026rsquo;m not showing this here because it does not translate well to paper and would make whoever chooses to print this waste paper.\nModes Now it\u0026rsquo;s time to get a hang of the modes of the variable records within our data set. To do so, we have two choices, we can either subset the data frame by columns and apply the class() function to each column subset or simply apply the str() function to the data frame object. The reason str() may be favourable in this case is due to the fact that str() automatically breaks down the structure of R-internal objects and hence saves us the sub-setting:\nstr(Data_df)\r ## 'data.frame':\t87 obs. of 8 variables:\r## $ name : chr \u0026quot;Luke Skywalker\u0026quot; \u0026quot;C-3PO\u0026quot; \u0026quot;R2-D2\u0026quot; \u0026quot;Darth Vader\u0026quot; ...\r## $ height : int 172 167 96 202 150 178 165 97 183 182 ...\r## $ mass : num 77 75 32 136 49 120 75 32 84 77 ...\r## $ hair_color: chr \u0026quot;blond\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;none\u0026quot; ...\r## $ skin_color: chr \u0026quot;fair\u0026quot; \u0026quot;gold\u0026quot; \u0026quot;white, blue\u0026quot; \u0026quot;white\u0026quot; ...\r## $ eye_color : chr \u0026quot;blue\u0026quot; \u0026quot;yellow\u0026quot; \u0026quot;red\u0026quot; \u0026quot;yellow\u0026quot; ...\r## $ birth_year: num 19 112 33 41.9 19 52 47 NA 24 57 ...\r## $ gender : chr \u0026quot;male\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;male\u0026quot; ...\r As it turns out, our data frame knows the 8 variables of name, height, mass, hair_color, skin_color, eye_color, birth_year, gender which range from integer to numeric and factor modes.\nData Content So what does our data actually tell us? Answering this question usually comes down to some analyses but for now we are only really interested in what kind of information our data frame is storing.\nAgain, this would be easiest to asses using a README file or the View() function in R. However, for the sake of brevity we can make due with the following to commands which present the user with the first and last five rows of any respective data frame:\nhead(Data_df)\r ## name height mass hair_color skin_color eye_color birth_year\r## 1 Luke Skywalker 172 77 blond fair blue 19.0\r## 2 C-3PO 167 75 gold yellow 112.0\r## 3 R2-D2 96 32 white, blue red 33.0\r## 4 Darth Vader 202 136 none white yellow 41.9\r## 5 Leia Organa 150 49 brown light brown 19.0\r## 6 Owen Lars 178 120 brown, grey light blue 52.0\r## gender\r## 1 male\r## 2 ## 3 ## 4 male\r## 5 female\r## 6 male\r tail(Data_df)\r ## name height mass hair_color skin_color eye_color birth_year\r## 82 Finn NA NA black dark dark NA\r## 83 Rey NA NA brown light hazel NA\r## 84 Poe Dameron NA NA brown light brown NA\r## 85 BB8 NA NA none none black NA\r## 86 Captain Phasma NA NA unknown unknown unknown NA\r## 87 Padm\\xe9 Amidala 165 45 brown light brown 46\r## gender\r## 82 male\r## 83 female\r## 84 male\r## 85 none\r## 86 female\r## 87 female\r The avid reader will surely have picked up on the fact that all the records in the name column of Data_df belong to characters from the Star Wars universe. In fact, this data set is a modified version of the StarWars data set supplied by the dplyr package and contains information of many of the important cast members of the Star Wars movie universe.\nParameters of descriptive statistics Names As it turns out (and should\u0026rsquo;ve been obvious from the onset if we\u0026rsquo;re honest), every major character in the cinematic Star Wars Universe has a unique name to themselves. Conclusively, the calculation of any parameters of descriptive statistics makes no sense with the names of our characters for the two following reasons:\n The name variable is of mode character/factor and only allows for the calculation of the mode Since every name only appears once, there is no mode  As long as the calculation of descriptive parameters of the name variable of our data set is concerned, Admiral Ackbar said it best: \u0026ldquo;It\u0026rsquo;s a trap\u0026rdquo;.\nHeight Let\u0026rsquo;s get started on figuring out some parameters of descriptive statistics for the height variable of our Star Wars characters.\nSubsetting First, we need to extract the data in question from our big data frame object. This can be achieved by indexing through the column name as follows:\nHeight \u0026lt;- Data_df$height\r Location Parameters Now, with our Height vector being the numeric height records of the Star Wars characters in our data set, we are primed to calculate location parameters as follows:\nmean \u0026lt;- mean(Height, na.rm = TRUE)\rmedian \u0026lt;- median(Height, na.rm = TRUE)\rmode \u0026lt;- mlv(na.omit(Height), method = \u0026quot;mfv\u0026quot;)\rmin \u0026lt;- min(Height, na.rm = TRUE)\rmax \u0026lt;- max(Height, na.rm = TRUE)\rrange \u0026lt;- max - min\r# Combining all location parameters into one vector for easier viewing\rLocPars_vec \u0026lt;- c(mean, median, mode, min, max, range)\rnames(LocPars_vec) \u0026lt;- c(\u0026quot;mean\u0026quot;, \u0026quot;median\u0026quot;, \u0026quot;mode\u0026quot;, \u0026quot;minimum\u0026quot;, \u0026quot;maximum\u0026quot;, \u0026quot;range\u0026quot;)\rLocPars_vec\r ## mean median mode minimum maximum range ## 174.358 180.000 183.000 66.000 264.000 198.000\r As you can clearly see, there is a big range in the heights of our respective Star Wars characters with mean and median being fairly disjunct due to the outliers in height on especially either end.\nDistribution Parameters Now that we are aware of the location parameters of the Star Wars height records, we can move on to the distribution parameters/parameters of spread. Those can be calculated in R as follows:\nvar \u0026lt;- var(Height, na.rm = TRUE)\rsd \u0026lt;- sd(Height, na.rm = TRUE)\rquantiles \u0026lt;- quantile(Height, na.rm = TRUE)\r# Combining all location parameters into one vector for easier viewing\rDisPars_vec \u0026lt;- c(var, sd, quantiles)\rnames(DisPars_vec) \u0026lt;- c(\u0026quot;var\u0026quot;, \u0026quot;sd\u0026quot;, \u0026quot;0%\u0026quot;, \u0026quot;25%\u0026quot;, \u0026quot;50%\u0026quot;, \u0026quot;75%\u0026quot;, \u0026quot;100%\u0026quot;)\rDisPars_vec\r ## var sd 0% 25% 50% 75% 100% ## 1208.98272 34.77043 66.00000 167.00000 180.00000 191.00000 264.00000\r Notice how some of the quantiles (actually quartiles in this case) link up with some of the parameters of central tendency.\nSummary Just to round this off, have a look at what the summary() function in R supplies you with:\nsummary \u0026lt;- summary(na.omit(Height))\rsummary\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 66.0 167.0 180.0 174.4 191.0 264.0\r This is a nice assortment of location and dispersion parameters.\nMass Now let\u0026rsquo;s focus on the weight of our Star Wars characters.\nSubsetting Again, we need to extract our data from the data frame. For the sake of brevity, I will refrain from showing you the rest of the analysis and only present its results to save some space.\nMass \u0026lt;- Data_df$mass\r Location Parameters ## mean median mode minimum maximum range ## 97.31186 79.00000 80.00000 15.00000 1358.00000 1343.00000\r As you can see, there is a huge range in weight records of Star Wars characters and especially the outlier on the upper end (1358kg) push the mean towards the upper end of the weight range and away from the median. We\u0026rsquo;ve got Jabba Desilijic Tiure to thank for that.\nDistribution Parameters ## var sd 0% 25% 50% 75% 100% ## 28715.7300 169.4572 15.0000 55.6000 79.0000 84.5000 1358.0000\r Quite obviously, the wide range of weight records also prompts a large variance and standard deviation.\nHair Color Hair colour in our data set is saved in column 4 of our data set and so when sub-setting the data frame to obtain information about a characters hair colour, instead of calling on Data_df$hair_color we can also do so as follows:\nHCs \u0026lt;- Data_df[, 4]\r Of course, hair colour is not a numeric variable and much better represent by being of mode factor. Therefore, we are unable to obtain most parameters of descriptive statistics but we can show a frequency count as follows which allows for the calculation of the mode:\ntable(HCs)\r ## HCs\r## auburn auburn, grey auburn, white black ## 5 1 1 1 13 ## blond blonde brown brown, grey grey ## 3 1 18 1 1 ## none unknown white ## 37 1 4\r Eye Colour Eye colour is another factor mode variable:\nECs \u0026lt;- Data_df$eye_color\r We can only calculate the mode by looking for the maximum in our table() output:\ntable(ECs)\r ## ECs\r## black blue blue-gray brown dark ## 10 19 1 21 1 ## gold green, yellow hazel orange pink ## 1 1 3 8 1 ## red red, blue unknown white yellow ## 5 1 3 1 11\r Birth Year Subsetting As another numeric variable, birth year allows for the calculation of the full range of parameters of descriptive statistics:\nBY \u0026lt;- Data_df$birth_year\r Keep in mind that StarWars operates on a different time reference scale than we do.\nLocation Parameters ## mean median mode minimum maximum range ## 87.56512 52.00000 19.00000 8.00000 896.00000 888.00000\r Again, there is a big disparity here between mean and median which stems from extreme outliers on both ends of the age spectrum (Yoda and Wicket Systri Warrick, respectively).\nDistribution Parameters ## var sd 0% 25% 50% 75% 100% ## 23929.4414 154.6914 8.0000 35.0000 52.0000 72.0000 896.0000\r Unsurprisingly, there is a big variance and standard deviation for the observed birth year/age records.\nGender Gender is another factor mode variable (obviously):\nGender \u0026lt;- Data_df$gender\r We can, again, only judge the mode of our data from the output of the table() function:\ntable(Gender)\r ## Gender\r## female hermaphrodite male none ## 3 19 1 62 2\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"2ac78d68251e37026ae978d784eadb7b","permalink":"https://www.erikkusch.com/courses/biostat101/descriptive-statistics/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/descriptive-statistics/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to Descriptive Statistics which walks you through the basics of descriptive statistics and its parameters. The analyses presented here are using data from the `StarWars` data set supplied through the `dplyr` package that have been saved as a .csv file.","tags":["R","Statistics"],"title":"Descriptive Statistics","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"\rKrigR is currently undergoing development. As a result, this part of the workshop has become deprecated. Please refer to the setup quick guide portions of this material as these are up-to-date. \r\r\rR Packages for the Workshop For the sake of this series of tutorials, we need some extra packages for visualisations. To load them, we use a custom function (install.load.package(), see below). This function checks whether a package is already installed, subsequently install (if necessary) and loads the package. To carry this operation out for several packages, we simply apply it to a vector of package names using sapply():\ninstall.load.package \u0026lt;- function(x){\rif (!require(x, character.only = TRUE))\rinstall.packages(x, repos='http://cran.us.r-project.org')\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;tidyr\u0026quot;, # for turning rasters into ggplot-dataframes\r\u0026quot;ggplot2\u0026quot;, # for plotting\r\u0026quot;viridis\u0026quot;, # colour palettes\r\u0026quot;cowplot\u0026quot;, # gridding multiple plots\r\u0026quot;ggmap\u0026quot;, # obtaining satellite maps\r\u0026quot;gimms\u0026quot;, # to get some pre-existing data to match in our downscaling\r\u0026quot;rnaturalearth\u0026quot;, # for shapefiles\r\u0026quot;rnaturalearthdata\u0026quot;, # for high-resolution shapefiles\r\u0026quot;mapview\u0026quot; # for generating mapview outputs\r)\rsapply(package_vec, install.load.package)\r ## tidyr ggplot2 viridis cowplot ggmap ## TRUE TRUE TRUE TRUE TRUE ## gimms rnaturalearth rnaturalearthdata mapview ## TRUE TRUE TRUE TRUE\r Setting up Directories The workshop is designed to run completely from scratch. For this to work in a structured way, we create a folder/directory structure so that we got some nice compartments on our hard drives. We create the following directories:\n A Data directory for all of our data downloads A Covariate directory for all of our covariate data An Exports directory for all of our Kriging outputs  Dir.Base \u0026lt;- getwd() # identifying the current directory\rDir.Data \u0026lt;- file.path(Dir.Base, \u0026quot;Data\u0026quot;) # folder path for data\rDir.Covariates \u0026lt;- file.path(Dir.Base, \u0026quot;Covariates\u0026quot;) # folder path for covariates\rDir.Exports \u0026lt;- file.path(Dir.Base, \u0026quot;Exports\u0026quot;) # folder path for exports\r## create directories, if they don't exist yet\rDirs \u0026lt;- sapply(c(Dir.Data, Dir.Covariates, Dir.Exports), function(x) if(!dir.exists(x)) dir.create(x))\r Visualiation Functions In order to easily visualise our Kriging procedure including (1) inputs, (2) covariates, and (3) outputs without repeating too much of the same code, we have prepared some plotting functions which you can download as FUN_Plotting.R.\nWith the FUN_Plotting.R file placed in the project directory of your workshop material (i.e., the directory returned by Dir.Base), running the following will register the three plotting functions in your R environment.\nsource(\u0026quot;FUN_Plotting.R\u0026quot;)\r The plotting functions you have just loaded are called:\n Plot_Raw() - we will use this function to visualise data downloaded with KrigR Plot_Covs() - this function will help us visualise the covariates we use for statistical interpolation Plot_Krigs() - kriged products and their associated uncertainty will be visualised using this function  \rDon’t worry about understanding how these functions work off the bat here. Kriging and the package KrigR are what we want to demonstrate here - not visualisation strategies.\r\r\rLocations of Interest Our Workshop Target Region To keep this workshop material concise and make it so you don\u0026rsquo;t need access to a server of cluster throughout the following demonstrations of KrigR, we will specify a set of locations in which we are interested.\nThe locations we focus on for this workshop are situated throughout eastern Germany and the north-western parts of the Czech Republic. Why do we focus on this particular part of the Earth? There are three reasons:\n Topographical Heterogeneity - the area we select here contains large swaths of flat lowlands as well as some mountain ridges. This will make for visually pleasing plots and highlight the capability of kriging. Geographic Scale - the area we are selecting here hits a certain sweet-spot for our purposes as its size makes it so that all KrigR functions run to completion in a relatively short time. Familiarity - I was born and grew up in this region and have fond memories of the place. Please excuse my indulging in a bit of nostalgia.  \rChange the locations of interest at your own risk.\r\r\rUsing a different set of locations than the ones we specify here will change computational load and time as well as disk space required when working through the workshop material.\n\rKrigR will be able to get you the data you want for the locations you desire, but computational requirements will vary.\r\r\rSpatial Preferences in KrigR \rKrigR is capable of learning about your spatial preferences in three ways:\n As an extent input (a rectangular box). As a SpatialPolygons input (a polygon or set of polygons). As a set of locations stored in a data.frame.  \r\rTo demonstrate the range of specifications permitted in KrigR, we make use of all three specifications. As we will see in this tutorial, masking out unnecessary areas from our analyses speeds up Kriging tremendously hence why we strongly suggest you make use of SpatialPolygons or data.frames whenever possible.\nArea of Interest (extent) The simplest way in which you can run the functions of the KrigR package is by specifying a rectangular bounding box (i.e., an extent) to specify your study region(s). We simply specify the longitude and latitude ranges and store the object as an extent:\nExtent_ext \u0026lt;- extent(c(9.87, 15.03, 49.89, 53.06))\r Shape of Interest (SpatialPolygons) To define SpatialPolygons for our purposes, I make use of the NaturalEarthData. Here, I select a set of polygons corresponding to some states in Germany and the Czech Republic:\nShape_shp \u0026lt;- ne_states(country = c(\u0026quot;Germany\u0026quot;, \u0026quot;Czech Republic\u0026quot;))\rShape_shp \u0026lt;- Shape_shp[Shape_shp$name_en %in% c(\u0026quot;Saxony\u0026quot;, \u0026quot;Saxony-Anhalt\u0026quot;, \u0026quot;Thuringia\u0026quot;, \u0026quot;Ústí nad Labem Region\u0026quot;, \u0026quot;Karlovy Vary Region\u0026quot;), ]\r \rThe above requires the naturalhighres package which can give some users troubles.\r\r\rHere\u0026rsquo;s a workaround if naturalhighres does not work for you:\ndownload.file(\u0026quot;https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_1_states_provinces.zip\u0026quot;,\rdestfile = \u0026quot;highres.zip\u0026quot;)\runzip(\u0026quot;highres.zip\u0026quot;)\rShape_shp \u0026lt;- readOGR(\u0026quot;ne_10m_admin_1_states_provinces.shp\u0026quot;)\rShape_shp \u0026lt;- Shape_shp[Shape_shp$name_en %in% c(\u0026quot;Saxony\u0026quot;, \u0026quot;Saxony-Anhalt\u0026quot;, \u0026quot;Thuringia\u0026quot;,\r\u0026quot;ÃÅ¡stÃÂ­ nad Labem\u0026quot;, \u0026quot;Karlovy Vary\u0026quot;), ]\r Points of Interest (data.frame) Finally, to represent specific points of interest, I have prepared a small data set of mountains for each state in the shapefile above. You can download this file here: Mountains_df.RData. Simply place this file into your data directory and continue the workshop.\nLet\u0026rsquo;s load this data set and quickly visualise it:\nload(file.path(Dir.Data, \u0026quot;Mountains_df.RData\u0026quot;)) # load an sp object called Mountains_sp\rMountains_df\r ## Mountain Lon Lat\r## 1 Fichtelberg 12.95472 50.42861\r## 2 Brocken 10.61722 51.80056\r## 3 Großer Beerberg 10.74611 50.65944\r## 4 Meluzína 13.00778 50.39028\r## 5 Milešovka 13.93153 50.55523\r \rWe now have all of our objects for spatial preferences ready for the workshop.\r\r\rVisualising our Study Setting To finish our preparations for this workshop, let\u0026rsquo;s visualise the different locations of interest:\n## Establish rectangular bounding box from extent\rbbox \u0026lt;- as.numeric(as(Extent_ext, 'SpatialPolygons')@bbox)\rnames(bbox) \u0026lt;- c(\u0026quot;left\u0026quot;, \u0026quot;bottom\u0026quot;, \u0026quot;right\u0026quot;, \u0026quot;top\u0026quot;)\r## Make locations of mountains into SpatialPoints\rMountains_sp \u0026lt;- Mountains_df\rcoordinates(Mountains_sp) \u0026lt;- ~Lon+Lat\r## download a map of the area specified by the extent\rback_gg \u0026lt;- get_map(bbox, maptype = 'terrain')\r## combine locations of interest into one plot\rggmap(back_gg, extent = \u0026quot;device\u0026quot;) + # plot the extent area\r## display the SpatialPolygons area\rgeom_polygon(aes(x = long, y = lat, group = id), data = fortify(Shape_shp),\rcolour = 'black', size = 1, fill = 'black', alpha = .5) + ## add the data.frame data\rgeom_point(aes(x = Lon, y = Lat), data = data.frame(Mountains_sp), colour = \u0026quot;red\u0026quot;, size = 4, pch = 13) + ## some style additions\rtheme_bw() + labs(x= \u0026quot;Longitude [°]\u0026quot;, y = \u0026quot;Latitude [°]\u0026quot;) + theme(plot.margin=unit(c(0, 1, 0, 1),\u0026quot;lines\u0026quot;))\r In the above figure, the map area designates the extent specifications while the grey overlay display the SpatialPolygons preference and points of interest (form our data.frame input) are highlighted with red plotting symbols.\n\rWe are now ready to start the KrigR portion of the workshop!\r\r\rSession Info ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 ## [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] mapview_2.10.2 rnaturalearthdata_0.1.0 rnaturalearth_0.1.0 ## [4] gimms_1.2.0 ggmap_3.0.0 cowplot_1.1.1 ## [7] viridis_0.6.0 viridisLite_0.4.0 ggplot2_3.3.6 ## [10] tidyr_1.1.3 KrigR_0.1.2 httr_1.4.2 ## [13] stars_0.5-3 abind_1.4-5 fasterize_1.0.3 ## [16] sf_1.0-0 lubridate_1.7.10 automap_1.0-14 ## [19] doSNOW_1.0.19 snow_0.4-3 doParallel_1.0.16 ## [22] iterators_1.0.13 foreach_1.5.1 rgdal_1.5-23 ## [25] raster_3.4-13 sp_1.4-5 stringr_1.4.0 ## [28] keyring_1.2.0 ecmwfr_1.3.0 ncdf4_1.17 ## ## loaded via a namespace (and not attached):\r## [1] bitops_1.0-7 satellite_1.0.2 xts_0.12.1 ## [4] webshot_0.5.2 tools_4.0.5 bslib_0.3.1 ## [7] utf8_1.2.1 R6_2.5.0 zyp_0.10-1.1 ## [10] KernSmooth_2.23-18 DBI_1.1.1 colorspace_2.0-0 ## [13] withr_2.4.2 tidyselect_1.1.0 gridExtra_2.3 ## [16] leaflet_2.0.4.1 curl_4.3.2 compiler_4.0.5 ## [19] leafem_0.1.3 gstat_2.0-7 labeling_0.4.2 ## [22] bookdown_0.22 sass_0.4.1 scales_1.1.1 ## [25] classInt_0.4-3 proxy_0.4-25 digest_0.6.27 ## [28] rmarkdown_2.14 base64enc_0.1-3 jpeg_0.1-8.1 ## [31] pkgconfig_2.0.3 htmltools_0.5.2 highr_0.9 ## [34] fastmap_1.1.0 htmlwidgets_1.5.3 rlang_0.4.11 ## [37] FNN_1.1.3 farver_2.1.0 jquerylib_0.1.4 ## [40] generics_0.1.0 zoo_1.8-9 jsonlite_1.7.2 ## [43] crosstalk_1.1.1 dplyr_1.0.5 magrittr_2.0.1 ## [46] Rcpp_1.0.7 munsell_0.5.0 fansi_0.4.2 ## [49] lifecycle_1.0.0 stringi_1.5.3 yaml_2.2.1 ## [52] plyr_1.8.6 grid_4.0.5 crayon_1.4.1 ## [55] lattice_0.20-41 knitr_1.33 pillar_1.6.0 ## [58] boot_1.3-27 rjson_0.2.20 spacetime_1.2-4 ## [61] stats4_4.0.5 codetools_0.2-18 glue_1.4.2 ## [64] evaluate_0.14 blogdown_1.3 vctrs_0.3.7 ## [67] png_0.1-7 RgoogleMaps_1.4.5.3 gtable_0.3.0 ## [70] purrr_0.3.4 reshape_0.8.8 assertthat_0.2.1 ## [73] cachem_1.0.4 xfun_0.31 lwgeom_0.2-6 ## [76] e1071_1.7-6 rnaturalearthhires_0.2.0 class_7.3-18 ## [79] Kendall_2.2 tibble_3.1.1 intervals_0.15.2 ## [82] memoise_2.0.0 units_0.7-2 ellipsis_0.3.2\r ","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"3fd4a054d08b3d0a789bccbe05429fb1","permalink":"https://www.erikkusch.com/courses/krigr/prep/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/prep/","section":"courses","summary":"Preparations for the workshop.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Preparing the Workshop","type":"docs"},{"authors":["Erik Kusch"],"categories":["Excursion into Biostatistics"],"content":"Theory These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.\nI have prepared some Lecture Slides  for this session.\nExercise First, imagine we have been out and about collecting samples for our sparrow populations. You can find the data came home with after our field work season here. This data set contains errors/mis-specified data entry and other slip-ups that can happen as a part of data collection exercises. We need to fix that.\nPreparing Our Procedure The following three sections are what I consider to be essential parts of the preamble to any R-based analysis. I highly recommend clearly indicating these bits in your code.\nMore often than not, you will use variations of these code chunks whether you are working on data handling, data exploration or full-fledged statistical analyses.\nNecessary Steps For Reproducibility Reproducibility is the be-all and end-all of any statistical analysis, particularly in light of the peer-review process in life sciences.\nrm(list = ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep = \u0026quot;/\u0026quot;) # soft-coding our data directory\r Once you get into highly complex statistical analyses, you may wish to break up chunks of your analysis into separate documents. To ensure that remnants of an earlier analysis or analysis chunk do not influence the results of your current analysis, you may wish to empty R\u0026rsquo;s cache (Environment) before attempting a new analysis. This is achieved via the command rm(list=ls()).\nNext, you need to remember the importance of soft-coding for the sake of reproducibility. One of the worst offences to the peer-review process in R-based statistics is the erroneous hard-coding of the working directory. The getwd() function shown above solves this exact problem. However, for this workaround to function properly you need to open the code document of interest by double-clicking it within its containing folder.\nWhen using the xlsx package or any Excel-reliant process via R, your code will automatically run a Java process in the background. By default the Java engine is limited as far as RAM allocation goes and tends to fail when faced with enormous data sets. The workaround options(java.parameters = \u0026quot;-Xmx8g\u0026quot;) gets rid of this issue by allocation 8 GBs of RAM to Java.\nPackages Packages are R\u0026rsquo;s way of giving you access to a seemingly infinite repository of functions.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE)) {\rinstall.packages(x)\r}\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\r\u0026quot;dplyr\u0026quot; # we need this package to fix the most common data errors\r)\rsapply(package_vec, install.load.package)\r ## dplyr ## TRUE\r Using the above function is way more sophisticated than the usual install.packages() + library() approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.\nLoading The Data Loading data is crucial to any analysis in R. Period.\nR offers a plethora of approaches to data loading and you will usually be taught the read.table() command in basic biostatistics courses. However, I have found to prefer the functionality provided by the xlsx package since most data recording is taking place in Excel. As this package is dependant on the installation of Java and RJava, we will settle on the base R function read.csv().\nData_df_base \u0026lt;- read.csv(file = paste(Dir.Data, \u0026quot;/SparrowData.csv\u0026quot;, sep = \u0026quot;\u0026quot;), header = TRUE)\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Another trick to have up your sleeve (if your RAM enables you to act on it) is to duplicate your initial data onto a new object once loaded into R. This will enable you to easily remedy mistakes in data treatment without having to reload your initial data set from the data file.\nInspecting The Data Once the data is loaded into R, you need to inspect it to make sure it is ready for use.\nAssessing A Data Frame in R Most, if not all, data you will ever load into R will be stored as a data.frame within R. Some of the most important functions for inspecting data frames (\u0026ldquo;df\u0026rdquo; in the following) in base R are the following four:\n dim(df) returns the dimensions (Rows x Columns)of the data frame head(df) returns the first 6 rows of the data frame by default (here changed to 4) tail(df) returns the last 6 rows of the data frame by default (here changed to 4) View(df) opens nearly any R object in a separate tab for further inspection. Since we are dealing with an enormous data set here, I will exclude this function for now to save you from printing unnecessary pages.  dim(Data_df)\r ## [1] 1068 21\r head(Data_df, n = 4)\r ## X Site Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size\r## 1 1 Siberia SI 60 100 Continental Native 34,05 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA NA B Large 16\r## 2 2 Siberia SI 60 100 Continental Native 34,86 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large 16\r## 3 3 Siberia SI 60 100 Continental Native 32,34 12.66 6.64 Black Female Shrub 35.6 1 3.21 C Large 14\r## 4 4 Siberia SI 60 100 Continental Native 34,78 15.09 7.00 Brown Female Shrub 47.75 0 NA E Large 10\r## Predator.Presence Predator.Type\r## 1 Yes Avian\r## 2 Yes Avian\r## 3 Yes Avian\r## 4 Yes Avian\r tail(Data_df, n = 4)\r ## X Site Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size\r## 1065 1065 Falkland Isles FI -51.75 -59.17 Coastal Introduced 34.25 15.26 7.04 Grey Male A Large 19\r## 1066 1066 Falkland Isles FI -51.75 -59.17 Coastal Introduced 31.76 12.78 6.67 Grey Male A Large 19\r## 1067 1067 Falkland Isles FI -51.75 -59.17 Coastal Introduced 31.48 12.49 6.63 Black Male C Large 18\r## 1068 1068 Falkland Isles FI -51.75 -59.17 Coastal Introduced 31.94 12.96 6.70 Grey Male A Large 19\r## Predator.Presence Predator.Type\r## 1065 Yes Avian\r## 1066 Yes Avian\r## 1067 Yes Avian\r## 1068 Yes Avian\r When having an initial look at the results of head(Data_df) and tail(Data_df) we can spot two important things:\n NAs in head and tail of our data set are stored differently. This is a common problem with biological data sets and we will deal with this issue extensively in the next few sections of this document. Due to our data loading procedure we ended up with a redundant first column that is simply showing the respective row numbers. However, this is unnecessary in R and so we can delete this column as seen below.  Data_df \u0026lt;- Data_df[, -1] # eliminating the erroneous first column as it is redundant\rdim(Data_df) # checking if the elimination went right\r ## [1] 1068 20\r The Summary() Function As already stated in our seminar series, the summary() function is invaluable to data exploration and data inspection. However, it is only partially applicable as it will not work flawlessly on every class of data. Examples of this are shown below.\nThe weight data contained within our data frame should be numeric and thus pose no issue to the summary() function. However, as shown in the next section, it is currently of type character which leads the summary() function to work improperly.\nsummary(Data_df$Weight)\r ## Length Class Mode ## 1068 character character\r The height data within our data set, on the other hand, is stored correctly as class numeric. Thus the summary() function performs flawlessly.\nsummary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.35 13.52 14.52 15.39 16.22 135.40\r Making data inspection more easy, one may which to automate the use of the summary() function. However, this only makes sense, when every data column is presenting data in the correct class type. Therefore, we will first fix the column classes and then use the summary() command.\nData Cleaning Workflow Identifying Problems Indentifying most problems in any data set you may ever encounter comes down to mostly two manifestations of inadequate data entry or handling:\n**1. Types/Classes **\nBefore even opening a data set, we should know what kind of data classes we expect for every variable (for example, height records as a factor don\u0026rsquo;t make much sense). Problems with data/variable classes can have lasting influence on your analyses and so we need to test the class for each variable (column) individually. Before we alter any column classes, we will first need to identify columns whose classes need fixing. Doing so is as easy applying the class() function to the data contained within every column of our data frame separately.\nR offers multiple functions for this but I find the lapply() function to perform flawlessly as shown below. Since lapply() returns a list of class identifiers and these don\u0026rsquo;t translate well to paper, I have opted to transform the list into a named character vector using the unlist() command. One could also use the str() function.\nunlist(lapply(Data_df, class))\r ## Site Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;numeric\u0026quot; \u0026quot;numeric\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;numeric\u0026quot; \u0026quot;numeric\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; ## Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size Predator.Presence Predator.Type ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;integer\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot;\r For further inspection, one may want to combine the information obtained by using the class() function with either the summary() function (for all non-numeric records) or the hist function (particularly useful for numeric records).\n**2. Contents/Values **\nTypos and the like will always lead to some data that simply doesn\u0026rsquo;t make sense given the context of your project. Sometimes, errors like these are salvageable but doing so can be a very difficult process. Before we alter any column contents, we will first need to identify columns whose contents need fixing, however. Doing so is as easy applying an automated version of summary() to the data contained within every column of our data frame separately after having fixed possibly erroneous data classes.\nFixing The Problems Fixing the problems in our data sets always comes down to altering data classes, altering faulty values or removing them entirely.\nTo make sure we fix all problems, we may often wish to enlist the summary() function as well as the hist() function for data inspection and visualisation.\nBefore we alter any column contents, we will first need to identify columns whose contents need fixing.\nOur Data Site Variable Class Expectation: factor (only 11 possible values)\nIdentifying Problems Let\u0026rsquo;s asses our Site records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Site)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Site)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nIndex Variable Class Expectation: factor (only 11 possible values)\nIdentifying Problems Let\u0026rsquo;s asses our Index records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Index)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Index)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to. Pay attention that thes shortened index numbers lign up with the numbers of site records!\nFixing Problems We don\u0026rsquo;t need to fix anything here.\n\\newpage\nLatitude Variable Class Expectation: numeric (Latitude is inherently continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Latitude records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Latitude)\r ## [1] \u0026quot;numeric\u0026quot;\r table(Data_df$Latitude) # use this instead of summary due to station-dependency here\r ## ## -51.75 -25 -21.1 4 10.5 17.25 31 54 55 60 70 ## 69 88 95 250 114 105 81 68 68 66 64\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nLongitude Variable Class Expectation: numeric (Longitude is inherently continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Longitude records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Longitude)\r ## [1] \u0026quot;numeric\u0026quot;\r table(Data_df$Longitude) # use this instead of summary due to station-dependency here\r ## ## -97 -92 -90 -88.75 -67 -59.17 -53 -2 55.6 100 135 ## 68 81 64 105 114 69 250 68 95 66 88\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nClimate Variable Class Expectation: factor (three levels: coastal, semi-coastal, continental)\nIdentifying Problems Let\u0026rsquo;s asses our Climate records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Climate)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Climate)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPopulation Status Variable Class Expectation: factor (two levels: native, introduced)\nIdentifying Problems Let\u0026rsquo;s asses our Population Status records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Population.Status)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Population.Status)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nWeight Variable Class Expectation: numeric (weight is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Weight records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Weight)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Weight)\r ## Length Class Mode ## 1068 character character\r Obviously, something is wrong.\nFixing Problems As seen above, weight records are currently stored as character which they shouldn\u0026rsquo;t. So how do we fix this?\nFirstly, let\u0026rsquo;s try an intuitive as.numeric() approach which attempts to convert all values contained within a vector into numeric records.\nData_df$Weight \u0026lt;- as.numeric(Data_df_base$Weight)\rsummary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 26.34 30.38 29.40 31.87 420.00 66\r Apparently, this didn\u0026rsquo;t do the trick since weight data values (recorded in g) below 13 and above 40 are highly unlikely for Passer domesticus.\nSometimes, the as.numeric() can be made more powerful by handing it data of class character. To do so, simply combine as.numeric() with as.character() as shown below.\nData_df$Weight \u0026lt;- as.numeric(as.character(Data_df_base$Weight))\rsummary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 26.34 30.38 29.40 31.87 420.00 66\r That still didn\u0026rsquo;t resolve our problem. Weight measurements were taken for all study organisms and so there shouldn\u0026rsquo;t be any NAs and yet we find 66.\nInterestingly enough this is the exact same number as observations available for Siberia. A closer look at the data frame shows us that weight data for Siberia has been recorded with commas as decimal delimiters whilst the rest of the data set utilises dots.\nFixing this is not necessarily difficult but it is an erroneous issue for data handling which comes up often and is easy to avoid. Getting rid of the flaws is as simple as using the gsub() function contained within the dplyr package.\nData_df$Weight \u0026lt;- as.numeric(gsub(pattern = \u0026quot;,\u0026quot;, replacement = \u0026quot;.\u0026quot;, x = Data_df_base$Weight))\rsummary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 19.38 27.90 30.63 29.69 32.24 420.00\r There is one data record left hat exceeds the biologically viable span for body weight records of Passer domesticus. This data record holds the value 420. Since this is unlikely to be a simple mistake of placing the decimal delimiter in the wrong place (both 4.2 and 42 grams are also not feasible weight records for house sparrows), we have to delete the weight data record in question:\nData_df$Weight[which(Data_df_base$Weight == 420)] \u0026lt;- NA\rsummary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 27.89 30.63 29.33 32.23 36.66 1\r hist(Data_df$Weight, breaks = 100)\r We finally fixed it!\nHeight Variable Class Expectation: numeric (height is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Height records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Height)\r ## [1] \u0026quot;numeric\u0026quot;\r summary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.35 13.52 14.52 15.39 16.22 135.40\r Again, some of our data don\u0026rsquo;t behave the way the should (a 135.4 or 1.35 cm tall sparrow are just absurd).\nFixing Problems Height (or \u0026ldquo;Length\u0026rdquo;) records of Passer domesticus should fall roughly between 10cm and 22cm. Looking at the data which exceed these thresholds, it is apparent that these are generated simply through misplaced decimal delimiters. So we fix them as follows and use a histogram to check if it worked.\nData_df$Height[which(Data_df$Height \u0026lt; 10)] # decimal point placed wrong here\r ## [1] 1.350 1.446\r Data_df$Height[which(Data_df$Height \u0026lt; 10)] \u0026lt;- Data_df$Height[which(Data_df$Height \u0026lt; 10)] * 10 # FIXED IT!\rData_df$Height[which(Data_df$Height \u0026gt; 22)] # decimal point placed wrong here\r ## [1] 126.7 135.4\r Data_df$Height[which(Data_df$Height \u0026gt; 22)] \u0026lt;- Data_df$Height[which(Data_df$Height \u0026gt; 22)] / 10 # FIXED IT!\rsummary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 11.09 13.52 14.51 15.20 16.20 21.68\r hist(Data_df$Height, breaks = 100)\r We finally fixed it!\nWing Chord Variable Class Expectation: numeric (wing chord is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Wing Chord records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Wing.Chord)\r ## [1] \u0026quot;numeric\u0026quot;\r summary(Data_df$Wing.Chord)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 6.410 6.840 7.050 7.337 7.400 9.000\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nColour Variable Class Expectation: factor (three levels: black, grey, brown)\nIdentifying Problems Let\u0026rsquo;s asses our Colour records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Colour)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Colour)\r ## Length Class Mode ## 1068 character character\r Some of the colour records are very odd.\nFixing Problems The colour records \u0026ldquo;Bright black\u0026rdquo; and \u0026ldquo;Grey with black spots\u0026rdquo; should be \u0026ldquo;Grey\u0026rdquo;. Someone clearly got too eager on the assignment of colours here. The fix is as easy as identifying the data records which are \u0026ldquo;too precise\u0026rdquo; and overwrite them with the correct assignment:\nData_df$Colour[which(Data_df$Colour == \u0026quot;Bright black\u0026quot;)] \u0026lt;- \u0026quot;Grey\u0026quot;\rData_df$Colour[which(Data_df$Colour == \u0026quot;Grey with black spots\u0026quot;)] \u0026lt;- \u0026quot;Grey\u0026quot;\rData_df$Colour \u0026lt;- droplevels(factor(Data_df$Colour)) # drop unused factor levels\rsummary(Data_df$Colour) # FIXED IT!\r ## Black Brown Grey ## 356 298 414\r We finally fixed it!\nSex Variable Class Expectation: factor (two levels: male and female)\nIdentifying Problems Let\u0026rsquo;s asses our Climate records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Sex)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Sex)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nNesting Site Variable Class Expectation: factor (two levels: shrub and tree)\nIdentifying Problems Let\u0026rsquo;s asses our Nesting Site records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Nesting.Site)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Nesting.Site)\r ## Length Class Mode ## 1068 character character\r Fixing Problems One individual is recording to be nesting on the ground. This is something house sparrows don\u0026rsquo;t do. Therefore, we have to assume that this individual is not even a Passer domesticus to begin with.\nThe only way to solve this is to remove all observations pertaining to this individual:\nData_df \u0026lt;- Data_df[-which(Data_df$Nesting.Site == \u0026quot;Ground\u0026quot;), ]\rsummary(Data_df$Nesting.Site)\r ## Length Class Mode ## 1067 character character\r We just deleted a data record. This affects the flock size of the flock it belongs to (basically, this column contains hard-coded values) which we are going to deal with later.\nStill, there are manually entered NA records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The nesting site for a data record where sex reads \u0026ldquo;Male\u0026rdquo; has to be NA.\nData_df$Nesting.Site[which(Data_df$Sex == \u0026quot;Male\u0026quot;)] \u0026lt;- NA\rData_df$Nesting.Site \u0026lt;- droplevels(factor(Data_df$Nesting.Site)) # drop unused factor levels\rsummary(Data_df$Nesting.Site) # FIXED IT!\r ## Shrub Tree NA's ## 292 231 544\r Nesting Height Variable Class Expectation: numeric (continuous records in two clusters corresponding to shrubs and trees)\nIdentifying Problems Let\u0026rsquo;s asses our Nesting Height records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Nesting.Height)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Nesting.Height)\r ## Length Class Mode ## 1067 character character\r There are obviously some issues here.\nFixing Problems Nesting height is a clear example of a variable that should be recorded as numeric and yet our data frame currently stores them as character.\nOur first approach to fixing this, again, is using the as.numeric() function.\nsummary(as.numeric(Data_df$Nesting.Height))\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 11.78 42.34 64.85 480.59 951.38 1950.86 544\r Clearly, something went horribly wrong here. When taking a closer look, the number of 1s is artificially inflated. This is due to the NAs contained within the data set. These are currently stored as characters since they have been entered into the Excel sheet itself. The as.numeric() function transforms these into 1s.\nOne way of circumventing this issue is to combine the as.numeric() function with the as.character() function.\nData_df$Nesting.Height \u0026lt;- as.numeric(as.character(Data_df$Nesting.Height))\rsummary(Data_df$Nesting.Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 11.78 42.34 64.85 480.59 951.38 1950.86 544\r This quite clearly fixed our problems.\nNumber of Eggs Variable Class Expectation: numeric (no a priori knowledge of levels)\nIdentifying Problems Let\u0026rsquo;s asses our Number of Eggs records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Number.of.Eggs)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Number.of.Eggs)\r ## Length Class Mode ## 1067 character character\r One very out of the ordinary record is to be seen.\nFixing Problems Number of eggs is another variable which should be recorded as numeric and yet is currently stored as character.\nOur first approach to fixing this, again, is using the as.numeric() function.\nsummary(as.numeric(Data_df$Number.of.Eggs))\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 0.000 2.000 3.000 3.746 4.000 10.000 544\r Again, this didn\u0026rsquo;t do the trick. The number of 1s might be inflated and we expect exactly 544 (number of males) NAs since number of eggs have only been recorded for female house sparrows.\nWe already know that improperly stored NA records are prone to causing an inflation of data records of value 1. We also remember that head and tail of our data frame hold different types of NA records. Let\u0026rsquo;s find out who entered NAs correctly:\nunique(Data_df$Site[which(is.na(Data_df$Egg.Weight))])\r ## character(0)\r The code above identifies the sites at which proper NA recording has been done. The Falkland Isle team did it right (NA fields in Excel were left blank). Fixing this is actually a bit more challenging and so we do the following:\n# make everything into characters\rData_df$Number.of.Eggs \u0026lt;- as.character(Data_df$Number.of.Eggs)\r# writing character NA onto actual NAs\rData_df$Number.of.Eggs[which(is.na(Data_df$Number.of.Eggs))] \u0026lt;- \u0026quot; NA\u0026quot;\r# make all character NAs into proper NAs\rData_df$Number.of.Eggs[Data_df$Number.of.Eggs == \u0026quot; NA\u0026quot;] \u0026lt;- NA\r# make everything numeric\rData_df$Number.of.Eggs \u0026lt;- as.numeric(as.character(Data_df$Number.of.Eggs))\rsummary(Data_df$Number.of.Eggs)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 0.000 2.000 3.000 3.746 4.000 10.000 544\r We did it!\nEgg Weight Variable Class Expectation: numeric (another weight measurement that needs to be continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Egg Weight records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Egg.Weight)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Egg.Weight)\r ## Length Class Mode ## 1067 character character\r Fixing Problems Egg weight should be recorded as numeric and yet is currently stored as character. Our first approach to fixing this, again, is using the as.numeric() function again.\nsummary(as.numeric(Data_df$Egg.Weight))\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 1.580 2.340 2.670 2.619 2.890 3.590 590\r Something is wrong here. Not enough NAs are recorded. We expect exactly 590 NAs (Number of males + Number of Females with zero eggs). Additionally, there are way too many 1s. Our problem, again, lies with the way the NAs have been entered into the data set from the beginning and so we use the following fix again.\n# make everything into characters\rData_df$Egg.Weight \u0026lt;- as.character(Data_df$Egg.Weight)\r# writing character NA onto actual NAs\rData_df$Egg.Weight[which(is.na(Data_df$Egg.Weight))] \u0026lt;- \u0026quot; NA\u0026quot;\r# make all character NAs into proper NAs\rData_df$Egg.Weight[Data_df$Egg.Weight == \u0026quot; NA\u0026quot;] \u0026lt;- NA\r# make everything numeric\rData_df$Egg.Weight \u0026lt;- as.numeric(as.character(Data_df$Egg.Weight))\rsummary(Data_df$Egg.Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 1.580 2.340 2.670 2.619 2.890 3.590 590\r Flock Variable Class Expectation: factor (each sparrow was assigned to one particular flock)\nIdentifying Problems Let\u0026rsquo;s asses our Flock records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Flock)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Flock)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nHome Range Variable Class Expectation: factor (three levels: small, medium, large)\nIdentifying Problems Let\u0026rsquo;s asses our Home Range records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Home.Range)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Home.Range)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nFlock Size Variable Class Expectation: numeric (continuous measurement of how many sparrows are in each flock - measured as integers)\nIdentifying Problems Let\u0026rsquo;s asses our Flock Size records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Flock.Size)\r ## [1] \u0026quot;integer\u0026quot;\r summary(Data_df$Flock.Size)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 7.00 16.00 19.00 25.81 31.00 58.00\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPredator Presence Variable Class Expectation: factor (two levels: yes and no)\nIdentifying Problems Let\u0026rsquo;s asses our Predator Presence records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Predator.Presence)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Predator.Presence)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPredator Type Variable Class Expectation: factor (three levels: Avian, Non-Avian, and NA)\nIdentifying Problems Let\u0026rsquo;s asses our Predator Type records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Predator.Type)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Predator.Type)\r ## Length Class Mode ## 1067 character character\r Something doesn\u0026rsquo;t sit well here.\nFixing Problems Someone got overly eager when recording Predator Type and specified the presence of a hawk instead of taking down \u0026ldquo;Avian\u0026rdquo;. We fix this as follows:\nData_df$Predator.Type[which(Data_df$Predator.Type == \u0026quot;Hawk\u0026quot;)] \u0026lt;- \u0026quot;Avian\u0026quot;\rsummary(Data_df$Predator.Type)\r ## Length Class Mode ## 1067 character character\r This fixed it but there are still manually entered NA records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The predator type for a data record where predator presence reads \u0026ldquo;No\u0026rdquo; has to be NA.\nData_df$Predator.Type[which(Data_df$Predator.Presence == \u0026quot;No\u0026quot;)] \u0026lt;- NA\rData_df$Predator.Type \u0026lt;- droplevels(factor(Data_df$Predator.Type)) # drop unused factor levels\rsummary(Data_df$Predator.Type) # FIXED IT!\r ## Avian Non-Avian NA's ## 490 220 357\r Redundant Data Our data contains redundant columns (i.e.: columns whose data is present in another column already). These are (1) Flock Size (data contained in Flock column) and (2) Site (data contained in Index column). The fix to this is as easy as removing the columns in question.\nData_df \u0026lt;- within(Data_df, rm(Flock.Size, Site))\rdim(Data_df)\r ## [1] 1067 18\r Fixed it!\nBy doing so, we have gotten rid of our flock size problem stemming from the deletion of a data record. You could also argue that the columns Site and Index are redundant. We could arguably keep both for quality-of-life when interpreting our results (make use of Sites) and coding (make use of Index).\nSaving The Fixed Data Set We fixed out entire data set! The data set is now ready for use.\nKeep in mind that the data set I provided you with was relatively clean and real-world messy data sets can be far more difficult to clean up.\nBefore going forth, we need to save it. Attention: don\u0026rsquo;t overwrite your initial data file!\nFinal Check Before exporting you may want to ensure that everything is in order and do a final round of data inspection. This can be achieved by running the automated summary() command from earlier again as follows:\nfor (i in 1:dim(Data_df)[2]) {\rprint(colnames(Data_df)[i])\rprint(summary(Data_df[, i]))\rprint(\u0026quot;------------------------------------------------------\u0026quot;)\r}\r ## [1] \u0026quot;Index\u0026quot;\r## Length Class Mode ## 1067 character character ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Latitude\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -51.75 4.00 10.50 13.63 31.00 70.00 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Longitude\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -97.00 -88.75 -53.00 -28.47 -2.00 135.00 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Climate\u0026quot;\r## Length Class Mode ## 1067 character character ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Population.Status\u0026quot;\r## Length Class Mode ## 1067 character character ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Weight\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 27.87 30.61 29.32 32.24 36.66 1 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Height\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 11.09 13.52 14.51 15.20 16.20 21.68 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Wing.Chord\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 6.410 6.840 7.050 7.337 7.400 9.000 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Colour\u0026quot;\r## Black Brown Grey ## 356 298 413 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Sex\u0026quot;\r## Length Class Mode ## 1067 character character ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Nesting.Site\u0026quot;\r## Shrub Tree NA's ## 292 231 544 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Nesting.Height\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 11.78 42.34 64.85 480.59 951.38 1950.86 544 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Number.of.Eggs\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 0.000 2.000 3.000 3.746 4.000 10.000 544 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Egg.Weight\u0026quot;\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 1.580 2.340 2.670 2.619 2.890 3.590 590 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Flock\u0026quot;\r## Length Class Mode ## 1067 character character ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Home.Range\u0026quot;\r## Length Class Mode ## 1067 character character ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Predator.Presence\u0026quot;\r## Length Class Mode ## 1067 character character ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r## [1] \u0026quot;Predator.Type\u0026quot;\r## Avian Non-Avian NA's ## 490 220 357 ## [1] \u0026quot;------------------------------------------------------\u0026quot;\r Everything checks out. Let\u0026rsquo;s save our final data frame.\nExporting The Altered Data Since Excel is readily available for viewing data outside of R, I like to save my final data set in excel format as can be seen below. Additionally, I recommend saving your final data frame as an RDS file. These are R specific data files which you will not be able to alter outside of R thus saving yourself from accidentally changing records when only trying to view your data. On top of that, RDS files take up less space than either Excel or TXT files do.\n# saving in excel sheet\rwrite.csv(Data_df, file = paste(Dir.Data, \u0026quot;/SparrowData_FIXED.csv\u0026quot;, sep=\u0026quot;\u0026quot;))\r# saving as R data frame object\rsaveRDS(Data_df, file = paste(Dir.Data, \u0026quot;/SparrowData.rds\u0026quot;, sep=\u0026quot;\u0026quot;))  SessionInfo sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] dplyr_1.1.0\r## ## loaded via a namespace (and not attached):\r## [1] bslib_0.4.2 compiler_4.2.3 pillar_1.8.1 jquerylib_0.1.4 highr_0.10 R.methodsS3_1.8.2 R.utils_2.12.2 tools_4.2.3 digest_0.6.31 jsonlite_1.8.4 ## [11] evaluate_0.20 lifecycle_1.0.3 tibble_3.2.0 R.cache_0.16.0 pkgconfig_2.0.3 rlang_1.0.6 cli_3.6.0 rstudioapi_0.14 yaml_2.3.7 blogdown_1.16 ## [21] xfun_0.37 fastmap_1.1.1 styler_1.9.1 knitr_1.42 generics_0.1.3 vctrs_0.5.2 sass_0.4.5 tidyselect_1.2.0 glue_1.6.2 R6_2.5.1 ## [31] fansi_1.0.4 rmarkdown_2.20 bookdown_0.33 purrr_1.0.1 magrittr_2.0.3 htmltools_0.5.4 utf8_1.2.3 cachem_1.0.7 R.oo_1.25.0\r ","date":1614384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"a580fc872f1b52c21546bc3581106099","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/","publishdate":"2021-02-27T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/data-handling-and-data-assumptions/","section":"courses","summary":"These are exercises and solutions meant as a compendium to my talk on Data Handling.","tags":["R","Statistics"],"title":"Data Handling and Data Assumptions","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Introduction These are answers and solutions to additional exercises from previous versions of the end of chapter 4 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Gregor Mathes.\nPractice 1 Question: Refit model m4.3 from the chapter but omit the mean weight xbar. Compare the new model’s posterior to that of the original model. In particular, look at the covariance among the parameters. What is difference?\nAnswer: Let\u0026rsquo;s firstly refit the model m4.3 using the code on pages 100 \u0026amp; 101:\nlibrary(rethinking)\rdata(Howell1)\rd \u0026lt;- Howell1\rd2 \u0026lt;- d[d$age \u0026gt;= 18, ]\r# define the average weight, x-bar\rxbar \u0026lt;- mean(d2$weight)\r# fit original model\rm4.3 \u0026lt;- quap(alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * (weight - xbar),\ra ~ dnorm(178, 20),\rb ~ dlnorm(0, 1),\rsigma ~ dunif(0, 50)\r), data = d2)\r# fit reduced model\rm4.3_reduced \u0026lt;- quap(alist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * weight,\ra ~ dnorm(178, 20),\rb ~ dlnorm(0, 1),\rsigma ~ dunif(0, 50)\r), data = d2)\r How do we compare these models and their posteriors? Here, I want to look at three things:\n Covariances between parameters estimates  round(vcov(m4.3), digits = 3)\r ## a b sigma\r## a 0.073 0.000 0.000\r## b 0.000 0.002 0.000\r## sigma 0.000 0.000 0.037\r round(vcov(m4.3_reduced), digits = 3)\r ## a b sigma\r## a 3.601 -0.078 0.009\r## b -0.078 0.002 0.000\r## sigma 0.009 0.000 0.037\r As we can see, the covariances increase quite a bit when omitting xbar and this not centring.\nSummaries of each parameter in the posterior  summary(extract.samples(m4.3))\r ## a b sigma ## Min. :153.6 Min. :0.7505 Min. :4.324 ## 1st Qu.:154.4 1st Qu.:0.8738 1st Qu.:4.947 ## Median :154.6 Median :0.9027 Median :5.076 ## Mean :154.6 Mean :0.9023 Mean :5.076 ## 3rd Qu.:154.8 3rd Qu.:0.9307 3rd Qu.:5.205 ## Max. :155.7 Max. :1.0443 Max. :5.773\r summary(extract.samples(m4.3_reduced))\r ## a b sigma ## Min. :108.2 Min. :0.7290 Min. :4.434 ## 1st Qu.:113.2 1st Qu.:0.8632 1st Qu.:4.945 ## Median :114.5 Median :0.8911 Median :5.071 ## Mean :114.5 Mean :0.8911 Mean :5.072 ## 3rd Qu.:115.8 3rd Qu.:0.9195 3rd Qu.:5.199 ## Max. :121.7 Max. :1.0403 Max. :5.833\r Between the two models, neither $\\beta$ (b) nor $\\sigma$ (sigma) differ greatly. However, our posterior estimate of $\\alpha$ (a) is quite a bit lower in the reduced model than it is in the original model. This is down to the interpretation of the $\\alpha$ parameter itself. In the original model, $\\alpha$ denotes the average height of a person at the mean weight in the data set. Since we removed the xbar component in the reduced model, $\\alpha$ now identifies the average height of a person of weight $0kg$ - a nonsense metric.\nPredictions and Intervals\nHere, I have written a function that takes a model object, data, and some additional arguments to automate plot generation:  plot.predictions \u0026lt;- function(X, Y, data, model, main) {\rXOrig \u0026lt;- X\rX \u0026lt;- data[, colnames(data) == X]\rY \u0026lt;- data[, colnames(data) == Y]\rplot(Y ~ X, col = col.alpha(rangi2, 0.8), main = main)\r# Estimate and plot the quap regression line and 97% HPDI for the mean\rweight.seq \u0026lt;- seq(from = min(X), to = max(X), length.out = 1000)\rpredict_df \u0026lt;- data.frame(XOrig = weight.seq)\rcolnames(predict_df) \u0026lt;- XOrig\rmu \u0026lt;- link(model, data = predict_df)\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.HPDI \u0026lt;- apply(mu, 2, HPDI, prob = 0.97)\rlines(weight.seq, mu.mean)\rshade(mu.HPDI, weight.seq)\r# Estimate and plot the 97% HPDI for the predicted heights\rpredict_ls \u0026lt;- list(weight = weight.seq)\rnames(predict_ls) \u0026lt;- XOrig\rsim.height \u0026lt;- sim(model, data = predict_ls)\rheight.HPDI \u0026lt;- apply(sim.height, 2, HPDI, prob = 0.97)\rshade(height.HPDI, weight.seq)\r}\rplot.predictions(X = \u0026quot;weight\u0026quot;, Y = \u0026quot;height\u0026quot;, data = d2, model = m4.3, main = \u0026quot;Original Model\u0026quot;)\r plot.predictions(X = \u0026quot;weight\u0026quot;, Y = \u0026quot;height\u0026quot;, data = d2, model = m4.3_reduced, main = \u0026quot;Reduced Model\u0026quot;)\r So. Does centring or not change the predictions of our model? No, it does not. At least in this case.\nPractice 2 Question: In the chapter, we used 15 knots with the cherry blossom spline. Increase the number of knots and observe what happens to the resulting spline. Then adjust also the width of the prior on the weights - change the standard deviation of the prior and watch what happens. What do you think the combination of knot number and the prior on the weights controls?\nAnswer: Again, I start with code from the book - pages 118, 120 \u0026amp; 122 to be precise - and implement it into a function for easy changing of model specifications:\nlibrary(rethinking)\rlibrary(splines)\rdata(cherry_blossoms)\rd \u0026lt;- cherry_blossoms\rd2 \u0026lt;- d[complete.cases(d$temp), ] # complete cases on temp\rcherry_spline \u0026lt;- function(n_Knots, StdV) {\r# knot list\rknot_list \u0026lt;- quantile(d2$year, probs = seq(0, 1, length.out = n_Knots))[-c(1, n_Knots)]\r# basis function\rB \u0026lt;- bs(d2$year,\rknots = knot_list,\rdegree = 3, intercept = TRUE\r)\r# Run quap model\rm4.7 \u0026lt;- quap(alist(\rT ~ dnorm(mu, sigma),\rmu \u0026lt;- a + B %*% w,\ra ~ dnorm(6, 10),\rw ~ dnorm(0, StdV),\rsigma ~ dexp(1)\r),\rdata = list(T = d2$temp, B = B, StdV = StdV),\rstart = list(w = rep(0, ncol(B)))\r)\r# get 97% posterior interval for mean and plot\rmu \u0026lt;- link(m4.7)\rmu_PI \u0026lt;- apply(mu, 2, PI, 0.97)\rplot(d2$year, d2$temp,\rcol = col.alpha(rangi2, 0.3), pch = 16,\rmain = paste(\u0026quot;Knots:\u0026quot;, n_Knots, \u0026quot;-\u0026quot;, \u0026quot;Prior Weight:\u0026quot;, StdV)\r)\rshade(mu_PI, d2$year, col = col.alpha(\u0026quot;black\u0026quot;, 0.5))\r}\r Let\u0026rsquo;s start by increasing the number of knots:\ncherry_spline(n_Knots = 15, StdV = 1)\r cherry_spline(n_Knots = 20, StdV = 1)\r cherry_spline(n_Knots = 30, StdV = 1)\r The more knots we use, the more flexible the resulting function becomes. It fits the data better, but might overfit if we try to do predictions.\nNow, we change the prior weights:\ncherry_spline(n_Knots = 15, StdV = 1) # base standard deviation\r cherry_spline(n_Knots = 15, StdV = .1) # decreased standard deviation\r cherry_spline(n_Knots = 15, StdV = 100) # increased standard deviation\r As I decrease the standard deviation for the prior or the weights, I see that the resulting function becomes less flexible. I expected our function to become less flexible as I lower the StdV parameter since a lower standard deviation here will increase the weights and thus give each base function more of say in determining the overall function globally, making the result smoother.\nPractice 3 Question: Return to data(cherry_blossoms) and model the association between blossom date (doy) and March temperature (temp). Note that there are many missing values in both variables. You may consider a linear model, a polynomial, or a spline on temperature. How well does temperature rend predict the blossom trend?\nAnswer:\nlibrary(rethinking)\rlibrary(splines)\rdata(cherry_blossoms)\rd \u0026lt;- cherry_blossoms[, 2:3]\rd2 \u0026lt;- na.omit(d)\rd2$temps \u0026lt;- scale(d2$temp)\rwith(d2, plot(temps, doy,\rxlab = \u0026quot;Centred Temperature in March\u0026quot;, ylab = \u0026quot;Day in Year\u0026quot;\r))\r There is a seemingly negative relationship here, but there is also a lot of noise. I expect polynomial or spline approaches to capture too much of that noise and opt for a simple linear regression instead:\n# define average temp\rxbar \u0026lt;- mean(d2$temp)\r# fit modell\rcherry_linear \u0026lt;- quap(\ralist(\rdoy ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * (temp - xbar),\ra ~ dnorm(115, 30),\rb ~ dnorm(-2, 5),\rsigma ~ dunif(0, 50)\r),\rdata = d2\r)\r# output\rprecis(cherry_linear)\r ## mean sd 5.5% 94.5%\r## a 104.921713 0.2106637 104.585032 105.258394\r## b -2.990211 0.3078719 -3.482249 -2.498172\r## sigma 5.910003 0.1489654 5.671927 6.148078\r With average temperatures in March, cherries blossom on day 105 of the year. With every increase of 1°C in temperature in March, cherries blossom - on average - 3 earlier. Our PI shows that we are pretty certain of this relationship. Let\u0026rsquo;s plot this to finish:\nplot.predictions(X = \u0026quot;temp\u0026quot;, Y = \u0026quot;doy\u0026quot;, data = d2, model = cherry_linear, main = \u0026quot;Cherry Blossoms\u0026quot;)\r Off, that\u0026rsquo;s quite some uncertainty there. I guess we aren\u0026rsquo;t doing a tremendous job at predicting cherry blossom dates depending on temperature in March with this model.\nPractice 4 Question: Simulate the prior predictive distribution for the cherry blossom spline in the chapter. Adjust the prior on the weights and observe what happens. What do you think the prior on the weight is doing?\nAnswer:\nI haven\u0026rsquo;t solved this myself (yet). In the meantime, you can consult the answer provided by Gregor Mathes.\nPractice 5 Question: The cherry blossom spline in the chapter used an intercept a, but technically it doesn’t require one. The first basis function could substitute for the intercept. Try refitting the cherry blossom spline without the intercept. What else about the model do you need to change to make this work?\nAnswer:\nlibrary(rethinking)\rlibrary(splines)\rdata(cherry_blossoms)\rd \u0026lt;- cherry_blossoms\rd2 \u0026lt;- d[complete.cases(d$temp), ] # complete cases on temp\rn_Knots \u0026lt;- 15\r# knot list\rknot_list \u0026lt;- quantile(d2$year, probs = seq(0, 1, length.out = n_Knots))[-c(1, n_Knots)]\r# basis function\rB \u0026lt;- bs(d2$year,\rknots = knot_list,\rdegree = 3, intercept = FALSE\r)\r# Run quap model\rm4.7 \u0026lt;- quap(alist(\rT ~ dnorm(mu, sigma),\rmu \u0026lt;- B %*% w,\ra ~ dnorm(6, 10),\rw ~ dnorm(0, 1),\rsigma ~ dexp(1)\r),\rdata = list(T = d2$temp, B = B),\rstart = list(w = rep(0, ncol(B)))\r)\r# get 97% posterior interval for mean and plot\rmu \u0026lt;- link(m4.7)\rmu_PI \u0026lt;- apply(mu, 2, PI, 0.97)\rplot(d2$year, d2$temp,\rcol = col.alpha(rangi2, 0.3), pch = 16,\rmain = \u0026quot;No Intercept\u0026quot;\r)\rshade(mu_PI, d2$year, col = col.alpha(\u0026quot;black\u0026quot;, 0.5))\r We need to change the deterministic formula in the model as well as the creation of basis functions by setting Intercept = FALSE in the bs() function call.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] splines parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 R6_2.5.0 ## [11] backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 ## [21] jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 ## [31] pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 codetools_0.2-18 matrixStats_0.61.0\r## [41] fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 lifecycle_1.0.0 ## [51] DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.7 ## [61] rematch2_2.1.2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 ## [71] sass_0.3.1\r ","date":1610668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610697600,"objectID":"daa3f4bc8ef0703e7a34a255b05b4aae","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-04b/","publishdate":"2021-01-15T00:00:00Z","relpermalink":"/courses/rethinking/chapter-04b/","section":"courses","summary":"Answers and solutions to additional exercises and homework belonging to chapter 4 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 04 (Extra Material)","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory These are the solutions to the exercises contained within the handout to Data Visualisation which walks you through the basics of data visualisation in Rusing ggplot2. The plots presented here are using data from the iris data set supplied through the datasets package. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions.\nI have prepared some Lecture Slides  for this session.\nData This practical makes use of R-internal data so you don\u0026rsquo;t need to download anything extra today.\nPackages Recall the exercise that went along with the last seminar (Descriptive Statistics) where we learnt the difference between a basic and advanced preamble for package loading in R. Here (and in future exercises) I will only supply you with the advanced version of the preamble.\nNow let\u0026rsquo;s load the ggplot2 package into our R session so we\u0026rsquo;ll be able to use its functionality for data visualisation as well as the datasets package to get the iris data set.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\r# packages to load/install if necessary\rpackage_vec \u0026lt;- c(\u0026quot;ggplot2\u0026quot;, \u0026quot;datasets\u0026quot;)\r# applying function install.load.package to all packages specified in package_vec\rsapply(package_vec, install.load.package)\r ## Loading required package: ggplot2\r ## ggplot2 datasets ## TRUE TRUE\r Loading R-internal data sets (iris) The iris data set is included in the datasets package in R. An R-internal data set is loaded through the command data(). Take note that you do not have to assign this command\u0026rsquo;s output to a new object (via \u0026lt;-). Instead, the dataset is loaded to your current environment by its name (iris, in this case). Keep in mind that this can override objects of the same name that are already present in your current session of R.\ndata(\u0026quot;iris\u0026quot;)\r Inspect the data set Since we know that iris is a dataset, we can be reasonably sure that this object will be complex enough to warrant using the str() function for inspection:\nstr(iris)\r ## 'data.frame':\t150 obs. of 5 variables:\r## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\r## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\r## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\r## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\r## $ Species : Factor w/ 3 levels \u0026quot;setosa\u0026quot;,\u0026quot;versicolor\u0026quot;,..: 1 1 1 1 1 1 1 1 1 1 ...\r The iris dataset contains four measurements (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) for 150 flowers representing three species of iris (Iris setosa, versicolor and virginica).\nBoxplot of Petal.Length by Species ggplot(iris, # the data set\raes(x=Species, y=Petal.Length) # aesthetics\r) + geom_boxplot() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Length of three different species of Iris\u0026quot;)\r THis boxplot shows us exactly how the distributions of petal length measurements of our three species of Iris are differing from one another. Despite the obvious trend in the data, be sure not to report results through figures alone! We will find out how to test whether the pattern we can observe here holds up to scrutiny at a later point in time of our seminars.\nScatterplot of Petal.Length and Petal.Width ggplot(iris, # the data set\raes(x=Petal.Width, y=Petal.Length) # aesthetics\r) + geom_point() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;)\r Scatterplot of Petal.Length and Petal.Width grouped by Species ggplot(iris, # the data set\raes(x=Petal.Width, y=Petal.Length, colour = Species) # aesthetics\r) + geom_point() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;) + theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside\rscale_color_discrete(name=\u0026quot;Iris Species\u0026quot;) # Change legend title\r Relationship of Sepal.Length and Sepal.Width ggplot(iris, # the data set\raes(x=Sepal.Width, y=Sepal.Length) # aesthetics\r) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;)\r ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\r Relationship of Sepal.Length and Sepal.Width (grouped by Species) ggplot(iris, # the data set\raes(x=Sepal.Width, y=Sepal.Length, colour = Species) # aesthetics\r) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;) + theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside\rscale_color_discrete(name=\u0026quot;Iris Species\u0026quot;) # Change legend title\r ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"002e1e1b5c0a50737514828e3f172cef","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/data-visualisation/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/data-visualisation/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to Data Visualisation which walks you through the basics of data visualisation in `R`using `ggplot2`. The plots presented here are using data from the `iris` data set supplied through the `datasets` package.","tags":["R","Statistics"],"title":"Data Visualisation","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory These are the solutions to the exercises contained within the handout to Data Visualisation which walks you through the basics of data visualisation in R using ggplot2. The plots presented here are using data from the iris data set supplied through the datasets package. Keep in mind that there is probably a myriad of other ways to reach the same conclusions as presented in these solutions. I have prepared some slides for this session: \nData This practical makes use of R-internal data so you don\u0026rsquo;t need to download anything extra today.\nPackages Recall the exercise that went along with the last seminar (Descriptive Statistics) where we learnt the difference between a basic and advanced preamble for package loading in R. Here (and in future exercises) I will only supply you with the advanced version of the preamble.\nNow let\u0026rsquo;s load the ggplot2 package into our R session so we\u0026rsquo;ll be able to use its functionality for data visualisation as well as the datasets package to get the iris data set.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\r# packages to load/install if necessary\rpackage_vec \u0026lt;- c(\u0026quot;ggplot2\u0026quot;, \u0026quot;datasets\u0026quot;)\r# applying function install.load.package to all packages specified in package_vec\rsapply(package_vec, install.load.package)\r ## Loading required package: ggplot2\r ## ggplot2 datasets ## TRUE TRUE\r Loading R-internal data sets (iris) The iris data set is included in the datasets package in R. An R-internal data set is loaded through the command data(). Take note that you do not have to assign this command\u0026rsquo;s output to a new object (via \u0026lt;-). Instead, the dataset is loaded to your current environment by its name (iris, in this case). Keep in mind that this can override objects of the same name that are already present in your current session of R.\ndata(\u0026quot;iris\u0026quot;)\r Inspect the data set Since we know that iris is a dataset, we can be reasonably sure that this object will be complex enough to warrant using the str() function for inspection:\nstr(iris)\r ## 'data.frame':\t150 obs. of 5 variables:\r## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\r## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\r## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\r## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\r## $ Species : Factor w/ 3 levels \u0026quot;setosa\u0026quot;,\u0026quot;versicolor\u0026quot;,..: 1 1 1 1 1 1 1 1 1 1 ...\r The iris dataset contains four measurements (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) for 150 flowers representing three species of iris (Iris setosa, versicolor and virginica).\nBoxplot of Petal.Length by Species ggplot(iris, # the data set\raes(x=Species, y=Petal.Length) # aesthetics\r) + geom_boxplot() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Length of three different species of Iris\u0026quot;)\r THis boxplot shows us exactly how the distributions of petal length measurements of our three species of Iris are differing from one another. Despite the obvious trend in the data, be sure not to report results through figures alone! We will find out how to test whether the pattern we can observe here holds up to scrutiny at a later point in time of our seminars.\nScatterplot of Petal.Length and Petal.Width ggplot(iris, # the data set\raes(x=Petal.Width, y=Petal.Length) # aesthetics\r) + geom_point() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;)\r Scatterplot of Petal.Length and Petal.Width grouped by Species ggplot(iris, # the data set\raes(x=Petal.Width, y=Petal.Length, colour = Species) # aesthetics\r) + geom_point() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;) + theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside\rscale_color_discrete(name=\u0026quot;Iris Species\u0026quot;) # Change legend title\r Relationship of Sepal.Length and Sepal.Width ggplot(iris, # the data set\raes(x=Sepal.Width, y=Sepal.Length) # aesthetics\r) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;)\r ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\r Relationship of Sepal.Length and Sepal.Width (grouped by Species) ggplot(iris, # the data set\raes(x=Sepal.Width, y=Sepal.Length, colour = Species) # aesthetics\r) + geom_point() + geom_smooth() + # this is the end of the bare minimum plot\rtheme_bw() + labs(title=\u0026quot;Petal Width and Petal Length of three different species of Iris\u0026quot;) + theme(legend.justification=c(1,0), legend.position=c(1,0)) + # legend inside\rscale_color_discrete(name=\u0026quot;Iris Species\u0026quot;) # Change legend title\r ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"e018c4b8e08a664ef0fa9b1bbcebd035","permalink":"https://www.erikkusch.com/courses/biostat101/data-visualisation/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/data-visualisation/","section":"courses","summary":"These are the solutions to the exercises contained within the handout to Data Visualisation which walks you through the basics of data visualisation in `R`using `ggplot2`. The plots presented here are using data from the `iris` data set supplied through the `datasets` package.","tags":["R","Statistics"],"title":"Data Visualisation","type":"docs"},{"authors":["Erik Kusch"],"categories":["Excursion into Biostatistics"],"content":"Theory These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.\nI have prepared some Lecture Slides  for this session.\nOur Resarch Project Today, we are looking at a big (and entirely fictional) data base of the common house sparrow (Passer domesticus). In particular, we are interested in the Evolution of Passer domesticus in Response to Climate Change which was previously explained here.\nThe Data I have created a large data set for this exercise which is available here and we previously cleaned up so that is now usable here.\nReading the Data into R Let\u0026rsquo;s start by reading the data into R and taking an initial look at it:\nSparrows_df \u0026lt;- readRDS(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))\rhead(Sparrows_df)\r ## Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type\r## 1 SI 60 100 Continental Native 34.05 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 2 SI 60 100 Continental Native 34.86 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 3 SI 60 100 Continental Native 32.34 12.66 6.64 Black Female Shrub 35.60 1 3.21 C Large Yes Avian\r## 4 SI 60 100 Continental Native 34.78 15.09 7.00 Brown Female Shrub 47.75 0 NA E Large Yes Avian\r## 5 SI 60 100 Continental Native 35.01 13.82 6.81 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 6 SI 60 100 Continental Native 32.36 12.67 6.64 Brown Female Shrub 32.47 1 3.17 E Large Yes Avian\r## TAvg TSD\r## 1 269.9596 15.71819\r## 2 269.9596 15.71819\r## 3 269.9596 15.71819\r## 4 269.9596 15.71819\r## 5 269.9596 15.71819\r## 6 269.9596 15.71819\r Hypotheses Let\u0026rsquo;s remember our hypotheses:\n Sparrow Morphology is determined by:\nA. Climate Conditions with sparrows in stable, warm environments fairing better than those in colder, less stable ones.\nB. Competition with sparrows in small flocks doing better than those in big flocks.\nC. Predation with sparrows under pressure of predation doing worse than those without. Sites accurately represent sparrow morphology. This may mean:\nA. Population status as inferred through morphology.\nB. Site index as inferred through morphology.\nC. Climate as inferred through morphology.  Quite obviously, hypothesis 2 is the only one lending itself well to classification exercises. In fact, what we want to answer is the question: \u0026ldquo;Can we successfully classify populations at different sites according to their morphological expressions?\u0026quot;.\nR Environment For this exercise, we will need the following packages:\ninstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE)) {\rinstall.packages(x, repos = \u0026quot;http://cran.us.r-project.org\u0026quot;)\r}\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\r\u0026quot;ggplot2\u0026quot;, # for visualisation\r\u0026quot;mclust\u0026quot;, # for k-means clustering,\r\u0026quot;vegan\u0026quot;, # for distance matrices in hierarchical clustering\r\u0026quot;rpart\u0026quot;, # for decision trees\r\u0026quot;rpart.plot\u0026quot;, # for plotting decision trees\r\u0026quot;randomForest\u0026quot;, # for randomForest classifier\r\u0026quot;car\u0026quot;, # check multicollinearity\r\u0026quot;MASS\u0026quot; # for ordinal logistic regression\r)\rsapply(package_vec, install.load.package)\r ## ggplot2 mclust vegan rpart rpart.plot randomForest car MASS ## TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\r Using the above function is way more sophisticated than the usual install.packages() \u0026amp; library() approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.\nLogistic Regression Remember the Assumptions of Logistic Regression:\n Absence of influential outliers Absence of multi-collinearity Predictor Variables and log odds are related in a linear fashion  Binary Logistic Regression Binary Logistic regression only accommodates binary outcomes. This leaves only one of our hypotheses open for investigation - 2.A. Population Status - since this is the only response variable boasting two levels.\nTo reduce the effect of as many confounding variables as possible, I reduce the data set to just those observations belonging to our station in Siberia and Manitoba. Both are located at very similar latitudes. They really only differ in their climate condition and the population status:\nLogReg_df \u0026lt;- Sparrows_df[Sparrows_df$Index == \u0026quot;MA\u0026quot; | Sparrows_df$Index == \u0026quot;SI\u0026quot;, c(\u0026quot;Population.Status\u0026quot;, \u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;)]\rLogReg_df$PS \u0026lt;- as.numeric(LogReg_df$Population.Status) - 1 # make climate numeric for model\r Initial Model \u0026amp; Collinearity Let\u0026rsquo;s start with the biggest model we can build here and then assess if our assumptions are met:\nH2_LogReg_mod \u0026lt;- glm(PS ~ Weight + Height + Wing.Chord,\rdata = LogReg_df,\rfamily = binomial(link = \u0026quot;logit\u0026quot;),\r)\rsummary(H2_LogReg_mod)\r ## ## Call:\r## glm(formula = PS ~ Weight + Height + Wing.Chord, family = binomial(link = \u0026quot;logit\u0026quot;), ## data = LogReg_df)\r## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.657e-05 -2.110e-08 -2.110e-08 2.110e-08 2.855e-05 ## ## Coefficients:\r## Estimate Std. Error z value Pr(\u0026gt;|z|)\r## (Intercept) 1.557e+03 3.312e+07 0.000 1.000\r## Weight 7.242e+01 3.735e+04 0.002 0.998\r## Height 2.153e+01 1.061e+06 0.000 1.000\r## Wing.Chord -6.247e+02 6.928e+06 0.000 1.000\r## ## (Dispersion parameter for binomial family taken to be 1)\r## ## Null deviance: 1.8437e+02 on 132 degrees of freedom\r## Residual deviance: 6.8926e-09 on 129 degrees of freedom\r## AIC: 8\r## ## Number of Fisher Scoring iterations: 25\r Well\u0026hellip; nothing here is significant. Let\u0026rsquo;s see what the culprit might be. With morphological traits, you are often looking at a whole set of collinearity, so let\u0026rsquo;s start by investigating that:\nvif(H2_LogReg_mod)\r ## Weight Height Wing.Chord ## 9.409985 6550.394451 6342.683550\r A Variance Inflation Factor (VIF) value of $\\geq5-10$ is seen as identifying problematic collinearity. Quite obviously, this is the case. We need to throw away some predictors. I only want to keep Weight.\nWeight Model and Further Assumptions Let\u0026rsquo;s run a simplified model that just used Weight as a predictor:\nH2_LogReg_mod \u0026lt;- glm(PS ~ Weight,\rdata = LogReg_df,\rfamily = binomial(link = \u0026quot;logit\u0026quot;)\r)\rsummary(H2_LogReg_mod)\r ## ## Call:\r## glm(formula = PS ~ Weight, family = binomial(link = \u0026quot;logit\u0026quot;), ## data = LogReg_df)\r## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.1980 -0.5331 -0.1235 0.5419 1.9067 ## ## Coefficients:\r## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) -46.3244 7.8319 -5.915 3.32e-09 ***\r## Weight 1.4052 0.2374 5.920 3.23e-09 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## (Dispersion parameter for binomial family taken to be 1)\r## ## Null deviance: 184.37 on 132 degrees of freedom\r## Residual deviance: 105.08 on 131 degrees of freedom\r## AIC: 109.08\r## ## Number of Fisher Scoring iterations: 5\r A significant effect, huzzah! We still need to test for our assumptions, however. Checking for multicollinearity makes no sense since we only use one predictor, so we can skip that.\nLinear Relationship between predictor(s) and log-odds of the output can be assessed as follows:\nprobabilities \u0026lt;- predict(H2_LogReg_mod, type = \u0026quot;response\u0026quot;) # predict model response on original data\rLogReg_df$Probs \u0026lt;- probabilities # safe probabilities to data frame\rLogReg_df$LogOdds \u0026lt;- log(probabilities / (1 - probabilities)) # calculate log-odds\r## Plot Log-Odds vs. Predictor\rggplot(data = LogReg_df, aes(x = Weight, y = LogOdds)) +\rgeom_point() +\rgeom_smooth(method = \u0026quot;lm\u0026quot;, se = TRUE) +\rtheme_bw()\r That is clearly linear relationship!\nMoving on to our final assumption, we want to assess whether there are influential Outliers. For this, we want to look at the Cook\u0026rsquo;s distance as well as the standardised residuals per observation:\n## Cook's distance\rplot(H2_LogReg_mod, which = 4, id.n = 3)\r ## Standardises Residuals\rOutlier_df \u0026lt;- data.frame(\rResiduals = resid(H2_LogReg_mod),\rIndex = 1:nrow(LogReg_df),\rOutcome = factor(LogReg_df$PS)\r)\rOutlier_df$Std.Resid \u0026lt;- scale(Outlier_df$Residuals)\r# Plot Residuals\rggplot(Outlier_df, aes(Outcome, Std.Resid)) +\rgeom_boxplot() +\rtheme_bw()\r Both of these plots do not highlight any worrying influential outliers. An influential outliers would manifest with a prominent standardises residual ($|Std.Resid|\\sim3$)/Cook\u0026rsquo;s distance.\nLet\u0026rsquo;s finally plot what the model predicts:\nggplot(data = LogReg_df, aes(x = Weight, y = LogReg_df$PS)) +\rgeom_point() +\rtheme_bw() +\rgeom_smooth(\rdata = LogReg_df, aes(x = Weight, y = Probs),\rmethod = \u0026quot;glm\u0026quot;,\rmethod.args = list(family = \u0026quot;binomial\u0026quot;),\rse = TRUE\r) +\rlabs(y = \u0026quot;Introduced Population\u0026quot;)\r Ordinal Logistic Regression Ordinal Logistic regression allows for multiple levels of the response variable so long as they are on an ordinal scale. Here, we could test all of our above hypotheses. However, I\u0026rsquo;d like to stick with 2.C. Climate for this example.\nAgain, to reduce the effect of as many confounding variables as possible, I reduce the data set to just those observations belonging to our station in Siberia, Manitoba, and also the United Kingdom this time. All three are located at very similar latitudes. They really only differ in their climate condition and the population status:\nLogReg_df \u0026lt;- Sparrows_df[Sparrows_df$Index == \u0026quot;UK\u0026quot; | Sparrows_df$Index == \u0026quot;MA\u0026quot; | Sparrows_df$Index == \u0026quot;SI\u0026quot;, c(\u0026quot;Climate\u0026quot;, \u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;)]\rLogReg_df$CL \u0026lt;- factor(as.numeric(LogReg_df$Climate) - 1) # make climate factored numeric for model\r Initial Model \u0026amp; Collinearity Let\u0026rsquo;s start with the biggest model we can build here and then assess if our assumptions are met:\nH2_LogReg_mod \u0026lt;- polr(CL ~ Weight + Height + Wing.Chord,\rdata = LogReg_df,\rHess = TRUE\r)\rsummary_table \u0026lt;- coef(summary(H2_LogReg_mod))\rpval \u0026lt;- pnorm(abs(summary_table[, \u0026quot;t value\u0026quot;]), lower.tail = FALSE) * 2\rsummary_table \u0026lt;- cbind(summary_table, \u0026quot;p value\u0026quot; = round(pval, 6))\rsummary_table\r ## Value Std. Error t value p value\r## Weight -0.4595719 0.09750018 -4.713549 2e-06\r## Height 25.0808034 0.19522606 128.470573 0e+00\r## Wing.Chord -164.1103857 0.51246129 -320.239573 0e+00\r## 0|1 -788.2133893 0.11008589 -7159.985419 0e+00\r## 1|2 -786.8019284 0.18747890 -4196.749302 0e+00\r Well\u0026hellip; a lot here is significant. We identified multicollinearity as a problem earlier. Let\u0026rsquo;s investigate that again:\nvif(H2_LogReg_mod)\r ## Weight Height Wing.Chord ## 431.6796 294.6353 536.5452\r Horrible!. A Variance Inflation Factor (VIF) value of $\\geq5-10$ is seen as identifying problematic collinearity. Quite obviously, this is the case. We need to throw away some predictors. I only want to keep Weight.\nWeight Model and Further Assumptions Let\u0026rsquo;s run a simplified model that just used Weight as a predictor:\nH2_LogReg_mod \u0026lt;- polr(CL ~ Weight,\rdata = LogReg_df,\rHess = TRUE\r)\rsummary_table \u0026lt;- coef(summary(H2_LogReg_mod))\rpval \u0026lt;- pnorm(abs(summary_table[, \u0026quot;t value\u0026quot;]), lower.tail = FALSE) * 2\rsummary_table \u0026lt;- cbind(summary_table, \u0026quot;p value\u0026quot; = round(pval, 6))\rsummary_table\r ## Value Std. Error t value p value\r## Weight -0.020768177 0.0761669 -0.272666718 0.785109\r## 0|1 -1.354848455 2.5131706 -0.539099272 0.589818\r## 1|2 0.009549511 2.5112093 0.003802754 0.996966\r Well\u0026hellip; this model doesn\u0026rsquo;t help us at all in understanding climate through morphology of our sparrows. Let\u0026rsquo;s abandon this and move on to classification methods which are much better suited to this task.\nK-Means Clustering K-Means clustering is incredibly potent in identifying a number of appropriate clusters, their attributes, and sort observations into appropriate clusters.\nPopulation Status Classifier Let\u0026rsquo;s start with understanding population status through morphological traits:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Population.Status\u0026quot;)]\rH2_PS_mclust \u0026lt;- Mclust(Morph_df[-4], G = length(unique(Morph_df[, 4])))\rplot(H2_PS_mclust, what = \u0026quot;uncertainty\u0026quot;)\r As we can see, K-means clustering is able to really neatly identify two groups in our data. But do they actually belong do the right groups of Population.Status? We\u0026rsquo;ll find out in Model Selection and Validation.\nSite Classifier On to our site index classification. Running the k-means clustering algorithm returns:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Index\u0026quot;)]\rH2_Index_mclust \u0026lt;- Mclust(Morph_df[-4], G = length(unique(Morph_df[, 4])))\rplot(H2_Index_mclust, what = \u0026quot;uncertainty\u0026quot;)\r That\u0026rsquo;s a pretty bad classification. I would not place trust in these clusters seeing how much they overlap.\nClimate Classifier Lastly, turning to our climate classification using k-means classification:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Climate\u0026quot;)]\rH2_Climate_mclust \u0026lt;- Mclust(Morph_df[-4], G = length(unique(Morph_df[, 4])))\rplot(H2_Climate_mclust, what = \u0026quot;uncertainty\u0026quot;)\r These clusters are decent although there is quite a bit of overlap between the blue and red cluster.\nOptimal Model K-means clustering is also able to identify the most \u0026ldquo;appropriate\u0026rdquo; number of clusters given the data and uncertainty of classification:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;)]\rdataBIC \u0026lt;- mclustBIC(Morph_df)\rsummary(dataBIC) # show summary of top-ranking models\r ## Best BIC values:\r## VVV,7 EVV,7 EVV,8\r## BIC 63.39237 -304.1895 -336.0531\r## BIC diff 0.00000 -367.5819 -399.4455\r plot(dataBIC)\r G \u0026lt;- as.numeric(strsplit(names(summary(dataBIC))[1], \u0026quot;,\u0026quot;)[[1]][2])\rH2_Opt_mclust \u0026lt;- Mclust(Morph_df, # data for the cluster model\rG = G # BIC index for model to be built\r)\rH2_Opt_mclust[[\u0026quot;parameters\u0026quot;]][[\u0026quot;mean\u0026quot;]] # mean values of clusters\r ## [,1] [,2] [,3] [,4] [,5] [,6] [,7]\r## Weight 34.830000 32.677280 33.63023 31.354892 30.146417 22.585240 22.796014\r## Height 13.641765 13.570427 14.20721 14.317070 14.085826 18.847550 19.036621\r## Wing.Chord 6.787059 6.780954 6.99186 7.044881 6.965047 8.576106 8.609035\r plot(H2_Opt_mclust, what = \u0026quot;uncertainty\u0026quot;)\r Here, K-means clustering would have us settle on 7 clusters. That does not coincide with anything we could really test for at this point. COnclusively, this model goes into the category of \u0026ldquo;Nice to have, but ultimately useless here\u0026rdquo;.\nSummary of K-Means Clustering So what do we take from this? Well\u0026hellip; Population status was well explained all morphological traits and so would in turn also do a good job of being a proxy for the other when doing mixed regression models, for example. Hence, we might want to include this variable in future Regression Models.\nHierarchical Clustering Moving on to hierarchical clustering, we luckily only need to create a few trees to start with:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;)] # selecting morphology data\rdist_mat \u0026lt;- dist(Morph_df) # distance matrix\r## Hierarchical clustering using different linkages\rH2_Hierachical_clas1 \u0026lt;- hclust(dist_mat, method = \u0026quot;complete\u0026quot;)\rH2_Hierachical_clas2 \u0026lt;- hclust(dist_mat, method = \u0026quot;single\u0026quot;)\rH2_Hierachical_clas3 \u0026lt;- hclust(dist_mat, method = \u0026quot;average\u0026quot;)\r## Plotting Hierarchies\rpar(mfrow = c(1, 3))\rplot(H2_Hierachical_clas1, main = \u0026quot;complete\u0026quot;)\rplot(H2_Hierachical_clas2, main = \u0026quot;single\u0026quot;)\rplot(H2_Hierachical_clas3, main = \u0026quot;average\u0026quot;)\r Here, you can see that the type of linkage employed by your hierarchical approach is very important as to how the hierarchy ends up looking like. For now, we run with all of them.\nPopulation Status Classifier For our population status classifier, let\u0026rsquo;s obtain our data and cluster number we are after:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Population.Status\u0026quot;)]\rG \u0026lt;- length(unique(Morph_df[, 4]))\r Now we can look at how well our different Hierarchies fair at explaining these categories when cut at the point where the same number of categories is present in the tree:\nclusterCut \u0026lt;- cutree(H2_Hierachical_clas1, k = G) # cut tree\rtable(clusterCut, Morph_df$Population.Status) # assess fit\r ## ## clusterCut Introduced Native\r## 1 682 134\r## 2 250 0\r clusterCut \u0026lt;- cutree(H2_Hierachical_clas2, k = G) # cut tree\rtable(clusterCut, Morph_df$Population.Status) # assess fit\r ## ## clusterCut Introduced Native\r## 1 682 134\r## 2 250 0\r clusterCut \u0026lt;- cutree(H2_Hierachical_clas3, k = G) # cut tree\rtable(clusterCut, Morph_df$Population.Status) # assess fit\r ## ## clusterCut Introduced Native\r## 1 682 134\r## 2 250 0\r Interestingly enough, no matter the linkage, all of these approaches get Introduced and Native populations confused in the first group, but not the second.\nLet\u0026rsquo;s look at the decisions that we could make when following a decision tree for this example:\nH2_PS_decision \u0026lt;- rpart(Population.Status ~ ., data = Morph_df)\rrpart.plot(H2_PS_decision)\r Following this decision tree we first ask \u0026ldquo;Is our sparrow lighter than 35g?\u0026quot;. If the answer is yes, we move to the left and ask the question \u0026ldquo;Is the wing span of our sparrow greater/equal than 6.9cm?\u0026quot;. If the answer is yes, we move to the left and assign this sparrow to an introduced population status. 62% of all observations are in this node and to 2% we believe that this node might actually be a Native node. All other nodes are explained accordingly. More about their interpretation can be found in this PDF Manual.\nSite Classifier Moving on to the site index classifier, we need our data and number of clusters:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Index\u0026quot;)]\rG \u0026lt;- length(unique(Morph_df[, 4]))\r Looking at our different outputs:\nclusterCut \u0026lt;- cutree(H2_Hierachical_clas1, k = G) # cut tree\rtable(clusterCut, Morph_df$Index) # assess fit\r ## ## clusterCut AU BE FG FI LO MA NU RE SA SI UK\r## 1 24 0 0 21 0 15 17 0 0 22 13\r## 2 17 0 0 5 3 7 6 0 0 31 5\r## 3 19 0 0 29 12 22 21 0 0 13 25\r## 4 24 26 0 2 33 5 7 32 16 0 12\r## 5 3 0 0 12 4 18 13 0 0 0 13\r## 6 0 60 0 0 20 0 0 49 77 0 0\r## 7 0 19 0 0 9 0 0 14 21 0 0\r## 8 0 0 80 0 0 0 0 0 0 0 0\r## 9 0 0 138 0 0 0 0 0 0 0 0\r## 10 0 0 16 0 0 0 0 0 0 0 0\r## 11 0 0 16 0 0 0 0 0 0 0 0\r clusterCut \u0026lt;- cutree(H2_Hierachical_clas2, k = G) # cut tree\rtable(clusterCut, Morph_df$Index) # assess fit\r ## ## clusterCut AU BE FG FI LO MA NU RE SA SI UK\r## 1 0 0 0 0 0 0 0 0 0 28 0\r## 2 87 102 0 69 80 67 64 95 112 32 68\r## 3 0 0 0 0 0 0 0 0 0 4 0\r## 4 0 0 0 0 0 0 0 0 0 2 0\r## 5 0 0 0 0 1 0 0 0 0 0 0\r## 6 0 1 0 0 0 0 0 0 0 0 0\r## 7 0 2 0 0 0 0 0 0 0 0 0\r## 8 0 0 122 0 0 0 0 0 0 0 0\r## 9 0 0 126 0 0 0 0 0 0 0 0\r## 10 0 0 2 0 0 0 0 0 0 0 0\r## 11 0 0 0 0 0 0 0 0 2 0 0\r clusterCut \u0026lt;- cutree(H2_Hierachical_clas3, k = G) # cut tree\rtable(clusterCut, Morph_df$Index) # assess fit\r ## ## clusterCut AU BE FG FI LO MA NU RE SA SI UK\r## 1 44 0 0 15 14 15 22 0 0 45 19\r## 2 42 31 0 50 50 49 40 27 0 12 44\r## 3 1 0 0 0 0 0 0 0 0 5 0\r## 4 0 0 0 0 0 0 0 0 0 4 0\r## 5 0 6 0 4 9 3 2 1 0 0 5\r## 6 0 34 0 0 0 0 0 35 81 0 0\r## 7 0 21 0 0 8 0 0 27 23 0 0\r## 8 0 13 0 0 0 0 0 5 10 0 0\r## 9 0 0 106 0 0 0 0 0 0 0 0\r## 10 0 0 134 0 0 0 0 0 0 0 0\r## 11 0 0 10 0 0 0 0 0 0 0 0\r We can now see clearly how different linkages have a major impact in determining how our hierarchy groups different observations. I won\u0026rsquo;t go into interpretations here to save time and energy since these outputs are so busy.\nOur decision tree is also excrutiatingly busy:\nH2_Index_decision \u0026lt;- rpart(Index ~ ., data = Morph_df)\rrpart.plot(H2_Index_decision)\r Climate Classifier Back over to our climate classifier:\nMorph_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Climate\u0026quot;)]\rG \u0026lt;- length(unique(Morph_df[, 4]))\r Let\u0026rsquo;s look at how the different linkages impact our results:\nclusterCut \u0026lt;- cutree(H2_Hierachical_clas1, k = G) # cut tree\rtable(clusterCut, Morph_df$Climate) # assess fit\r ## ## clusterCut Coastal Continental Semi-Coastal\r## 1 577 105 60\r## 2 19 48 7\r## 3 250 0 0\r clusterCut \u0026lt;- cutree(H2_Hierachical_clas2, k = G) # cut tree\rtable(clusterCut, Morph_df$Climate) # assess fit\r ## ## clusterCut Coastal Continental Semi-Coastal\r## 1 595 153 67\r## 2 1 0 0\r## 3 250 0 0\r clusterCut \u0026lt;- cutree(H2_Hierachical_clas3, k = G) # cut tree\rtable(clusterCut, Morph_df$Climate) # assess fit\r ## ## clusterCut Coastal Continental Semi-Coastal\r## 1 596 153 67\r## 2 240 0 0\r## 3 10 0 0\r All of our linkage types have problems discerning Coastal types. I wager that is because of a ton of confounding effects which drive morphological traits in addition to climate types.\nHere\u0026rsquo;s another look at a decision tree:\nH2_Climate_decision \u0026lt;- rpart(Climate ~ ., data = Morph_df)\rrpart.plot(H2_Climate_decision)\r Summary of Hierarchical Clustering We have seen that site indices may hold some explanatory power regarding sparrow morphology, but the picture is very complex. We may want to keep them in mind as random effects for future models (don\u0026rsquo;t worry if that doesn\u0026rsquo;t mean much to you yet).\nRandom Forest Random Forests are one of the most powerful classification methods and I love them. They are incredibly powerful, accurate, and easy to use. Unfortunately, they are black-box algorithms (you don\u0026rsquo;t know what\u0026rsquo;s happening in them exactly in numerical terms) and they require observed outcomes. That\u0026rsquo;s not a problem for us with this research project!\nPopulation Status Classifier Running our random for model for population statuses:\nset.seed(42) # set seed because the process is random\rH2_PS_RF \u0026lt;- tuneRF(\rx = Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;)], # variables which to use for clustering\ry = Sparrows_df$Population.Status, # correct cluster assignment\rstrata = Sparrows_df$Population.Status, # stratified sampling\rdoBest = TRUE, # run the best overall tree\rntreeTry = 20000, # consider this number of trees\rimprove = 0.0000001, # improvement if this is exceeded\rtrace = FALSE, plot = FALSE\r)\r ## -0.08235294 1e-07\r Works perfectly.\nRandom forests give us access to confusion matrices which tell us about classification accuracy:\nH2_PS_RF[[\u0026quot;confusion\u0026quot;]]\r ## Introduced Native class.error\r## Introduced 902 30 0.03218884\r## Native 55 79 0.41044776\r Evidently, we are good at predicting Introduced population status, but Native population status is almost as random as a coin toss.\nWhich variables give us the most information when establishing these groups?\nvarImpPlot(H2_PS_RF)\r Well look who it is. Weight comes out as the most important variable once again!\nSite Classifier Let\u0026rsquo;s run a random forest analysis for our site indices:\nset.seed(42) # set seed because the process is random\rH2_Index_RF \u0026lt;- tuneRF(\rx = Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;)], # variables which to use for clustering\ry = Sparrows_df$Index, # correct cluster assignment\rstrata = Sparrows_df$Index, # stratified sampling\rdoBest = TRUE, # run the best overall tree\rntreeTry = 20000, # consider this number of trees\rimprove = 0.0000001, # improvement if this is exceeded\rtrace = FALSE, plot = FALSE\r)\r ## 0.01630435 1e-07 ## 0 1e-07\r H2_Index_RF[[\u0026quot;confusion\u0026quot;]]\r ## AU BE FG FI LO MA NU RE SA SI UK class.error\r## AU 77 0 0 2 8 0 0 0 0 0 0 0.11494253\r## BE 0 102 0 0 0 0 0 0 3 0 0 0.02857143\r## FG 0 0 250 0 0 0 0 0 0 0 0 0.00000000\r## FI 0 0 0 33 0 21 0 0 0 0 15 0.52173913\r## LO 9 0 0 0 69 0 0 2 0 0 1 0.14814815\r## MA 0 0 0 17 0 26 2 0 0 0 22 0.61194030\r## NU 0 0 0 0 0 7 44 0 0 7 6 0.31250000\r## RE 0 4 0 0 3 0 0 87 1 0 0 0.08421053\r## SA 0 5 0 0 0 0 0 0 109 0 0 0.04385965\r## SI 0 0 0 0 0 1 7 0 0 58 0 0.12121212\r## UK 0 0 0 14 0 25 1 0 0 0 28 0.58823529\r varImpPlot(H2_Index_RF)\r Except for Manitoba and the UK (which are often mistaken for each other), morphology (and mostly Weight) explains station indices quite adequately.\nClimate Classifier Lastly, we turn to our climate classifier again:\nset.seed(42) # set seed because the process is random\rH2_Climate_RF \u0026lt;- tuneRF(\rx = Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;)], # variables which to use for clustering\ry = Sparrows_df$Climate, # correct cluster assignment\rstrata = Sparrows_df$Climate, # stratified sampling\rdoBest = TRUE, # run the best overall tree\rntreeTry = 20000, # consider this number of trees\rimprove = 0.0000001, # improvement if this is exceeded\rtrace = FALSE, plot = FALSE\r)\r ## 0.05172414 1e-07 ## -0.02727273 1e-07\r H2_Climate_RF[[\u0026quot;confusion\u0026quot;]]\r ## Coastal Continental Semi-Coastal class.error\r## Coastal 797 16 33 0.05791962\r## Continental 15 137 1 0.10457516\r## Semi-Coastal 47 0 20 0.70149254\r varImpPlot(H2_Climate_RF)\r Oof. We get semi-coastal habitats almost completely wrong. The other climate conditions are explained well through morphology, though.\nFinal Models In our upcoming Model Selection and Validation Session, we will look into how to compare and validate models. We now need to select some models we have created here today and want to carry forward to said session.\nPersonally, I am quite enamoured with our models H2_PS_mclust (k-means clustering of population status), H2_PS_RF (random forest of population status), and H2_Index_RF (random forest of site indices). Let\u0026rsquo;s save these as a separate object ready to be loaded into our R environment in the coming session:\nsave(H2_PS_mclust, H2_PS_RF, H2_Index_RF, file = file.path(\u0026quot;Data\u0026quot;, \u0026quot;H2_Models.RData\u0026quot;))\r SessionInfo sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] MASS_7.3-58.2 car_3.1-1 carData_3.0-5 randomForest_4.7-1.1 rpart.plot_3.1.1 rpart_4.1.19 vegan_2.6-4 lattice_0.20-45 permute_0.9-7 ## [10] mclust_6.0.0 ggplot2_3.4.1 ## ## loaded via a namespace (and not attached):\r## [1] styler_1.9.1 tidyselect_1.2.0 xfun_0.37 bslib_0.4.2 purrr_1.0.1 splines_4.2.3 colorspace_2.1-0 vctrs_0.5.2 generics_0.1.3 htmltools_0.5.4 ## [11] yaml_2.3.7 mgcv_1.8-42 utf8_1.2.3 rlang_1.0.6 R.oo_1.25.0 jquerylib_0.1.4 pillar_1.8.1 glue_1.6.2 withr_2.5.0 R.utils_2.12.2 ## [21] R.cache_0.16.0 lifecycle_1.0.3 munsell_0.5.0 blogdown_1.16 gtable_0.3.1 R.methodsS3_1.8.2 evaluate_0.20 labeling_0.4.2 knitr_1.42 fastmap_1.1.1 ## [31] parallel_4.2.3 fansi_1.0.4 highr_0.10 scales_1.2.1 cachem_1.0.7 jsonlite_1.8.4 abind_1.4-5 farver_2.1.1 digest_0.6.31 bookdown_0.33 ## [41] dplyr_1.1.0 grid_4.2.3 cli_3.6.0 tools_4.2.3 magrittr_2.0.3 sass_0.4.5 tibble_3.2.0 cluster_2.1.4 pkgconfig_2.0.3 Matrix_1.5-3 ## [51] rmarkdown_2.20 rstudioapi_0.14 R6_2.5.1 nlme_3.1-162 compiler_4.2.3\r ","date":1614384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"4268da4f933ebf1437e2ad8b993f3057","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/classifications-order-from-chaos/","publishdate":"2021-02-27T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/classifications-order-from-chaos/","section":"courses","summary":"These are exercises and solutions meant as a compendium to my talk on Classifications.","tags":["R","Statistics"],"title":"Classifications","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"The Many Variables \u0026amp; The Spurious Waffles Material  \rSlides Chapter 5  Introduction These are answers and solutions to the exercises at the end of chapter 5 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Jeffrey Girard, and This GitHub Repository.\nEasy Exercises Practice E1 Question: Which of the linear models below are multiple regressions?\n(1) $μ_i=α+βx_i$\n(2) $μ_i=β_xx_i+β_zz_i$\n(3) $μ_i=α+β(x_i–z_i)$\n(4) $μ_i=α+β_xx_i+β_zz_i$\nAnswer: 2 and 4 are multiple regressions.\nModel 1 does only considers one predictor variable ($x_i$) and can thus not be a multiple regression. Models 2 and 4 contain multiple predictors with ($x_i$ and $z_i$) with separate slope parameters ($\\beta_x$ and $\\beta_z$) and thus qualify to be considered multiple regressions. The presence or absence of an intercept parameter ($\\alpha$) does not change this interpretation.\nModel 3 is a tad out there. While it only contains one slope parameter ($\\beta$), it does make use of two variables ($x_i$ and $z_i$). It can be rewritten as $μ_i=α+βx_i–βz_i$. Now, the notation is in line with models 2 and 4, but has a fixed slope for both. For that reason, I do not think that it is a multiple regression.\nPractice E2 Question: Write down a multiple regression to evaluate the claim: Animal diversity is linearly related to latitude, but only after controlling for plant diversity. You just need to write down the model definition.\nAnswer: $Div_ {Animals} = \\alpha + \\beta_{Lat}Lat + \\beta_{Plants}Div_{Plants}$\nPractice E3 Question: Write down a multiple regression to evaluate the claim: Neither amount of funding nor size of laboratory is by itself a good predictor of time to PhD degree; but together these variables are both positively associated with time to degree. Write down the model definition and indicate which side of zero each slope parameter should be on.\nAnswer: $T = \\alpha + \\beta_FF + \\beta_SS$\nwith $T$ (time to PhD), $F$ (funding), and $S$ (size of laboratory).\nOn a side-note, I am a bit unclear as to whether the question should really state that they have a \u0026ldquo;positive\u0026rdquo; effect as this indicates, by intuition, a decrease in time to PhD, but in statistical terms, denote the exact opposite.\nSince the combined effect of both slopes is supposed to be positive, the individual slopes must both be positive (or negative, depending on what you understand by \u0026ldquo;positive effect on time\u0026rdquo;).\nPractice E4 Question: Suppose you have a single categorical predictor with 4 levels (unique values), labelled $A$, $B$, $C$ and $D$. Let $A_i$ be an indicator variable that is 1 where case $i$ is in category $A$. Also suppose $B_i$, $C_i$, and $D_i$ for the other categories. Now which of the following linear models are inferentially equivalent ways to include the categorical variable in a regression? Models are inferentially equivalent when it’s possible to compute one posterior distribution from the posterior distribution of another model.\n(1) $μ_i=α+β_AA_i+β_BB_i+β_DD_i$\n(2) $μ_i=α+β_AA_i+β_BB_i+β_CC_i+β_DD_i$\n(3) $μ_i=α+β_BB_i+β_CC_i+β_DD_i$\n(4) $μ_i=α_AA_i+α_BB_i+α_CC_i+α_DD_i$\n(5) $μ_i=α_A(1–Bi–Ci–Di)+α_BB_i+α_CC_i+α_DD_i$\nAnswer: Model 1 and 3-5 are inferentially equivalent.\nModels 1 and 3 both make use of 3 of the 4 total indicator variables which means that we can always derive the the parameter estimates for the 4th indicator variable from a combination of the three parameter estimates present as well as the intercept. Model 4 is akin to an index variable approach which is inferentially the same as an indicator approach (Models 1 and 3). Model 5 is the same as Model 4, so long as we assume that each observation has to belong to one of the four indicator variables.\nMedium Exercises Time to get into R:\nrm(list = ls())\rlibrary(rethinking)\rlibrary(ggplot2)\rlibrary(GGally)\rlibrary(dagitty)\r Practice M1 Question: Invent your own example of a spurious correlation. An outcome variable should be correlated with both predictor variables. But when both predictors are entered in the same model, the correlation between the outcome and one of the predictors should mostly vanish (or at least be greatly reduced).\nAnswer: Here, I follow the example in the Overthinking box on page 138. I create an example in which I consider a relationship between standardised vegetative height, standardised air temperature that vanishes once standardised elevation enters the picture.\nset.seed(42)\rN \u0026lt;- 1e2\rElev \u0026lt;- rnorm(n = N, mean = 0, sd = 1)\rVegHeight \u0026lt;- rnorm(n = 100, mean = -Elev, sd = 1)\rAirTemp \u0026lt;- rnorm(n = N, mean = Elev, sd = 2)\rd \u0026lt;- data.frame(Elev, VegHeight, AirTemp)\rggpairs(d)\r First, I need to show that there even is a (spurious) association between vegetation height (VegHeight) and air temperature (AirTemp):\nm \u0026lt;- quap(\ralist(\rVegHeight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bAT * AirTemp,\ra ~ dnorm(0, 1),\rbAT ~ dnorm(0, 1),\rsigma ~ dunif(0, 2)\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a -0.1163981 0.13088036 -0.3255702 0.09277397\r## bAT -0.1334516 0.06168793 -0.2320409 -0.03486242\r## sigma 1.3201363 0.09334783 1.1709484 1.46932412\r Next, let\u0026rsquo;s see what happens when I add elevation data (Elev):\nm \u0026lt;- quap(\ralist(\rVegHeight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bAT * AirTemp + bEL * Elev,\ra ~ dnorm(0, 1),\rbAT ~ dnorm(0, 1),\rbEL ~ dnorm(0, 1),\rsigma ~ dunif(0, 2)\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a -0.08752358 0.08934620 -0.23031606 0.0552689\r## bAT 0.03291017 0.04470657 -0.03853957 0.1043599\r## bEL -0.98905981 0.09190458 -1.13594107 -0.8421785\r## sigma 0.89659689 0.06340391 0.79526519 0.9979286\r Conclusively, according to our simulated data and the multiple regression analysis, increasing elevation leads to decreased vegetation height directly. Since the bivariate effect of decreasing air temperature leading to decreases in vegetation height vanishes when we include elevation data, we deem this association to be spurious.\nPractice M2 Question: Invent your own example of a masked relationship. An outcome variable should be correlated with both predictor variables, but in opposite directions. And the two predictor variables should be correlated with one another.\nAnswer: Again, I take inspiration from an Overthinking box. This time from page 156. Here, I create an example of of species richness (S) as driven by human footprint (H), and latitude centred on the equator (L).\nN \u0026lt;- 1e2\rrho \u0026lt;- 0.6\rL \u0026lt;- rnorm(n = N, mean = 0, sd = 1)\rH \u0026lt;- rnorm(n = N, mean = rho * L, sd = sqrt(1 - rho^2))\rS \u0026lt;- rnorm(n = N, mean = L - H, sd = 1)\rd \u0026lt;- data.frame(S, L, H)\rggpairs(d)\r Let\u0026rsquo;s start with some bivariate models:\n## Latitude centred on equator\rm1 \u0026lt;- quap(\ralist(\rS ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bL * L,\ra ~ dnorm(0, 1),\rbL ~ dnorm(0, 1),\rsigma ~ dunif(0, 2)\r),\rdata = d\r)\rprecis(m1)\r ## mean sd 5.5% 94.5%\r## a 0.09656591 0.12275009 -0.09961245 0.2927443\r## bL 0.26165086 0.13796469 0.04115663 0.4821451\r## sigma 1.23678173 0.08745475 1.09701214 1.3765513\r ## Human footprint\rm2 \u0026lt;- quap(\ralist(\rS ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bH * H,\ra ~ dnorm(0, 1),\rbH ~ dnorm(0, 1),\rsigma ~ dunif(0, 2)\r),\rdata = d\r)\rprecis(m2)\r ## mean sd 5.5% 94.5%\r## a 0.07758373 0.1209797 -0.1157652 0.2709327\r## bH -0.30689555 0.1147838 -0.4903422 -0.1234489\r## sigma 1.21600759 0.0859864 1.0785847 1.3534305\r Finally, let\u0026rsquo;s combine these into one big multiple regression:\nm3 \u0026lt;- quap(\ralist(\rS ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bH * H + bL * L,\ra ~ dnorm(0, 1),\rbH ~ dnorm(0, 1),\rbL ~ dnorm(0, 1),\rsigma ~ dunif(0, 2)\r),\rdata = d\r)\rprecis(m3)\r ## mean sd 5.5% 94.5%\r## a 0.03603387 0.10567367 -0.1328531 0.2049208\r## bH -0.78399406 0.13167742 -0.9944400 -0.5735481\r## bL 0.86622135 0.15576555 0.6172779 1.1151648\r## sigma 1.05757879 0.07482312 0.9379970 1.1771606\r Both associations became stronger! To link this back to reality, equatoward position has been linked to increased species richness for a long time (through many hypotheses I won\u0026rsquo;t go into here), there is also a global pattern of reduced human footprint around the equator (although this may change\u0026hellip; looking at you, Brazil). Human footprint itself has been unequivocally linked with a decrease in species richness.\nLet\u0026rsquo;s look at this in plotted form:\nplot(coeftab(m3, m2, m1), par = c(\u0026quot;bH\u0026quot;, \u0026quot;bL\u0026quot;))\r In a Directed Acyclic Graph, this works out to:\ndag \u0026lt;- dagitty(\u0026quot;dag { L -\u0026gt; S L -\u0026gt; H H -\u0026gt; S}\u0026quot;)\rcoordinates(dag) \u0026lt;- list(x = c(L = 0, S = 1, H = 2), y = c(L = 0, S = 1, H = 0))\rdrawdag(dag)\r Practice M3 Question: It is sometimes observed that the best predictor of fire risk is the presence of firefighters - States and localities with many firefighters also have more fires. Presumably firefighters do not cause fires. Nevertheless, this is not a spurious correlation. Instead fires cause firefighters. Consider the same reversal of causal inference in the context of the divorce and marriage data. How might a high divorce rate cause a higher marriage rate? Can you think of a way to evaluate this relationship, using multiple regression?\nAnswer: Divorces introduce un-married individuals to the population. These individuals have already demonstrated a readiness to get married in the first place and so might spike marriage rates via re-marrying. I would test for this by running a multiple regression in which I regress marriage rate on divorce rate and re-marriage rate (this excludes first-marriages). As long as divorce no longer predicts marriage rate once re-marriage rate is known, our hypothesis would be true.\nPractice M4 Question: In the divorce data, States with high numbers of Mormons (members of The Church of Jesus Christ of Latter-day Saints, LDS) have much lower divorce rates than the regression models expected. Find a list of LDS population by State and use those numbers as a predictor variable, predicting divorce rate using marriage rate, median age at marriage, and percent LDS population (possibly standardised). You may want to consider transformations of the raw percent LDS variable.\nAnswer: Here, I use the percentage values of LDS as obtained through Wikipedia by Jeffrey Girard. Since there is a large skew in these data due to states with large LDS populations, I apply a log-transformation before standardising:\ndata(\u0026quot;WaffleDivorce\u0026quot;)\rd \u0026lt;- WaffleDivorce\rd$LDS \u0026lt;- c(0.0077, 0.0453, 0.0610, 0.0104, 0.0194, 0.0270, 0.0044, 0.0057, 0.0041, 0.0075, 0.0082, 0.0520, 0.2623, 0.0045, 0.0067, 0.0090, 0.0130, 0.0079, 0.0064, 0.0082, 0.0072, 0.0040, 0.0045, 0.0059, 0.0073, 0.0116, 0.0480, 0.0130, 0.0065, 0.0037, 0.0333, 0.0041, 0.0084, 0.0149, 0.0053, 0.0122, 0.0372, 0.0040, 0.0039, 0.0081, 0.0122, 0.0076, 0.0125, 0.6739, 0.0074, 0.0113, 0.0390, 0.0093, 0.0046, 0.1161)\rd$logLDS \u0026lt;- log(d$LDS)\rd$logLDS.s \u0026lt;- (d$logLDS - mean(d$logLDS)) / sd(d$logLDS)\rpar(mfrow = c(1, 3))\rhist(d$LDS)\rhist(d$logLDS)\rhist(d$logLDS.s)\r Now I am ready to build the model:\nm \u0026lt;- map(\ralist(\rDivorce ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bm * Marriage + ba * MedianAgeMarriage + bl * logLDS.s,\ra ~ dnorm(10, 20),\rbm ~ dnorm(0, 10),\rba ~ dnorm(0, 10),\rbl ~ dnorm(0, 10),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a 35.43051636 6.77505687 24.602667 46.2583658\r## bm 0.05343619 0.08261404 -0.078597 0.1854694\r## ba -1.02939820 0.22468646 -1.388491 -0.6703058\r## bl -0.60777261 0.29055419 -1.072134 -0.1434109\r## sigma 1.37864526 0.13836923 1.157505 1.5997860\r While marriage rate is not a powerful predictor of divorce rate, both age at marriage and percentage of LDS population are strongly negatively associated with divorce rates.\nPractice M5 Question: One way to reason through multiple causation hypotheses is to imagine detailed mechanisms through which predictor variables may influence outcomes. For example, it is sometimes argued that the price of gasoline (predictor variable) is positively associated with lower obesity rates (outcome variable). However, there are at least two important mechanisms by which the price of gas could reduce obesity. First, it could lead to less driving and therefore more exercise. Second, it could lead to less driving, which leads to less eating out, which leads to less consumption of huge restaurant meals. Can you outline one or more multiple regressions that address these two mechanisms? Assume you can have any predictor data you need.\nAnswer: $μ_i=α+β_GG_i+β_EE_i+β_RR_i$. I propose we run a multiple regression containing a variable $E$ denoting frequency of exercising, and another variable $R$ which captures the frequency of restaurant visits. We use these alongside the variable $G$ (gasoline price) to model obesity rates.\nHard Exercises Disclaimer: All three exercises below use the same data, data(foxes) (part of rethinking). The urban fox (Vulpes vulpes) is a successful exploiter of human habitat. Since urban foxes move in packs and defend territories, data on habitat quality and population density is also included. The data frame has five columns:\n(1) group: Number of the social group the individual fox belongs to\n(2) avgfood: The average amount of food available in the territory\n(3) groupsize: The number of foxes in the social group\n(4) area: Size of the territory\n(5) weight: Body weight of the individual fox\ndata(\u0026quot;foxes\u0026quot;)\r Practice H1 Question: Fit two bivariate Gaussian regressions, using quap: (1) body weight as a linear function of territory size (area), and (2) body weight as a linear function of groupsize. Plot the results of these regressions, displaying the MAP regression line and the 95% interval of the mean. Is either variable important for predicting fox body weight?\nAnswer: Let\u0026rsquo;s start with the models:\n## Area\rd \u0026lt;- foxes\rma \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + ba * area,\ra ~ dnorm(5, 5),\rba ~ dnorm(0, 5),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(ma)\r ## mean sd 5.5% 94.5%\r## a 4.45430638 0.38955723 3.8317187 5.0768941\r## ba 0.02385824 0.11803080 -0.1647778 0.2124943\r## sigma 1.17868417 0.07738415 1.0550093 1.3023590\r area.seq \u0026lt;- seq(from = min(d$area), to = max(d$area), length.out = 1e4)\rmu \u0026lt;- link(ma, data = data.frame(area = area.seq))\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.95)\rplot(weight ~ area, data = d, col = rangi2)\rabline(ma)\rshade(mu.PI, area.seq)\r ## Group Size\rmg \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bg * groupsize,\ra ~ dnorm(5, 5),\rbg ~ dnorm(0, 5),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(mg)\r ## mean sd 5.5% 94.5%\r## a 5.0675829 0.32418282 4.5494762 5.58568969\r## bg -0.1238161 0.07038361 -0.2363027 -0.01132946\r## sigma 1.1635303 0.07638932 1.0414454 1.28561522\r groupsize.seq \u0026lt;- seq(from = min(d$groupsize), to = max(d$groupsize), length.out = 1e4)\rmu \u0026lt;- link(mg, data = data.frame(groupsize = groupsize.seq))\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.95)\rplot(weight ~ groupsize, data = d, col = rangi2)\rabline(mg)\rshade(mu.PI, groupsize.seq)\r According to these two bivariate models, neither area nor groupsize have strong associations with weight of which we could be certain.\nPractice H2 Question: Now fit a multiple linear regression with weight as the outcome and both area and groupsize as predictor variables. Plot the predictions of the model for each predictor, holding the other predictor constant at its mean. What does this model say about the importance of each variable? Why do you get different results than you got in the exercise just above?\nAnswer: First, we run the model itself:\nmag \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + ba * area + bg * groupsize,\ra ~ dnorm(5, 5),\rba ~ dnorm(0, 5),\rbg ~ dnorm(0, 5),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(mag)\r ## mean sd 5.5% 94.5%\r## a 4.4541696 0.36977162 3.8632031 5.0451360\r## ba 0.6159473 0.19978363 0.2966545 0.9352402\r## bg -0.4318471 0.12066677 -0.6246959 -0.2389982\r## sigma 1.1184516 0.07342985 1.0010965 1.2358067\r Now, I want to actually have a look at the underlying data:\nggpairs(d[, 3:5])\r groupsize and area are pretty heavily associated it seems. Finally, we establish counterfactual plots:\n## Fixing Group Size\rG.avg \u0026lt;- mean(d$groupsize)\rA.seq \u0026lt;- seq(from = 0, to = 6, length.out = 1e4)\rpred.data \u0026lt;- data.frame(\rgroupsize = G.avg,\rarea = A.seq\r)\rmu \u0026lt;- link(mag, data = pred.data)\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.95)\rA.sim \u0026lt;- sim(mag, data = pred.data, n = 1e4)\rA.PI \u0026lt;- apply(A.sim, 2, PI)\rplot(weight ~ area, data = d, type = \u0026quot;n\u0026quot;)\rmtext(\u0026quot;groupsize = 4.345\u0026quot;)\rlines(A.seq, mu.mean)\rshade(mu.PI, A.seq)\rshade(A.PI, A.seq)\r ## Fixing Area\rA.avg \u0026lt;- mean(d$area)\rG.seq \u0026lt;- seq(from = 1, to = 10, length.out = 1e4)\rpred.data \u0026lt;- data.frame(\rgroupsize = G.seq,\rarea = A.avg\r)\rmu \u0026lt;- link(mag, data = pred.data)\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.95)\rG.sim \u0026lt;- sim(mag, data = pred.data, n = 1e4)\rG.PI \u0026lt;- apply(G.sim, 2, PI)\rplot(weight ~ groupsize, data = d, type = \u0026quot;n\u0026quot;)\rmtext(\u0026quot;area = 3.169\u0026quot;)\rlines(G.seq, mu.mean)\rshade(mu.PI, G.seq)\rshade(G.PI, G.seq)\r This is a clear example of a masking relationship. When considered in isolation (bivariate models) neither groupsize nor area show clear associations with weight. However, as soon as we use a multiple regression, we find that weight declines as groupsize increases, while area has the opposite effect. These effects cancel each other out in bivariate settings.\nPractice H3 Question: Finally, consider the avgfood variable. Fit two more multiple regressions: (1) body weight as an additive function of avgfood and groupsize, and (2) body weight as an additive function of all three variables, avgfood and groupsize and area. Compare the results of these models to the previous models you\u0026rsquo;ve fit, in the first two exercises.\nAnswer: First, we require the model with two variables:\nm \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bf * avgfood + bg * groupsize,\ra ~ dnorm(5, 5),\rbf ~ dnorm(0, 5),\rbg ~ dnorm(0, 5),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a 4.1806405 0.42501186 3.5013895 4.8598915\r## bf 3.6052545 1.17683527 1.7244445 5.4860646\r## bg -0.5433458 0.15271144 -0.7874082 -0.2992834\r## sigma 1.1166611 0.07332213 0.9994782 1.2338441\r Next, we need the model with three variables:\nm \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bf * avgfood + bg * groupsize + ba * area,\ra ~ dnorm(5, 5),\rbf ~ dnorm(0, 5),\rbg ~ dnorm(0, 5),\rba ~ dnorm(0, 5),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a 4.1010815 0.42308541 3.42490933 4.7772537\r## bf 2.3024285 1.39359133 0.07520038 4.5296566\r## bg -0.5926614 0.15385399 -0.83854977 -0.3467730\r## ba 0.4017410 0.23609446 0.02441642 0.7790655\r## sigma 1.1044452 0.07252194 0.98854116 1.2203493\r Part A Question: Is avgfood or area a better predictor of body weight? If you had to choose one or the other to include in a model, which would it be? Support your assessment with any tables or plots you choose.\nAnswer: According to intuition, I would prefer avgfood because it is directly and obviously linked to a gain in calories and thus weight whereas area is a fairly indirect relationship. However, I still want to test this in R. Let\u0026rsquo;s first look at the raw data:\nggpairs(d[, -1])\r avgfood and area are strikingly correlated with one another. To chose the most informative of these two, I build models of weight solely dependant on standardised records of both (so the slope estimates are comparable in their magnitude) as well as groupsize:\n## Average Food\rd$avgfood.s \u0026lt;- (d$avgfood - mean(d$avgfood)) / sd(d$avgfood)\rm \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bf * avgfood.s + bg * groupsize,\ra ~ dnorm(5, 5),\rbf ~ dnorm(0, 5),\rbg ~ dnorm(0, 5),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a 6.9566906 0.67995576 5.8699900 8.0433913\r## bf 0.7450529 0.23844151 0.3639773 1.1261284\r## bg -0.5588002 0.15473498 -0.8060966 -0.3115038\r## sigma 1.1166194 0.07331182 0.9994530 1.2337859\r ## Area\rd$area.s \u0026lt;- (d$area - mean(d$area)) / sd(d$area)\rm \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + ba * area.s + bg * groupsize,\ra ~ dnorm(5, 5),\rba ~ dnorm(0, 5),\rbg ~ dnorm(0, 5),\rsigma ~ dunif(0, 5)\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a 6.3903420 0.53148096 5.5409327 7.2397512\r## ba 0.5682683 0.18494820 0.2726854 0.8638512\r## bg -0.4283914 0.12001993 -0.6202064 -0.2365764\r## sigma 1.1184575 0.07343099 1.0011006 1.2358144\r Given these results, I prefer the stronger relationship between weight and avgfood over that relying on area and would chose a model using only avgfood.\nPart B Question: When both avgfood or area are in the same model, their effects are reduced (closer to zero) and their standard errors are larger than when they are included in separate models. Can you explain this result?\nAnswer: I am pretty sure that this is our old friend multicollinearity rearing its ugly head. Since the two are highly correlated, their respective effects become less when controlling for either in the same model.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] dagitty_0.3-1 GGally_2.1.2 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 plyr_1.8.6 ## [11] R6_2.5.0 backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 ## [21] callr_3.7.0 jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 labeling_0.4.2 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 ## [31] compiler_4.0.5 xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 ## [41] codetools_0.2-18 matrixStats_0.61.0 reshape_0.8.8 fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 ## [51] jsonlite_1.7.2 gtable_0.3.0 lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 farver_2.1.0 ## [61] bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.7 boot_1.3-27 rematch2_2.1.2 RColorBrewer_1.1-2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 ## [71] purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611234000,"objectID":"df36afb8630f27219abb6de490eeb9ff","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-05/","publishdate":"2021-01-21T00:00:00Z","relpermalink":"/courses/rethinking/chapter-05/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 5 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 05","type":"docs"},{"authors":null,"categories":null,"content":"This is a purely theoretical session and there is no practical exercise attached.\nI have prepared some Lecture Slides  for this session.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e4ff485d7fd4cb13e6284891ce6bf60b","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/06-inferential-statistics-hypotheses-and-our-research-project/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/06-inferential-statistics-hypotheses-and-our-research-project/","section":"courses","summary":"This is a purely theoretical session and there is no practical exercise attached.\nI have prepared some Lecture Slides  for this session.","tags":null,"title":"Inferential Statistics, Hypotheses And Our Research Project","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some slides for this session: \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0c08d63f606b3ed8ae856ad156e46f34","permalink":"https://www.erikkusch.com/courses/biostat101/06-inferential-statistics-hypotheses-and-our-research-project/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/biostat101/06-inferential-statistics-hypotheses-and-our-research-project/","section":"courses","summary":"I have prepared some slides for this session:","tags":null,"title":"Inferential Statistics, Hypotheses And Our Research Project","type":"docs"},{"authors":["Erik Kusch"],"categories":["Excursion into Biostatistics"],"content":"Theory These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.\nI have prepared some Lecture Slides  for this session.\nOur Resarch Project Today, we are looking at a big (and entirely fictional) data base of the common house sparrow (Passer domesticus). In particular, we are interested in the Evolution of Passer domesticus in Response to Climate Change which was previously explained here.\nThe Data I have created a large data set for this exercise which is available here and we previously cleaned up so that is now usable here.\nReading the Data into R Let\u0026rsquo;s start by reading the data into R and taking an initial look at it:\nSparrows_df \u0026lt;- readRDS(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))\rhead(Sparrows_df)\r ## Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type\r## 1 SI 60 100 Continental Native 34.05 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 2 SI 60 100 Continental Native 34.86 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 3 SI 60 100 Continental Native 32.34 12.66 6.64 Black Female Shrub 35.60 1 3.21 C Large Yes Avian\r## 4 SI 60 100 Continental Native 34.78 15.09 7.00 Brown Female Shrub 47.75 0 NA E Large Yes Avian\r## 5 SI 60 100 Continental Native 35.01 13.82 6.81 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 6 SI 60 100 Continental Native 32.36 12.67 6.64 Brown Female Shrub 32.47 1 3.17 E Large Yes Avian\r## TAvg TSD\r## 1 269.9596 15.71819\r## 2 269.9596 15.71819\r## 3 269.9596 15.71819\r## 4 269.9596 15.71819\r## 5 269.9596 15.71819\r## 6 269.9596 15.71819\r Hypotheses Let\u0026rsquo;s remember our hypotheses:\n Sparrow Morphology is determined by:\nA. Climate Conditions with sparrows in stable, warm environments fairing better than those in colder, less stable ones.\nB. Competition with sparrows in small flocks doing better than those in big flocks.\nC. Predation with sparrows under pressure of predation doing worse than those without. Sites accurately represent sparrow morphology. This may mean:\nA. Population status as inferred through morphology.\nB. Site index as inferred through morphology.\nC. Climate as inferred through morphology.  Quite obviously, hypothesis 1 is the only one lending itself well to regression exercises. Since we have three variables that describe sparrow morphology (Weight, Height, Wing.Chord) and multi-response-variable models are definitely above the pay-grade of this material, we need to select one of our morphology variables as our response variable here. Remembering the Classification exercise, we recall that Weight was the most informative morphological trait so far. Hence, we stick with this one for these exercises.\nR Environment For this exercise, we will need the following packages:\ninstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE)) {\rinstall.packages(x, repos = \u0026quot;http://cran.us.r-project.org\u0026quot;)\r}\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\r\u0026quot;ggplot2\u0026quot;, # for visualisation\r\u0026quot;nlme\u0026quot;, # for mixed effect models\r\u0026quot;HLMdiag\u0026quot; # for leverage of mixed effect models\r)\rsapply(package_vec, install.load.package)\r ## ggplot2 nlme HLMdiag ## TRUE TRUE TRUE\r Using the above function is way more sophisticated than the usual install.packages() \u0026amp; library() approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.\nLinear Regression Remember the Assumptions of Linear Regression:\n Variable values follow homoscedasticity (equal variance across entire data range) Residuals follow normal distribution (normality) Absence of influential outliers Response and Predictor are related in a linear fashion  Climate Conditions Weight as a result of average temperature (TAvg) Before we begin, let\u0026rsquo;s plot the data we want to model:\nggplot(data = Sparrows_df, aes(y = Weight, x = TAvg)) +\rstat_smooth(method = \u0026quot;lm\u0026quot;) +\rgeom_point() +\rtheme_bw()\r I have an inkling that we might run into some issues here, but let\u0026rsquo;s continue for now:\nLet\u0026rsquo;s build the actual model:\nH1_ClimateTavg \u0026lt;- lm(Weight ~ TAvg, data = Sparrows_df)\rpar(mfrow = c(2, 2))\rplot(H1_ClimateTavg)\r While the meeting of most of the assumptions here might be debatable, we certainly cannot accept a linear model with residuals this non-normal distributed. Sow hat do we? We try to remove as many confounding effects as possible!\nRemember the plot-locations, climates, and population statues in the data set (go back here if necessary). How about we look exclusively at stations in the Americas which are all housing introduced sparrow populations and almost exclusively lie in coastal habitats? I\u0026rsquo;ll remove all non-coastal climate sites and only consider the central and North America here. Let\u0026rsquo;s do that:\n# everything west of -7° is on the Americas\r# every that's coastal climate type is retained\r# everything north of 11° is central and north America\rCentralNorthAm_df \u0026lt;- Sparrows_df[Sparrows_df$Longitude \u0026lt; -7 \u0026amp; Sparrows_df$Climate == \u0026quot;Coastal\u0026quot; \u0026amp; Sparrows_df$Latitude \u0026gt; 11, ]\rggplot(data = CentralNorthAm_df, aes(y = Weight, x = TAvg)) +\rstat_smooth(method = \u0026quot;lm\u0026quot;) +\rgeom_point() +\rtheme_bw()\r H1_ClimateTavg \u0026lt;- lm(Weight ~ TAvg, data = CentralNorthAm_df)\rpar(mfrow = c(2, 2))\rplot(H1_ClimateTavg)\r This looks sensible to me! The scatterplot shows that sparrows are lighter in warmer areas which makes sense to me.\nsummary(H1_ClimateTavg)\r ## ## Call:\r## lm(formula = Weight ~ TAvg, data = CentralNorthAm_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -4.1440 -1.0861 0.0219 0.9823 3.9743 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 45.167990 1.618752 27.903 \u0026lt; 2e-16 ***\r## TAvg -0.049501 0.005635 -8.785 2.63e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.404 on 248 degrees of freedom\r## Multiple R-squared: 0.2373,\tAdjusted R-squared: 0.2343 ## F-statistic: 77.18 on 1 and 248 DF, p-value: 2.633e-16\r Our model estimates show the same pattern.\nWeight as a result of temperature variability (TSD) I\u0026rsquo;ll continue with my North American, coastal subset here:\n# everything west of -7° is on the Americas\r# every that's coastal climate type is retained\r# everything north of 11° is central and north America\rCentralNorthAm_df \u0026lt;- Sparrows_df[Sparrows_df$Longitude \u0026lt; -7 \u0026amp; Sparrows_df$Climate == \u0026quot;Coastal\u0026quot; \u0026amp; Sparrows_df$Latitude \u0026gt; 11, ]\rggplot(data = CentralNorthAm_df, aes(y = Weight, x = TSD)) +\rstat_smooth(method = \u0026quot;lm\u0026quot;) +\rgeom_point() +\rtheme_bw()\r H1_ClimateTSD \u0026lt;- lm(Weight ~ TSD, data = CentralNorthAm_df)\rpar(mfrow = c(2, 2))\rplot(H1_ClimateTSD)\r summary(H1_ClimateTSD)\r ## ## Call:\r## lm(formula = Weight ~ TSD, data = CentralNorthAm_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -3.7978 -1.0053 0.0002 1.0042 3.5648 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 29.61266 0.14922 198.45 \u0026lt;2e-16 ***\r## TSD 0.22680 0.02069 10.96 \u0026lt;2e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.319 on 248 degrees of freedom\r## Multiple R-squared: 0.3263,\tAdjusted R-squared: 0.3236 ## F-statistic: 120.1 on 1 and 248 DF, p-value: \u0026lt; 2.2e-16\r Again all assumptions are met and the model itself is very intuitive: The more variable the climate, the heavier the sparrows.\nWeight as a result of both temperature mean (TAvg) and temperature variability (TSD) Naturally, we continue with the same subset of the data as before:\n# everything west of -7° is on the Americas\r# every that's coastal climate type is retained\r# everything north of 11° is central and north America\rCentralNorthAm_df \u0026lt;- Sparrows_df[Sparrows_df$Longitude \u0026lt; -7 \u0026amp; Sparrows_df$Climate == \u0026quot;Coastal\u0026quot; \u0026amp; Sparrows_df$Latitude \u0026gt; 11, ]\rH1_ClimateCont \u0026lt;- lm(Weight ~ TAvg + TSD, data = CentralNorthAm_df)\rpar(mfrow = c(2, 2))\rplot(H1_ClimateCont)\r summary(H1_ClimateCont)\r ## ## Call:\r## lm(formula = Weight ~ TAvg + TSD, data = CentralNorthAm_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -3.6593 -1.0263 0.0272 0.9207 3.2359 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 16.59866 4.68943 3.540 0.000479 ***\r## TAvg 0.04215 0.01518 2.777 0.005915 ** ## TSD 0.38142 0.05931 6.431 6.52e-10 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.302 on 247 degrees of freedom\r## Multiple R-squared: 0.3467,\tAdjusted R-squared: 0.3414 ## F-statistic: 65.54 on 2 and 247 DF, p-value: \u0026lt; 2.2e-16\r Interestingly, average temperature has a different (and weaker) effect now than when investigated in isolation. Variability of temperature has become even more important (i.e. stronger effect). So which model should we use? That\u0026rsquo;s exactly what we\u0026rsquo;ll investigate in our session on Model Selection and Validation!\nCompetition Next, we build models which aim to explain sparrow Weight through variables pertaining to competition. To do so, I first calculate the size for each flock at each site and append these to each bird:\nFlockSizes \u0026lt;- with(Sparrows_df, table(Flock, Index))\rSparrows_df$Flock.Size \u0026lt;- NA\rfor (Flock_Iter in rownames(FlockSizes)) { # loop over flocks\rfor (Site_Iter in colnames(FlockSizes)) { # loop over sites\rPositions \u0026lt;- Sparrows_df$Index == Site_Iter \u0026amp; Sparrows_df$Flock == Flock_Iter\rSparrows_df$Flock.Size[Positions] \u0026lt;- FlockSizes[Flock_Iter, Site_Iter]\r}\r}\r With that done, we can now build our models up again like we did with the climate data before.\nWeight as a result of Home Range size (Home.Range) ggplot(data = Sparrows_df, aes(x = Home.Range, y = Weight)) +\rgeom_boxplot() +\rtheme_bw()\r H1_CompetitionHR \u0026lt;- lm(Weight ~ Home.Range, data = Sparrows_df)\rpar(mfrow = c(2, 2))\rplot(H1_CompetitionHR)\r Nope. Those residuals have me nope out. We won\u0026rsquo;t use this model.\nWeight as a result of Flock Size size (Flock.Size) ggplot(data = Sparrows_df, aes(x = Flock.Size, y = Weight)) +\rstat_smooth(method = \u0026quot;lm\u0026quot;) +\rgeom_point() +\rtheme_bw()\r H1_CompetitionFS \u0026lt;- lm(Weight ~ Flock.Size, data = Sparrows_df)\rpar(mfrow = c(2, 2))\rplot(H1_CompetitionFS)\r summary(H1_CompetitionFS)\r ## ## Call:\r## lm(formula = Weight ~ Flock.Size, data = Sparrows_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.7421 -1.2163 0.0961 1.2823 4.7176 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 35.456378 0.114500 309.7 \u0026lt;2e-16 ***\r## Flock.Size -0.237908 0.003831 -62.1 \u0026lt;2e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.893 on 1064 degrees of freedom\r## Multiple R-squared: 0.7838,\tAdjusted R-squared: 0.7836 ## F-statistic: 3857 on 1 and 1064 DF, p-value: \u0026lt; 2.2e-16\r Now that\u0026rsquo;s a neat model! Not only do the diagnostics plot look spot-on (not showing these here), the relationship is strong and clear to see - the bigger the flock, the lighter the sparrow.\nWeight as a result of Home Range size (Home.Range) and Flock Size size (Flock.Size) ggplot(data = Sparrows_df, aes(x = Flock.Size, y = Weight, col = Home.Range)) +\rgeom_point() +\rstat_smooth(method = \u0026quot;lm\u0026quot;) +\rtheme_bw()\r H1_CompetitionFULL \u0026lt;- lm(Weight ~ Home.Range * Flock.Size, data = Sparrows_df)\rpar(mfrow = c(2, 2))\rplot(H1_CompetitionFULL)\r summary(H1_CompetitionFULL)\r ## ## Call:\r## lm(formula = Weight ~ Home.Range * Flock.Size, data = Sparrows_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.5599 -1.2261 0.0427 1.2806 4.5553 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 33.29279 0.31986 104.086 \u0026lt; 2e-16 ***\r## Home.RangeMedium 0.29700 0.89288 0.333 0.739 ## Home.RangeSmall 1.88176 0.35265 5.336 1.16e-07 ***\r## Flock.Size -0.07337 0.01848 -3.970 7.66e-05 ***\r## Home.RangeMedium:Flock.Size -0.03363 0.05787 -0.581 0.561 ## Home.RangeSmall:Flock.Size -0.16211 0.01896 -8.548 \u0026lt; 2e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.8 on 1060 degrees of freedom\r## Multiple R-squared: 0.8051,\tAdjusted R-squared: 0.8042 ## F-statistic: 876 on 5 and 1060 DF, p-value: \u0026lt; 2.2e-16\r We see that our model is unsure of what to do with the home ranges when it comes to medium-sized ranges. The scatterplot shows that is is probably due to us not having a lot of samples for medium-sized home-ranges. Aside from that, our model meets all assumptions and produces quite intuitive parameter estimates.\nPredation Next, we look at sparrow Weight through the lens of predation. To do so, we need to recode all NAs in the Predator.Type variable into something else for our models ro tun properly. I chose \u0026quot;None\u0026quot; here to indicate that there is no predation-pressure at these sites:\nlevels(Sparrows_df$Predator.Type) \u0026lt;- c(levels(Sparrows_df$Predator.Type), \u0026quot;None\u0026quot;)\rSparrows_df$Predator.Type[is.na(Sparrows_df$Predator.Type)] \u0026lt;- \u0026quot;None\u0026quot;\r With that taken care of, we again build our models one-by-one.\nAgain, because of issues with normality of residuals, we default to our three sites across Central and North America, which are of coastal climate:\n# everything west of -7° is on the Americas\r# every that's coastal climate type is retained\r# everything north of 11° is central and north America\rCentralNorthAm_df \u0026lt;- Sparrows_df[Sparrows_df$Longitude \u0026lt; -7 \u0026amp; Sparrows_df$Climate == \u0026quot;Coastal\u0026quot; \u0026amp; Sparrows_df$Latitude \u0026gt; 11, ]\r Weight as a result of Predator.Presence ggplot(data = CentralNorthAm_df, aes(x = Predator.Presence, y = Weight)) +\rgeom_boxplot() +\rtheme_bw()\r H1_PredationPresence \u0026lt;- lm(Weight ~ Predator.Presence, data = CentralNorthAm_df)\rpar(mfrow = c(2, 2))\rplot(H1_PredationPresence)\r summary(H1_PredationPresence)\r ## ## Call:\r## lm(formula = Weight ~ Predator.Presence, data = CentralNorthAm_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -4.5051 -1.0701 -0.0396 1.0749 4.2549 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 31.4141 0.1752 179.261 \u0026lt; 2e-16 ***\r## Predator.PresenceYes -0.6589 0.2131 -3.092 0.00222 ** ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.577 on 248 degrees of freedom\r## Multiple R-squared: 0.03711,\tAdjusted R-squared: 0.03323 ## F-statistic: 9.557 on 1 and 248 DF, p-value: 0.002219\r According to our model, sparrows under pressure of predation are lighter than those which aren\u0026rsquo;t. Does that make sense? Intuitively, yes, but I would argue that there are too many confounding variable here to be sure.\nWeight as a result of Predator.Type ggplot(data = CentralNorthAm_df, aes(x = Predator.Type, y = Weight)) +\rgeom_boxplot() +\rtheme_bw()\r H1_PredationType \u0026lt;- lm(Weight ~ Predator.Type, data = CentralNorthAm_df)\rpar(mfrow = c(2, 2))\rplot(H1_PredationType)\r summary(H1_PredationType)\r ## ## Call:\r## lm(formula = Weight ~ Predator.Type, data = CentralNorthAm_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -3.6593 -1.0263 0.0272 0.9207 3.2359 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 29.9093 0.1270 235.439 \u0026lt; 2e-16 ***\r## Predator.TypeNon-Avian 2.2335 0.2064 10.819 \u0026lt; 2e-16 ***\r## Predator.TypeNone 1.5047 0.1925 7.817 1.56e-13 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.302 on 247 degrees of freedom\r## Multiple R-squared: 0.3467,\tAdjusted R-squared: 0.3414 ## F-statistic: 65.54 on 2 and 247 DF, p-value: \u0026lt; 2.2e-16\r OK. This clearly shows that there are either some confounds present or that our data shows something very counter-intuitive. Sparrows under nor predation are lighter than sparrows under non-avian predation? That makes no sense to me.\nWeight as a result of Predator.Presence and Predator.Type ggplot(data = CentralNorthAm_df, aes(x = Predator.Presence, y = Weight, fill = Predator.Type)) +\rgeom_boxplot() +\rtheme_bw()\r H1_PredationFULL \u0026lt;- lm(Weight ~ Predator.Presence + Predator.Type, data = Sparrows_df)\rpar(mfrow = c(2, 2))\rplot(H1_PredationFULL)\r summary(H1_PredationFULL)\r ## ## Call:\r## lm(formula = Weight ~ Predator.Presence + Predator.Type, data = Sparrows_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -7.6635 -2.2987 -0.0844 1.9563 9.6165 ## ## Coefficients: (1 not defined because of singularities)\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 30.6145 0.1816 168.60 \u0026lt;2e-16 ***\r## Predator.PresenceYes -3.5709 0.2387 -14.96 \u0026lt;2e-16 ***\r## Predator.TypeNon-Avian 5.2809 0.2789 18.94 \u0026lt;2e-16 ***\r## Predator.TypeNone NA NA NA NA ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 3.431 on 1063 degrees of freedom\r## Multiple R-squared: 0.2901,\tAdjusted R-squared: 0.2888 ## F-statistic: 217.2 on 2 and 1063 DF, p-value: \u0026lt; 2.2e-16\r Those residuals don\u0026rsquo;t look good, but that\u0026rsquo;s not what I am after with this model. Immediately, we should notice that our model returns NA for the parameter estimate of Predator.TypeNone. Why does that happen? Because Predator.TypeNone coincides with Predator.PresenceNo (the Intercept) of this model and so does not provide any additional information. In fact, Predator.Type offers all the information of Predator.Presence and then some! Consequently, including both in a model does not make sense and we can immediately disqualify this model.\nNull \u0026amp; Full Model For some comparison further down the line, we need a null model:\nH1_Null_Sparrows \u0026lt;- lm(Weight ~ 1, data = Sparrows_df)\rH1_Null_CNA \u0026lt;- lm(Weight ~ 1, data = CentralNorthAm_df)\r Our full model contains all of our aforementioned variables/parameters to the best of our knowledge/intuition at this point. We will get to making this model better later. Don\u0026rsquo;t worry:\nH1_FULL_Sparrows \u0026lt;- lm(Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + Predator.Type, data = Sparrows_df)\rpar(mfrow = c(2, 2))\rplot(H1_FULL_Sparrows)\r summary(H1_FULL_Sparrows)\r ## ## Call:\r## lm(formula = Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + ## Predator.Type, data = Sparrows_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.2164 -1.0436 0.0939 1.0495 4.7403 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 43.65271 4.09482 10.660 \u0026lt; 2e-16 ***\r## ClimateContinental 2.28851 0.31524 7.259 7.53e-13 ***\r## ClimateSemi-Coastal -0.79097 0.30663 -2.580 0.01003 * ## TAvg -0.04252 0.01402 -3.034 0.00247 ** ## TSD 0.01431 0.04032 0.355 0.72272 ## Home.RangeMedium 1.63110 0.85370 1.911 0.05632 . ## Home.RangeSmall 2.36146 0.41639 5.671 1.83e-08 ***\r## Flock.Size -0.03445 0.01896 -1.817 0.06955 . ## Predator.TypeNon-Avian 0.24253 0.16673 1.455 0.14605 ## Predator.TypeNone 0.75123 0.17268 4.350 1.49e-05 ***\r## Home.RangeMedium:Flock.Size -0.10115 0.05614 -1.802 0.07186 . ## Home.RangeSmall:Flock.Size -0.16452 0.01990 -8.267 4.09e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.605 on 1054 degrees of freedom\r## Multiple R-squared: 0.846,\tAdjusted R-squared: 0.8444 ## F-statistic: 526.6 on 11 and 1054 DF, p-value: \u0026lt; 2.2e-16\r Already at this point, it is interesting to point out how some previously non-significant effects drop out while other become significant due to the inclusion of all parameters in one model.\nNow we also need a full model for our Central-/North-America data:\nH1_FULL_CNA \u0026lt;- lm(Weight ~ TAvg + TSD + Home.Range * Flock.Size + Predator.Type, data = CentralNorthAm_df)\rpar(mfrow = c(2, 2))\rplot(H1_FULL_CNA)\r summary(H1_FULL_CNA)\r ## ## Call:\r## lm(formula = Weight ~ TAvg + TSD + Home.Range * Flock.Size + ## Predator.Type, data = CentralNorthAm_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -3.6979 -0.9364 -0.0501 1.0483 3.3590 ## ## Coefficients: (2 not defined because of singularities)\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 14.18473 6.20215 2.287 0.0231 * ## TAvg 0.05336 0.02038 2.618 0.0094 ** ## TSD 0.39853 0.07842 5.082 7.48e-07 ***\r## Home.RangeMedium -3.83588 1.99164 -1.926 0.0553 . ## Home.RangeSmall -1.50681 1.03368 -1.458 0.1462 ## Flock.Size -0.07581 0.05850 -1.296 0.1963 ## Predator.TypeNon-Avian NA NA NA NA ## Predator.TypeNone NA NA NA NA ## Home.RangeMedium:Flock.Size 0.29821 0.13273 2.247 0.0256 * ## Home.RangeSmall:Flock.Size 0.10097 0.06212 1.625 0.1054 ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.285 on 242 degrees of freedom\r## Multiple R-squared: 0.3765,\tAdjusted R-squared: 0.3585 ## F-statistic: 20.88 on 7 and 242 DF, p-value: \u0026lt; 2.2e-16\r Summary of Linear Regression To streamline the next few steps of our exercise on Model Selection and Validation, we combine all of our models into a list object for now:\nH1_ModelSparrows_ls \u0026lt;- list(\rH1_Null_Sparrows,\rH1_CompetitionFS,\rH1_CompetitionFULL,\rH1_FULL_Sparrows\r)\rnames(H1_ModelSparrows_ls) \u0026lt;- c(\r\u0026quot;Null\u0026quot;,\r\u0026quot;Comp_Flock.Size\u0026quot;, \u0026quot;Comp_Full\u0026quot;,\r\u0026quot;Full\u0026quot;\r)\rH1_ModelCNA_ls \u0026lt;- list(\rH1_Null_CNA,\rH1_ClimateTavg,\rH1_ClimateTSD,\rH1_ClimateCont,\rH1_PredationPresence,\rH1_PredationType,\rH1_FULL_CNA\r)\rnames(H1_ModelCNA_ls) \u0026lt;- c(\r\u0026quot;Null\u0026quot;,\r\u0026quot;Clim_TAvg\u0026quot;, \u0026quot;Clim_TSD\u0026quot;, \u0026quot;Clim_Full\u0026quot;,\r\u0026quot;Pred_Pres\u0026quot;, \u0026quot;Pred_Type\u0026quot;,\r\u0026quot;Full\u0026quot;\r)\r Mixed Effect Models Remember the Assumptions of Mixed Effect Models:\n Variable values follow homoscedasticity (equal variance across entire data range) Residuals follow normal distribution (normality) Absence of influential outliers Response and Predictor are related in a linear fashion  Climate Conditions Here, I create a mixed effect model that is accounting predicting Weight with a combination TAvg and TSD while accounting for random intercepts of Index and Population.Status. As we learned in our exercise on Classifications, these two are probably important in controlling for some morphology effects in Weight.\nI create such a model for:\n The entire sparrow data data set Only the Central-/North-America sparrows  to make models comparable to our previous basic, linear models.\nGlobal Model H1_Climate_ME_Sparrows \u0026lt;- lme(Weight ~ TAvg + TSD,\rrandom = list(\rPopulation.Status = ~1,\rIndex = ~1\r),\rdata = Sparrows_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Climate_ME_Sparrows), resid(H1_Climate_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Climate_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --\u0026gt; bad!\rqqnorm(resid(H1_Climate_ME_Sparrows)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Climate_ME_Sparrows)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r Quite evidently, the assumption of linearity is violated. Notice that we would not like to use this model for predictions, but will carry it forward for the purpose of subsequent Model Selection and Validation.\nsummary(H1_Climate_ME_Sparrows)\r ## Linear mixed-effects model fit by REML\r## Data: Sparrows_df ## AIC BIC logLik\r## 3557.109 3586.922 -1772.554\r## ## Random effects:\r## Formula: ~1 | Population.Status\r## (Intercept)\r## StdDev: 0.001507855\r## ## Formula: ~1 | Index %in% Population.Status\r## (Intercept) Residual\r## StdDev: 2.640311 1.237155\r## ## Fixed effects: Weight ~ TAvg + TSD ## Value Std.Error DF t-value p-value\r## (Intercept) 37.83099 31.229059 1055 1.2114034 0.2260\r## TAvg -0.03070 0.104602 7 -0.2934692 0.7777\r## TSD 0.27536 0.265143 7 1.0385452 0.3336\r## Correlation: ## (Intr) TAvg ## TAvg -0.999 ## TSD -0.826 0.809\r## ## Standardized Within-Group Residuals:\r## Min Q1 Med Q3 Max ## -2.956660984 -0.746001839 0.004452834 0.722973350 2.617329146 ## ## Number of Observations: 1066\r## Number of Groups: ## Population.Status Index %in% Population.Status ## 2 11\r Central-/North-American Model Accounting for population status in among the Central-/North-American sites makes no sense as all of them are introduced populations.\nH1_Climate_ME_CNA \u0026lt;- lme(Weight ~ TAvg + TSD,\rrandom = list(Index = ~1),\rdata = CentralNorthAm_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Climate_ME_CNA), resid(H1_Climate_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Climate_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --\u0026gt; good!\rqqnorm(resid(H1_Climate_ME_CNA)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Climate_ME_CNA)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r With this model, all of our assumption are met nicely!\nsummary(H1_Climate_ME_CNA)\r ## Linear mixed-effects model fit by REML\r## Data: CentralNorthAm_df ## AIC BIC logLik\r## 863.9566 881.5035 -426.9783\r## ## Random effects:\r## Formula: ~1 | Index\r## (Intercept) Residual\r## StdDev: 0.3802608 1.301734\r## ## Fixed effects: Weight ~ TAvg + TSD ## Value Std.Error DF t-value p-value\r## (Intercept) 16.598661 13.291655 247 1.2488031 0.2129\r## TAvg 0.042146 0.042863 0 0.9832757 NaN\r## TSD 0.381424 0.174011 0 2.1919464 NaN\r## Correlation: ## (Intr) TAvg ## TAvg -0.999 ## TSD -0.953 0.945\r## ## Standardized Within-Group Residuals:\r## Min Q1 Med Q3 Max ## -2.8111222 -0.7883782 0.0208856 0.7072618 2.4858581 ## ## Number of Observations: 250\r## Number of Groups: 3\r Competition With competition effects as my goal, I can now include climate classification as one of the random effects! Of course, this is with the exception of the Central-/North-American data as all of these sites are of the type \u0026ldquo;Coastal\u0026rdquo;.\nAgain, we do so for a global and a local model:\nGlobal Model H1_Comp_ME_Sparrows \u0026lt;- lme(Weight ~ Home.Range * Flock.Size,\rrandom = list(\rPopulation.Status = ~1,\rClimate = ~1\r),\rdata = Sparrows_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Comp_ME_Sparrows), resid(H1_Comp_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Comp_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --\u0026gt; bad!\rqqnorm(resid(H1_Comp_ME_Sparrows)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Comp_ME_Sparrows)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r Central-/North-American Model H1_Comp_ME_CNA \u0026lt;- lme(Weight ~ Home.Range * Flock.Size,\rrandom = list(Climate = ~1),\rdata = CentralNorthAm_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Comp_ME_CNA), resid(H1_Comp_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Comp_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --\u0026gt; good!\rqqnorm(resid(H1_Comp_ME_CNA)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Comp_ME_CNA)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r Predation With predation effects, I do the same as with competition effects and set a random intercept for climate classification at each site for a global and a local model:\nGlobal Model H1_Pred_ME_Sparrows \u0026lt;- lme(Weight ~ Predator.Type,\rrandom = list(\rPopulation.Status = ~1,\rClimate = ~1\r),\rdata = Sparrows_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Pred_ME_Sparrows), resid(H1_Pred_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Pred_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --\u0026gt; bad!\rqqnorm(resid(H1_Pred_ME_Sparrows)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Pred_ME_Sparrows)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r Central-/North-American Model H1_Pred_ME_CNA \u0026lt;- lme(Weight ~ Predator.Type,\rrandom = list(Index = ~1),\rdata = CentralNorthAm_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Pred_ME_CNA), resid(H1_Pred_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Pred_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --\u0026gt; good!\rqqnorm(resid(H1_Pred_ME_CNA)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Pred_ME_CNA)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r Full Model Global Model H1_Full_ME_Sparrows \u0026lt;- lme(Weight ~ Predator.Type + Flock.Size * Home.Range + TAvg + TSD,\rrandom = list(Population.Status = ~1),\rdata = Sparrows_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Full_ME_Sparrows), resid(H1_Full_ME_Sparrows)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Full_ME_Sparrows), Sparrows_df$Weight) # Linearity, there is a clear pattern here --\u0026gt; bad!\rqqnorm(resid(H1_Full_ME_Sparrows)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Full_ME_Sparrows)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r Central-/North-American Model H1_Full_ME_CNA \u0026lt;- lme(Weight ~ Flock.Size * Home.Range + TAvg + TSD,\rrandom = list(Index = ~1),\rdata = CentralNorthAm_df\r)\rpar(mfrow = c(2, 2))\rplot(fitted(H1_Full_ME_CNA), resid(H1_Full_ME_CNA)) # Homogeneity of Variances, values around 0, no pattern --\u0026gt; good!\rplot(fitted(H1_Full_ME_CNA), CentralNorthAm_df$Weight) # Linearity, there is no clear pattern here --\u0026gt; good!\rqqnorm(resid(H1_Full_ME_CNA)) # Normality, residuals are normal distributed -\u0026gt; good!\rhist(leverage(H1_Full_ME_CNA)[, 1]) # Leverage, not really any outliers --\u0026gt; good!\r Summary of Mixed Effect Models Mixed effect models are hard and I have certainly not given them full credit for what they are worth here. I highly suggest giving this a read if you see yourself using mixed effect models.\nFor now, I want to carry along only the full models for our session on Model Selection and Validation:\nH1_ModelSparrows_ls$Mixed_Full \u0026lt;- H1_Full_ME_Sparrows\rH1_ModelCNA_ls$Mixed_Full \u0026lt;- H1_Full_ME_CNA\r Generalised Linear Models For a generalised linear model, we may want to run a logistic regression, which we already did.\nFor a different example, we now turn to poisson models by trying to understand how Flock.Size comes about.\nFirstly, we limit our data set to necessary variables and then cut all duplicate rows:\nFlock_df \u0026lt;- Sparrows_df[, c(\u0026quot;Flock.Size\u0026quot;, \u0026quot;TAvg\u0026quot;, \u0026quot;TSD\u0026quot;, \u0026quot;Index\u0026quot;, \u0026quot;Climate\u0026quot;, \u0026quot;Predator.Type\u0026quot;)]\rFlock_df \u0026lt;- unique(Flock_df)\r Now we are ready to build a basic linear model:\nFlock_lm \u0026lt;- lm(Flock.Size ~ TAvg * TSD * Predator.Type, data = Flock_df)\rpar(mfrow = c(2, 2))\rplot(Flock_lm)\r Everything looks line but that Scale-Location plot. That one seems to indicate that variance in our Flock.Size increases as the Flock.Size itself increases - a very typical example of a poisson distributed variable.\nGLMs to the rescue with the poisson GLM:\npoisson.model \u0026lt;- glm(Flock.Size ~ TAvg * TSD * Predator.Type, data = Flock_df, family = poisson(link = \u0026quot;log\u0026quot;))\rpar(mfrow = c(2, 2))\rplot(poisson.model)\r We fixed it! Now just for the parameter estimates:\nsummary(poisson.model)\r ## ## Call:\r## glm(formula = Flock.Size ~ TAvg * TSD * Predator.Type, family = poisson(link = \u0026quot;log\u0026quot;), ## data = Flock_df)\r## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.02420 -0.88953 -0.09629 0.94122 2.12737 ## ## Coefficients: (1 not defined because of singularities)\r## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) -13.822674 2.540369 -5.441 5.29e-08 ***\r## TAvg 0.061744 0.008564 7.209 5.62e-13 ***\r## TSD 7.243621 1.056843 6.854 7.18e-12 ***\r## Predator.TypeNon-Avian -48.160439 9.412905 -5.116 3.11e-07 ***\r## Predator.TypeNone 10.338971 8.694652 1.189 0.234 ## TAvg:TSD -0.026895 0.003936 -6.833 8.34e-12 ***\r## TAvg:Predator.TypeNon-Avian 0.171883 0.033327 5.157 2.50e-07 ***\r## TAvg:Predator.TypeNone -0.039510 0.029180 -1.354 0.176 ## TSD:Predator.TypeNon-Avian 0.067442 0.041609 1.621 0.105 ## TSD:Predator.TypeNone -6.742437 1.177538 -5.726 1.03e-08 ***\r## TAvg:TSD:Predator.TypeNon-Avian NA NA NA NA ## TAvg:TSD:Predator.TypeNone 0.025061 0.004321 5.800 6.64e-09 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## (Dispersion parameter for poisson family taken to be 1)\r## ## Null deviance: 276.538 on 49 degrees of freedom\r## Residual deviance: 53.417 on 39 degrees of freedom\r## AIC: 310.71\r## ## Number of Fisher Scoring iterations: 4\r Final Models In our upcoming Model Selection and Validation Session, we will look into how to compare and validate models. We now need to select some models we have created here today and want to carry forward to said session.\nWe have already created list objects for this purpose. Let\u0026rsquo;s save them alongside the data that was used to create them (in the case of the localised models, at least). Let\u0026rsquo;s save these as a separate object ready to be loaded into our R environment in the coming session:\nsave(H1_ModelSparrows_ls, H1_ModelCNA_ls, CentralNorthAm_df, Sparrows_df, file = file.path(\u0026quot;Data\u0026quot;, \u0026quot;H1_Models.RData\u0026quot;))\r SessionInfo sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] HLMdiag_0.5.0 nlme_3.1-162 ggplot2_3.4.1\r## ## loaded via a namespace (and not attached):\r## [1] styler_1.9.1 tidyselect_1.2.0 xfun_0.37 bslib_0.4.2 janitor_2.2.0 reshape2_1.4.4 purrr_1.0.1 splines_4.2.3 lattice_0.20-45 snakecase_0.11.0 ## [11] colorspace_2.1-0 vctrs_0.5.2 generics_0.1.3 htmltools_0.5.4 mgcv_1.8-42 yaml_2.3.7 utf8_1.2.3 rlang_1.0.6 R.oo_1.25.0 jquerylib_0.1.4 ## [21] pillar_1.8.1 glue_1.6.2 withr_2.5.0 R.utils_2.12.2 plyr_1.8.8 R.cache_0.16.0 lifecycle_1.0.3 stringr_1.5.0 munsell_0.5.0 blogdown_1.16 ## [31] gtable_0.3.1 R.methodsS3_1.8.2 diagonals_6.4.0 evaluate_0.20 labeling_0.4.2 knitr_1.42 fastmap_1.1.1 fansi_1.0.4 highr_0.10 Rcpp_1.0.10 ## [41] scales_1.2.1 cachem_1.0.7 jsonlite_1.8.4 farver_2.1.1 digest_0.6.31 stringi_1.7.12 bookdown_0.33 dplyr_1.1.0 grid_4.2.3 cli_3.6.0 ## [51] tools_4.2.3 magrittr_2.0.3 sass_0.4.5 tibble_3.2.0 pkgconfig_2.0.3 MASS_7.3-58.2 Matrix_1.5-3 lubridate_1.9.2 timechange_0.2.0 rmarkdown_2.20 ## [61] rstudioapi_0.14 R6_2.5.1 compiler_4.2.3\r ","date":1614384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"54b92ef6e96c88fad92163a6223f28c2","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/regressions-correlations-for-the-advanced/","publishdate":"2021-02-27T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/regressions-correlations-for-the-advanced/","section":"courses","summary":"These are exercises and solutions meant as a compendium to my talk on Regression Models.","tags":["R","Statistics"],"title":"Regressions","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"The Haunted DAG \u0026amp; The Causal Terror Material  \rSlides Chapter 6  Introduction These are answers and solutions to the exercises at the end of chapter 6 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Jake Thompson. The PDF version of Satistical Rethinking 2 is lacking some exercises of the print version, it seems. I do not address these here.\nMedium Exercises We are stepping right into R:\nlibrary(rethinking)\rlibrary(dagitty)\rlibrary(ggdag)\rlibrary(ggplot2)\rlibrary(tidybayes)\r Practice M1 Question: Modify the DAG on page 190 to include the variable $V$, an unobserved cause of $C$ and $Y$: variables $C ← V → Y$. Reanalyze the DAG. How many paths connect $X$ to $Y$? Which must be closed? Which should you condition on now?\nAnswer: Let\u0026rsquo;s start by assigning some coordinates and names of our variables which will end up as nodes in our DAG:\ndag_coords \u0026lt;- data.frame(\rname = c(\u0026quot;X\u0026quot;, \u0026quot;U\u0026quot;, \u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;Y\u0026quot;, \u0026quot;V\u0026quot;),\rx = c(1, 1, 2, 2, 3, 3, 3.5),\ry = c(1, 2, 2.5, 1.5, 2, 1, 1.5)\r)\r Now I add the actual path specifications and make a DAG object:\nDAG_m1 \u0026lt;- dagify(Y ~ X + C + V,\rX ~ U,\rU ~ A,\rB ~ U + C,\rC ~ A + V,\rcoords = dag_coords\r)\r Finally, I plot the resulting object:\nggplot(DAG_m1, aes(x = x, y = y, xend = xend, yend = yend)) +\rgeom_dag_point(shape = 1, stroke = 2, color = \u0026quot;black\u0026quot;) +\rgeom_dag_text(color = \u0026quot;black\u0026quot;, size = 10) +\rgeom_dag_edges(\redge_color = \u0026quot;black\u0026quot;, edge_width = 2,\rarrow_directed = grid::arrow(\rlength = grid::unit(15, \u0026quot;pt\u0026quot;),\rtype = \u0026quot;closed\u0026quot;\r)\r) +\rtheme_void()\r The original DAG on page 190 boasted the following two paths which needed closing:\n $X \u0026lt;- U \u0026lt;- A -\u0026gt; C -\u0026gt; Y$ $X \u0026lt;- U -\u0026gt; B \u0026lt;- C -\u0026gt; Y$  These remain unaltered. Through our novel inclusion of $V$, we now have another two paths that require closing between $X$ and $Y$:\n3. $X \u0026lt;- U \u0026lt;- A -\u0026gt; C \u0026lt;- V -\u0026gt; Y$\n4. $X \u0026lt;- U -\u0026gt; B \u0026lt;- C \u0026lt;- V -\u0026gt; Y$\nNow, how do we close these paths? First of all, paths 2 and 4 are already closed because $B$ acts as a collider. Path 3 is also closed as $C$ acts as a collider (Thanks to Ruxandra Tesloianu for pointing this out to me). Path 1 requires closing since $A$ is a fork. If we leave it up to R, we would condition on the following variables to close all paths between $X$ and $Y$:\nadjustmentSets(DAG_m1, exposure = \u0026quot;X\u0026quot;, outcome = \u0026quot;Y\u0026quot;)\r ## { C, V }\r## { A }\r## { U }\r Alright, let\u0026rsquo;s think about this. Our above DAG does not yet know which variables are unobserved. R suggests we condition on $C$ and $V$. That\u0026rsquo;s going to be impossible since we don\u0026rsquo;t have data for $V$. Next, we are pointed towards conditioning on $A$ as an alternative. That looks alright. Thirdly, we are prompted to consider conditioning on $U$. Again, we don\u0026rsquo;t have data for that. So, we are only left with one option: Condition on $A$.\nFinally, let\u0026rsquo;s actually give R all the information we have and rerun the adjustmentSets() function:\nDAG_m1 \u0026lt;- dagitty(\u0026quot;dag { U [unobserved]\rV [unobserved]\rX -\u0026gt; Y\rX \u0026lt;- U \u0026lt;- A -\u0026gt; C -\u0026gt; Y\rU -\u0026gt; B \u0026lt;- C\rC \u0026lt;- V -\u0026gt; Y }\u0026quot;)\radjustmentSets(DAG_m1, exposure = \u0026quot;X\u0026quot;, outcome = \u0026quot;Y\u0026quot;)\r ## { A }\r Cool. That\u0026rsquo;s exactly the solution we arrived at earlier as well.\nHard Exercises Practice H1 Question: Use the Waffle House data, data(WaffleDivorce), to find the total causal influence of number of Waffle Houses on divorce rate. Justify your model or models with a causal graph.\nAnswer: Let\u0026rsquo;s start by recreating the DAG on page 191 with some code from page 192 while sprucing it up with some coordinates for our nodes in the DAG:\n# Define Paths\rDAG_h1 \u0026lt;- dagitty(\u0026quot;dag {\rA -\u0026gt; D\rA -\u0026gt; M -\u0026gt; D\rA \u0026lt;- S -\u0026gt; M\rS -\u0026gt; W -\u0026gt; D\r}\u0026quot;)\r# Add Coordinates\rcoordinates(DAG_h1) \u0026lt;- list(\rx = c(A = 1, S = 1, M = 2, W = 3, D = 3),\ry = c(A = 1, S = 3, M = 2, W = 3, D = 1)\r)\r# Plotting\rggplot(DAG_h1, aes(x = x, y = y, xend = xend, yend = yend)) +\rgeom_dag_text(color = \u0026quot;black\u0026quot;, size = 10) +\rgeom_dag_edges(\redge_color = \u0026quot;black\u0026quot;, edge_width = 2,\rarrow_directed = grid::arrow(\rlength = grid::unit(15, \u0026quot;pt\u0026quot;),\rtype = \u0026quot;closed\u0026quot;\r)\r) +\rtheme_void()\r Let\u0026rsquo;s check which variables we need to condition on to allow any subsequent model to identify the causal relationship between $W$ and $D$:\nadjustmentSets(DAG_h1, exposure = \u0026quot;W\u0026quot;, outcome = \u0026quot;D\u0026quot;)\r ## { A, M }\r## { S }\r We could either condition on $A$ and $M$, or condition only on $S$. The latter seems simpler to me, so I\u0026rsquo;ll run with that! On to build that model:\n## Loading Data\rdata(WaffleDivorce)\rd \u0026lt;- WaffleDivorce\r## Scaling Relevant Variables\rd$D \u0026lt;- scale(d$Divorce)\rd$W \u0026lt;- scale(d$WaffleHouses)\rd$S \u0026lt;- scale(d$South)\r## Specifying and Running Model\rMOD_h1 \u0026lt;- quap(\ralist(\rD ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bS * S + bW * W,\ra ~ dnorm(0, 0.2),\rc(bS, bW) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\rplot(precis(MOD_h1))\r Our model clearly shows that once we know about whether a state is located in the Southern Contiguous U.S., we don\u0026rsquo;t gain additional information about the local divorce rate by learning about the number of Waffle Houses in the area.\nPractice H2 Question: Build a series of models to test the implied conditional independencies of the causal graph you used in the previous problem. If any of the tests fail, how do you think the graph needs to be amended? Does the graph need more or fewer arrows? Feel free to nominate variables that aren\u0026rsquo;t in the data.\nAnswer: Let\u0026rsquo;s start by letting R identify all the implied conditional independecies:\nimpliedConditionalIndependencies(DAG_h1)\r ## A _||_ W | S\r## D _||_ S | A, M, W\r## M _||_ W | S\r There are three models we need to build to assertain the conditional independencies here.\nFirstly, I am reloading the data and standardise all variables of interest:\n## Loading Data\rdata(WaffleDivorce)\rd \u0026lt;- WaffleDivorce\r## Scaling Relevant Variables\rd$A \u0026lt;- scale(d$MedianAgeMarriage)\rd$D \u0026lt;- scale(d$Divorce)\rd$M \u0026lt;- scale(d$Marriage)\rd$W \u0026lt;- scale(d$WaffleHouses)\rd$S \u0026lt;- scale(d$South)\r Now let\u0026rsquo;s get going with the actual models:\n A || W | S  MOD_h2a \u0026lt;- quap(\ralist(\rA ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bS * S + bW * W,\ra ~ dnorm(0, 0.2),\rc(bS, bW) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\rplot(precis(MOD_h2a))\r Conditional independence of $A$ of $W$ given $S$ - confirmed!\nD || S | A, M, W  MOD_h2b \u0026lt;- quap(\ralist(\rD ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bA * A + bS * S + bM * M + bW * W,\ra ~ dnorm(0, 0.2),\rc(bA, bS, bM, bW) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\rplot(precis(MOD_h2b))\r Conditional independence of $D$ of $S$ given $A$, $M$, and $W$ - confirmed!\nM || W | S  MOD_h2c \u0026lt;- quap(\ralist(\rM ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bS * S + bW * W,\ra ~ dnorm(0, 0.2),\rc(bS, bW) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\rplot(precis(MOD_h2c))\r Conditional independence of $M$ of $W$ given $S$ - confirmed!\nI finish this exercise by looking at only the relevant posteriors for each model:\nPlot_df \u0026lt;- data.frame(\rPosteriors = c(\rextract.samples(MOD_h2a, n = 1e4)$bW,\rextract.samples(MOD_h2b, n = 1e4)$bS,\rextract.samples(MOD_h2c, n = 1e4)$bW\r),\rName = rep(c(\u0026quot;bw\u0026quot;, \u0026quot;bS\u0026quot;, \u0026quot;bw\u0026quot;), each = 1e4),\rModel = rep(c(\u0026quot;h2_a\u0026quot;, \u0026quot;h2_b\u0026quot;, \u0026quot;h2_c\u0026quot;), each = 1e4)\r)\rlbls \u0026lt;- c(\rexpression(\u0026quot;Model 1:\u0026quot; ~ beta[W]),\rexpression(\u0026quot;Model 2:\u0026quot; ~ beta[S]),\rexpression(\u0026quot;Model 3:\u0026quot; ~ beta[W])\r)\rggplot(Plot_df, aes(y = Model, x = Posteriors)) +\rstat_halfeye() +\rscale_y_discrete(labels = lbls) +\rlabs(x = \u0026quot;Parameter Estimate\u0026quot;, y = \u0026quot;Implied Conditional Independency\u0026quot;) +\rtheme_bw() +\rgeom_vline(xintercept = 0)\r Session Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] tidybayes_2.3.1 ggdag_0.2.3 dagitty_0.3-1 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] matrixStats_0.61.0 R.cache_0.14.0 tools_4.0.5 backports_1.2.1 bslib_0.2.4 utf8_1.2.1 R6_2.5.0 DBI_1.1.1 colorspace_2.0-0 ## [10] ggdist_2.4.0 withr_2.4.2 tidyselect_1.1.0 gridExtra_2.3 prettyunits_1.1.1 processx_3.5.1 curl_4.3.2 compiler_4.0.5 cli_3.0.0 ## [19] arrayhelpers_1.1-0 labeling_0.4.2 bookdown_0.22 sass_0.3.1 scales_1.1.1 mvtnorm_1.1-1 callr_3.7.0 stringr_1.4.0 digest_0.6.27 ## [28] rmarkdown_2.7 R.utils_2.10.1 pkgconfig_2.0.3 htmltools_0.5.1.1 styler_1.4.1 highr_0.9 rlang_0.4.11 shape_1.4.5 jquerylib_0.1.4 ## [37] farver_2.1.0 generics_0.1.0 svUnit_1.0.6 jsonlite_1.7.2 dplyr_1.0.5 R.oo_1.24.0 distributional_0.2.2 inline_0.3.17 magrittr_2.0.1 ## [46] loo_2.4.1 Rcpp_1.0.7 munsell_0.5.0 fansi_0.4.2 viridis_0.6.0 lifecycle_1.0.0 R.methodsS3_1.8.1 stringi_1.5.3 yaml_2.2.1 ## [55] ggraph_2.0.5 MASS_7.3-53.1 pkgbuild_1.2.0 plyr_1.8.6 grid_4.0.5 ggrepel_0.9.1 forcats_0.5.1 crayon_1.4.1 lattice_0.20-41 ## [64] graphlayouts_0.7.1 knitr_1.33 ps_1.6.0 pillar_1.6.0 igraph_1.2.6 boot_1.3-27 codetools_0.2-18 stats4_4.0.5 glue_1.4.2 ## [73] evaluate_0.14 blogdown_1.3 V8_3.4.1 RcppParallel_5.1.2 vctrs_0.3.7 tweenr_1.0.2 gtable_0.3.0 purrr_0.3.4 polyclip_1.10-0 ## [82] tidyr_1.1.3 rematch2_2.1.2 assertthat_0.2.1 xfun_0.22 ggforce_0.3.3 tidygraph_1.2.0 coda_0.19-4 viridisLite_0.4.0 tibble_3.1.1 ## [91] ellipsis_0.3.2\r ","date":1611792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611853200,"objectID":"cc1c547be7353cf8f169267626e3ac05","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-06/","publishdate":"2021-01-28T00:00:00Z","relpermalink":"/courses/rethinking/chapter-06/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 6 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 06","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our first \u0026ldquo;real\u0026rdquo; practical experience in R. The following notes present you with an example of how data handling (also known as data cleaning) can be done. Obviously, the possibility for flaws to occur in any given data set are seemingly endless and so the following, tedious procedure should be thought of as less of an recipe of how to fix common flaws in biological data sets but make you aware of how important proper data collection and data entry is.\nI have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here.\nPreparing Our Procedure The following three sections are what I consider to be essential parts of the preamble to any R-based analysis. I highly recommend clearly indicating these bits in your code.\nMore often than not, you will use variations of these code chunks whether you are working on data handling, data exploration or full-fledged statistical analyses.\nNecessary Steps For Reproducibility Reproducibility is the be-all and end-all of any statistical analysis, particularly in light of the peer-review process in life sciences.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Once you get into highly complex statistical analyses, you may wish to break up chunks of your analysis into separate documents. To ensure that remnants of an earlier analysis or analysis chunk do not influence the results of your current analysis, you may wish to empty R\u0026rsquo;s cache (Environment) before attempting a new analysis. This is achieved via the command rm(list=ls()).\nNext, you need to remember the importance of soft-coding for the sake of reproducibility. One of the worst offences to the peer-review process in R-based statistics is the erroneous hard-coding of the working directory. The getwd() function shown above solves this exact problem. However, for this workaround to function properly you need to open the code document of interest by double-clicking it within its containing folder.\nWhen using the xlsx package or any Excel-reliant process via R, your code will automatically run a Java process in the background. By default the Java engine is limited as far as RAM allocation goes and tends to fail when faced with enormous data sets. The workaround options(java.parameters = \u0026quot;-Xmx8g\u0026quot;) gets rid of this issue by allocation 8 GBs of RAM to Java.\nPackages Packages are R\u0026rsquo;s way of giving you access to a seemingly infinite repository of functions.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;dplyr\u0026quot; # we need this package to fix the most common data errors\r)\rsapply(package_vec, install.load.package)\r ## Loading required package: dplyr\r ## ## Attaching package: 'dplyr'\r ## The following objects are masked from 'package:stats':\r## ## filter, lag\r ## The following objects are masked from 'package:base':\r## ## intersect, setdiff, setequal, union\r ## dplyr ## TRUE\r Using the above function is way more sophisticated than the usual install.packages() + library() approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.\nLoading The Data Loading data is crucial to any analysis in R. Period.\nR offers a plethora of approaches to data loading and you will usually be taught the read.table() command in basic biostatistics courses. However, I have found to prefer the functionality provided by the xlsx package since most data recording is taking place in Excel. As this package is dependant on the installation of Java and RJava, we will settle on the base R function read.csv().\nData_df_base \u0026lt;- read.csv(file = paste(Dir.Data, \u0026quot;/SparrowData.csv\u0026quot;, sep=\u0026quot;\u0026quot;), header = TRUE)\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Another trick to have up your sleeve (if your RAM enables you to act on it) is to duplicate your initial data onto a new object once loaded into R. This will enable you to easily remedy mistakes in data treatment without having to reload your initial data set from the data file.\nInspecting The Data Once the data is loaded into R, you need to inspect it to make sure it is ready for use.\nAssessing A Data Frame in R Most, if not all, data you will ever load into R will be stored as a data.frame within R. Some of the most important functions for inspecting data frames (\u0026ldquo;df\u0026rdquo; in the following) in base R are the following four:\n dim(df) returns the dimensions (Rows $\\times$ Columns)of the data frame head(df) returns the first 6 rows of the data frame by default (here changed to 4) tail(df) returns the last 6 rows of the data frame by default (here changed to 4) View(df) opens nearly any R object in a separate tab for further inspection. Since we are dealing with an enormous data set here, I will exclude this function for now to save you from printing unnecessary pages.  dim(Data_df)\r ## [1] 1068 21\r head(Data_df, n = 4)\r ## X Site Index Latitude Longitude Climate Population.Status Weight\r## 1 1 Siberia SI 60 100 Continental Native 34,05\r## 2 2 Siberia SI 60 100 Continental Native 34,86\r## 3 3 Siberia SI 60 100 Continental Native 32,34\r## 4 4 Siberia SI 60 100 Continental Native 34,78\r## Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs\r## 1 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA\r## 2 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA\r## 3 12.66 6.64 Black Female Shrub 35.6 1\r## 4 15.09 7.00 Brown Female Shrub 47.75 0\r## Egg.Weight Flock Home.Range Flock.Size Predator.Presence Predator.Type\r## 1 NA B Large 16 Yes Avian\r## 2 NA B Large 16 Yes Avian\r## 3 3.21 C Large 14 Yes Avian\r## 4 NA E Large 10 Yes Avian\r tail(Data_df, n = 4)\r ## X Site Index Latitude Longitude Climate Population.Status\r## 1065 1065 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## 1066 1066 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## 1067 1067 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## 1068 1068 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height\r## 1065 34.25 15.26 7.04 Grey Male ## 1066 31.76 12.78 6.67 Grey Male ## 1067 31.48 12.49 6.63 Black Male ## 1068 31.94 12.96 6.70 Grey Male ## Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size Predator.Presence\r## 1065 A Large 19 Yes\r## 1066 A Large 19 Yes\r## 1067 C Large 18 Yes\r## 1068 A Large 19 Yes\r## Predator.Type\r## 1065 Avian\r## 1066 Avian\r## 1067 Avian\r## 1068 Avian\r When having an initial look at the results of head(Data_df) and tail(Data_df) we can spot two important things:\n NAs in head and tail of our data set are stored differently. This is a common problem with biological data sets and we will deal with this issue extensively in the next few sections of this document. Due to our data loading procedure we ended up with a redundant first column that is simply showing the respective row numbers. However, this is unnecessary in R and so we can delete this column as seen below.  Data_df \u0026lt;- Data_df[,-1] # eliminating the erroneous first column as it is redundant\rdim(Data_df) # checking if the elimination went right\r ## [1] 1068 20\r The Summary() Function As already stated in our seminar series, the summary() function is invaluable to data exploration and data inspection. However, it is only partially applicable as it will not work flawlessly on every class of data. Examples of this are shown below.\nThe weight data contained within our data frame should be numeric and thus pose no issue to the summary() function. However, as shown in the next section, it is currently of type character which leads the summary() function to work improperly.\nsummary(Data_df$Weight)\r ## Length Class Mode ## 1068 character character\r The height data within our data set, on the other hand, is stored correctly as class numeric. Thus the summary() function performs flawlessly.\nsummary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.35 13.52 14.52 15.39 16.22 135.40\r Making data inspection more easy, one may which to automate the use of the summary() function. However, this only makes sense, when every data column is presenting data in the correct class type. Therefore, we will first fix the column classes and then use the summary() command.\nData Cleaning Workflow Identifying Problems Indentifying most problems in any data set you may ever encounter comes down to mostly two manifestations of inadequate data entry or handling:\n**1. Types/Classes **\nBefore even opening a data set, we should know what kind of data classes we expect for every variable (for example, height records as a factor don\u0026rsquo;t make much sense). Problems with data/variable classes can have lasting influence on your analyses and so we need to test the class for each variable (column) individually. Before we alter any column classes, we will first need to identify columns whose classes need fixing. Doing so is as easy applying the class() function to the data contained within every column of our data frame separately.\nR offers multiple functions for this but I find the lapply() function to perform flawlessly as shown below. Since lapply() returns a list of class identifiers and these don\u0026rsquo;t translate well to paper, I have opted to transform the list into a named character vector using the unlist() command. One could also use the str() function.\nunlist(lapply(Data_df, class))\r ## Site Index Latitude Longitude ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;numeric\u0026quot; \u0026quot;numeric\u0026quot; ## Climate Population.Status Weight Height ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;numeric\u0026quot; ## Wing.Chord Colour Sex Nesting.Site ## \u0026quot;numeric\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; ## Nesting.Height Number.of.Eggs Egg.Weight Flock ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; ## Home.Range Flock.Size Predator.Presence Predator.Type ## \u0026quot;character\u0026quot; \u0026quot;integer\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot;\r For further inspection, one may want to combine the information obtained by using the class() function with either the summary() function (for all non-numeric records) or the hist function (particularly useful for numeric records).\n**2. Contents/Values **\nTypos and the like will always lead to some data that simply doesn\u0026rsquo;t make sense given the context of your project. Sometimes, errors like these are salvageable but doing so can be a very difficult process. Before we alter any column contents, we will first need to identify columns whose contents need fixing, however. Doing so is as easy applying an automated version of summary() to the data contained within every column of our data frame separately after having fixed possibly erroneous data classes.\nFixing The Problems Fixing the problems in our data sets always comes down to altering data classes, altering faulty values or removing them entirely.\nTo make sure we fix all problems, we may often wish to enlist the summary() function as well as the hist() function for data inspection and visualisation.\nBefore we alter any column contents, we will first need to identify columns whose contents need fixing.\nOur Data Site Variable Class Expectation: factor (only 11 possible values)\nIdentifying Problems Let\u0026rsquo;s asses our Site records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Site)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Site)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nIndex Variable Class Expectation: factor (only 11 possible values)\nIdentifying Problems Let\u0026rsquo;s asses our Index records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Index)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Index)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to. Pay attention that thes shortened index numbers lign up with the numbers of site records!\nFixing Problems We don\u0026rsquo;t need to fix anything here.\n\\newpage\nLatitude Variable Class Expectation: numeric (Latitude is inherently continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Latitude records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Latitude)\r ## [1] \u0026quot;numeric\u0026quot;\r table(Data_df$Latitude) # use this instead of summary due to station-dependency here\r ## ## -51.75 -25 -21.1 4 10.5 17.25 31 54 55 60 70 ## 69 88 95 250 114 105 81 68 68 66 64\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nLongitude Variable Class Expectation: numeric (Longitude is inherently continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Longitude records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Longitude)\r ## [1] \u0026quot;numeric\u0026quot;\r table(Data_df$Longitude) # use this instead of summary due to station-dependency here\r ## ## -97 -92 -90 -88.75 -67 -59.17 -53 -2 55.6 100 135 ## 68 81 64 105 114 69 250 68 95 66 88\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nClimate Variable Class Expectation: factor (three levels: coastal, semi-coastal, continental)\nIdentifying Problems Let\u0026rsquo;s asses our Climate records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Climate)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Climate)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPopulation Status Variable Class Expectation: factor (two levels: native, introduced)\nIdentifying Problems Let\u0026rsquo;s asses our Population Status records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Population.Status)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Population.Status)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nWeight Variable Class Expectation: numeric (weight is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Weight records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Weight)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Weight)\r ## Length Class Mode ## 1068 character character\r Obviously, something is wrong.\nFixing Problems As seen above, weight records are currently stored as character which they shouldn\u0026rsquo;t. So how do we fix this?\nFirstly, let\u0026rsquo;s try an intuitive as.numeric() approach which attempts to convert all values contained within a vector into numeric records.\nData_df$Weight \u0026lt;- as.numeric(Data_df_base$Weight)\r ## Warning: NAs introduced by coercion\r summary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 26.34 30.38 29.40 31.87 420.00 66\r Apparently, this didn\u0026rsquo;t do the trick since weight data values (recorded in g) below 13 and above 40 are highly unlikely for Passer domesticus.\nSometimes, the as.numeric() can be made more powerful by handing it data of class character. To do so, simply combine as.numeric() with as.character() as shown below.\nData_df$Weight \u0026lt;- as.numeric(as.character(Data_df_base$Weight))\r ## Warning: NAs introduced by coercion\r summary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 26.34 30.38 29.40 31.87 420.00 66\r That still didn\u0026rsquo;t resolve our problem. Weight measurements were taken for all study organisms and so there shouldn\u0026rsquo;t be any NAs and yet we find 66.\nInterestingly enough this is the exact same number as observations available for Siberia. A closer look at the data frame shows us that weight data for Siberia has been recorded with commas as decimal delimiters whilst the rest of the data set utilises dots.\nFixing this is not necessarily difficult but it is an erroneous issue for data handling which comes up often and is easy to avoid. Getting rid of the flaws is as simple as using the gsub() function contained within the dplyr package.\nData_df$Weight \u0026lt;- as.numeric(gsub(pattern = \u0026quot;,\u0026quot;, replacement = \u0026quot;.\u0026quot;, x = Data_df_base$Weight))\rsummary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 19.38 27.90 30.63 29.69 32.24 420.00\r There is one data record left hat exceeds the biologically viable span for body weight records of Passer domesticus. This data record holds the value 420. Since this is unlikely to be a simple mistake of placing the decimal delimiter in the wrong place (both 4.2 and 42 grams are also not feasible weight records for house sparrows), we have to delete the weight data record in question:\nData_df$Weight[which(Data_df_base$Weight == 420)] \u0026lt;- NA summary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 27.89 30.63 29.33 32.23 36.66 1\r hist(Data_df$Weight, breaks = 100)\r We finally fixed it!\nHeight Variable Class Expectation: numeric (height is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Height records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Height)\r ## [1] \u0026quot;numeric\u0026quot;\r summary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.35 13.52 14.52 15.39 16.22 135.40\r Again, some of our data don\u0026rsquo;t behave the way the should (a 135.4 or 1.35 cm tall sparrow are just absurd).\nFixing Problems Height (or \u0026ldquo;Length\u0026rdquo;) records of Passer domesticus should fall roughly between 10cm and 22cm. Looking at the data which exceed these thresholds, it is apparent that these are generated simply through misplaced decimal delimiters. So we fix them as follows and use a histogram to check if it worked.\nData_df$Height[which(Data_df$Height \u0026lt; 10)] # decimal point placed wrong here\r ## [1] 1.350 1.446\r Data_df$Height[which(Data_df$Height \u0026lt; 10)] \u0026lt;- Data_df$Height[which(Data_df$Height \u0026lt; 10)] * 10 # FIXED IT!\rData_df$Height[which(Data_df$Height \u0026gt; 22)] # decimal point placed wrong here\r ## [1] 126.7 135.4\r Data_df$Height[which(Data_df$Height \u0026gt; 22)] \u0026lt;- Data_df$Height[which(Data_df$Height \u0026gt; 22)]/10 # FIXED IT!\rsummary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 11.09 13.52 14.51 15.20 16.20 21.68\r hist(Data_df$Height, breaks = 100)\r We finally fixed it!\nWing Chord Variable Class Expectation: numeric (wing chord is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Wing Chord records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Wing.Chord)\r ## [1] \u0026quot;numeric\u0026quot;\r summary(Data_df$Wing.Chord)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 6.410 6.840 7.050 7.337 7.400 9.000\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nColour Variable Class Expectation: factor (three levels: black, grey, brown)\nIdentifying Problems Let\u0026rsquo;s asses our Colour records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Colour)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Colour)\r ## Length Class Mode ## 1068 character character\r Some of the colour records are very odd.\nFixing Problems The colour records \u0026ldquo;Bright black\u0026rdquo; and \u0026ldquo;Grey with black spots\u0026rdquo; should be \u0026ldquo;Grey\u0026rdquo;. Someone clearly got too eager on the assignment of colours here. The fix is as easy as identifying the data records which are \u0026ldquo;too precise\u0026rdquo; and overwrite them with the correct assignment:\nData_df$Colour[which(Data_df$Colour == \u0026quot;Bright black\u0026quot;)] \u0026lt;- \u0026quot;Grey\u0026quot;\rData_df$Colour[which(Data_df$Colour == \u0026quot;Grey with black spots\u0026quot;)] \u0026lt;- \u0026quot;Grey\u0026quot;\rData_df$Colour \u0026lt;- droplevels(factor(Data_df$Colour)) # drop unused factor levels\rsummary(Data_df$Colour) # FIXED IT!\r ## Black Brown Grey ## 356 298 414\r We finally fixed it!\nSex Variable Class Expectation: factor (two levels: male and female)\nIdentifying Problems Let\u0026rsquo;s asses our Climate records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Sex)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Sex)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nNesting Site Variable Class Expectation: factor (two levels: shrub and tree)\nIdentifying Problems Let\u0026rsquo;s asses our Nesting Site records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Nesting.Site)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Nesting.Site)\r ## Length Class Mode ## 1068 character character\r Fixing Problems One individual is recording to be nesting on the ground. This is something house sparrows don\u0026rsquo;t do. Therefore, we have to assume that this individual is not even a Passer domesticus to begin with.\nThe only way to solve this is to remove all observations pertaining to this individual:\nData_df \u0026lt;- Data_df[-which(Data_df$Nesting.Site == \u0026quot;Ground\u0026quot;), ]\rsummary(Data_df$Nesting.Site)\r ## Length Class Mode ## 1067 character character\r We just deleted a data record. This affects the flock size of the flock it belongs to (basically, this column contains hard-coded values) which we are going to deal with later.\nStill, there are manually entered NA records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The nesting site for a data record where sex reads \u0026ldquo;Male\u0026rdquo; has to be NA.\nData_df$Nesting.Site[which(Data_df$Sex == \u0026quot;Male\u0026quot;)] \u0026lt;- NA Data_df$Nesting.Site \u0026lt;- droplevels(factor(Data_df$Nesting.Site)) # drop unused factor levels\rsummary(Data_df$Nesting.Site)# FIXED IT!\r ## Shrub Tree NA's ## 292 231 544\r Nesting Height Variable Class Expectation: numeric (continuous records in two clusters corresponding to shrubs and trees)\nIdentifying Problems Let\u0026rsquo;s asses our Nesting Height records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Nesting.Height)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Nesting.Height)\r ## Length Class Mode ## 1067 character character\r There are obviously some issues here.\nFixing Problems Nesting height is a clear example of a variable that should be recorded as numeric and yet our data frame currently stores them as character.\nOur first approach to fixing this, again, is using the as.numeric() function.\nsummary(as.numeric(Data_df$Nesting.Height))\r ## Warning in summary(as.numeric(Data_df$Nesting.Height)): NAs introduced by\r## coercion\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 11.78 42.34 64.85 480.59 951.38 1950.86 544\r Clearly, something went horribly wrong here. When taking a closer look, the number of 1s is artificially inflated. This is due to the NAs contained within the data set. These are currently stored as characters since they have been entered into the Excel sheet itself. The as.numeric() function transforms these into 1s.\nOne way of circumventing this issue is to combine the as.numeric() function with the as.character() function.\nData_df$Nesting.Height \u0026lt;- as.numeric(as.character(Data_df$Nesting.Height))\r ## Warning: NAs introduced by coercion\r summary(Data_df$Nesting.Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 11.78 42.34 64.85 480.59 951.38 1950.86 544\r This quite clearly fixed our problems.\nNumber of Eggs Variable Class Expectation: numeric (no a priori knowledge of levels)\nIdentifying Problems Let\u0026rsquo;s asses our Number of Eggs records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Number.of.Eggs)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Number.of.Eggs)\r ## Length Class Mode ## 1067 character character\r One very out of the ordinary record is to be seen.\nFixing Problems Number of eggs is another variable which should be recorded as numeric and yet is currently stored as character.\nOur first approach to fixing this, again, is using the as.numeric() function.\nsummary(as.numeric(Data_df$Number.of.Eggs))\r ## Warning in summary(as.numeric(Data_df$Number.of.Eggs)): NAs introduced by\r## coercion\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 0.000 2.000 3.000 3.746 4.000 10.000 544\r Again, this didn\u0026rsquo;t do the trick. The number of 1s might be inflated and we expect exactly 544 (number of males) NAs since number of eggs have only been recorded for female house sparrows.\nWe already know that improperly stored NA records are prone to causing an inflation of data records of value 1. We also remember that head and tail of our data frame hold different types of NA records. Let\u0026rsquo;s find out who entered NAs correctly:\nunique(Data_df$Site[which(is.na(Data_df$Egg.Weight))])\r ## character(0)\r The code above identifies the sites at which proper NA recording has been done. The Falkland Isle team did it right (NA fields in Excel were left blank). Fixing this is actually a bit more challenging and so we do the following:\n# make everything into characters\rData_df$Number.of.Eggs \u0026lt;- as.character(Data_df$Number.of.Eggs) # writing character NA onto actual NAs\rData_df$Number.of.Eggs[which(is.na(Data_df$Number.of.Eggs))] \u0026lt;- \u0026quot; NA\u0026quot;\r# make all character NAs into proper NAs\rData_df$Number.of.Eggs[Data_df$Number.of.Eggs == \u0026quot; NA\u0026quot;] \u0026lt;- NA # make everything numeric\rData_df$Number.of.Eggs \u0026lt;- as.numeric(as.character(Data_df$Number.of.Eggs))\r ## Warning: NAs introduced by coercion\r summary(Data_df$Number.of.Eggs)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 0.000 2.000 3.000 3.746 4.000 10.000 544\r We did it!\nEgg Weight Variable Class Expectation: numeric (another weight measurement that needs to be continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Egg Weight records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Egg.Weight)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Egg.Weight)\r ## Length Class Mode ## 1067 character character\r Fixing Problems Egg weight should be recorded as numeric and yet is currently stored as character. Our first approach to fixing this, again, is using the as.numeric() function again.\nsummary(as.numeric(Data_df$Egg.Weight))\r ## Warning in summary(as.numeric(Data_df$Egg.Weight)): NAs introduced by coercion\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 1.580 2.340 2.670 2.619 2.890 3.590 590\r Something is wrong here. Not enough NAs are recorded. We expect exactly 590 NAs (Number of males + Number of Females with zero eggs). Additionally, there are way too many 1s. Our problem, again, lies with the way the NAs have been entered into the data set from the beginning and so we use the following fix again.\n# make everything into characters\rData_df$Egg.Weight \u0026lt;- as.character(Data_df$Egg.Weight) # writing character NA onto actual NAs\rData_df$Egg.Weight[which(is.na(Data_df$Egg.Weight))] \u0026lt;- \u0026quot; NA\u0026quot; # make all character NAs into proper NAs\rData_df$Egg.Weight[Data_df$Egg.Weight == \u0026quot; NA\u0026quot;] \u0026lt;- NA # make everything numeric\rData_df$Egg.Weight \u0026lt;- as.numeric(as.character(Data_df$Egg.Weight))\rsummary(Data_df$Egg.Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 1.580 2.340 2.670 2.619 2.890 3.590 590\r Flock Variable Class Expectation: factor (each sparrow was assigned to one particular flock)\nIdentifying Problems Let\u0026rsquo;s asses our Flock records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Flock)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Flock)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nHome Range Variable Class Expectation: factor (three levels: small, medium, large)\nIdentifying Problems Let\u0026rsquo;s asses our Home Range records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Home.Range)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Home.Range)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nFlock Size Variable Class Expectation: numeric (continuous measurement of how many sparrows are in each flock - measured as integers)\nIdentifying Problems Let\u0026rsquo;s asses our Flock Size records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Flock.Size)\r ## [1] \u0026quot;integer\u0026quot;\r summary(Data_df$Flock.Size)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 7.00 16.00 19.00 25.81 31.00 58.00\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPredator Presence Variable Class Expectation: factor (two levels: yes and no)\nIdentifying Problems Let\u0026rsquo;s asses our Predator Presence records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Predator.Presence)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Predator.Presence)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPredator Type Variable Class Expectation: factor (three levels: Avian, Non-Avian, and NA)\nIdentifying Problems Let\u0026rsquo;s asses our Predator Type records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Predator.Type)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Predator.Type)\r ## Length Class Mode ## 1067 character character\r Something doesn\u0026rsquo;t sit well here.\nFixing Problems Someone got overly eager when recording Predator Type and specified the presence of a hawk instead of taking down \u0026ldquo;Avian\u0026rdquo;. We fix this as follows:\nData_df$Predator.Type[which(Data_df$Predator.Type == \u0026quot;Hawk\u0026quot;)] \u0026lt;- \u0026quot;Avian\u0026quot;\rsummary(Data_df$Predator.Type)\r ## Length Class Mode ## 1067 character character\r This fixed it but there are still manually entered NA records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The predator type for a data record where predator presence reads \u0026ldquo;No\u0026rdquo; has to be NA.\nData_df$Predator.Type[which(Data_df$Predator.Presence == \u0026quot;No\u0026quot;)] \u0026lt;- NA Data_df$Predator.Type \u0026lt;- droplevels(factor(Data_df$Predator.Type)) # drop unused factor levels\rsummary(Data_df$Predator.Type)# FIXED IT!\r ## Avian Non-Avian NA's ## 490 220 357\r Redundant Data Our data contains redundant columns (i.e.: columns whose data is present in another column already). These are (1) Flock Size (data contained in Flock column) and (2) Flock.Size (data contained in Index column). The fix to this is as easy as removing the columns in question.\nData_df \u0026lt;- within(Data_df, rm(Flock.Size, Site))\rdim(Data_df)\r ## [1] 1067 18\r Fixed it!\nBy doing so, we have gotten rid of our flock size problem stemming from the deletion of a data record. You could also argue that the columns Site and Index are redundant. We keep both for quality-of-life when interpreting our results (make use of Sites) and coding (make use os Index).\nSaving The Fixed Data Set We fixed out entire data set! The data set is now ready for use.\nKeep in mind that the data set I provided you with was relatively clean and real-world messy data sets can be far more difficult to clean up.\nBefore going forth, we need to save it. Attention: don\u0026rsquo;t overwrite your initial data file!\nFinal Check Before exporting you may want to ensure that everything is in order and do a final round of data inspection. This can be achieved by running the automated summary() command from earlier again as follows. I am not including the output here to save some space.\nfor(i in 1:dim(Data_df)[2]){\rprint(colnames(Data_df)[i])\rprint(summary(Data_df[,i]))\rprint(\u0026quot;------------------------------------------------------\u0026quot;)\r}\r Everything checks out. Let\u0026rsquo;s save our final data frame.\nExporting The Altered Data Since Excel is readily available for viewing data outside of R, I like to save my final data set in excel format as can be seen below. Additionally, I recommend saving your final data frame as an RDS file. These are R specific data files which you will not be able to alter outside of R thus saving yourself from accidentally changing records when only trying to view your data. On top of that, RDS files take up less space than either Excel or TXT files do.\n# saving in excel sheet\rwrite.csv(Data_df, file = paste(Dir.Data, \u0026quot;/SparrowData_FIXED.csv\u0026quot;, sep=\u0026quot;\u0026quot;))\r# saving as R data frame object\rsaveRDS(Data_df, file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))  ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"20d25011c2271708dc2e70306a51e9b9","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/data-handling-and-data-mining/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/data-handling-and-data-mining/","section":"courses","summary":"Welcome to our first \"real\" practical experience in `R`. The following notes present you with an example of how data handling (also known as data cleaning) can be done. Obviously, the possibility for flaws to occur in any given data set are seemingly endless and so the following, tedious procedure should be thought of as less of an recipe of how to fix common flaws in biological data sets but make you aware of how important proper data collection and data entry is.","tags":["R","Statistics"],"title":"Data Handling and Data Mining","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our first \u0026ldquo;real\u0026rdquo; practical experience in R. The following notes present you with an example of how data handling (also known as data cleaning) can be done. Obviously, the possibility for flaws to occur in any given data set are seemingly endless and so the following, tedious procedure should be thought of as less of an recipe of how to fix common flaws in biological data sets but make you aware of how important proper data collection and data entry is. I have prepared some slides for this session: \nData Find the data for this exercise here.\nPreparing Our Procedure The following three sections are what I consider to be essential parts of the preamble to any R-based analysis. I highly recommend clearly indicating these bits in your code.\nMore often than not, you will use variations of these code chunks whether you are working on data handling, data exploration or full-fledged statistical analyses.\nNecessary Steps For Reproducibility Reproducibility is the be-all and end-all of any statistical analysis, particularly in light of the peer-review process in life sciences.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Once you get into highly complex statistical analyses, you may wish to break up chunks of your analysis into separate documents. To ensure that remnants of an earlier analysis or analysis chunk do not influence the results of your current analysis, you may wish to empty R\u0026rsquo;s cache (Environment) before attempting a new analysis. This is achieved via the command rm(list=ls()).\nNext, you need to remember the importance of soft-coding for the sake of reproducibility. One of the worst offences to the peer-review process in R-based statistics is the erroneous hard-coding of the working directory. The getwd() function shown above solves this exact problem. However, for this workaround to function properly you need to open the code document of interest by double-clicking it within its containing folder.\nWhen using the xlsx package or any Excel-reliant process via R, your code will automatically run a Java process in the background. By default the Java engine is limited as far as RAM allocation goes and tends to fail when faced with enormous data sets. The workaround options(java.parameters = \u0026quot;-Xmx8g\u0026quot;) gets rid of this issue by allocation 8 GBs of RAM to Java.\nPackages Packages are R\u0026rsquo;s way of giving you access to a seemingly infinite repository of functions.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;dplyr\u0026quot; # we need this package to fix the most common data errors\r)\rsapply(package_vec, install.load.package)\r ## Loading required package: dplyr\r ## ## Attaching package: 'dplyr'\r ## The following objects are masked from 'package:stats':\r## ## filter, lag\r ## The following objects are masked from 'package:base':\r## ## intersect, setdiff, setequal, union\r ## dplyr ## TRUE\r Using the above function is way more sophisticated than the usual install.packages() + library() approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.\nLoading The Data Loading data is crucial to any analysis in R. Period.\nR offers a plethora of approaches to data loading and you will usually be taught the read.table() command in basic biostatistics courses. However, I have found to prefer the functionality provided by the xlsx package since most data recording is taking place in Excel. As this package is dependant on the installation of Java and RJava, we will settle on the base R function read.csv().\n# Data_df_base \u0026lt;- read.csv(file = paste(Dir.Data, \u0026quot;/SparrowData.csv\u0026quot;, sep=\u0026quot;\u0026quot;), header = TRUE)\rData_df_base \u0026lt;- read.csv(\u0026quot;https://github.com/ErikKusch/Homepage/raw/master/content/courses/biostat101/Data/SparrowData.csv\u0026quot;, header = TRUE)\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Another trick to have up your sleeve (if your RAM enables you to act on it) is to duplicate your initial data onto a new object once loaded into R. This will enable you to easily remedy mistakes in data treatment without having to reload your initial data set from the data file.\nInspecting The Data Once the data is loaded into R, you need to inspect it to make sure it is ready for use.\nAssessing A Data Frame in R Most, if not all, data you will ever load into R will be stored as a data.frame within R. Some of the most important functions for inspecting data frames (\u0026ldquo;df\u0026rdquo; in the following) in base R are the following four:\n dim(df) returns the dimensions (Rows $\\times$ Columns)of the data frame head(df) returns the first 6 rows of the data frame by default (here changed to 4) tail(df) returns the last 6 rows of the data frame by default (here changed to 4) View(df) opens nearly any R object in a separate tab for further inspection. Since we are dealing with an enormous data set here, I will exclude this function for now to save you from printing unnecessary pages.  dim(Data_df)\r ## [1] 1068 21\r head(Data_df, n = 4)\r ## X Site Index Latitude Longitude Climate Population.Status Weight\r## 1 1 Siberia SI 60 100 Continental Native 34,05\r## 2 2 Siberia SI 60 100 Continental Native 34,86\r## 3 3 Siberia SI 60 100 Continental Native 32,34\r## 4 4 Siberia SI 60 100 Continental Native 34,78\r## Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs\r## 1 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA\r## 2 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA\r## 3 12.66 6.64 Black Female Shrub 35.6 1\r## 4 15.09 7.00 Brown Female Shrub 47.75 0\r## Egg.Weight Flock Home.Range Flock.Size Predator.Presence Predator.Type\r## 1 NA B Large 16 Yes Avian\r## 2 NA B Large 16 Yes Avian\r## 3 3.21 C Large 14 Yes Avian\r## 4 NA E Large 10 Yes Avian\r tail(Data_df, n = 4)\r ## X Site Index Latitude Longitude Climate Population.Status\r## 1065 1065 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## 1066 1066 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## 1067 1067 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## 1068 1068 Falkland Isles FI -51.75 -59.17 Coastal Introduced\r## Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height\r## 1065 34.25 15.26 7.04 Grey Male ## 1066 31.76 12.78 6.67 Grey Male ## 1067 31.48 12.49 6.63 Black Male ## 1068 31.94 12.96 6.70 Grey Male ## Number.of.Eggs Egg.Weight Flock Home.Range Flock.Size Predator.Presence\r## 1065 A Large 19 Yes\r## 1066 A Large 19 Yes\r## 1067 C Large 18 Yes\r## 1068 A Large 19 Yes\r## Predator.Type\r## 1065 Avian\r## 1066 Avian\r## 1067 Avian\r## 1068 Avian\r When having an initial look at the results of head(Data_df) and tail(Data_df) we can spot two important things:\n NAs in head and tail of our data set are stored differently. This is a common problem with biological data sets and we will deal with this issue extensively in the next few sections of this document. Due to our data loading procedure we ended up with a redundant first column that is simply showing the respective row numbers. However, this is unnecessary in R and so we can delete this column as seen below.  Data_df \u0026lt;- Data_df[,-1] # eliminating the erroneous first column as it is redundant\rdim(Data_df) # checking if the elimination went right\r ## [1] 1068 20\r The Summary() Function As already stated in our seminar series, the summary() function is invaluable to data exploration and data inspection. However, it is only partially applicable as it will not work flawlessly on every class of data. Examples of this are shown below.\nThe weight data contained within our data frame should be numeric and thus pose no issue to the summary() function. However, as shown in the next section, it is currently of type character which leads the summary() function to work improperly.\nsummary(Data_df$Weight)\r ## Length Class Mode ## 1068 character character\r The height data within our data set, on the other hand, is stored correctly as class numeric. Thus the summary() function performs flawlessly.\nsummary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.35 13.52 14.52 15.39 16.22 135.40\r Making data inspection more easy, one may which to automate the use of the summary() function. However, this only makes sense, when every data column is presenting data in the correct class type. Therefore, we will first fix the column classes and then use the summary() command.\nData Cleaning Workflow Identifying Problems Indentifying most problems in any data set you may ever encounter comes down to mostly two manifestations of inadequate data entry or handling:\n**1. Types/Classes **\nBefore even opening a data set, we should know what kind of data classes we expect for every variable (for example, height records as a factor don\u0026rsquo;t make much sense). Problems with data/variable classes can have lasting influence on your analyses and so we need to test the class for each variable (column) individually. Before we alter any column classes, we will first need to identify columns whose classes need fixing. Doing so is as easy applying the class() function to the data contained within every column of our data frame separately.\nR offers multiple functions for this but I find the lapply() function to perform flawlessly as shown below. Since lapply() returns a list of class identifiers and these don\u0026rsquo;t translate well to paper, I have opted to transform the list into a named character vector using the unlist() command. One could also use the str() function.\nunlist(lapply(Data_df, class))\r ## Site Index Latitude Longitude ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;numeric\u0026quot; \u0026quot;numeric\u0026quot; ## Climate Population.Status Weight Height ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;numeric\u0026quot; ## Wing.Chord Colour Sex Nesting.Site ## \u0026quot;numeric\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; ## Nesting.Height Number.of.Eggs Egg.Weight Flock ## \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot; ## Home.Range Flock.Size Predator.Presence Predator.Type ## \u0026quot;character\u0026quot; \u0026quot;integer\u0026quot; \u0026quot;character\u0026quot; \u0026quot;character\u0026quot;\r For further inspection, one may want to combine the information obtained by using the class() function with either the summary() function (for all non-numeric records) or the hist function (particularly useful for numeric records).\n**2. Contents/Values **\nTypos and the like will always lead to some data that simply doesn\u0026rsquo;t make sense given the context of your project. Sometimes, errors like these are salvageable but doing so can be a very difficult process. Before we alter any column contents, we will first need to identify columns whose contents need fixing, however. Doing so is as easy applying an automated version of summary() to the data contained within every column of our data frame separately after having fixed possibly erroneous data classes.\nFixing The Problems Fixing the problems in our data sets always comes down to altering data classes, altering faulty values or removing them entirely.\nTo make sure we fix all problems, we may often wish to enlist the summary() function as well as the hist() function for data inspection and visualisation.\nBefore we alter any column contents, we will first need to identify columns whose contents need fixing.\nOur Data Site Variable Class Expectation: factor (only 11 possible values)\nIdentifying Problems Let\u0026rsquo;s asses our Site records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Site)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Site)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nIndex Variable Class Expectation: factor (only 11 possible values)\nIdentifying Problems Let\u0026rsquo;s asses our Index records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Index)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Index)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to. Pay attention that thes shortened index numbers lign up with the numbers of site records!\nFixing Problems We don\u0026rsquo;t need to fix anything here.\n\\newpage\nLatitude Variable Class Expectation: numeric (Latitude is inherently continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Latitude records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Latitude)\r ## [1] \u0026quot;numeric\u0026quot;\r table(Data_df$Latitude) # use this instead of summary due to station-dependency here\r ## ## -51.75 -25 -21.1 4 10.5 17.25 31 54 55 60 70 ## 69 88 95 250 114 105 81 68 68 66 64\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nLongitude Variable Class Expectation: numeric (Longitude is inherently continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Longitude records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Longitude)\r ## [1] \u0026quot;numeric\u0026quot;\r table(Data_df$Longitude) # use this instead of summary due to station-dependency here\r ## ## -97 -92 -90 -88.75 -67 -59.17 -53 -2 55.6 100 135 ## 68 81 64 105 114 69 250 68 95 66 88\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nClimate Variable Class Expectation: factor (three levels: coastal, semi-coastal, continental)\nIdentifying Problems Let\u0026rsquo;s asses our Climate records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Climate)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Climate)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPopulation Status Variable Class Expectation: factor (two levels: native, introduced)\nIdentifying Problems Let\u0026rsquo;s asses our Population Status records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Population.Status)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Population.Status)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nWeight Variable Class Expectation: numeric (weight is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Weight records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Weight)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Weight)\r ## Length Class Mode ## 1068 character character\r Obviously, something is wrong.\nFixing Problems As seen above, weight records are currently stored as character which they shouldn\u0026rsquo;t. So how do we fix this?\nFirstly, let\u0026rsquo;s try an intuitive as.numeric() approach which attempts to convert all values contained within a vector into numeric records.\nData_df$Weight \u0026lt;- as.numeric(Data_df_base$Weight)\r ## Warning: NAs introduced by coercion\r summary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 26.34 30.38 29.40 31.87 420.00 66\r Apparently, this didn\u0026rsquo;t do the trick since weight data values (recorded in g) below 13 and above 40 are highly unlikely for Passer domesticus.\nSometimes, the as.numeric() can be made more powerful by handing it data of class character. To do so, simply combine as.numeric() with as.character() as shown below.\nData_df$Weight \u0026lt;- as.numeric(as.character(Data_df_base$Weight))\r ## Warning: NAs introduced by coercion\r summary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 26.34 30.38 29.40 31.87 420.00 66\r That still didn\u0026rsquo;t resolve our problem. Weight measurements were taken for all study organisms and so there shouldn\u0026rsquo;t be any NAs and yet we find 66.\nInterestingly enough this is the exact same number as observations available for Siberia. A closer look at the data frame shows us that weight data for Siberia has been recorded with commas as decimal delimiters whilst the rest of the data set utilises dots.\nFixing this is not necessarily difficult but it is an erroneous issue for data handling which comes up often and is easy to avoid. Getting rid of the flaws is as simple as using the gsub() function contained within the dplyr package.\nData_df$Weight \u0026lt;- as.numeric(gsub(pattern = \u0026quot;,\u0026quot;, replacement = \u0026quot;.\u0026quot;, x = Data_df_base$Weight))\rsummary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 19.38 27.90 30.63 29.69 32.24 420.00\r There is one data record left hat exceeds the biologically viable span for body weight records of Passer domesticus. This data record holds the value 420. Since this is unlikely to be a simple mistake of placing the decimal delimiter in the wrong place (both 4.2 and 42 grams are also not feasible weight records for house sparrows), we have to delete the weight data record in question:\nData_df$Weight[which(Data_df_base$Weight == 420)] \u0026lt;- NA summary(Data_df$Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 19.38 27.89 30.63 29.33 32.23 36.66 1\r hist(Data_df$Weight, breaks = 100)\r We finally fixed it!\nHeight Variable Class Expectation: numeric (height is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Height records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Height)\r ## [1] \u0026quot;numeric\u0026quot;\r summary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.35 13.52 14.52 15.39 16.22 135.40\r Again, some of our data don\u0026rsquo;t behave the way the should (a 135.4 or 1.35 cm tall sparrow are just absurd).\nFixing Problems Height (or \u0026ldquo;Length\u0026rdquo;) records of Passer domesticus should fall roughly between 10cm and 22cm. Looking at the data which exceed these thresholds, it is apparent that these are generated simply through misplaced decimal delimiters. So we fix them as follows and use a histogram to check if it worked.\nData_df$Height[which(Data_df$Height \u0026lt; 10)] # decimal point placed wrong here\r ## [1] 1.350 1.446\r Data_df$Height[which(Data_df$Height \u0026lt; 10)] \u0026lt;- Data_df$Height[which(Data_df$Height \u0026lt; 10)] * 10 # FIXED IT!\rData_df$Height[which(Data_df$Height \u0026gt; 22)] # decimal point placed wrong here\r ## [1] 126.7 135.4\r Data_df$Height[which(Data_df$Height \u0026gt; 22)] \u0026lt;- Data_df$Height[which(Data_df$Height \u0026gt; 22)]/10 # FIXED IT!\rsummary(Data_df$Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 11.09 13.52 14.51 15.20 16.20 21.68\r hist(Data_df$Height, breaks = 100)\r We finally fixed it!\nWing Chord Variable Class Expectation: numeric (wing chord is a continuous metric)\nIdentifying Problems Let\u0026rsquo;s asses our Wing Chord records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Wing.Chord)\r ## [1] \u0026quot;numeric\u0026quot;\r summary(Data_df$Wing.Chord)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 6.410 6.840 7.050 7.337 7.400 9.000\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nColour Variable Class Expectation: factor (three levels: black, grey, brown)\nIdentifying Problems Let\u0026rsquo;s asses our Colour records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Colour)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Colour)\r ## Length Class Mode ## 1068 character character\r Some of the colour records are very odd.\nFixing Problems The colour records \u0026ldquo;Bright black\u0026rdquo; and \u0026ldquo;Grey with black spots\u0026rdquo; should be \u0026ldquo;Grey\u0026rdquo;. Someone clearly got too eager on the assignment of colours here. The fix is as easy as identifying the data records which are \u0026ldquo;too precise\u0026rdquo; and overwrite them with the correct assignment:\nData_df$Colour[which(Data_df$Colour == \u0026quot;Bright black\u0026quot;)] \u0026lt;- \u0026quot;Grey\u0026quot;\rData_df$Colour[which(Data_df$Colour == \u0026quot;Grey with black spots\u0026quot;)] \u0026lt;- \u0026quot;Grey\u0026quot;\rData_df$Colour \u0026lt;- droplevels(factor(Data_df$Colour)) # drop unused factor levels\rsummary(Data_df$Colour) # FIXED IT!\r ## Black Brown Grey ## 356 298 414\r We finally fixed it!\nSex Variable Class Expectation: factor (two levels: male and female)\nIdentifying Problems Let\u0026rsquo;s asses our Climate records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Sex)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Sex)\r ## Length Class Mode ## 1068 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nNesting Site Variable Class Expectation: factor (two levels: shrub and tree)\nIdentifying Problems Let\u0026rsquo;s asses our Nesting Site records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Nesting.Site)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Nesting.Site)\r ## Length Class Mode ## 1068 character character\r Fixing Problems One individual is recording to be nesting on the ground. This is something house sparrows don\u0026rsquo;t do. Therefore, we have to assume that this individual is not even a Passer domesticus to begin with.\nThe only way to solve this is to remove all observations pertaining to this individual:\nData_df \u0026lt;- Data_df[-which(Data_df$Nesting.Site == \u0026quot;Ground\u0026quot;), ]\rsummary(Data_df$Nesting.Site)\r ## Length Class Mode ## 1067 character character\r We just deleted a data record. This affects the flock size of the flock it belongs to (basically, this column contains hard-coded values) which we are going to deal with later.\nStill, there are manually entered NA records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The nesting site for a data record where sex reads \u0026ldquo;Male\u0026rdquo; has to be NA.\nData_df$Nesting.Site[which(Data_df$Sex == \u0026quot;Male\u0026quot;)] \u0026lt;- NA Data_df$Nesting.Site \u0026lt;- droplevels(factor(Data_df$Nesting.Site)) # drop unused factor levels\rsummary(Data_df$Nesting.Site)# FIXED IT!\r ## Shrub Tree NA's ## 292 231 544\r Nesting Height Variable Class Expectation: numeric (continuous records in two clusters corresponding to shrubs and trees)\nIdentifying Problems Let\u0026rsquo;s asses our Nesting Height records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Nesting.Height)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Nesting.Height)\r ## Length Class Mode ## 1067 character character\r There are obviously some issues here.\nFixing Problems Nesting height is a clear example of a variable that should be recorded as numeric and yet our data frame currently stores them as character.\nOur first approach to fixing this, again, is using the as.numeric() function.\nsummary(as.numeric(Data_df$Nesting.Height))\r ## Warning in summary(as.numeric(Data_df$Nesting.Height)): NAs introduced by\r## coercion\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 11.78 42.34 64.85 480.59 951.38 1950.86 544\r Clearly, something went horribly wrong here. When taking a closer look, the number of 1s is artificially inflated. This is due to the NAs contained within the data set. These are currently stored as characters since they have been entered into the Excel sheet itself. The as.numeric() function transforms these into 1s.\nOne way of circumventing this issue is to combine the as.numeric() function with the as.character() function.\nData_df$Nesting.Height \u0026lt;- as.numeric(as.character(Data_df$Nesting.Height))\r ## Warning: NAs introduced by coercion\r summary(Data_df$Nesting.Height)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 11.78 42.34 64.85 480.59 951.38 1950.86 544\r This quite clearly fixed our problems.\nNumber of Eggs Variable Class Expectation: numeric (no a priori knowledge of levels)\nIdentifying Problems Let\u0026rsquo;s asses our Number of Eggs records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Number.of.Eggs)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Number.of.Eggs)\r ## Length Class Mode ## 1067 character character\r One very out of the ordinary record is to be seen.\nFixing Problems Number of eggs is another variable which should be recorded as numeric and yet is currently stored as character.\nOur first approach to fixing this, again, is using the as.numeric() function.\nsummary(as.numeric(Data_df$Number.of.Eggs))\r ## Warning in summary(as.numeric(Data_df$Number.of.Eggs)): NAs introduced by\r## coercion\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 0.000 2.000 3.000 3.746 4.000 10.000 544\r Again, this didn\u0026rsquo;t do the trick. The number of 1s might be inflated and we expect exactly 544 (number of males) NAs since number of eggs have only been recorded for female house sparrows.\nWe already know that improperly stored NA records are prone to causing an inflation of data records of value 1. We also remember that head and tail of our data frame hold different types of NA records. Let\u0026rsquo;s find out who entered NAs correctly:\nunique(Data_df$Site[which(is.na(Data_df$Egg.Weight))])\r ## character(0)\r The code above identifies the sites at which proper NA recording has been done. The Falkland Isle team did it right (NA fields in Excel were left blank). Fixing this is actually a bit more challenging and so we do the following:\n# make everything into characters\rData_df$Number.of.Eggs \u0026lt;- as.character(Data_df$Number.of.Eggs) # writing character NA onto actual NAs\rData_df$Number.of.Eggs[which(is.na(Data_df$Number.of.Eggs))] \u0026lt;- \u0026quot; NA\u0026quot;\r# make all character NAs into proper NAs\rData_df$Number.of.Eggs[Data_df$Number.of.Eggs == \u0026quot; NA\u0026quot;] \u0026lt;- NA # make everything numeric\rData_df$Number.of.Eggs \u0026lt;- as.numeric(as.character(Data_df$Number.of.Eggs))\r ## Warning: NAs introduced by coercion\r summary(Data_df$Number.of.Eggs)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 0.000 2.000 3.000 3.746 4.000 10.000 544\r We did it!\nEgg Weight Variable Class Expectation: numeric (another weight measurement that needs to be continuous)\nIdentifying Problems Let\u0026rsquo;s asses our Egg Weight records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Egg.Weight)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Egg.Weight)\r ## Length Class Mode ## 1067 character character\r Fixing Problems Egg weight should be recorded as numeric and yet is currently stored as character. Our first approach to fixing this, again, is using the as.numeric() function again.\nsummary(as.numeric(Data_df$Egg.Weight))\r ## Warning in summary(as.numeric(Data_df$Egg.Weight)): NAs introduced by coercion\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 1.580 2.340 2.670 2.619 2.890 3.590 590\r Something is wrong here. Not enough NAs are recorded. We expect exactly 590 NAs (Number of males + Number of Females with zero eggs). Additionally, there are way too many 1s. Our problem, again, lies with the way the NAs have been entered into the data set from the beginning and so we use the following fix again.\n# make everything into characters\rData_df$Egg.Weight \u0026lt;- as.character(Data_df$Egg.Weight) # writing character NA onto actual NAs\rData_df$Egg.Weight[which(is.na(Data_df$Egg.Weight))] \u0026lt;- \u0026quot; NA\u0026quot; # make all character NAs into proper NAs\rData_df$Egg.Weight[Data_df$Egg.Weight == \u0026quot; NA\u0026quot;] \u0026lt;- NA # make everything numeric\rData_df$Egg.Weight \u0026lt;- as.numeric(as.character(Data_df$Egg.Weight))\rsummary(Data_df$Egg.Weight)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA's ## 1.580 2.340 2.670 2.619 2.890 3.590 590\r Flock Variable Class Expectation: factor (each sparrow was assigned to one particular flock)\nIdentifying Problems Let\u0026rsquo;s asses our Flock records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Flock)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Flock)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nHome Range Variable Class Expectation: factor (three levels: small, medium, large)\nIdentifying Problems Let\u0026rsquo;s asses our Home Range records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Home.Range)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Home.Range)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nFlock Size Variable Class Expectation: numeric (continuous measurement of how many sparrows are in each flock - measured as integers)\nIdentifying Problems Let\u0026rsquo;s asses our Flock Size records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Flock.Size)\r ## [1] \u0026quot;integer\u0026quot;\r summary(Data_df$Flock.Size)\r ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 7.00 16.00 19.00 25.81 31.00 58.00\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPredator Presence Variable Class Expectation: factor (two levels: yes and no)\nIdentifying Problems Let\u0026rsquo;s asses our Predator Presence records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Predator.Presence)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Predator.Presence)\r ## Length Class Mode ## 1067 character character\r Indeed, they do behave just like we\u0026rsquo;d expect them to.\nFixing Problems We don\u0026rsquo;t need to fix anything here.\nPredator Type Variable Class Expectation: factor (three levels: Avian, Non-Avian, and NA)\nIdentifying Problems Let\u0026rsquo;s asses our Predator Type records for our Passer domesticus individuals and check whether they behave as expected:\nclass(Data_df$Predator.Type)\r ## [1] \u0026quot;character\u0026quot;\r summary(Data_df$Predator.Type)\r ## Length Class Mode ## 1067 character character\r Something doesn\u0026rsquo;t sit well here.\nFixing Problems Someone got overly eager when recording Predator Type and specified the presence of a hawk instead of taking down \u0026ldquo;Avian\u0026rdquo;. We fix this as follows:\nData_df$Predator.Type[which(Data_df$Predator.Type == \u0026quot;Hawk\u0026quot;)] \u0026lt;- \u0026quot;Avian\u0026quot;\rsummary(Data_df$Predator.Type)\r ## Length Class Mode ## 1067 character character\r This fixed it but there are still manually entered NA records present which we have to get rid of. These can be fixed easily without altering column classes and simply making use of logic by indexing their dependencies on other column values. The predator type for a data record where predator presence reads \u0026ldquo;No\u0026rdquo; has to be NA.\nData_df$Predator.Type[which(Data_df$Predator.Presence == \u0026quot;No\u0026quot;)] \u0026lt;- NA Data_df$Predator.Type \u0026lt;- droplevels(factor(Data_df$Predator.Type)) # drop unused factor levels\rsummary(Data_df$Predator.Type)# FIXED IT!\r ## Avian Non-Avian NA's ## 490 220 357\r Redundant Data Our data contains redundant columns (i.e.: columns whose data is present in another column already). These are (1) Flock Size (data contained in Flock column) and (2) Flock.Size (data contained in Index column). The fix to this is as easy as removing the columns in question.\nData_df \u0026lt;- within(Data_df, rm(Flock.Size, Site))\rdim(Data_df)\r ## [1] 1067 18\r Fixed it!\nBy doing so, we have gotten rid of our flock size problem stemming from the deletion of a data record. You could also argue that the columns Site and Index are redundant. We keep both for quality-of-life when interpreting our results (make use of Sites) and coding (make use os Index).\nSaving The Fixed Data Set We fixed out entire data set! The data set is now ready for use.\nKeep in mind that the data set I provided you with was relatively clean and real-world messy data sets can be far more difficult to clean up.\nBefore going forth, we need to save it. Attention: don\u0026rsquo;t overwrite your initial data file!\nFinal Check Before exporting you may want to ensure that everything is in order and do a final round of data inspection. This can be achieved by running the automated summary() command from earlier again as follows. I am not including the output here to save some space.\nfor(i in 1:dim(Data_df)[2]){\rprint(colnames(Data_df)[i])\rprint(summary(Data_df[,i]))\rprint(\u0026quot;------------------------------------------------------\u0026quot;)\r}\r Everything checks out. Let\u0026rsquo;s save our final data frame.\nExporting The Altered Data Since Excel is readily available for viewing data outside of R, I like to save my final data set in excel format as can be seen below. Additionally, I recommend saving your final data frame as an RDS file. These are R specific data files which you will not be able to alter outside of R thus saving yourself from accidentally changing records when only trying to view your data. On top of that, RDS files take up less space than either Excel or TXT files do.\n# saving in excel sheet\rwrite.csv(Data_df, file = paste(Dir.Data, \u0026quot;/SparrowData_FIXED.csv\u0026quot;, sep=\u0026quot;\u0026quot;))\r# saving as R data frame object\rsaveRDS(Data_df, file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))  ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"ee44d4166bf36bfd34a3e9cfce7d1334","permalink":"https://www.erikkusch.com/courses/biostat101/data-handling-and-data-mining/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/data-handling-and-data-mining/","section":"courses","summary":"Welcome to our first \"real\" practical experience in `R`. The following notes present you with an example of how data handling (also known as data cleaning) can be done. Obviously, the possibility for flaws to occur in any given data set are seemingly endless and so the following, tedious procedure should be thought of as less of an recipe of how to fix common flaws in biological data sets but make you aware of how important proper data collection and data entry is.","tags":["R","Statistics"],"title":"Data Handling and Data Mining","type":"docs"},{"authors":["Erik Kusch"],"categories":["Excursion into Biostatistics"],"content":"Theory These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.\nI have prepared some I have prepared some Lecture Slides  for this session. For a more mathematical look at these concepts, I cannot recommend enough Eduardo García Portugués' blog.\nR Environment For this exercise, we will need the following packages:\ninstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE)) {\rinstall.packages(x, repos = \u0026quot;http://cran.us.r-project.org\u0026quot;)\r}\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\r\u0026quot;ggplot2\u0026quot;, # for visualisation\r\u0026quot;leaflet\u0026quot;, # for maps\r\u0026quot;splitstackshape\u0026quot;, # for stratified sampling\r\u0026quot;caret\u0026quot;, # for cross-validation exercises\r\u0026quot;boot\u0026quot;, # for bootstrap parameter estimates\r\u0026quot;tidyr\u0026quot;, # for reshaping data frames\r\u0026quot;tidybayes\u0026quot;, # for visualisation of bootstrap estimates\r\u0026quot;pROC\u0026quot;, # for ROC-curves\r\u0026quot;olsrr\u0026quot;, # for subset selection\r\u0026quot;MASS\u0026quot;, # for stepwise subset selection\r\u0026quot;nlme\u0026quot;, # for mixed effect models\r\u0026quot;mclust\u0026quot;, # for k-means clustering,\r\u0026quot;randomForest\u0026quot;, # for randomForest classifier\r\u0026quot;lmeresampler\u0026quot; # for validation of lmer models\r)\rsapply(package_vec, install.load.package)\r ## ggplot2 leaflet splitstackshape caret boot tidyr tidybayes pROC olsrr MASS nlme mclust ## TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## randomForest lmeresampler ## TRUE TRUE\r Using the above function is way more sophisticated than the usual install.packages() \u0026amp; library() approach since it automatically detects which packages require installing and only install these thus not overwriting already installed packages.\nOur Resarch Project Today, we are looking at a big (and entirely fictional) data base of the common house sparrow (Passer domesticus). In particular, we are interested in the Evolution of Passer domesticus in Response to Climate Change which was previously explained here.\nThe Data I have created a large data set for this exercise which is available here and we previously cleaned up so that is now usable here.\nReading the Data into R Let\u0026rsquo;s start by reading the data into R and taking an initial look at it:\nSparrows_df \u0026lt;- readRDS(file.path(\u0026quot;Data\u0026quot;, \u0026quot;SparrowDataClimate.rds\u0026quot;))\rhead(Sparrows_df)\r ## Index Latitude Longitude Climate Population.Status Weight Height Wing.Chord Colour Sex Nesting.Site Nesting.Height Number.of.Eggs Egg.Weight Flock Home.Range Predator.Presence Predator.Type\r## 1 SI 60 100 Continental Native 34.05 12.87 6.67 Brown Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 2 SI 60 100 Continental Native 34.86 13.68 6.79 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 3 SI 60 100 Continental Native 32.34 12.66 6.64 Black Female Shrub 35.60 1 3.21 C Large Yes Avian\r## 4 SI 60 100 Continental Native 34.78 15.09 7.00 Brown Female Shrub 47.75 0 NA E Large Yes Avian\r## 5 SI 60 100 Continental Native 35.01 13.82 6.81 Grey Male \u0026lt;NA\u0026gt; NA NA NA B Large Yes Avian\r## 6 SI 60 100 Continental Native 32.36 12.67 6.64 Brown Female Shrub 32.47 1 3.17 E Large Yes Avian\r## TAvg TSD\r## 1 269.9596 15.71819\r## 2 269.9596 15.71819\r## 3 269.9596 15.71819\r## 4 269.9596 15.71819\r## 5 269.9596 15.71819\r## 6 269.9596 15.71819\r Hypotheses Let\u0026rsquo;s remember our hypotheses:\n Sparrow Morphology is determined by:\nA. Climate Conditions with sparrows in stable, warm environments fairing better than those in colder, less stable ones.\nB. Competition with sparrows in small flocks doing better than those in big flocks.\nC. Predation with sparrows under pressure of predation doing worse than those without. Sites accurately represent sparrow morphology. This may mean:\nA. Population status as inferred through morphology.\nB. Site index as inferred through morphology.\nC. Climate as inferred through morphology.  We have already built some models for these here and here.\nCandidate Models Before we can get started on model selection and validation, we need some actual models. Let\u0026rsquo;s create some. Since the data set contains three variables pertaining to sparrow morphology (i.e. Weight, Height, Wing.Chord) and I don\u0026rsquo;t want this exercise to spiral out of control with models that account for more than one response variable, we need to settle on one as our response variable in the first hypothesis. I am going with Weight.\nAdditionally, because I am under a bit of time pressure in creating this material, I forego all checking of assumptions on any of the following candidate models as the goal with this material is model selection/validation and not model assumption checking.\nContinuous Models load(file = file.path(\u0026quot;Data\u0026quot;, \u0026quot;H1_Models.RData\u0026quot;))\r This just loaded three objects into R:\n H1_ModelSparrows_ls - a list of candidate models built for the entire Sparrow_df data set Sparrows_df - the data frame used to build the global candidate models H1_ModelCNA_ls - a list of candidate models built just for three coastal sites across Central and North America CentralNorthAm_df - the data frame used to build the candidate model for Central and North America  Global Models Global regression models include:\nsapply(H1_ModelSparrows_ls, \u0026quot;[[\u0026quot;, \u0026quot;call\u0026quot;)\r ## $Null\r## lm(formula = Weight ~ 1, data = Sparrows_df)\r## ## $Comp_Flock.Size\r## lm(formula = Weight ~ Flock.Size, data = Sparrows_df)\r## ## $Comp_Full\r## lm(formula = Weight ~ Home.Range * Flock.Size, data = Sparrows_df)\r## ## $Full\r## lm(formula = Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + ## Predator.Type, data = Sparrows_df)\r## ## $Mixed_Full\r## lme.formula(fixed = Weight ~ Predator.Type + Flock.Size * Home.Range + ## TAvg + TSD, data = Sparrows_df, random = list(Population.Status = ~1))\r Local Models Local regression models for the region of Central/North America include:\nsapply(H1_ModelCNA_ls, \u0026quot;[[\u0026quot;, \u0026quot;call\u0026quot;)\r ## $Null\r## lm(formula = Weight ~ 1, data = CentralNorthAm_df)\r## ## $Clim_TAvg\r## lm(formula = Weight ~ TAvg, data = CentralNorthAm_df)\r## ## $Clim_TSD\r## lm(formula = Weight ~ TSD, data = CentralNorthAm_df)\r## ## $Clim_Full\r## lm(formula = Weight ~ TAvg + TSD, data = CentralNorthAm_df)\r## ## $Pred_Pres\r## lm(formula = Weight ~ Predator.Presence, data = CentralNorthAm_df)\r## ## $Pred_Type\r## lm(formula = Weight ~ Predator.Type, data = CentralNorthAm_df)\r## ## $Full\r## lm(formula = Weight ~ TAvg + TSD + Home.Range * Flock.Size + ## Predator.Type, data = CentralNorthAm_df)\r## ## $Mixed_Full\r## lme.formula(fixed = Weight ~ Flock.Size * Home.Range + TAvg + ## TSD, data = CentralNorthAm_df, random = list(Index = ~1))\r Categorical Models load(file = file.path(\u0026quot;Data\u0026quot;, \u0026quot;H2_Models.RData\u0026quot;))\r This just loaded three objects into R:\n H2_PS_mclust - a k-means classifier aiming to group Population.Status by Weight, Height, and Wing.Chord H2_PS_RF - a random forest classifier which identifies Population.Status by Weight, Height, and Wing.Chord H2_Index_RF - a random forest classifier which identifies Index of sites by Weight, Height, and Wing.Chord  Model Comparison/Selection (adjusted) Coefficient of Determination The coefficient of determination ($R^2$) measures the proportion of variation in our response (Weight) that can be explained by regression using our predictor(s). The higher this value, the better. Unfortunately, $R^2$ does not penalize complex models (i.e. those with multiple parameters) while the adjusted $R^2$ does. Extracting these for a model object is as easy as writing:\nExampleModel \u0026lt;- H1_ModelSparrows_ls$Comp_Flock.Size\rsummary(ExampleModel)$r.squared\r ## [1] 0.7837715\r summary(ExampleModel)$adj.r.squared\r ## [1] 0.7835683\r This tells us that the flock size model explains roughly 0.784% of the variation in the Weight variable. That is pretty decent.\nTo check for all other models, I have written a quick sapply function that does the extraction for us. Because obtaining (adjusted) $R^2$ requires additional packages, I am excluding these from this analysis:\nGlobal Regression Models H1_Summary_ls \u0026lt;- sapply(H1_ModelSparrows_ls[-length(H1_ModelSparrows_ls)], summary)\rR2_df \u0026lt;- data.frame(\rR2 = sapply(H1_Summary_ls, \u0026quot;[[\u0026quot;, \u0026quot;r.squared\u0026quot;),\rAdj.R2 = sapply(H1_Summary_ls, \u0026quot;[[\u0026quot;, \u0026quot;adj.r.squared\u0026quot;)\r)\rR2_df\r ## R2 Adj.R2\r## Null 0.0000000 0.0000000\r## Comp_Flock.Size 0.7837715 0.7835683\r## Comp_Full 0.8051421 0.8042229\r## Full 0.8460500 0.8444433\r You can immediately see that some of our candidate models are doing quite well for themselves.\nLocal Regression Models H1_Summary_ls \u0026lt;- sapply(H1_ModelCNA_ls[-length(H1_ModelCNA_ls)], summary)\rR2_df \u0026lt;- data.frame(\rR2 = sapply(H1_Summary_ls, \u0026quot;[[\u0026quot;, \u0026quot;r.squared\u0026quot;),\rAdj.R2 = sapply(H1_Summary_ls, \u0026quot;[[\u0026quot;, \u0026quot;adj.r.squared\u0026quot;)\r)\rR2_df\r ## R2 Adj.R2\r## Null 0.00000000 0.00000000\r## Clim_TAvg 0.23733707 0.23426182\r## Clim_TSD 0.32632351 0.32360707\r## Clim_Full 0.34671348 0.34142371\r## Pred_Pres 0.03710799 0.03322536\r## Pred_Type 0.34671348 0.34142371\r## Full 0.37651991 0.35848536\r Oof! None of our locally fitted models did well at explaining the data to begin with. With that identified, we are sure not going to trust them when it comes to predictions and so we are scrapping all of them.\nConsequently, we can generalise our naming conventions a bit and now write:\nH1_Model_ls \u0026lt;- H1_ModelSparrows_ls\r Anova Analysis of Variance (Anova) is another tool you will often run into when trying to understand explanatory power of a model. Here, I do something relatively complex to run an anova for all models in our list without having to type them all out. Again,we omit the mixed effect model:\neval(parse(text = paste(\u0026quot;anova(\u0026quot;, paste(\u0026quot;H1_Model_ls[[\u0026quot;, 1:(length(H1_Model_ls) - 1), \u0026quot;]]\u0026quot;, sep = \u0026quot;\u0026quot;, collapse = \u0026quot;,\u0026quot;), \u0026quot;)\u0026quot;)))\r ## Analysis of Variance Table\r## ## Model 1: Weight ~ 1\r## Model 2: Weight ~ Flock.Size\r## Model 3: Weight ~ Home.Range * Flock.Size\r## Model 4: Weight ~ Climate + TAvg + TSD + Home.Range * Flock.Size + Predator.Type\r## Res.Df RSS Df Sum of Sq F Pr(\u0026gt;F) ## 1 1065 17627.2 ## 2 1064 3811.5 1 13815.7 5365.996 \u0026lt; 2.2e-16 ***\r## 3 1060 3434.8 4 376.7 36.578 \u0026lt; 2.2e-16 ***\r## 4 1054 2713.7 6 721.1 46.678 \u0026lt; 2.2e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r As you can see, according to this, all of our models are doing much better in explaining our underlying data when compared to the Null Model.\nInformation Criteria Personally, I would like to have a model that\u0026rsquo;s good at predicting things instead of \u0026ldquo;just\u0026rdquo; explaining things and so we step into information criteria next. These aim to provide us with exactly that information: \u0026ldquo;How well will our model predict new data?\u0026rdquo; Information criteria make use of information theory which allows us to make such statements with pretty decent certainty despite not having new data.\nAkaike Information Criterion (AIC) Looking at the AIC:\nsapply(H1_Model_ls, AIC)\r ## Null Comp_Flock.Size Comp_Full Full Mixed_Full ## 6019.872 4389.378 4286.445 4047.250 4162.779\r Our full model is the clear favourite here.\nBayesian Information Criterion (BIC) As far as the BIC is concerned:\nsapply(H1_Model_ls, BIC)\r ## Null Comp_Flock.Size Comp_Full Full Mixed_Full ## 6029.815 4404.293 4321.247 4111.882 4222.326\r Our full model wins again!\nReceiver-Operator Characteristic (ROC) The Receiver-Operator Characteristic (ROC) shows the trade-off between Sensitivity (rate of true positives) and Specificity (rate of true negatives). It also provides an Area under the Curve which serves as a proxy of classification accuracy.\nFirst, we establish the ROC-Curve for our classification of Population.Status given sparrow Morphology and a k-means algorithm:\nMclust_PS.roc \u0026lt;- roc(\rSparrows_df$Population.Status, # known outcome\rH2_PS_mclust$z[, 1] # probability of assigning one out of two outcomes\r)\rplot(Mclust_PS.roc)\r auc(Mclust_PS.roc)\r ## Area under the curve: 0.6341\r Certainly, we could do better! Let\u0026rsquo;s see what more advanced methods have to offer.\nWith that, we turn to random forest:\nRF_PS.roc \u0026lt;- roc(\rSparrows_df$Population.Status,\rH2_PS_RF$votes[, 1]\r)\rplot(RF_PS.roc)\r auc(RF_PS.roc)\r ## Area under the curve: 0.9274\r Now this is doing much better!\nLastly, we want to look at the site Index as predicted by sparrow morphology given a random forest algorithm:\nRF_Index.roc \u0026lt;- multiclass.roc(\rSparrows_df$Index, # known outcome\rH2_Index_RF$votes # matrix of certainties of prediction\r)\rRF_Index.roc[[\u0026quot;auc\u0026quot;]] # average ROC-AUC\r ## Multi-class area under the curve: 0.9606\r ## Plot ROC curve for each binary comparison\rrs \u0026lt;- RF_Index.roc[[\u0026quot;rocs\u0026quot;]] ## extract comparisons\rplot.roc(rs[[1]][[1]]) # blot first comparison\rplot.roc(rs[[1]][[2]], add = TRUE) # plot first comparison, in opposite direction\rinvisible(capture.output(sapply(2:length(rs), function(i) lines.roc(rs[[i]][[1]], col = i))))\rinvisible(capture.output(sapply(2:length(rs), function(i) lines.roc(rs[[i]][[2]], col = i))))\r This is certainly busy, but look at that average AUC of almost 1! That is the power of Random Forest.\nSummary of Model Selection Morphology Hypothesis Regarding our morphology hypothesis, we saw that most of our hypothesised effects can be detected. However, some models clearly perform better than others. Usual model selection exercises would have us discard all but the best model (Full, in this case) and leave the rest never to be spoken of again. Doing so would have us miss a pretty neat opportunity to do some model comparison which can already help us identify which effects to focus on in particular.\nTo demonstrate some of this, allow me step into the local regression models:\nsapply(H1_ModelCNA_ls, AIC)\r ## Null Clim_TAvg Clim_TSD Clim_Full Pred_Pres Pred_Type Full Mixed_Full ## 948.7346 882.9998 851.9833 846.2997 941.2811 846.2997 844.6250 875.7659\r as well as global regression models:\nsapply(H1_Model_ls, AIC)\r ## Null Comp_Flock.Size Comp_Full Full Mixed_Full ## 6019.872 4389.378 4286.445 4047.250 4162.779\r  Climate - interestingly, temperature variability is much more informative than average temperature and even adding the two into the same model only marginally improves over the variability-only model. This tells us much about which effects are probably meaningful and which aren\u0026rsquo;t. Competition - The competition models did well across the board, but were aided immensely by adding climate information and accounting for random effects. Predation - predation effects were best explained by predation type with only a marginal improvement of adding predator presence. That is because predator type already contains all of the information that is within predator presence.  What we can do so far, is remove some obviously erroneous models which in this case is the entirety of local regression models.\nCategorisation Hypothesis As far as the categorisation hypotheses are concerned, we now have confirmation that population status and sparrow morphology are linked quite well.\nWe have also learned that random forest is an incredibly powerful method for classification and variable selection.\nModel Validation So far, we have not introduced our models to any new data. We have looked at explanatory power with (adjusted) $R^2$, and the Anova. We have also looked at estimates of predictive power with our information criteria (e.g. AIC, BIC).\nWhat about actually seeing how robust and accurate our models are? That\u0026rsquo;s what Model Validation is for!\nCross-Validation Before we get started, I remove the Null model from our model list. Doing cross-validation on this does not make any sense because there are no actual predictors in it which could be affected by cross-validation processes.\nH1_Model_ls \u0026lt;- H1_Model_ls[-1]\r Training vs. Test Data The simplest example of cross-validation is the validation data cross-validation approach; also known as Training vs. Test Data approach.\nTo make use of this approach, we need to (1) randomly split our data, (2) build our models using the training data, and (3) test our models on the test data.\nSince we have highly compartmentalised data at different sites, I am employing a stratified sampling scheme to ensure all of my sites are represented in each data set resulting from the split:\nset.seed(42) # make randomness reproducible\rStratified_ls \u0026lt;- stratified(Sparrows_df, # what to split\rgroup = \u0026quot;Index\u0026quot;, # by which group to stratify\rsize = .7, # what proportion of each group shall be contained in the training data\rbothSets = TRUE # save both training and test data\r)\rTrain_df \u0026lt;- Stratified_ls$SAMP1 # extract training data\rTest_df \u0026lt;- Stratified_ls$SAMP2 # extract test data\r Now that we have our training and test data, we are ready to run our pre-specified models on said data and subsequently test it\u0026rsquo;s performance on the test data by predicting with the newly trained model and calculating mean squared test error.\nFor a single model, we can do it like this:\nExampleModel \u0026lt;- H1_ModelSparrows_ls$Comp_Flock.Size # extract Model from list\rExampleModel \u0026lt;- update(ExampleModel, data = Train_df) # train model on training data\rPrediction \u0026lt;- predict(ExampleModel, newdata = Test_df) # predict outcome for test data\rsum((Test_df$Weight - Prediction)^2) # Mean Squared Error\r ## [1] 1133.996\r Since we have multiple models stored in a list, here\u0026rsquo;s a way to do the above for the entire list:\nH1_Train_ls \u0026lt;- sapply(X = H1_Model_ls, FUN = function(x) update(x, data = Train_df))\rH1_Test_mat \u0026lt;- sapply(X = H1_Train_ls, FUN = function(x) predict(x, newdata = Test_df))\rapply(H1_Test_mat, MARGIN = 2, FUN = function(x) sum((Test_df$Weight - x)^2))\r ## Comp_Flock.Size Comp_Full Full Mixed_Full ## 1133.9958 1026.2199 816.5166 866.2941\r Again, our full model comes out on top!\nUnfortunately, this approach is fickle due to the randomness of the data split. How can we make this more robust? Easy. We split many, many times and average our mean squared errors out.\nThis bring us to traditional Cross-Validation approaches. Luckily, the complex parts of cross-validation are already offered to us with the caret package in R\nLeave-One-Out Cross-Validation (LOOCV) Leave-One-Out Cross-Validation is a method within which we split our data into a training data set with $n-1$ observation and a test data set that contains just $1$ observation. We do training and testing as above on this split and then repeat this procedure until every observation has been left out once.\nFor a simple model, this can be done like such:\ntrain(Weight ~ Climate,\rdata = Sparrows_df,\rmethod = \u0026quot;lm\u0026quot;,\rtrControl = trainControl(method = \u0026quot;LOOCV\u0026quot;)\r)\r ## Linear Regression ## ## 1066 samples\r## 1 predictor\r## ## No pre-processing\r## Resampling: Leave-One-Out Cross-Validation ## Summary of sample sizes: 1065, 1065, 1065, 1065, 1065, 1065, ... ## Resampling results:\r## ## RMSE Rsquared MAE ## 3.628905 0.2036173 2.976221\r## ## Tuning parameter 'intercept' was held constant at a value of TRUE\r Notice the RMSE (Residual mean squared error). That\u0026rsquo;s what we use to compare models.\nHere, I create a function that automatically rebuilds our models for the LOOCV so we can run this on our list of models later.\nCV_LOOCV \u0026lt;- function(x) {\rif (length(x[[\u0026quot;terms\u0026quot;]][[3]]) == 1) {\rTerms \u0026lt;- paste(x[[\u0026quot;terms\u0026quot;]][[3]], collapse = \u0026quot; + \u0026quot;)\r} else {\rTerms \u0026lt;- paste(x[[\u0026quot;terms\u0026quot;]][[3]][-1], collapse = \u0026quot; + \u0026quot;)\r}\rtrain(as.formula(paste(\u0026quot;Weight ~\u0026quot;, Terms)),\rdata = Sparrows_df,\rmethod = \u0026quot;lm\u0026quot;,\rtrControl = trainControl(method = \u0026quot;LOOCV\u0026quot;)\r)\r}\r Unfortunately, this cannot be executed for mixed effect models, so for now, I only run this on all our models except the mixed effect model:\nBegin \u0026lt;- Sys.time()\rH1_LOOCV_ls \u0026lt;- sapply(H1_Model_ls[-length(H1_Model_ls)], CV_LOOCV)\rEnd \u0026lt;- Sys.time()\rEnd - Begin\r ## Time difference of 9.41841 secs\r sapply(H1_LOOCV_ls, \u0026quot;[[\u0026quot;, \u0026quot;results\u0026quot;)[-1, ]\r ## Comp_Flock.Size Comp_Full Full ## RMSE 1.894279 1.865854 1.609296 ## Rsquared 0.7829992 0.7894634 0.8433834\r## MAE 1.520181 1.492409 1.279003\r Unsurprisingly, our full model has the lowest RMSE (which is the mark of a good model).\nSo what about our mixed effect model? Luckily, doing LOOCV by hand isn\u0026rsquo;t all that difficult and so we can still compute a RMSE for LOOCV for our mixed effect model:\nRMSE_LOOCV \u0026lt;- rep(NA, nrow(Sparrows_df))\rfor (Fold_Iter in 1:nrow(Sparrows_df)) {\rIter_mod \u0026lt;- update(H1_Model_ls$Mixed_Full, data = Sparrows_df[-Fold_Iter, ])\rPrediction \u0026lt;- predict(Iter_mod, newdata = Sparrows_df[Fold_Iter, ])\rRMSE_LOOCV[Fold_Iter] \u0026lt;- (Sparrows_df[Fold_Iter, ]$Weight - Prediction)^2\r}\rmean(RMSE_LOOCV)\r ## [1] 2.757373\r Ouh\u0026hellip; that is quite worse than out other models. Curious. This goes to show how much less robust a more complex model can be.\nk-Fold Cross-Validation (k-fold CV) k-Fold Cross-Validation uses the same concept as all of the previous cross-validation methods, but at less of a computational cost than LOOCV and more robustly than the training/test data approach:\nAgain, I write a function for this and run it on my list of models without the mixed effect model:\nCV_kFold \u0026lt;- function(x) {\rif (length(x[[\u0026quot;terms\u0026quot;]][[3]]) == 1) {\rTerms \u0026lt;- paste(x[[\u0026quot;terms\u0026quot;]][[3]], collapse = \u0026quot; + \u0026quot;)\r} else {\rTerms \u0026lt;- paste(x[[\u0026quot;terms\u0026quot;]][[3]][-1], collapse = \u0026quot; + \u0026quot;)\r}\rtrain(as.formula(paste(\u0026quot;Weight ~\u0026quot;, Terms)),\rdata = Sparrows_df,\rmethod = \u0026quot;lm\u0026quot;,\rtrControl = trainControl(method = \u0026quot;cv\u0026quot;, number = 15)\r)\r}\rBegin \u0026lt;- Sys.time()\rH1_kFold_ls \u0026lt;- sapply(H1_Model_ls[-length(H1_Model_ls)], CV_kFold)\rEnd \u0026lt;- Sys.time()\rEnd - Begin\r ## Time difference of 0.3413441 secs\r sapply(H1_kFold_ls, \u0026quot;[[\u0026quot;, \u0026quot;results\u0026quot;)[-1, ]\r ## Comp_Flock.Size Comp_Full Full ## RMSE 1.889439 1.859135 1.603168 ## Rsquared 0.7882333 0.7942782 0.8465977 ## MAE 1.519962 1.491493 1.277595 ## RMSESD 0.1408563 0.1520344 0.1491081 ## RsquaredSD 0.03375562 0.03153792 0.03034729\r## MAESD 0.1382304 0.1122565 0.1150599\r Full model performs best still and see how much quicker that was done!\nBootstrap On to the Bootstrap. God, I love the boostrap.\nThe idea here is to run a model multiple times on a random sample of the underlying data and then store all of the estimates or the parameters as well as avaerage out the RMSE:\nBootStrap \u0026lt;- function(x) {\rif (length(x[[\u0026quot;terms\u0026quot;]][[3]]) == 1) {\rTerms \u0026lt;- paste(x[[\u0026quot;terms\u0026quot;]][[3]], collapse = \u0026quot; + \u0026quot;)\r} else {\rTerms \u0026lt;- paste(x[[\u0026quot;terms\u0026quot;]][[3]][-1], collapse = \u0026quot; + \u0026quot;)\r}\rtrain(as.formula(paste(\u0026quot;Weight ~\u0026quot;, Terms)),\rdata = Sparrows_df,\rmethod = \u0026quot;lm\u0026quot;,\rtrControl = trainControl(method = \u0026quot;boot\u0026quot;, number = 100)\r)\r}\rBegin \u0026lt;- Sys.time()\rH1_BootStrap_ls \u0026lt;- sapply(H1_Model_ls[-length(H1_Model_ls)], BootStrap)\rEnd \u0026lt;- Sys.time()\rEnd - Begin\r ## Time difference of 1.308739 secs\r sapply(H1_BootStrap_ls, \u0026quot;[[\u0026quot;, \u0026quot;results\u0026quot;)[-1, ]\r ## Comp_Flock.Size Comp_Full Full ## RMSE 1.893652 1.871873 1.622079 ## Rsquared 0.7835412 0.7896534 0.8425108 ## MAE 1.520457 1.498216 1.288087 ## RMSESD 0.04675792 0.05178669 0.04885059\r## RsquaredSD 0.01243994 0.01318599 0.01092356\r## MAESD 0.04287091 0.04531032 0.03910463\r The full model is still doing great, of course.\nBut what about our mixed effect model? Luckily, there is a function that can do bootstrapping for us on our lme objects:\n## Bootstrap mixed model\rMixed_boot \u0026lt;- lmeresampler::bootstrap(H1_Model_ls[[length(H1_Model_ls)]], .f = fixef, type = \u0026quot;parametric\u0026quot;, B = 3e3)\rMixed_boot\r ## Bootstrap type: parametric ## ## Number of resamples: 3000 ## ## term observed rep.mean se bias\r## 1 (Intercept) 2.212717e+01 22.0672111291 2.853845096 -0.0599612233\r## 2 Predator.TypeNon-Avian 6.626664e-01 0.6580310750 0.161081567 -0.0046353000\r## 3 Predator.TypeNone 2.694373e-02 0.0212966961 0.152739708 -0.0056470340\r## 4 Flock.Size 1.497092e-05 0.0005839265 0.019216411 0.0005689556\r## 5 Home.RangeMedium 1.261878e+00 1.2675791500 0.881426872 0.0057008365\r## 6 Home.RangeSmall 3.049068e+00 3.0583903125 0.417796779 0.0093225898\r## 7 TAvg 3.015153e-02 0.0303345903 0.009892483 0.0001830556\r## 8 TSD 1.983744e-01 0.1984962823 0.021196164 0.0001219321\r## 9 Flock.Size:Home.RangeMedium -1.208598e-01 -0.1213017777 0.057929474 -0.0004419594\r## 10 Flock.Size:Home.RangeSmall -2.110972e-01 -0.2117971129 0.019731749 -0.0006998822\r## ## There were 0 messages, 0 warnings, and 0 errors.\r With this, we are getting into the heart of the bootstrap. Distributions of our parameter estimates. These give us an amazing understanding of just which parameter values our model sees as plausible given our data:\nEstimates_df \u0026lt;- data.frame(Mixed_boot[[\u0026quot;replicates\u0026quot;]])\r## reshape estimates data frame for plotting\rHist_df \u0026lt;- data.frame(pivot_longer(\rdata = Estimates_df,\rcols = colnames(Estimates_df)\r))\r## plot parameter estimate distributions\rggplot(data = Hist_df, aes(x = value, group = name)) +\rtidybayes::stat_pointinterval() +\rtidybayes::stat_dots() +\rfacet_wrap(~name, scales = \u0026quot;free\u0026quot;) +\rlabs(\rx = \u0026quot;Parameter Estimate\u0026quot;, y = \u0026quot;Parameter\u0026quot;,\rtitle = paste(\u0026quot;Bootstrap parameter estimates of\u0026quot;, names(H1_Model_ls[[length(H1_Model_ls)]]), \u0026quot;Model\u0026quot;)\r) +\rtheme_bw()\r As you can see for our mixed effect model, while most parameter estimates are nicely constrained, the Intercept estimate can vary wildly. This is likely to do with our model being very flexible and allowing for a bunch of different combinations of intercepts.\nLet\u0026rsquo;s do the same for our remaining three candidate models:\nBootPlot_ls \u0026lt;- as.list(rep(NA, (length(H1_Model_ls) - 1)))\rfor (Model_Iter in 1:(length(H1_Model_ls) - 1)) { # loop over all models except the null model\r## Formula to compute coefficients\rx \u0026lt;- H1_Model_ls[[Model_Iter]]\rif (length(x[[\u0026quot;terms\u0026quot;]][[3]]) == 1) {\rTerms \u0026lt;- as.character(x[[\u0026quot;terms\u0026quot;]][[3]])\r} else {\rTerms \u0026lt;- paste(as.character(x[[\u0026quot;terms\u0026quot;]][[3]])[-1], collapse = as.character(x[[\u0026quot;terms\u0026quot;]][[3]])[1])\r}\rmodel_coef \u0026lt;- function(data, index) {\rcoef(lm(as.formula(paste(\u0026quot;Weight ~\u0026quot;, Terms)), data = data, subset = index))\r}\r## Bootstrapping\rBoot_test \u0026lt;- boot(data = Sparrows_df, statistic = model_coef, R = 3e3)\r## set column names of estimates to coefficients\rcolnames(Boot_test[[\u0026quot;t\u0026quot;]]) \u0026lt;- names(H1_Model_ls[[Model_Iter]][[\u0026quot;coefficients\u0026quot;]])\r## make data frame of estimates\rEstimates_df \u0026lt;- data.frame(Boot_test[[\u0026quot;t\u0026quot;]])\r## reshape estimates data frame for plotting\rHist_df \u0026lt;- data.frame(pivot_longer(\rdata = Estimates_df,\rcols = colnames(Estimates_df)\r))\r## plot parameter estimate distributions\rBootPlot_ls[[Model_Iter]] \u0026lt;- ggplot(data = Hist_df, aes(x = value, group = name)) +\rtidybayes::stat_pointinterval() +\rtidybayes::stat_dots() +\rfacet_wrap(~name, scales = \u0026quot;free\u0026quot;) +\rlabs(\rx = \u0026quot;Parameter Estimate\u0026quot;, y = \u0026quot;Parameter\u0026quot;,\rtitle = paste(\u0026quot;Bootstrap parameter estimates of\u0026quot;, names(H1_Model_ls)[[Model_Iter]], \u0026quot;Model\u0026quot;),\rsubtitle = paste(\u0026quot;Weight ~\u0026quot;, Terms)\r) +\rtheme_bw()\r}\rBootPlot_ls[[1]]\r BootPlot_ls[[2]]\r BootPlot_ls[[3]]\r Subset Selection So far, we have built our own models according to out intuition. Did we test all possible models? No. Should we go back and test all possible models by hand? Hell no! Can we let R do it for us? You bet we can!\nBest Subset Selection Let\u0026rsquo;s start with best subset selection. Doing so asks us/R to establish all possible models and then select the one that performs best according to information criteria. Because our data set contains over 20 variables, including all of our variables would have us establish close to 1 million (you read that right) models. THat is, of course, infeasible.\nTherefore, let\u0026rsquo;s just allow our subset selection to use all variables we have used ourselves thus far (with the exclusion of Index because it\u0026rsquo;s an amazing, but ultimately useless shorthand):\nReduced_df \u0026lt;- Sparrows_df[, c(\u0026quot;Weight\u0026quot;, \u0026quot;Climate\u0026quot;, \u0026quot;TAvg\u0026quot;, \u0026quot;TSD\u0026quot;, \u0026quot;Population.Status\u0026quot;, \u0026quot;Flock.Size\u0026quot;, \u0026quot;Predator.Type\u0026quot;, \u0026quot;Predator.Presence\u0026quot;)] # reduce data\rmodel \u0026lt;- lm(Weight ~ ., data = Reduced_df) # specify full model\rk \u0026lt;- ols_step_best_subset(model) # create all models and select the best\rk # show us comparison of best subsets\r ## Best Subsets Regression ## --------------------------------------------------------------------------------------------\r## Model Index Predictors\r## --------------------------------------------------------------------------------------------\r## 1 Flock.Size ## 2 Climate Flock.Size ## 3 Climate TAvg Flock.Size ## 4 Climate TAvg Flock.Size Predator.Type ## 5 Climate TAvg TSD Flock.Size Predator.Type ## 6 Climate TAvg TSD Population.Status Flock.Size Predator.Type ## 7 Climate TAvg TSD Population.Status Flock.Size Predator.Type Predator.Presence ## --------------------------------------------------------------------------------------------\r## ## Subsets Regression Summary ## ----------------------------------------------------------------------------------------------------------------------------------\r## Adj. Pred ## Model R-Square R-Square R-Square C(p) AIC SBIC SBC MSEP FPE HSP APC ## ----------------------------------------------------------------------------------------------------------------------------------\r## 1 0.7838 0.7836 0.783 298.7733 4389.3782 NA 4404.2932 3818.6664 3.5890 0.0034 0.2170 ## 2 0.8175 0.8169 0.8163 88.8025 4212.8692 NA 4237.7276 3226.8597 3.0384 0.0029 0.1836 ## 3 0.8227 0.8220 0.8213 58.0852 4184.0693 NA 4213.8994 3137.9149 2.9575 0.0028 0.1787 ## 4 0.8315 0.8305 0.8296 4.5702 4133.6815 NA 4173.4549 2984.6456 2.8183 0.0026 0.1701 ## 5 0.8320 0.8309 0.8298 3.3977 4132.4880 NA 4177.2330 2978.5274 2.8151 0.0026 0.1699 ## 6 0.8320 0.8308 0.8296 5.0000 4134.0870 NA 4183.8036 2980.2214 2.8194 0.0026 0.1702 ## 7 0.8320 0.8308 0.8296 5.0000 4136.0870 NA 4190.7753 2980.2214 2.8194 0.0026 0.1702 ## ----------------------------------------------------------------------------------------------------------------------------------\r## AIC: Akaike Information Criteria ## SBIC: Sawa's Bayesian Information Criteria ## SBC: Schwarz Bayesian Criteria ## MSEP: Estimated error of prediction, assuming multivariate normality ## FPE: Final Prediction Error ## HSP: Hocking's Sp ## APC: Amemiya Prediction Criteria\r Model 5 (Climate TAvg TSD Flock.Size Predator.Type ) is the one we want to go for here.\nLet\u0026rsquo;s look at visualisation of our different model selection criteria:\nplot(k)\r Forward Subset Selection Ok. So best subset selection can become intractable given a lot of variables. How about building our models up to be increasingly complex until we hit on gold?\nUnfortunately, doing so does not guarantee finding an optimal model and can easily get stuck, depending on what the model starts off with:\nmodel \u0026lt;- lm(Weight ~ Climate, data = Reduced_df)\rstep.model \u0026lt;- stepAIC(model,\rdirection = \u0026quot;forward\u0026quot;,\rtrace = FALSE\r)\rsummary(step.model)\r ## ## Call:\r## lm(formula = Weight ~ Climate, data = Reduced_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -9.020 -2.033 1.050 2.640 6.610 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 28.3998 0.1248 227.628 \u0026lt; 2e-16 ***\r## ClimateContinental 4.9785 0.3188 15.616 \u0026lt; 2e-16 ***\r## ClimateSemi-Coastal 3.3400 0.4606 7.252 7.9e-13 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 3.629 on 1063 degrees of freedom\r## Multiple R-squared: 0.2059,\tAdjusted R-squared: 0.2044 ## F-statistic: 137.8 on 2 and 1063 DF, p-value: \u0026lt; 2.2e-16\r We immediately remain on Climate as the only predictor in this example.\nWhat if we start with a true null model?\nmodel \u0026lt;- lm(Weight ~ 1, data = Reduced_df)\rstep.model \u0026lt;- stepAIC(model,\rdirection = \u0026quot;forward\u0026quot;,\rtrace = FALSE\r)\rsummary(step.model)\r ## ## Call:\r## lm(formula = Weight ~ 1, data = Reduced_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -9.944 -1.452 1.291 2.913 7.336 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 29.3243 0.1246 235.3 \u0026lt;2e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 4.068 on 1065 degrees of freedom\r We even get stuck on our null model!\nBackward Subset Selection So what about making our full model simpler?\nmodel \u0026lt;- lm(Weight ~ ., data = Reduced_df)\rstep.model \u0026lt;- stepAIC(model,\rdirection = \u0026quot;backward\u0026quot;,\rtrace = FALSE\r)\rsummary(step.model)\r ## ## Call:\r## lm(formula = Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type, ## data = Reduced_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.2398 -1.1180 0.1215 1.1474 4.9151 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 53.505428 3.748484 14.274 \u0026lt; 2e-16 ***\r## ClimateContinental 2.978894 0.301131 9.892 \u0026lt; 2e-16 ***\r## ClimateSemi-Coastal -0.640161 0.310970 -2.059 0.0398 * ## TAvg -0.068582 0.012713 -5.395 8.47e-08 ***\r## TSD -0.069306 0.038900 -1.782 0.0751 . ## Flock.Size -0.189607 0.005122 -37.019 \u0026lt; 2e-16 ***\r## Predator.TypeNon-Avian 0.379606 0.161332 2.353 0.0188 * ## Predator.TypeNone 1.258391 0.165347 7.611 6.02e-14 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.673 on 1058 degrees of freedom\r## Multiple R-squared: 0.832,\tAdjusted R-squared: 0.8309 ## F-statistic: 748.4 on 7 and 1058 DF, p-value: \u0026lt; 2.2e-16\r Interesting. This time, we have hit on the same model that was identified by the best subset selection above.\nForward \u0026amp; Backward Can we combine the directions of stepwise model selection? Yes, we can:\nmodel \u0026lt;- lm(Weight ~ ., data = Reduced_df)\rstep.model \u0026lt;- stepAIC(model,\rdirection = \u0026quot;both\u0026quot;,\rtrace = FALSE\r)\rsummary(step.model)\r ## ## Call:\r## lm(formula = Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type, ## data = Reduced_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -5.2398 -1.1180 0.1215 1.1474 4.9151 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 53.505428 3.748484 14.274 \u0026lt; 2e-16 ***\r## ClimateContinental 2.978894 0.301131 9.892 \u0026lt; 2e-16 ***\r## ClimateSemi-Coastal -0.640161 0.310970 -2.059 0.0398 * ## TAvg -0.068582 0.012713 -5.395 8.47e-08 ***\r## TSD -0.069306 0.038900 -1.782 0.0751 . ## Flock.Size -0.189607 0.005122 -37.019 \u0026lt; 2e-16 ***\r## Predator.TypeNon-Avian 0.379606 0.161332 2.353 0.0188 * ## Predator.TypeNone 1.258391 0.165347 7.611 6.02e-14 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.673 on 1058 degrees of freedom\r## Multiple R-squared: 0.832,\tAdjusted R-squared: 0.8309 ## F-statistic: 748.4 on 7 and 1058 DF, p-value: \u0026lt; 2.2e-16\r Again, we land on our best subset selection model!\nSubset Selection vs. Our Intuition Given our best subset selection, we have a very good idea of which model to go for.\nTo see how well said model shapes up against our full model, we can simply look at LOOCV:\ntrain(Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type,\rdata = Sparrows_df,\rmethod = \u0026quot;lm\u0026quot;,\rtrControl = trainControl(method = \u0026quot;LOOCV\u0026quot;)\r)\r ## Linear Regression ## ## 1066 samples\r## 5 predictor\r## ## No pre-processing\r## Resampling: Leave-One-Out Cross-Validation ## Summary of sample sizes: 1065, 1065, 1065, 1065, 1065, 1065, ... ## Resampling results:\r## ## RMSE Rsquared MAE ## 1.677673 0.8297908 1.338399\r## ## Tuning parameter 'intercept' was held constant at a value of TRUE\r sapply(H1_LOOCV_ls, \u0026quot;[[\u0026quot;, \u0026quot;results\u0026quot;)[-1, ]\r ## Comp_Flock.Size Comp_Full Full ## RMSE 1.894279 1.865854 1.609296 ## Rsquared 0.7829992 0.7894634 0.8433834\r## MAE 1.520181 1.492409 1.279003\r And our full model still wins! But why? Didn\u0026rsquo;t we test for all models? Yes, we tested for all additive models, but our Full model contains an interaction terms which the automated functions above just cannot handle, sadly.\nLet\u0026rsquo;s ask a completely different question. Would we have even adopted the best subset selection model if we had thought of it given the assumptions of a linear regression?\npar(mfrow = c(2, 2))\rplot(lm(Weight ~ Climate + TAvg + TSD + Flock.Size + Predator.Type, data = Sparrows_df))\r As it turns out, this is a perfectly reasonable model. It\u0026rsquo;s just not as good as our full model.\n","date":1614384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"f8cf1e21a34362b80ad2cb1f5ce909c4","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/excursion-into-biostatistics/","publishdate":"2021-02-27T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/excursion-into-biostatistics/","section":"courses","summary":"These are exercises and solutions meant as a compendium to my talk on Model Selection and Model Building.","tags":["R","Statistics"],"title":"Model Selection","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Ulysses' Compass Material  \rSlides Chapter 7  Introduction These are answers and solutions to the exercises at the end of chapter 7 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Jeffrey Girard.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(ggplot2)\r Easy Exercises Practice E1 Question: State the three motivating criteria that define information entropy. Try to express each in your own words.\nAnswer: The principle of information theory is motivated by the three following criteria:\n Continuity. Uncertainty must be measured on a continuous scale of equal intervals to ensure comparability. Additivity. Total uncertainty is derived by adding up the uncertainties associated with each prediction. Scalability. Uncertainty scales with number of possible outcomes to reflect changes in certainty just by virtue of different numbers of possible outcomes.  Practice E2 Question: Suppose a coin is weighted such that, when it is tossed and lands on a table, it comes up heads 70% of the time. What is the entropy of this coin?\nAnswer: Following the formula 7.1 on page 210:\n$H(p)=−\\sum_{i=1}^n p_ilog(p_i) = −(p_Hlog(p_H)+p_Tlog(p_T))$\nwith $p_H$ being probability of heads, and $p_T$ being probability of tails, we can simply plug in our values as follows:\np \u0026lt;- c(0.7, 0.3)\r-sum(p * log(p))\r ## [1] 0.6108643\r Thus, the entropy is 0.61.\nPractice E3 Question: Suppose a four-sided die is loaded such that, when tossed onto a table, it shows “1” 20%, “2” 25%, “3” 25%, and “4” 30% of the time. What is the entropy of this die?\nAnswer: Again, we use the formula approach as above:\np \u0026lt;- c(0.2, 0.25, 0.25, 0.3)\r-sum(p * log(p))\r ## [1] 1.376227\r The entropy of our D4 is 1.38.\nPractice E4 Question: Suppose another four-sided die is loaded such that it never shows “4”. The other three sides show equally often. What is the entropy of this die?\nAnswer: By knowing that one side never shows up, we can omit it altogether and are now looking at a perfectly balanced D3 rather than a D4:\np \u0026lt;- c(1 / 3, 1 / 3, 1 / 3)\r-sum(p * log(p))\r ## [1] 1.098612\r I have never seen a D3 in real-life, but we could easily imagine a D6 where the numbers 1 through 3 show up twice each. The entropy of our D3 is 1.1.\nMedium Exercises Practice M1 Question: Write down and compare the definitions of AIC, and WAIC. Which of these criteria is most general? Which assumptions are required to transform a more general criterion into a less general one?\nAnswer:\n AIC $= D_{train}+2p$; ($D_{train} =$ in-sample deviance, $p =$ number of parameters estimated in the model). It is built on the assumptions that:\nA) Priors are flat or overwhelmed by model\nB) Posterior distribution is approximately multivariate Gaussian\nC) Sample size $\u0026raquo;$ Number of parameters WAIC $= −2(lppd −\\sum_i(var_θ log p(y_i|θ))$; ($y_i =$ observation $i$, $θ =$ posterior distribution, $lppd(y, Θ) =\\sum_ilog\\frac{1}{S} \\sum_Sp(y_i|Θ_s) =$ log-pointwise-predictive-density) . It is built on the assumptions that: Sample size $\u0026raquo;$ Number of parameters.  WAIC is clearly the more general method here as it comes with less assumptions. To transform WAIC into AIC, we need to assume A. and B. of the assumptions of AIC.\nPractice M2 Question: Explain the difference between model selection and model comparison. What information is lost under model selection?\nAnswer: Model selection and model comparison both use information criteria and/or cross-validation exercises to determine goddess of fit of models to data set (their explanatory power) as well as their accuracy in terms of making inferences (their predictive power). Where they differ is what these approaches do with the models at hand once the desired information is obtained. In model selection all but the \u0026ldquo;best\u0026rdquo; model is discarded, whereas under model comparison we use our new-found information to identify relative model accuracy to assess the influences of different parameters in different models. The latter can lead to understanding causal relationships and identification of confounds in the different models.\nPractice M3 Question: When comparing models with an information criterion, why must all models be fit to exactly the same observations? What would happen to the information criterion values, if the models were fit to different numbers of observations? Perform some experiments, if you are not sure.\nAnswer: Information criteria are based on deviance. Deviance, in turn, is a sum and not a mean product of all observations. All else being equal, a model with more observations returns a higher deviance and thus worse accuracy according to information criteria.\nPractice M4 Question: What happens to the effective number of parameters, as measured by PSIS or WAIC, as a prior becomes more concentrated? Why? Perform some experiments, if you are not sure.\nAnswer: The effective number of parameters (or \u0026quot;pWAIC\u0026quot; in the WAIC() function output), is the penalty term of our regularisation approaches. As priors become more regularising (i.e. more concentrated on certain prior knowledge or assumptions), the effective number of parameters decreases.\nIn the case of WAIC, $p_{WAIC}$ is the variance in the log-likelihoods for each observation in the training data. More concentrated priors constrain this likelihood and subsequent measure of variance, thus reducing it.\nAs for PSIS, $P_D$ (effective number of parameters) tells us about the flexibility of the model. Increasingly regularised priors decrease the flexibility of the model.\nPractice M5 Question: Provide an informal explanation of why informative priors reduce overfitting.\nAnswer: Informative priors constrain the model by making it harder for the model to pick up on extreme parameter values and assign them high posterior probabilities.\nPractice M6 Question: Provide an informal explanation of why overly informative priors result in underfitting.\nAnswer: Informative priors can constrain a model so much that it becomes impossible for the model to change the prior distribution into an accurate posterior distribution given the data. This can especially problematic when we use informative priors that are born under false premises, stem from bad intuition, or are just plain stupid.\nHard Exercises Practice H1 Question: In 2007, The Wall Street Journal published an editorial (“We’re Number One, Alas”) with a graph of corporate tax rates in 29 countries plotted against tax Revenue. A badly fit curve was drawn in (reconstructed to the right), seemingly by hand, to make the argument that the relationship between tax rate and tax Revenue increases and then declines, such that higher tax rates can actually produce less tax Revenue. I want you to actually fit a curve to these data, found in data(Laffer). Consider models that use tax rate to predict tax Revenue. Compare, using WAIC or PSIS, a straight-line model to any curved models you like. What do you conclude about the relationship between tax rate and tax Revenue?\nAnswer: First, I begin by loading the data and standardising my variables:\n# data preparation\rdata(Laffer)\rd \u0026lt;- Laffer\rd$Rate \u0026lt;- standardize(d$tax_rate)\rd$Revenue \u0026lt;- standardize(d$tax_revenue)\r With this preparation out of the way, I am ready to run three models: Linear, Quadratic, and Cubic. I could run many more than these, but I wager this will be enough.\n# linear model\rm7H1a \u0026lt;- quap(\ralist(\rRevenue ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * Rate,\ra ~ dnorm(0, 0.2),\rb ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# quadratic model\rm7H1b \u0026lt;- quap(\ralist(\rRevenue ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * Rate + b2 * Rate^2,\ra ~ dnorm(0, 0.2),\rc(b, b2) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# cubic model\rm7H1c \u0026lt;- quap(\ralist(\rRevenue ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * Rate + b2 * Rate^2 + b3 * Rate^3,\ra ~ dnorm(0, 0.2),\rc(b, b2, b3) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# Comparing Models\rcomparison \u0026lt;- compare(m7H1a, m7H1b, m7H1c)\rcomparison\r ## WAIC SE dWAIC dSE pWAIC weight\r## m7H1a 87.98410 21.63416 0.0000000 NA 5.528420 0.4448646\r## m7H1b 88.79927 24.58351 0.8151711 3.382774 6.990224 0.2959482\r## m7H1c 89.06454 24.19943 1.0804389 3.089764 7.070477 0.2591872\r According to these WAIC values and their Standard Deviations, I cannot make a clear statement as to which relationship between tax rate and tax revenue should be assumed.\nLet me plot these to make a clearer image of what I mean:\n## base sequence for predictions\rplot_df \u0026lt;- data.frame(Rate = seq(from = min(d$Rate), to = max(d$Rate), length.out = 1e4))\r## Predictions for Linear Model\rplot_df$m7H1a \u0026lt;- apply(link(m7H1a, data = plot_df), 2, mean)\rplot_df$m7H1aLower \u0026lt;- apply(link(m7H1a, data = plot_df), 2, PI, prob = .95)[1, ]\rplot_df$m7H1aUpper \u0026lt;- apply(link(m7H1a, data = plot_df), 2, PI, prob = .95)[2, ]\r## Predictions for Quadratic Model\rplot_df$m7H1b \u0026lt;- apply(link(m7H1b, data = plot_df), 2, mean)\rplot_df$m7H1bLower \u0026lt;- apply(link(m7H1b, data = plot_df), 2, PI, prob = .95)[1, ]\rplot_df$m7H1bUpper \u0026lt;- apply(link(m7H1b, data = plot_df), 2, PI, prob = .95)[2, ]\r## Predictions for Cubic Model\rplot_df$m7H1c \u0026lt;- apply(link(m7H1c, data = plot_df), 2, mean)\rplot_df$m7H1cLower \u0026lt;- apply(link(m7H1c, data = plot_df), 2, PI, prob = .95)[1, ]\rplot_df$m7H1cUpper \u0026lt;- apply(link(m7H1c, data = plot_df), 2, PI, prob = .95)[2, ]\r## Plotting\rggplot(plot_df) +\rgeom_point(data = d, aes(x = Rate, y = Revenue), size = 2) +\rgeom_line(data = plot_df, aes(y = m7H1a, x = Rate, colour = \u0026quot;Linear\u0026quot;), size = 1.5) +\rgeom_ribbon(data = plot_df, aes(ymin = m7H1aLower, ymax = m7H1aUpper, x = Rate), alpha = .1) +\rgeom_line(data = plot_df, aes(y = m7H1b, x = Rate, colour = \u0026quot;Quadratic\u0026quot;), size = 1.5) +\rgeom_ribbon(data = plot_df, aes(ymin = m7H1bLower, ymax = m7H1bUpper, x = Rate), alpha = .1) +\rgeom_line(data = plot_df, aes(y = m7H1c, x = Rate, colour = \u0026quot;Cubic\u0026quot;), size = 1.5) +\rgeom_ribbon(data = plot_df, aes(ymin = m7H1cLower, ymax = m7H1cUpper, x = Rate), alpha = .1) +\rtheme_bw() +\rscale_colour_discrete(name = \u0026quot;Model\u0026quot;)\r I think this highlights quite well just how little difference there is in how the models understand the data. What the Wall Street Journal did there was (quite unsurprisingly) utter trite.\nPractice H2 Question: In the Laffer data, there is one country with a high tax revenue that is an outlier. Use PSIS and WAIC to measure the importance of this outlier in the models you fit in the previous problem. Then use robust regression with a Student’s t distribution to revisit the curve fitting problem. How much does a curved relationship depend upon the outlier point?\nAnswer: Using the rethinking package, we could identify the outlier by a very high WAIC value in the output of WAIC(..., pointwise = TRUE), where ... represents our model name. From the plot, we already now that our outlier is the country with the highest tax revenue, so let\u0026rsquo;s remove that one:\n# data preparation\rdata(Laffer)\rd \u0026lt;- Laffer\rd$Rate \u0026lt;- standardize(d$tax_rate)\rd$Revenue \u0026lt;- standardize(d$tax_revenue)\rd \u0026lt;- d[d$tax_revenue != max(d$tax_revenue), ] # removing the outlier\r With this preparation out of the way, I am ready to run three models again:\n# linear model\rm7H2a \u0026lt;- quap(\ralist(\rRevenue ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * Rate,\ra ~ dnorm(0, 0.2),\rb ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# quadratic model\rm7H2b \u0026lt;- quap(\ralist(\rRevenue ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * Rate + b2 * Rate^2,\ra ~ dnorm(0, 0.2),\rc(b, b2) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# cubic model\rm7H2c \u0026lt;- quap(\ralist(\rRevenue ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * Rate + b2 * Rate^2 + b3 * Rate^3,\ra ~ dnorm(0, 0.2),\rc(b, b2, b3) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# Comparing Models\rcomparison \u0026lt;- compare(m7H2a, m7H2b, m7H2c)\rcomparison\r ## WAIC SE dWAIC dSE pWAIC weight\r## m7H2b 59.61977 9.702003 0.000000 NA 4.010763 0.6272073\r## m7H2c 61.37195 9.630274 1.752179 1.215336 4.863606 0.2611742\r## m7H2a 63.07215 9.669994 3.452382 4.146202 4.256780 0.1116184\r Well, the models still greatly overlap in their usefulness.\nNext, let\u0026rsquo;s use a robust regression. I was unsure whether to revert back to the data which contains the outlier here. I chose to do so:\n# Revert back to full data\rdata(Laffer)\rd \u0026lt;- Laffer\rd$Rate \u0026lt;- standardize(d$tax_rate)\rd$Revenue \u0026lt;- standardize(d$tax_revenue)\r# linear model\rm7H2aS \u0026lt;- quap(\ralist(\rRevenue ~ dstudent(2, mu, sigma),\rmu \u0026lt;- a + b * Rate,\ra ~ dnorm(0, 0.2),\rb ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# quadratic model\rm7H2bS \u0026lt;- quap(\ralist(\rRevenue ~ dstudent(2, mu, sigma),\rmu \u0026lt;- a + b * Rate + b2 * Rate^2,\ra ~ dnorm(0, 0.2),\rc(b, b2) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# cubic model\rm7H2cS \u0026lt;- quap(\ralist(\rRevenue ~ dstudent(2, mu, sigma),\rmu \u0026lt;- a + b * Rate + b2 * Rate^2 + b3 * Rate^3,\ra ~ dnorm(0, 0.2),\rc(b, b2, b3) ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# Comparing Models\rcomparison \u0026lt;- compare(m7H2aS, m7H2bS, m7H2cS)\rcomparison\r ## WAIC SE dWAIC dSE pWAIC weight\r## m7H2bS 70.42437 13.97355 0.000000 NA 3.726454 0.69002496\r## m7H2cS 72.57488 13.76632 2.150509 1.370840 4.983440 0.23544401\r## m7H2aS 74.87539 13.57939 4.451025 4.933044 4.008494 0.07453103\r What happened in comparison to our original models (including the outlier)?\ncomparison \u0026lt;- compare(m7H1a, m7H1b, m7H1c, m7H2a, m7H2b, m7H2c, m7H2aS, m7H2bS, m7H2cS)\rcomparison\r ## WAIC SE dWAIC dSE pWAIC weight\r## m7H2b 58.70723 9.337612 0.000000 NA 3.548011 6.669909e-01\r## m7H2c 61.41111 9.567978 2.703873 1.160931 4.897430 1.725764e-01\r## m7H2a 61.59824 9.188906 2.891004 3.943353 3.520610 1.571616e-01\r## m7H2bS 70.00986 13.878681 11.302627 10.451899 3.521786 2.343072e-03\r## m7H2cS 72.56361 13.867102 13.856375 10.523791 4.983524 6.535011e-04\r## m7H2aS 74.30030 13.502465 15.593071 10.302465 3.722951 2.742379e-04\r## m7H1b 89.68562 25.603534 30.978388 22.459013 7.469330 1.250975e-07\r## m7H1a 90.11345 23.731476 31.406222 20.599460 6.639281 1.010056e-07\r## m7H1c 90.25121 25.081664 31.543979 21.929293 7.672332 9.428269e-08\r Removing the outlier definitely made our models perform a lot better across the board. So did using a robust regression.\nPractice H3 Question: Consider three fictional Polynesian islands. On each there is a Royal Ornithologist charged by the king with surveying the bird population. They have each found the following proportions of 5 important bird species:\nNotice that each row sums to 1, all the birds. This problem has two parts. It is not computationally complicated. But it is conceptually tricky. First, compute the entropy of each island’s bird distribution. Interpret these entropy values. Second, use each island’s bird distribution to predict the other two. This means to compute the K-L Divergence of each island from the others, treating each island as if it were a statistical model of the other islands. You should end up with 6 different K-L Divergence values. Which island predicts the others best? Why?\nAnswer: First, let\u0026rsquo;s start with the entropies:\n# First Island\rp1 \u0026lt;- c(0.2, 0.2, 0.2, 0.2, 0.2)\r-sum(p1 * log(p1))\r ## [1] 1.609438\r # Second Island\rp2 \u0026lt;- c(0.8, 0.1, 0.05, 0.025, 0.025)\r-sum(p2 * log(p2))\r ## [1] 0.7430039\r # Third Island\rp3 \u0026lt;- c(0.05, 0.15, 0.7, 0.05, 0.05)\r-sum(p3 * log(p3))\r ## [1] 0.9836003\r Entropy is a measure of uncertainty. The higher the entropy, the more uncertain we are of the probability density distribution at hand. Here, the entropies of the islands are ordered (in increasing order) as Island 2, Island 3, and Island 1. This tells us that there is a lot of certainty (in relative terms) of the proportions assigned to each bird species at Island 2 over the other islands. I posit that this is because of the overwhelming presence of species A in Island 2 whilst all other species presences drop drastically to almost being non-existent on Island 2. In plain terms: \u0026ldquo;We are much more certain of which species to find on an island where we know which species is the sole inhabitant when contrasted with an island where all species are present in equal proportions\u0026rdquo;.\nNow, let\u0026rsquo;s move on to the computation of K-L distances also known as Divergence. Divergence is calculated as the average difference in log probability between target (p) and model (q). First things first, I need to identify the model (q). The task states to use information on two islands to obtain K-L distances to one target island. So, to identify the model, I need to average out the proportions on two islands and then compare these to the target island. For each of these pairings, I will obtain two K-L distances since these distances are not reversible in their directionality.\nLet me walk you through my first example of obtaining the Divergence between Island 1 and the Island 2 and 3 taken together:\n# Average the proportions of Island 2 and 3\r(q \u0026lt;- apply(cbind(p2, p3), 1, mean))\r ## [1] 0.4250 0.1250 0.3750 0.0375 0.0375\r # Divergence of Island 1 from combined Islands 2 \u0026amp; 3\r(D_pq \u0026lt;- sum(p1 * log(p1 / q)))\r ## [1] 0.4871152\r # Divergence of combined Islands 2 \u0026amp; 3 from Island 1\r(D_qp \u0026lt;- sum(q * log(q / p1)))\r ## [1] 0.3717826\r By using our combined knowledge of Islands 2 \u0026amp; 3 to approximate Island 1, we introduce an additional 0.49 of uncertainty. On the contrary, by using our knowledge of Island 1 to approximate the combination of Islands 2 \u0026amp; 3, we introduce an additional 0.37 of uncertainty.\nNow, I repeat this for the other two target islands:\noutput \u0026lt;- data.frame(\rApproximated = D_pq,\rApproximator = D_qp\r)\r# Target: Island 2\rq \u0026lt;- apply(cbind(p1, p3), 1, mean)\rD_pq \u0026lt;- sum(p2 * log(p2 / q))\rD_qp \u0026lt;- sum(q * log(q / p2))\routput \u0026lt;- rbind(output, c(D_pq, D_qp))\r# Target: Island 3\rq \u0026lt;- apply(cbind(p1, p2), 1, mean)\rD_pq \u0026lt;- sum(p3 * log(p3 / q))\rD_qp \u0026lt;- sum(q * log(q / p3))\routput \u0026lt;- rbind(output, c(D_pq, D_qp))\r# output\rrownames(output) \u0026lt;- c(\u0026quot;Island 1\u0026quot;, \u0026quot;Island 2\u0026quot;, \u0026quot;Island 3\u0026quot;)\routput\r ## Approximated Approximator\r## Island 1 0.4871152 0.3717826\r## Island 2 1.2387437 1.2570061\r## Island 3 1.0097143 1.1184060\r As it turns out, the divergence between a \u0026ldquo;safe bet\u0026rdquo; (i.e. Island 1 where all species are equally present) and other systems is much smaller than when comparing heavily skewed probability density distributions.\nPractice H4 Question: Recall the marriage, age, and happiness collider bias example from Chapter 6. Run models m6.9 and m6.10 again. Compare these two models using WAIC (or LOO, they will produce identical results). Which model is expected to make better predictions? Which model provides the correct causal inference about the influence of age on happiness? Can you explain why the answers to these two questions disagree?\nAnswer: Remember that in these models, m6.9 shows a negative relationship between age and happiness which we know to be untrue because it conditions on the collider of marriage status which itself, is influenced by age and happiness. m6.10 does not condition on said collider and thus does not find a relationship between age and happiness:\n## R code 6.21\rd \u0026lt;- sim_happiness(seed = 1977, N_years = 1000)\r## R code 6.22\rd2 \u0026lt;- d[d$age \u0026gt; 17, ] # only adults\rd2$A \u0026lt;- (d2$age - 18) / (65 - 18)\r## R code 6.23\rd2$mid \u0026lt;- d2$married + 1\rm6.9 \u0026lt;- quap(\ralist(\rhappiness ~ dnorm(mu, sigma),\rmu \u0026lt;- a[mid] + bA * A,\ra[mid] ~ dnorm(0, 1),\rbA ~ dnorm(0, 2),\rsigma ~ dexp(1)\r),\rdata = d2\r)\r## R code 6.24\rm6.10 \u0026lt;- quap(\ralist(\rhappiness ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bA * A,\ra ~ dnorm(0, 1),\rbA ~ dnorm(0, 2),\rsigma ~ dexp(1)\r),\rdata = d2\r)\r## Comparison\rcompare(m6.9, m6.10)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m6.9 2713.971 37.54465 0.0000 NA 3.738532 1.000000e+00\r## m6.10 3101.906 27.74379 387.9347 35.40032 2.340445 5.768312e-85\r According to these information criteria, model m6.9 is a lot better performing (in terms of out-of-sample deviance). However, we know that model m6.10 provides the true causal relationship between age and happiness: none!\nSo why would we want to use model m6.9 given the WAIC above instead of model m6.10. Because by thinking we should do so, we did model selection instead of model comparison! Argh. I stepped right into that one, didn\u0026rsquo;t I? By comparing these two models we can safely say that some confounding must be taking place. WAIC would have us favour model m6.9 simply because it does a better job at predicting the happiness of out-of-sample individuals. Why is that? Because this model identifies the happiness of the different groups of people: the miserable unmarried as well as the ecstatic married ones. Conditioning on the collider added statistical association and so aids predictive accuracy. Thus, while doing better at predicting model m6.9 fails at finding causality. It is important to highlight that again that a model may be good at predicting things without being causally correct.\nPractice H5 Question: Revisit the urban fox data, data(foxes), from the previous chapter’s practice problems. Use WAIC or PSIS based model comparison on five different models, each using weight as the outcome, and containing these sets of predictor variables:\n(1) avgfood + groupsize + area\n(2) avgfood + groupsize\n(3) groupsize + area\n(4) avgfood\n(5) area\nCan you explain the relative differences in WAIC scores, using the fox DAG from last week’s home-work? Be sure to pay attention to the standard error of the score differences (dSE).\nAnswer: The previous chapter in the pdf version I am using did not ask any questions about the fox data. I consulted Jake Thomspon\u0026rsquo;s Blog here:\n# data loading and prepping\rdata(foxes)\rd \u0026lt;- foxes\rd$area \u0026lt;- scale(d$area)\rd$avgfood \u0026lt;- scale(d$avgfood)\rd$weight \u0026lt;- scale(d$weight)\rd$groupsize \u0026lt;- scale(d$groupsize)\r## Models\r# (1) `avgfood + groupsize + area`\rb7h5_1 \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bFood * avgfood + bGroup * groupsize + bArea * area,\ra ~ dnorm(0, .2),\rc(bFood, bGroup, bArea) ~ dnorm(0, 5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# (2) `avgfood + groupsize`\rb7h5_2 \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bFood * avgfood + bGroup * groupsize,\ra ~ dnorm(0, .2),\rc(bFood, bGroup) ~ dnorm(0, 5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# (3) `groupsize + area`\rb7h5_3 \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bGroup * groupsize + bArea * area,\ra ~ dnorm(0, .2),\rc(bGroup, bArea) ~ dnorm(0, 5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# (4) `avgfood`\rb7h5_4 \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bFood * avgfood,\ra ~ dnorm(0, .2),\rbFood ~ dnorm(0, 5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r# (5) `area`\rb7h5_5 \u0026lt;- quap(\ralist(\rweight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bArea * area,\ra ~ dnorm(0, .2),\rbArea ~ dnorm(0, 5),\rsigma ~ dexp(1)\r),\rdata = d\r)\r## Comparison\rcompare(b7h5_1, b7h5_2, b7h5_3, b7h5_4, b7h5_5)\r ## WAIC SE dWAIC dSE pWAIC weight\r## b7h5_1 323.3416 16.88472 0.0000000 NA 5.187854 0.410865167\r## b7h5_2 323.9809 16.81807 0.6393574 3.894043 4.130907 0.298445216\r## b7h5_3 324.0666 16.18771 0.7250103 4.207249 3.945774 0.285933698\r## b7h5_4 333.5084 13.79238 10.1668387 8.659625 2.454047 0.002546821\r## b7h5_5 333.7929 13.79707 10.4513608 8.704578 2.684646 0.002209099\r Again, the differences of in the WAIC scores all fall well within the 99% intervals of the differences:\nplot(compare(b7h5_1, b7h5_2, b7h5_3, b7h5_4, b7h5_5))\r However, we can see that models b7h5_1, b7h5_2, and b7h5_3 are nearly identical in their out-of-sample deviance, as are models b7h5_4 and b7h5_5. To understand this, we want to look at the DAG that underlies this example:\nModels b7h5_1, b7h5_2, and b7h5_3 all use groupsize and one of/both area and/or avgfood. Consequently, all of these models fair the same in their predictive power because there are no open backdoor paths from either area or avgfood, as soon as groupsize is used in conjunction. In other words, the effect of area while adjusting for groupsize is the same as the effect of avgfood while adjusting for groupsize, because the effect of area is routed entirely through avgfood.\nLikewise, models b7h5_4 and b7h5_5 are nearly identical because these two only contain area or avgfood in isolation and all information of area onto weight must pass through avgfood.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 R6_2.5.0 ## [11] backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 ## [21] jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 labeling_0.4.2 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 ## [31] xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 codetools_0.2-18 ## [41] matrixStats_0.61.0 fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 ## [51] lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 farver_2.1.0 bslib_0.2.4 ellipsis_0.3.2 ## [61] generics_0.1.0 vctrs_0.3.7 rematch2_2.1.2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 ## [71] colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1612396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612465200,"objectID":"0f23328eb8a4b77cb677aff1b7b37ac4","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-07/","publishdate":"2021-02-04T00:00:00Z","relpermalink":"/courses/rethinking/chapter-07/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 7 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 07","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our second practical experience in R. Throughout the following notes, I will introduce you to a couple nominal statistical test approaches that might be useful to you and are often used in biology.\nTo do so, I will enlist the sparrow data set we handled in our last exercise.\nI have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;nonpar\u0026quot;, # needed for Cochran's Q\r\u0026quot;ggplot2\u0026quot;) # data visualisation\rsapply(package_vec, install.load.package)\r ## Loading required package: nonpar\r ## Loading required package: ggplot2\r ## nonpar ggplot2 ## TRUE TRUE\r Loading Data During our last exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Binomial Test As the name would suggest, a binomial test can only accommodate variables on a binomial scale. A binomial test is used to test whether both values of the binomial variable are present in equal proportions within the data set. The only binomial variables contained within the Passer domesticus data set are Sex (Male, Female) and Predator.Presence (Yes, No). The R function to carry out a binomial test comes with base R and is called binom.test(). The Null Hypothesis we operate on is that both data values are equally likely to occur although one can specify a different expectations using the p =  statement within the binom.test() function.\nSexual Dimorphism Are the sexes represented in equal proportions?\nFirst, we want to test whether our data has a bias leaning towards either sex of the surveyed sparrows. To do so, we may wish to first convert the binomial data into count records using the table() command of R as follows. The result of this can then be feed to binom.test().\ntable(Data_df$Sex)\r ## ## Female Male ## 523 544\r binom.test(table(Data_df$Sex))\r ## ## Exact binomial test\r## ## data: table(Data_df$Sex)\r## number of successes = 523, number of trials = 1067, p-value = 0.5404\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.4597580 0.5206151\r## sample estimates:\r## probability of success ## 0.4901593\r As we can see, there is no skew towards either male or female abundance of individuals of Passer domesticus and so we have to accept the null hypothesis. Note that, although our data is recorded in terms of Male and Female, the binom.test() function works with records of success and failure.\nThis is to be expected. After all no bias for sex is known in Passer domesticus and indeed the species does reproduce monogamously so a skew between the sexes wouldn\u0026rsquo;t go anywhere as far as evolution is concerned.\nPredation Are the sites dominated by predators?\nNow, let\u0026rsquo;s see if there is a skew towards predators being present at our sites or not. This time, however we make use of a different syntax for the binom.test() function. We do this for no reason of functionality but simply to show that there are multiple ways to using it.\ntable(Data_df$Predator.Presence)\r ## ## No Yes ## 357 710\r binom.test(x = sum(Data_df$Predator.Presence == \u0026quot;Yes\u0026quot;), n = length(Data_df$Predator.Presence))\r ## ## Exact binomial test\r## ## data: sum(Data_df$Predator.Presence == \u0026quot;Yes\u0026quot;) and length(Data_df$Predator.Presence)\r## number of successes = 710, number of trials = 1067, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.6362102 0.6937082\r## sample estimates:\r## probability of success ## 0.6654171\r Quite obviously, these proportions aren\u0026rsquo;t as equal as the ones of the sex example. In fact, they exhibit statistically significant proportion sizes within our data set (p $\\approx$ 0).\nThis is in concordance with what we\u0026rsquo;d expect from the natural world since predation is common in nature after all and so we reject the null hypothesis.\nMcNemar The McNemar Test (sometimes referred to as McNemar\u0026rsquo;s Chi-Square test because the test statistic has a chi-square distribution) is used when you are interested in finding a change in proportion for paired data. This is very common in repeated sampling analyses.\nThe null hypothesis reads: Class assignment probabilities do not change within different treatments.\nPreparing The Data Do sex ratios change over time?\nUnfortunately, our data does not allow for these types of analyses and so we will need to create some additional data here.\nLet\u0026rsquo;s say we wanted to resample the sex ratio of Passer domesticus in Australia (AU) a year after our initial survey because of an especially hostile winter and we\u0026rsquo;d like to see whether this resulted in an alteration of the sex ratio.\nWhat is our sex ratio before the winter?\ntable(Data_df$Sex[which(Data_df$Index == \u0026quot;AU\u0026quot;)])\r ## ## Female Male ## 44 44\r Sexes_AU_Now_vec \u0026lt;- Data_df$Sex[which(Data_df$Index == \u0026quot;AU\u0026quot;)]\r The sex ratio is not skewed. So let\u0026rsquo;s hypothesise about what might happen to the sex ratio when a strong winter hits our population. The sex ratio could either (1) stay the same or (2) change. Although it would make sense to assume that the population would shrink, McNemar tests can\u0026rsquo;t account for that and so we assume that our population size will stay the same and only the sex ratio might change. Let\u0026rsquo;s create some new data for a changed sex ratio that is male biased:\nSexes \u0026lt;- c(\u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;) # creating a vector of sexes to sample from\rset.seed(42) # making it reproducible\rSexes_AU_Next_vec \u0026lt;- sample(Sexes, sum(Data_df$Index==\u0026quot;AU\u0026quot;), replace = TRUE, prob = c(0.8,0.2))\r Here\u0026rsquo;s the data we will be testing:\ntable(Sexes_AU_Now_vec)  ## Sexes_AU_Now_vec\r## Female Male ## 44 44\r table(Sexes_AU_Next_vec)\r ## Sexes_AU_Next_vec\r## Female Male ## 21 67\r Running The Test Now let\u0026rsquo;s go on to test the unbiased vs. the male-skewed sex ratio:\nmcnemar_matrix_change \u0026lt;- matrix(rbind(table(Sexes_AU_Now_vec), table(Sexes_AU_Next_vec)), 2)\rmcnemar.test(mcnemar_matrix_change)\r ## ## McNemar's Chi-squared test with continuity correction\r## ## data: mcnemar_matrix_change\r## McNemar's chi-squared = 7.4462, df = 1, p-value = 0.006357\r Obviously, with this data we would record a statistically significant change and reject the null hypothesis.\nMaking Sense Of The Results Unfortunately, McNemar only tells us that there is a difference without any information about the direction of the difference. For now, we will have to settle on a visualisation of the sexes to shed some light on the difference.\n# preparing plotting\rplot_df \u0026lt;- data.frame(Data = c(prop.table(mcnemar_matrix_change[1,]),\rprop.table(mcnemar_matrix_change[2,])),\rIdentifiers = rep(c(\u0026quot;Female\u0026quot;, \u0026quot;Male\u0026quot;), 2),\rYear = rep(c(\u0026quot;Now\u0026quot;, \u0026quot;Next Year\u0026quot;), each = 2))\r# plotting\rggplot(plot_df, aes(x = Year, y = Data, fill = Identifiers)) + geom_bar(stat=\u0026quot;identity\u0026quot;) +\rggtitle(label = \u0026quot;Abundances of the sexes among study organisms\u0026quot;) + theme_bw() +\rylab(\u0026quot;Proportion\u0026quot;)\r The above plot is very crude and should only ever be used for data exploration and not for publishing purposes. Clearly, we can see the change in sex ratio towards a male-biased state (blue colour represents males).\nCochran\u0026rsquo;s Q Cochran\u0026rsquo;s Q is a non parametric test for finding differences in matched sets of three or more frequencies or proportions.\nAs such, the Cochran\u0026rsquo;s Q Test is an extension of the McNemar test - the two tests are equal if Cochran\u0026rsquo;s Q is calculated for two groups.\nThe null hypothesis for Cochran\u0026rsquo;s Q postulates an equal proportion of class assignents for all treatments.\nPreparing The Data Are colours related to sex or predator parameters?\nWhen exploring our data, we can clearly see a pattern concerning the colour polymorphism of house sparrows arise which is dependant on the value of Predator Presence.\ncounts \u0026lt;- table(Data_df$Colour, Data_df$Predator.Presence)\r# preparing plotting\rplot_df \u0026lt;- data.frame(Data = c(prop.table(counts[,1]), prop.table(counts[,2])),\rIdentifiers = rep(c(\u0026quot;Black\u0026quot;, \u0026quot;Brown\u0026quot;, \u0026quot;Grey\u0026quot;), 2),\rPredation = rep(c(\u0026quot;No\u0026quot;, \u0026quot;Yes\u0026quot;), each = 3))\r# plotting\rggplot(plot_df, aes(x = Predation, y = Data, fill = Identifiers)) + geom_bar(stat=\u0026quot;identity\u0026quot;) + ggtitle(label = \u0026quot;Colour Variations of the common House Sparrow\u0026quot;) + theme_bw() +ylab(\u0026quot;Proportions\u0026quot;) + scale_fill_manual(values=c(\u0026quot;black\u0026quot;, \u0026quot;saddlebrown\u0026quot;, \u0026quot;grey\u0026quot;))\r This might lead us to believe that the presence of predators cause an evolutionary change of the plumage colour of Passer domesticus (we will have a more in-depth look on this in later seminars) and we might even postulate that \u0026ldquo;Black\u0026rdquo; and \u0026ldquo;Grey\u0026rdquo; serve as camouflage.\nCochran\u0026rsquo;s Q requires data to be delivered as binomial records. Therefore, we prepare colour as a binary variable of \u0026ldquo;Brown\u0026rdquo; and \u0026ldquo;Camouflage\u0026rdquo; (which we postulate to encompass \u0026ldquo;Grey\u0026rdquo; and \u0026ldquo;Black\u0026rdquo;). Since Colour is of type factor within our data set, we need to take some precautions in changing the data records. Predator Presence and Sex don\u0026rsquo;t need any additional preparation.\n# Colour CochColour \u0026lt;- Data_df_base$Colour\r# adding new level to factor list\rlevels(CochColour) \u0026lt;- c(levels(CochColour), \u0026quot;Camouflage\u0026quot;) # defining black and grey to be camouflage\rCochColour[which(CochColour == \u0026quot;Grey\u0026quot;)] \u0026lt;- \u0026quot;Camouflage\u0026quot; CochColour[which(CochColour == \u0026quot;Black\u0026quot;)] \u0026lt;- \u0026quot;Camouflage\u0026quot; # dropping unnecessary factor levels\rCochColour \u0026lt;- droplevels(CochColour) # Predator Presence\rCochPredator.Presence \u0026lt;- factor(Data_df_base$Predator.Presence)\r# Sex\rCochSex \u0026lt;- factor(Data_df_base$Sex)\r# Making vectors into a matrix\rCochMatrix \u0026lt;- matrix(c(CochColour, CochPredator.Presence, CochSex), ncol = 3) - 1\rcolnames(CochMatrix) \u0026lt;- c(\u0026quot;Colour\u0026quot;, \u0026quot;Predator Presence\u0026quot;, \u0026quot;Sex\u0026quot;)\rhead(CochMatrix)\r ## Colour Predator Presence Sex\r## [1,] 0 1 1\r## [2,] 1 1 1\r## [3,] 1 1 0\r## [4,] 0 1 0\r## [5,] 1 1 1\r## [6,] 0 1 0\r Runing The Test Now let\u0026rsquo;s run our test using the cochrans.q() function that comes with the nonpar package:\ncochrans.q(CochMatrix)\r ## ## Cochran's Q Test ## ## H0: There is no difference in the effectiveness of treatments. ## HA: There is a difference in the effectiveness of treatments. ## ## Q = 122.984939759036 ## ## Degrees of Freedom = 2 ## ## Significance Level = 0.05 ## The p-value is 0 ## There is enough evidence to conclude that the effectiveness of at least two treatments differ. ##  As we can see, the output from this function is extremely user friendly. Additionally, as was to be expected the assignment probabilities for each class in each treatment are not equal thus forcing us to reject the null hypothesis.\nMaking Sense Of The Results Where are the differences coming from?\nAs you may recall from just a few pages ago, using the binomial test, we can identify the assignment proportions for any binomial variable individually.\nFirstly, let\u0026rsquo;s test the binary version of the colour variable:\ntable(CochColour)\r ## CochColour\r## Brown Camouflage ## 298 769\r binom.test(table(CochColour))\r ## ## Exact binomial test\r## ## data: table(CochColour)\r## number of successes = 298, number of trials = 1067, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.2525387 0.3072599\r## sample estimates:\r## probability of success ## 0.2792877\r Based on this result, we reject the null hypothesis of binary colour records being equally likely to occur.\nSecondly, let\u0026rsquo;s test the predator presence variable:\ntable(CochPredator.Presence)\r ## CochPredator.Presence\r## No Yes ## 357 710\r binom.test(table(CochPredator.Presence))\r ## ## Exact binomial test\r## ## data: table(CochPredator.Presence)\r## number of successes = 357, number of trials = 1067, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.3062918 0.3637898\r## sample estimates:\r## probability of success ## 0.3345829\r Based on this result, we reject the null hypothesis of predator presence records being equally likely to occur.\nLastly, recall the binomial test run on the sex data records which exhibit an almost even 50/50 split.\nWhilst none of these test give us any idea about the overlap of similar assignments along these variable vectors, a 50/50 split (sex) can never link up comparably with a roughly 30/70 split (predator presence and binary colour). Therefore, we could hypothesize a linkage of predator presence and colour rather than sex and colour morphs.\nChi-Squared The Chi-Squared (also known as $Chi^2$) Test can be regarded as a functional extension of the binomial test and is used to test the similarity of class assignment proportions for a categorical/nominal variable. Unlike the binomial test, however, this test is not constrained to binomial records alone.\nThe null hypothesis states that: Every class assignment contained within a given variable is equally likely.\nThe Chi-Squared Test can be applied in a one or two sample situation. One sample represents one variable in this setting.\nOne Sample Situation Binary Colour Let\u0026rsquo;s asses the proportions of one variable we have already looked at - the binary version of the colour variable:\ntable(CochColour)\r ## CochColour\r## Brown Camouflage ## 298 769\r chisq.test(table(CochColour))\r ## ## Chi-squared test for given probabilities\r## ## data: table(CochColour)\r## X-squared = 207.91, df = 1, p-value \u0026lt; 2.2e-16\r Based on this result, we reject the null hypothesis of binary colour records being equally likely to occur. Note how the Chi-Squared test returns the same p-value as the binomial test above (within the Cochran\u0026rsquo;s Q section).\nColour Now let\u0026rsquo;s run the same test on the non-binary colour data:\ntable(Data_df$Colour)\r ## ## Black Brown Grey ## 356 298 413\r chisq.test(table(Data_df$Colour))\r ## ## Chi-squared test for given probabilities\r## ## data: table(Data_df$Colour)\r## X-squared = 18.592, df = 2, p-value = 9.178e-05\r Again, we reject the null hypothesis thus concluding differing class proportions for every possible class of \u0026ldquo;Colour\u0026rdquo;.\nTwo Sample Situation The two sample Chi-Squared approach lets us identify whether class assignment proportions of one variable differ when they are considered in a dependency of another nominal variable.\nSexual Dimorphism Are colours of Passer domesticus related to their sexes?\nFirstly, let\u0026rsquo;s see if males and females share the same likelihoods of being of a certain colour:\ntable(Data_df$Colour, Data_df$Sex)\r ## ## Female Male\r## Black 320 36\r## Brown 122 176\r## Grey 81 332\r chisq.test(table(Data_df$Colour, Data_df$Sex))\r ## ## Pearson's Chi-squared test\r## ## data: table(Data_df$Colour, Data_df$Sex)\r## X-squared = 388.63, df = 2, p-value \u0026lt; 2.2e-16\r Clearly, they don\u0026rsquo;t and we reject the null hypothesis.\nPredation Are colours of Passer domesticus related to predator parameters?\nSecondly, we test whether colour proportions change when considering predator presence. Although we partially considered this already in the Cochran\u0026rsquo;s Q section. This time, however, we use a non-binary version of the colour variable:\ntable(Data_df$Colour, Data_df$Predator.Presence)\r ## ## No Yes\r## Black 64 292\r## Brown 211 87\r## Grey 82 331\r chisq.test(table(Data_df$Colour, Data_df$Predator.Presence))\r ## ## Pearson's Chi-squared test\r## ## data: table(Data_df$Colour, Data_df$Predator.Presence)\r## X-squared = 259.34, df = 2, p-value \u0026lt; 2.2e-16\r The statement holds. Predator presence seems likely to be a driver of the colour polymorphism in Passer domesticus and we reject the null hypothesis.\nSo what about a possible link of sparrow colour and predator type?\ntable(Data_df$Colour, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Black 197 95\r## Brown 60 27\r## Grey 233 98\r chisq.test(table(Data_df$Colour, Data_df$Predator.Type))\r ## ## Pearson's Chi-squared test\r## ## data: table(Data_df$Colour, Data_df$Predator.Type)\r## X-squared = 0.62164, df = 2, p-value = 0.7328\r Nope, no link here. We have to accept the null hypothesis and conclude that there may be no causal link of predator type and sparrow colour.\nAre nesting sites of Passer domesticus related to predator parameters?\nThird, let\u0026rsquo;s test whether nesting site assignments might differ based on predator presence:\ntable(Data_df$Nesting.Site, Data_df$Predator.Presence)\r ## ## No Yes\r## Shrub 87 205\r## Tree 94 137\r chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Presence))\r ## ## Pearson's Chi-squared test with Yates' continuity correction\r## ## data: table(Data_df$Nesting.Site, Data_df$Predator.Presence)\r## X-squared = 6.2955, df = 1, p-value = 0.0121\r There seems to be a link here and we reject the null hypothesis.\nSo what about a link of predator type and nesting site?\ntable(Data_df$Nesting.Site, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Shrub 182 23\r## Tree 49 88\r chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Type))\r ## ## Pearson's Chi-squared test with Yates' continuity correction\r## ## data: table(Data_df$Nesting.Site, Data_df$Predator.Type)\r## X-squared = 102.88, df = 1, p-value \u0026lt; 2.2e-16\r Apparently, there is a really strong one and we reject the null hypothesis.\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"39d19a566027552dbf8f681ddfb6ba26","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/nominal-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/nominal-tests/","section":"courses","summary":"Welcome to our second practical experience in `R`. Throughout the following notes, I will introduce you to a couple nominal statistical test approaches that might be useful to you and are often used in biology. To do so, I will enlist the sparrow data set we handled in our last exercise.","tags":["R","Statistics"],"title":"Nominal Tests","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our second practical experience in R. Throughout the following notes, I will introduce you to a couple nominal statistical test approaches that might be useful to you and are often used in biology. To do so, I will enlist the sparrow data set we handled in our last exercise. I have prepared some slides for this session: \nData Find the data for this exercise here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;nonpar\u0026quot;, # needed for Cochran's Q\r\u0026quot;ggplot2\u0026quot;) # data visualisation\rsapply(package_vec, install.load.package)\r ## Loading required package: nonpar\r ## Loading required package: ggplot2\r ## nonpar ggplot2 ## TRUE TRUE\r Loading Data During our last exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Binomial Test As the name would suggest, a binomial test can only accommodate variables on a binomial scale. A binomial test is used to test whether both values of the binomial variable are present in equal proportions within the data set. The only binomial variables contained within the Passer domesticus data set are Sex (Male, Female) and Predator.Presence (Yes, No). The R function to carry out a binomial test comes with base R and is called binom.test(). The Null Hypothesis we operate on is that both data values are equally likely to occur although one can specify a different expectations using the p =  statement within the binom.test() function.\nSexual Dimorphism Are the sexes represented in equal proportions?\nFirst, we want to test whether our data has a bias leaning towards either sex of the surveyed sparrows. To do so, we may wish to first convert the binomial data into count records using the table() command of R as follows. The result of this can then be feed to binom.test().\ntable(Data_df$Sex)\r ## ## Female Male ## 523 544\r binom.test(table(Data_df$Sex))\r ## ## Exact binomial test\r## ## data: table(Data_df$Sex)\r## number of successes = 523, number of trials = 1067, p-value = 0.5404\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.4597580 0.5206151\r## sample estimates:\r## probability of success ## 0.4901593\r As we can see, there is no skew towards either male or female abundance of individuals of Passer domesticus and so we have to accept the null hypothesis. Note that, although our data is recorded in terms of Male and Female, the binom.test() function works with records of success and failure.\nThis is to be expected. After all no bias for sex is known in Passer domesticus and indeed the species does reproduce monogamously so a skew between the sexes wouldn\u0026rsquo;t go anywhere as far as evolution is concerned.\nPredation Are the sites dominated by predators?\nNow, let\u0026rsquo;s see if there is a skew towards predators being present at our sites or not. This time, however we make use of a different syntax for the binom.test() function. We do this for no reason of functionality but simply to show that there are multiple ways to using it.\ntable(Data_df$Predator.Presence)\r ## ## No Yes ## 357 710\r binom.test(x = sum(Data_df$Predator.Presence == \u0026quot;Yes\u0026quot;), n = length(Data_df$Predator.Presence))\r ## ## Exact binomial test\r## ## data: sum(Data_df$Predator.Presence == \u0026quot;Yes\u0026quot;) and length(Data_df$Predator.Presence)\r## number of successes = 710, number of trials = 1067, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.6362102 0.6937082\r## sample estimates:\r## probability of success ## 0.6654171\r Quite obviously, these proportions aren\u0026rsquo;t as equal as the ones of the sex example. In fact, they exhibit statistically significant proportion sizes within our data set (p $\\approx$ 0).\nThis is in concordance with what we\u0026rsquo;d expect from the natural world since predation is common in nature after all and so we reject the null hypothesis.\nMcNemar The McNemar Test (sometimes referred to as McNemar\u0026rsquo;s Chi-Square test because the test statistic has a chi-square distribution) is used when you are interested in finding a change in proportion for paired data. This is very common in repeated sampling analyses.\nThe null hypothesis reads: Class assignment probabilities do not change within different treatments.\nPreparing The Data Do sex ratios change over time?\nUnfortunately, our data does not allow for these types of analyses and so we will need to create some additional data here.\nLet\u0026rsquo;s say we wanted to resample the sex ratio of Passer domesticus in Australia (AU) a year after our initial survey because of an especially hostile winter and we\u0026rsquo;d like to see whether this resulted in an alteration of the sex ratio.\nWhat is our sex ratio before the winter?\ntable(Data_df$Sex[which(Data_df$Index == \u0026quot;AU\u0026quot;)])\r ## ## Female Male ## 44 44\r Sexes_AU_Now_vec \u0026lt;- Data_df$Sex[which(Data_df$Index == \u0026quot;AU\u0026quot;)]\r The sex ratio is not skewed. So let\u0026rsquo;s hypothesise about what might happen to the sex ratio when a strong winter hits our population. The sex ratio could either (1) stay the same or (2) change. Although it would make sense to assume that the population would shrink, McNemar tests can\u0026rsquo;t account for that and so we assume that our population size will stay the same and only the sex ratio might change. Let\u0026rsquo;s create some new data for a changed sex ratio that is male biased:\nSexes \u0026lt;- c(\u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;) # creating a vector of sexes to sample from\rset.seed(42) # making it reproducible\rSexes_AU_Next_vec \u0026lt;- sample(Sexes, sum(Data_df$Index==\u0026quot;AU\u0026quot;), replace = TRUE, prob = c(0.8,0.2))\r Here\u0026rsquo;s the data we will be testing:\ntable(Sexes_AU_Now_vec)  ## Sexes_AU_Now_vec\r## Female Male ## 44 44\r table(Sexes_AU_Next_vec)\r ## Sexes_AU_Next_vec\r## Female Male ## 21 67\r Running The Test Now let\u0026rsquo;s go on to test the unbiased vs. the male-skewed sex ratio:\nmcnemar_matrix_change \u0026lt;- matrix(rbind(table(Sexes_AU_Now_vec), table(Sexes_AU_Next_vec)), 2)\rmcnemar.test(mcnemar_matrix_change)\r ## ## McNemar's Chi-squared test with continuity correction\r## ## data: mcnemar_matrix_change\r## McNemar's chi-squared = 7.4462, df = 1, p-value = 0.006357\r Obviously, with this data we would record a statistically significant change and reject the null hypothesis.\nMaking Sense Of The Results Unfortunately, McNemar only tells us that there is a difference without any information about the direction of the difference. For now, we will have to settle on a visualisation of the sexes to shed some light on the difference.\n# preparing plotting\rplot_df \u0026lt;- data.frame(Data = c(prop.table(mcnemar_matrix_change[1,]),\rprop.table(mcnemar_matrix_change[2,])),\rIdentifiers = rep(c(\u0026quot;Female\u0026quot;, \u0026quot;Male\u0026quot;), 2),\rYear = rep(c(\u0026quot;Now\u0026quot;, \u0026quot;Next Year\u0026quot;), each = 2))\r# plotting\rggplot(plot_df, aes(x = Year, y = Data, fill = Identifiers)) + geom_bar(stat=\u0026quot;identity\u0026quot;) +\rggtitle(label = \u0026quot;Abundances of the sexes among study organisms\u0026quot;) + theme_bw() +\rylab(\u0026quot;Proportion\u0026quot;)\r The above plot is very crude and should only ever be used for data exploration and not for publishing purposes. Clearly, we can see the change in sex ratio towards a male-biased state (blue colour represents males).\nCochran\u0026rsquo;s Q Cochran\u0026rsquo;s Q is a non parametric test for finding differences in matched sets of three or more frequencies or proportions.\nAs such, the Cochran\u0026rsquo;s Q Test is an extension of the McNemar test - the two tests are equal if Cochran\u0026rsquo;s Q is calculated for two groups.\nThe null hypothesis for Cochran\u0026rsquo;s Q postulates an equal proportion of class assignents for all treatments.\nPreparing The Data Are colours related to sex or predator parameters?\nWhen exploring our data, we can clearly see a pattern concerning the colour polymorphism of house sparrows arise which is dependant on the value of Predator Presence.\ncounts \u0026lt;- table(Data_df$Colour, Data_df$Predator.Presence)\r# preparing plotting\rplot_df \u0026lt;- data.frame(Data = c(prop.table(counts[,1]), prop.table(counts[,2])),\rIdentifiers = rep(c(\u0026quot;Black\u0026quot;, \u0026quot;Brown\u0026quot;, \u0026quot;Grey\u0026quot;), 2),\rPredation = rep(c(\u0026quot;No\u0026quot;, \u0026quot;Yes\u0026quot;), each = 3))\r# plotting\rggplot(plot_df, aes(x = Predation, y = Data, fill = Identifiers)) + geom_bar(stat=\u0026quot;identity\u0026quot;) + ggtitle(label = \u0026quot;Colour Variations of the common House Sparrow\u0026quot;) + theme_bw() +ylab(\u0026quot;Proportions\u0026quot;) + scale_fill_manual(values=c(\u0026quot;black\u0026quot;, \u0026quot;saddlebrown\u0026quot;, \u0026quot;grey\u0026quot;))\r This might lead us to believe that the presence of predators cause an evolutionary change of the plumage colour of Passer domesticus (we will have a more in-depth look on this in later seminars) and we might even postulate that \u0026ldquo;Black\u0026rdquo; and \u0026ldquo;Grey\u0026rdquo; serve as camouflage.\nCochran\u0026rsquo;s Q requires data to be delivered as binomial records. Therefore, we prepare colour as a binary variable of \u0026ldquo;Brown\u0026rdquo; and \u0026ldquo;Camouflage\u0026rdquo; (which we postulate to encompass \u0026ldquo;Grey\u0026rdquo; and \u0026ldquo;Black\u0026rdquo;). Since Colour is of type factor within our data set, we need to take some precautions in changing the data records. Predator Presence and Sex don\u0026rsquo;t need any additional preparation.\n# Colour CochColour \u0026lt;- Data_df_base$Colour\r# adding new level to factor list\rlevels(CochColour) \u0026lt;- c(levels(CochColour), \u0026quot;Camouflage\u0026quot;) # defining black and grey to be camouflage\rCochColour[which(CochColour == \u0026quot;Grey\u0026quot;)] \u0026lt;- \u0026quot;Camouflage\u0026quot; CochColour[which(CochColour == \u0026quot;Black\u0026quot;)] \u0026lt;- \u0026quot;Camouflage\u0026quot; # dropping unnecessary factor levels\rCochColour \u0026lt;- droplevels(CochColour) # Predator Presence\rCochPredator.Presence \u0026lt;- factor(Data_df_base$Predator.Presence)\r# Sex\rCochSex \u0026lt;- factor(Data_df_base$Sex)\r# Making vectors into a matrix\rCochMatrix \u0026lt;- matrix(c(\ras.numeric(CochColour), as.numeric(CochPredator.Presence), as.numeric(CochSex)\r), ncol = 3) - 1\rcolnames(CochMatrix) \u0026lt;- c(\u0026quot;Colour\u0026quot;, \u0026quot;Predator Presence\u0026quot;, \u0026quot;Sex\u0026quot;)\rhead(CochMatrix)\r ## Colour Predator Presence Sex\r## [1,] 0 1 1\r## [2,] 1 1 1\r## [3,] 1 1 0\r## [4,] 0 1 0\r## [5,] 1 1 1\r## [6,] 0 1 0\r Runing The Test Now let\u0026rsquo;s run our test using the cochrans.q() function that comes with the nonpar package:\ncochrans.q(CochMatrix)\r ## ## Cochran's Q Test ## ## H0: There is no difference in the effectiveness of treatments. ## HA: There is a difference in the effectiveness of treatments. ## ## Q = 122.984939759036 ## ## Degrees of Freedom = 2 ## ## Significance Level = 0.05 ## The p-value is 0 ## There is enough evidence to conclude that the effectiveness of at least two treatments differ. ##  As we can see, the output from this function is extremely user friendly. Additionally, as was to be expected the assignment probabilities for each class in each treatment are not equal thus forcing us to reject the null hypothesis.\nMaking Sense Of The Results Where are the differences coming from?\nAs you may recall from just a few pages ago, using the binomial test, we can identify the assignment proportions for any binomial variable individually.\nFirstly, let\u0026rsquo;s test the binary version of the colour variable:\ntable(CochColour)\r ## CochColour\r## Brown Camouflage ## 298 769\r binom.test(table(CochColour))\r ## ## Exact binomial test\r## ## data: table(CochColour)\r## number of successes = 298, number of trials = 1067, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.2525387 0.3072599\r## sample estimates:\r## probability of success ## 0.2792877\r Based on this result, we reject the null hypothesis of binary colour records being equally likely to occur.\nSecondly, let\u0026rsquo;s test the predator presence variable:\ntable(CochPredator.Presence)\r ## CochPredator.Presence\r## No Yes ## 357 710\r binom.test(table(CochPredator.Presence))\r ## ## Exact binomial test\r## ## data: table(CochPredator.Presence)\r## number of successes = 357, number of trials = 1067, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true probability of success is not equal to 0.5\r## 95 percent confidence interval:\r## 0.3062918 0.3637898\r## sample estimates:\r## probability of success ## 0.3345829\r Based on this result, we reject the null hypothesis of predator presence records being equally likely to occur.\nLastly, recall the binomial test run on the sex data records which exhibit an almost even 50/50 split.\nWhilst none of these test give us any idea about the overlap of similar assignments along these variable vectors, a 50/50 split (sex) can never link up comparably with a roughly 30/70 split (predator presence and binary colour). Therefore, we could hypothesize a linkage of predator presence and colour rather than sex and colour morphs.\nChi-Squared The Chi-Squared (also known as $Chi^2$) Test can be regarded as a functional extension of the binomial test and is used to test the similarity of class assignment proportions for a categorical/nominal variable. Unlike the binomial test, however, this test is not constrained to binomial records alone.\nThe null hypothesis states that: Every class assignment contained within a given variable is equally likely.\nThe Chi-Squared Test can be applied in a one or two sample situation. One sample represents one variable in this setting.\nOne Sample Situation Binary Colour Let\u0026rsquo;s asses the proportions of one variable we have already looked at - the binary version of the colour variable:\ntable(CochColour)\r ## CochColour\r## Brown Camouflage ## 298 769\r chisq.test(table(CochColour))\r ## ## Chi-squared test for given probabilities\r## ## data: table(CochColour)\r## X-squared = 207.91, df = 1, p-value \u0026lt; 2.2e-16\r Based on this result, we reject the null hypothesis of binary colour records being equally likely to occur. Note how the Chi-Squared test returns the same p-value as the binomial test above (within the Cochran\u0026rsquo;s Q section).\nColour Now let\u0026rsquo;s run the same test on the non-binary colour data:\ntable(Data_df$Colour)\r ## ## Black Brown Grey ## 356 298 413\r chisq.test(table(Data_df$Colour))\r ## ## Chi-squared test for given probabilities\r## ## data: table(Data_df$Colour)\r## X-squared = 18.592, df = 2, p-value = 9.178e-05\r Again, we reject the null hypothesis thus concluding differing class proportions for every possible class of \u0026ldquo;Colour\u0026rdquo;.\nTwo Sample Situation The two sample Chi-Squared approach lets us identify whether class assignment proportions of one variable differ when they are considered in a dependency of another nominal variable.\nSexual Dimorphism Are colours of Passer domesticus related to their sexes?\nFirstly, let\u0026rsquo;s see if males and females share the same likelihoods of being of a certain colour:\ntable(Data_df$Colour, Data_df$Sex)\r ## ## Female Male\r## Black 320 36\r## Brown 122 176\r## Grey 81 332\r chisq.test(table(Data_df$Colour, Data_df$Sex))\r ## ## Pearson's Chi-squared test\r## ## data: table(Data_df$Colour, Data_df$Sex)\r## X-squared = 388.63, df = 2, p-value \u0026lt; 2.2e-16\r Clearly, they don\u0026rsquo;t and we reject the null hypothesis.\nPredation Are colours of Passer domesticus related to predator parameters?\nSecondly, we test whether colour proportions change when considering predator presence. Although we partially considered this already in the Cochran\u0026rsquo;s Q section. This time, however, we use a non-binary version of the colour variable:\ntable(Data_df$Colour, Data_df$Predator.Presence)\r ## ## No Yes\r## Black 64 292\r## Brown 211 87\r## Grey 82 331\r chisq.test(table(Data_df$Colour, Data_df$Predator.Presence))\r ## ## Pearson's Chi-squared test\r## ## data: table(Data_df$Colour, Data_df$Predator.Presence)\r## X-squared = 259.34, df = 2, p-value \u0026lt; 2.2e-16\r The statement holds. Predator presence seems likely to be a driver of the colour polymorphism in Passer domesticus and we reject the null hypothesis.\nSo what about a possible link of sparrow colour and predator type?\ntable(Data_df$Colour, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Black 197 95\r## Brown 60 27\r## Grey 233 98\r chisq.test(table(Data_df$Colour, Data_df$Predator.Type))\r ## ## Pearson's Chi-squared test\r## ## data: table(Data_df$Colour, Data_df$Predator.Type)\r## X-squared = 0.62164, df = 2, p-value = 0.7328\r Nope, no link here. We have to accept the null hypothesis and conclude that there may be no causal link of predator type and sparrow colour.\nAre nesting sites of Passer domesticus related to predator parameters?\nThird, let\u0026rsquo;s test whether nesting site assignments might differ based on predator presence:\ntable(Data_df$Nesting.Site, Data_df$Predator.Presence)\r ## ## No Yes\r## Shrub 87 205\r## Tree 94 137\r chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Presence))\r ## ## Pearson's Chi-squared test with Yates' continuity correction\r## ## data: table(Data_df$Nesting.Site, Data_df$Predator.Presence)\r## X-squared = 6.2955, df = 1, p-value = 0.0121\r There seems to be a link here and we reject the null hypothesis.\nSo what about a link of predator type and nesting site?\ntable(Data_df$Nesting.Site, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Shrub 182 23\r## Tree 49 88\r chisq.test(table(Data_df$Nesting.Site, Data_df$Predator.Type))\r ## ## Pearson's Chi-squared test with Yates' continuity correction\r## ## data: table(Data_df$Nesting.Site, Data_df$Predator.Type)\r## X-squared = 102.88, df = 1, p-value \u0026lt; 2.2e-16\r Apparently, there is a really strong one and we reject the null hypothesis.\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"38dc059aa79cd96a19266f2f17282a45","permalink":"https://www.erikkusch.com/courses/biostat101/nominal-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/nominal-tests/","section":"courses","summary":"Welcome to our second practical experience in `R`. Throughout the following notes, I will introduce you to a couple nominal statistical test approaches that might be useful to you and are often used in biology. To do so, I will enlist the sparrow data set we handled in our last exercise.","tags":["R","Statistics"],"title":"Nominal Tests","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Conditional Manatees Material  \rSlides Chapter 8  Introduction These are answers and solutions to the exercises at the end of chapter 8 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Jeffrey Girard.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(ggplot2)\rlibrary(viridis)\r Easy Exercises Practice E1 Question: For each of the causal relationships below, name a hypothetical third variable that would lead to an interaction effect.\n Bread dough rises because of yeast. Education leads to higher income. Gasoline makes a car go.  Answer:\n Temperature. Yeast is active only in a certain range of temperatures and varyingly so. Age. Time spent in a profession usually comes with raises and thus higher pay as one gets older. This is not the case in all jobs, of course. Engine efficiency will interact with the presence of gasoline to determine how much the car will go.  Practice E2 Question: Which of the following explanations invokes an interaction?\n Caramelizing onions requires cooking over low heat and making sure the onions do not dry out. A car will go faster when it has more cylinders or when it has a better fuel injector. Most people acquire their political beliefs from their parents, unless they get them instead from their friends. Intelligent animal species tend to be either highly social or have manipulative appendages (hands, tentacles, etc.).  Answer:\n Yes, there is an interaction here. Water and low heat interact to caramelize onions. Yes, there is an interaction here. Number of cylinders and quality of fuel injector interact to determine the speed of the car. No, there is no interaction here. You either get your political belief from your parents or your friends. The two do not interact. Yes, there is an interaction here. Degree of sociality and possession of manipulative appendages combine to determine intelligence level.  Practice E3 Question: For each of the explanations in E2, write a linear model that expresses the stated relationship.\nAnswer:\n $\\mu_i = \\beta_T * T_i + \\beta_W*W_i + \\beta_{TW} * T_i W_i$ $\\mu_i = \\beta_C * C_i + \\beta_F * F_i + \\beta_{CF} * C_i F_i$ $\\mu_i = \\beta_P * P_i + \\beta_F * F_i$ $\\mu_i = \\beta_S * S_i + \\beta_A * A_i + \\beta_{SA} S_iA_i$  Medium Exercises Practice M1 Question: Recall the tulips example from the chapter. Suppose another set of treatments adjusted the temperature in the greenhouse over two levels: cold and hot. The data in the chapter were collected at the cold temperature. You find none of the plants grown under the hot temperature developed any blooms at all, regardless of the water and shade levels. Can you explain this result in terms of interactions between water, shade, and temperature?\nAnswer: We now have a model with a three-way interaction which comes with three two-way interactions:\n$$ \\begin{aligned} \\mu_i = \u0026amp; \\alpha + \\beta_T * T_i + \\beta_W * W_i + \\beta_S * S_i + \\newline \u0026amp; \\beta_{TW} * T_iW_i + \\beta_{TS} * T_iS_i + \\beta_{WS} * W_iS_i + \\newline \u0026amp; \\beta_{TWS} * T_iW_iS_i \\end{aligned} $$\nWithin this model all parameters work out such that when $T_i = 2$ (hot condition) we obtain $\\mu_i = 0$ (no blooms).\nPractice M2 Question: Can you invent a regression equation that would make the bloom size zero, whenever the temperature is hot?\nAnswer: Oops. I partially answered that in my previous exercise, but let\u0026rsquo;s go more in detail. Let\u0026rsquo;s first remember some values from the chapter: (1) water is recorded as 1-3 (dry to wet), (2) shade is coded as 1-3 (high to low), and (3) temperature is coded as 0/1 (cold/hot). So now we know that, irrespective of the values of water or shade, as long as $T = 1$, $mu_i$ has to be $0$ in this forumla:\n$$ \\begin{split} \\mu_i = \u0026amp;\\alpha + \\beta_T * T_i + \\beta_W * W_i + \\beta_S * S_i + \\newline \u0026amp;\\beta_{TW} * T_iW_i + \\beta_{TS} * T_iS_i + \\beta_{WS} * W_iS_i + \\newline \u0026amp;\\beta_{TWS} * T_iW_iS_i \\end{split} $$\nHow do we get there? For now, let\u0026rsquo;s set water and shade to 1 and temperature to 1. Doing so will result in a rewriting of the formula above to:\n\\begin{equation} \\begin{split} \\mu_{i|T=1,W=1,S=1} = \\alpha + \\beta_T + \\beta_W + \\beta_S + \\beta_{TW} + \\beta_{TS} + \\beta_{WS} + \\beta_{TWS} \\end{split} \\end{equation}\nSo now we need to get this formula to always work out to 0, irrespective of values of $\\alpha$, $\\beta_s$, $\\beta_W$, and $\\beta_{WS}$. We can do so by having parameters which include the effect of temperature ($\\beta_T$, $\\beta_{TW}$, $\\beta_{TS}$, and $\\beta_{TWS}$) counteract the $\\alpha$, $\\beta_s$, $\\beta_W$, and $\\beta_{WS}$. This has us rewrite the above formula as:\n\\begin{equation} \\begin{split} \\mu_{i|T=1,W=1,S=1} = (\\alpha + \\beta_T) + (\\beta_W + \\beta_{TW}) + (\\beta_S + \\beta_{TS}) + (\\beta_{WS} + \\beta_{TWS}) \\end{split} \\end{equation}\nNow for the outcome to be $0$, the contents of the brackets need to be 0, so $\\beta_T = -\\alpha$, $\\beta_{TW} = -\\beta_W$, and so on. This morphs our equation into:\n\\begin{equation} \\begin{split} \\mu_{i|T=1,W=1,S=1} = (\\alpha - \\alpha) + (\\beta_W - \\beta_W) + (\\beta_S - \\beta_S) + (\\beta_{WS} - \\beta_{WS}) \\end{split} \\end{equation}\nSo now, irrespective of $W$ or $S$, we will always obtain $\\mu_i = 0$ when $T=1$. When $T=0$, all temperature effects drop out and we obtain the same formula as in the book chapter.\nPractice M3 Question: In parts of North America, ravens depend upon wolves for their food. This is because ravens are carnivorous but cannot usually kill or open carcasses of prey. Wolves however can and do kill and tear open animals, and they tolerate ravens co-feeding at their kills. This species relationship is generally described as a “species interaction.” Can you invent a hypothetical set of data on raven population size in which this relationship would manifest as a statistical interaction? Do you think the biological interaction could be linear? Why or why not?\nAnswer: Here\u0026rsquo;s our regression:\n$Ravens∼Normal(μ,σ)$\n$μ=α+β_pPrey+β_wWolves+β_{pw}Prey*Wolves$\nwith $Ravens$, $Wolves$, and $Prey$ being the number of ravens, wolves, and prey animals respectively, in a given habitat.\nNow let\u0026rsquo;s make up some data with an in-built interaction effect:\nN \u0026lt;- 1e5 # simulation size\rrPW \u0026lt;- 0.2 # correlation between prey and wolf\rbP \u0026lt;- 0.05 # regression coefficient for prey\rbW \u0026lt;- -0.3 # regression coefficient for wolf\rbPW \u0026lt;- 0.2 # regression coefficient for prey-by-wolf interaction\r# Simulate data\rprey \u0026lt;- as.integer(rnorm(N, mean = 100, sd = 15)) # as.integer, so we have \u0026quot;whole\u0026quot; animals\rwolves \u0026lt;- as.integer(rnorm(N, mean = 10 + rPW * prey, sd = 7))\rravens \u0026lt;- as.integer(rnorm(N, mean = 5 + bP * prey + bW * wolves + bPW * wolves * prey, sd = 9))\rd \u0026lt;- data.frame(prey = prey, wolves = wolves, ravens = ravens)\r# plot the data\rpar(mfrow = c(1, 2))\rplot(ravens ~ prey, data = d, main = \u0026quot;Ravens like prey!\u0026quot;)\rplot(ravens ~ wolves, data = d, main = \u0026quot;Ravens like wolves?\u0026quot;)\r Immediately, we see in our data that, despite us having simulated the data in such a way that ravens do not flock around wolves, when not conditioning on prey, we would think that ravens do flock around wolves.\nTime for a model run:\nm \u0026lt;- quap(\ralist(\rravens ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bP * prey + bW * wolves + bPW * prey * wolves,\ra ~ dnorm(min(d$ravens), 10), # minimum of ravens for intercept prior\rbW ~ dnorm(0, 1),\rbP ~ dnorm(0, 1),\rbPW ~ dnorm(0, 1),\rsigma ~ dnorm(sd(d$ravens), 10) # sd of raven as an initial guess\r),\rdata = d\r)\rprecis(m)\r ## mean sd 5.5% 94.5%\r## a 5.41309759 0.6926177989 4.3061606 6.52003460\r## bW -0.32805262 0.0233269747 -0.3653336 -0.29077161\r## bP 0.04084714 0.0070894052 0.0295169 0.05217738\r## bPW 0.20027501 0.0002308127 0.1999061 0.20064390\r## sigma 8.97789166 0.0200777428 8.9458035 9.00997977\r And we successfully reconstructed our input interactions.\nHard Exercises Practice H1 Question: Return to the data(tulips) example in the chapter. Now include the bed variable as a predictor in the interaction model. Don’t interact bed with the other predictors; just include it as a main effect. Note that bed is categorical. So to use it properly, you will need to either construct dummy variables or rather an index variable, as explained in Chapter 6.\nAnswer:\n## Data\rdata(tulips)\rd \u0026lt;- tulips\rd$bed_id \u0026lt;- coerce_index(d$bed)\rd$blooms_std \u0026lt;- d$blooms / max(d$blooms) # now on a scale from 0 to 1\rd$shade_cent \u0026lt;- d$shade - mean(d$shade) # now on a scale from -1 to 1\rd$water_cent \u0026lt;- d$water - mean(d$water) # now on a scale from -1 to 1\r## Model\rset.seed(20) # setting a seed because I sometimes run out of model iterations here\rm.H1 \u0026lt;- quap(alist(\rblooms ~ dnorm(mu, sigma),\rmu \u0026lt;- a[bed_id] + bW * water_cent + bS * shade_cent + bWS * water_cent * shade_cent,\ra[bed_id] ~ dnorm(130, 100),\rbW ~ dnorm(0, 100),\rbS ~ dnorm(0, 100),\rbWS ~ dnorm(0, 100),\rsigma ~ dunif(0, 100)\r),\rdata = d\r)\rprecis(m.H1, depth = 2)\r ## mean sd 5.5% 94.5%\r## a[1] 97.54986 12.951192 76.85135 118.24837\r## a[2] 142.41547 12.950773 121.71763 163.11330\r## a[3] 147.11128 12.950771 126.41344 167.80911\r## bW 75.12289 9.197989 60.42272 89.82305\r## bS -41.23747 9.196690 -55.93555 -26.53938\r## bWS -52.23345 11.240444 -70.19785 -34.26905\r## sigma 39.18206 5.333939 30.65740 47.70673\r Practice H2 Question: Use WAIC to compare the model from H1 to a model that omits bed. What do you infer from this comparison? Can you reconcile the WAIC results with the posterior distribution of the bed coefficients?\nAnswer:\nm.H2 \u0026lt;- quap(\ralist(\rblooms ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bW * water_cent + bS * shade_cent + bWS * water_cent * shade_cent,\ra ~ dnorm(130, 100),\rbW ~ dnorm(0, 100),\rbS ~ dnorm(0, 100),\rbWS ~ dnorm(0, 100),\rsigma ~ dunif(0, 100)\r),\rdata = d,\rstart = list(a = mean(d$blooms), bW = 0, bS = 0, bWS = 0, sigma = sd(d$blooms))\r)\rprecis(m.H2)\r ## mean sd 5.5% 94.5%\r## a 129.00797 8.670771 115.15041 142.86554\r## bW 74.95946 10.601997 58.01542 91.90350\r## bS -41.14054 10.600309 -58.08188 -24.19920\r## bWS -51.87265 12.948117 -72.56625 -31.17906\r## sigma 45.22497 6.152982 35.39132 55.05863\r compare(m.H1, m.H2)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m.H2 295.0441 9.873189 0.000000 NA 6.062662 0.6776652\r## m.H1 296.5302 10.544146 1.486126 8.181914 10.771689 0.3223348\r The model including the bed index variables (m.H2) shows a slightly better WAIC than the model that contains the bed variable (m.H1), and most of the Akaike weight. Judging from this (and the variation in the bed intercepts of model m.H1), we can infer that there\u0026rsquo;s a lot of variability between the flower beds which model m.H1 addresses, but might overfit in doing so. Let me visualise this in a plot:\npost \u0026lt;- extract.samples(m.H1)\rpost.a \u0026lt;- post$a[, 1]\rpost.b \u0026lt;- post$a[, 2]\rpost.c \u0026lt;- post$a[, 3]\rdens(post.a, col = \u0026quot;red\u0026quot;, xlim = c(50, 200), ylim = c(0, 0.035))\rdens(post.b, col = \u0026quot;blue\u0026quot;, add = TRUE)\rdens(post.c, col = \u0026quot;black\u0026quot;, add = TRUE)\r Practice H3 Question: Consider again the data(rugged) data on economic development and terrain ruggedness, examined in this chapter. One of the African countries in that example, Seychelles, is far outside the cloud of other nations, being a rare country with both relatively high GDP and high ruggedness. Seychelles is also unusual, in that it is a group of islands far from the coast of mainland Africa, and its main economic activity is tourism.\nAnswer:\ndata(rugged)\rd \u0026lt;- rugged\rd \u0026lt;- rugged[complete.cases(rugged$rgdppc_2000), ]\rd$log_gdp \u0026lt;- log(d$rgdppc_2000)\rd$log_gdp_std \u0026lt;- d$log_gdp / mean(d$log_gdp)\rd$rugged_std \u0026lt;- d$rugged / max(d$rugged)\rd$cid \u0026lt;- ifelse(d$cont_africa == 1, 1, 2)\r Part A Question: Focus on model m8.5 from the chapter. Use WAIC point-wise penalties and PSIS Pareto k values to measure relative influence of each country. By these criteria, is Seychelles influencing the results? Are there other nations that are relatively influential? If so, can you explain why?\nAnswer:\nFirstly, the model that the exercise is after is not model m8.5, but model m8.3. Let\u0026rsquo;s run that and look at the PSIS point-wise values:\nm.H3a \u0026lt;- quap(alist(\rlog_gdp_std ~ dnorm(mu, sigma),\rmu \u0026lt;- a[cid] + b[cid] * (rugged_std - 0.215),\ra[cid] ~ dnorm(1, 0.1),\rb[cid] ~ dnorm(0, 0.3),\rsigma ~ dexp(1)\r),\rdata = d\r)\rprecis(m.H3a, depth = 2)\r ## mean sd 5.5% 94.5%\r## a[1] 0.8865690 0.015675759 0.86151610 0.91162189\r## a[2] 1.0505745 0.009936639 1.03469382 1.06645515\r## b[1] 0.1325281 0.074204674 0.01393472 0.25112152\r## b[2] -0.1425744 0.054749596 -0.23007484 -0.05507398\r## sigma 0.1094945 0.005935353 0.10000867 0.11898035\r Next, we look at point-wise WAIC values. I think there\u0026rsquo;s a pretty clear separation of high point-wise WAIC-values in the plot at around 1 so I draw that in and obtain the country names for these:\nWAIC \u0026lt;- WAIC(m.H3a, pointwise = TRUE)\rplot(WAIC$WAIC)\rabline(h = 1, col = \u0026quot;red\u0026quot;)\r as.character(d[WAIC$WAIC \u0026gt; 1, ]$country)\r ## [1] \u0026quot;Austria\u0026quot; \u0026quot;Bangladesh\u0026quot; \u0026quot;Switzerland\u0026quot; \u0026quot;Equatorial Guinea\u0026quot; \u0026quot;Luxembourg\u0026quot; \u0026quot;Republic of Moldova\u0026quot; \u0026quot;Seychelles\u0026quot; \u0026quot;Uzbekistan\u0026quot; ## [9] \u0026quot;Yemen\u0026quot;\r Now, we do the same with point-wise PSIS Pareto k values. Again, I believe there is a separation. This time at 0.35:\nPSIS \u0026lt;- PSIS(m.H3a, pointwise = TRUE)\rplot(PSIS$k)\rabline(h = .35, col = \u0026quot;red\u0026quot;)\r as.character(d[PSIS$k \u0026gt; .35, ]$country)\r ## [1] \u0026quot;Switzerland\u0026quot; \u0026quot;Lesotho\u0026quot; \u0026quot;Seychelles\u0026quot;\r Honestly, I cannot make too much sense of the countries I obtained via the point-wise WAIC-values, but the point-wise PSIS Pareto k values make obvious sense here. All of these are extremely rugged and much richer than even their surrounding flat countries.\nPart B Question: Now use robust regression, as described in the previous chapter. Modify m8.5 to use a Student-t distribution with $ν = 2$. Does this change the results in a substantial way?\nAnswer:\nm.H3b \u0026lt;- quap(alist(\rlog_gdp_std ~ dstudent(2, mu, sigma),\rmu \u0026lt;- a[cid] + b[cid] * (rugged_std - 0.215),\ra[cid] ~ dnorm(1, 0.1),\rb[cid] ~ dnorm(0, 0.3),\rsigma ~ dexp(1)\r),\rdata = d\r)\rprecis(m.H3b, depth = 2)\r ## mean sd 5.5% 94.5%\r## a[1] 0.86265354 0.016153871 0.836836529 0.88847054\r## a[2] 1.04573322 0.010971670 1.028198374 1.06326807\r## b[1] 0.11279640 0.075195199 -0.007380055 0.23297285\r## b[2] -0.21362933 0.063538165 -0.315175587 -0.11208307\r## sigma 0.08452953 0.006732778 0.073769255 0.09528981\r The parameter estimates changed slightly, but not crazily so. Let\u0026rsquo;s look at the point-wise importance again. This time, I see a split in WAIC values around 2:\nWAIC \u0026lt;- WAIC(m.H3b, pointwise = TRUE)\rplot(WAIC$WAIC)\rabline(h = 2, col = \u0026quot;red\u0026quot;)\r as.character(d[WAIC$WAIC \u0026gt; 2, ]$country)\r ## [1] \u0026quot;Switzerland\u0026quot; \u0026quot;Equatorial Guinea\u0026quot;\r Now for point-wise PSIS-values. This time, I see don\u0026rsquo;t really a separation so I\u0026rsquo;ll just pull out the highest ranking nations:\nPSIS \u0026lt;- PSIS(m.H3b, pointwise = TRUE)\rplot(PSIS$k)\r as.character(d$country[as.numeric(rownames(PSIS[order(PSIS$k), ])[1:5])])\r ## [1] \u0026quot;Malawi\u0026quot; \u0026quot;Ethiopia\u0026quot; \u0026quot;Yemen\u0026quot; \u0026quot;Singapore\u0026quot; \u0026quot;Burundi\u0026quot;\r Interestingly, only Switzerland shows up in our subset of potentially highly influential nations. That being said, the outliers in the WAIC and point-wise PSIS values are much closer to the main cloud of data points than they were previously. I expect this to be the effect of the ropbust regression.\nPractice H4 Question: The values in data(nettle) are data on language diversity in 74 nations. The meaning of each column is given below:\n country: Name of the country num.lang: Number of recognized languages spoken area: Area in square kilometres k.pop: Population, in thousands num.stations: Number of weather stations that provided data for the next two columns mean.growing.season: Average length of growing season, in months sd.growing.season: Standard deviation of length of growing season, in months  Use these data to evaluate the hypothesis that language diversity is partly a product of food security. The notion is that, in productive ecologies, people don’t need large social networks to buffer them against risk of food shortfalls. This means ethnic groups can be smaller and more self-sufficient, leading to more languages per capita. In contrast, in a poor ecology, there is more subsistence risk, and so human societies have adapted by building larger networks of mutual obligation to provide food insurance. This in turn creates social forces that help prevent languages from diversifying. Specifically, you will try to model the number of languages per capita as the outcome variable:\nd$lang.per.cap \u0026lt;- d$num.lang / d$k.pop\r Use the logarithm of this new variable as your regression outcome. (A count model would be better here, but you’ll learn those later, in Chapter 11.) This problem is open ended, allowing you to decide how you address the hypotheses and the uncertain advice the modelling provides. If you think you need to use WAIC any place, please do. If you think you need certain priors, argue for them. If you think you need to plot predictions in a certain way, please do. Just try to honestly evaluate the main effects of both mean.growing.season and sd.growing.season, as well as their two-way interaction, as outlined in parts (a), (b), and (c) below. If you are not sure which approach to use, try several.\nAnswer:\ndata(nettle)\rd \u0026lt;- nettle\rd$lang.per.cap \u0026lt;- d$num.lang / d$k.pop\rd$log_lpc \u0026lt;- log(d$lang.per.cap)\rd$log_area \u0026lt;- log(d$area)\rd$log_area.c \u0026lt;- d$log_area - mean(d$log_area)\rd$mgs.c \u0026lt;- d$mean.growing.season - mean(d$mean.growing.season)\rd$sgs.c \u0026lt;- d$sd.growing.season - mean(d$sd.growing.season)\r Part A Question: Evaluate the hypothesis that language diversity, as measured by log(lang.per.cap), is positively associated with the average length of the growing season, mean.growing.season. Consider log(area) in your regression(s) as a covariate (not an interaction). Interpret your results.\nAnswer: Let\u0026rsquo;s start this off by building a model that attempts to identify the logarithmic language per capita as defined above (log_lpc). I use this as my response variable to smooth out the effects of highly multilingual communities which would otherwise look like freakish outliers:\n### Model\rm.H4a \u0026lt;- quap(\ralist(\rlog_lpc ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bM * mean.growing.season + bA * log_area.c,\ra ~ dnorm(mean(d$log_lpc), sd(d$log_lpc)),\rbM ~ dnorm(0, 2),\rbA ~ dnorm(0, 2),\rsigma ~ dunif(0, 10)\r),\rdata = d\r)\rprecis(m.H4a)\r ## mean sd 5.5% 94.5%\r## a -6.3965435 0.40827385 -7.0490440 -5.744043063\r## bM 0.1349813 0.05390024 0.0488383 0.221124289\r## bA -0.2091213 0.13661084 -0.4274518 0.009209185\r## sigma 1.3894990 0.11424753 1.2069094 1.572088628\r ### Prediction plot\rmean.growing.season.seq \u0026lt;- seq(from = min(d$mean.growing.season), to = max(d$mean.growing.season), length.out = 50)\rmu \u0026lt;- link(m.H4a, data = data.frame(mean.growing.season = mean.growing.season.seq, log_area.c = 0), refresh = 0)\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.97)\rplot(log_lpc ~ mean.growing.season, data = d, col = rangi2)\rlines(mean.growing.season.seq, mu.mean)\rshade(mu.PI, mean.growing.season.seq)\r As we can see, there\u0026rsquo;s a positive linear relationship between mean.growing.season and number of languages spoken by a population while also conditioning on area of the nations in question. I highly doubt that there is any causality here, however and instead hypothesise that mean.growing.season can be used as a proxy for \u0026ldquo;sunniness\u0026rdquo; of a nation which, from anecdotal evidence, is much more appealing to immigration from all over the world than freezing countries with short growing seasons. To follow the rationale of the task however, this is evidence of ample food supply allowing for cultural diversity and thus higher language count.\nPart B Question: Now evaluate the hypothesis that language diversity is negatively associated with the standard deviation of length of growing season, sd.growing.season. This hypothesis follows from uncertainty in harvest favouring social insurance through larger social networks and therefore fewer languages. Again, consider log(area) as a covariate (not an interaction). Interpret your results.\nAnswer:\n### Model\rm.H4b \u0026lt;- quap(\ralist(\rlog_lpc ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bS * sd.growing.season + bA * log_area.c,\ra ~ dnorm(mean(d$log_lpc), sd(d$log_lpc)),\rbS ~ dnorm(0, 5),\rbA ~ dnorm(0, 5),\rsigma ~ dunif(0, 10)\r),\rdata = d\r)\rprecis(m.H4b)\r ## mean sd 5.5% 94.5%\r## a -5.1199557 0.3485729 -5.6770426 -4.562868804\r## bS -0.2005191 0.1824921 -0.4921768 0.091138529\r## bA -0.2433936 0.1552325 -0.4914852 0.004697949\r## sigma 1.4384790 0.1182463 1.2494986 1.627459505\r ### Prediction plot\rsd.growing.season.seq \u0026lt;- seq(from = min(d$sd.growing.season), to = max(d$sd.growing.season), length.out = 50)\rmu \u0026lt;- link(m.H4b, data = data.frame(sd.growing.season = sd.growing.season.seq, log_area.c = 0), refresh = 0)\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.97)\rplot(log_lpc ~ sd.growing.season, data = d, col = rangi2)\rlines(sd.growing.season.seq, mu.mean)\rshade(mu.PI, sd.growing.season.seq)\r Again, I find myself agreeing with the hypothesis seeing how I have identified a negative relationship between sd.growing.season and language count.\nPart C Question: Finally, evaluate the hypothesis that mean.growing.season and sd.growing.season interact to synergistically reduce language diversity. The idea is that, in nations with longer average growing seasons, high variance makes storage and redistribution even more important than it would be otherwise. That way, people can cooperate to preserve and protect windfalls to be used during the droughts. These forces in turn may lead to greater social integration and fewer languages.\nAnswer: Again, I build a model which conditions on centred logarithmic area of nations, while building an interaction between mean.growing.season and sd.growing.season:\nm.H4c \u0026lt;- quap(\ralist(\rlog_lpc ~ dnorm(mu, sigma),\rmu \u0026lt;- a +\rbM * mean.growing.season +\rbS * sd.growing.season +\rbMS * mean.growing.season * sd.growing.season +\rbA * log_area.c,\ra ~ dnorm(mean(d$log_lpc), sd(d$log_lpc)),\rbM ~ dnorm(0, 5),\rbS ~ dnorm(0, 5),\rbA ~ dnorm(0, 5),\rbMS ~ dnorm(0, 5),\rsigma ~ dunif(0, 10)\r),\rdata = d\r)\rprecis(m.H4c)\r ## mean sd 5.5% 94.5%\r## a -6.771794698 0.55161186 -7.6533770 -5.89021241\r## bM 0.277261541 0.07288992 0.1607694 0.39375371\r## bS 0.327529661 0.37052336 -0.2646382 0.91969756\r## bA -0.005517158 0.15891352 -0.2594917 0.24845734\r## bMS -0.098088334 0.04565210 -0.1710492 -0.02512746\r## sigma 1.307674873 0.10763683 1.1356504 1.47969932\r We seem to be quite sure of the interaction effect bMS.\nTo investiagte the interaction of the two predictors we are interested in, let\u0026rsquo;s produce a Tryptich each:\npar(mfrow = c(2, 3))\r# Discretize variables into groups\rd$mean.growing.season.group \u0026lt;- cut(\rd$mean.growing.season,\rbreaks = quantile(d$mean.growing.season, probs = c(0, 1 / 3, 2 / 3, 1)),\rinclude.lowest = TRUE,\rdig.lab = 2\r)\rd$sd.growing.season.group \u0026lt;- cut(\rd$sd.growing.season,\rbreaks = quantile(d$sd.growing.season, probs = c(0, 1 / 3, 2 / 3, 1)),\rinclude.lowest = TRUE,\rdig.lab = 2\r)\r# Plot first row as mean against SD\rmean.growing.season.seq \u0026lt;- seq(from = min(d$mean.growing.season), to = max(d$mean.growing.season), length.out = 50)\rfor (group in levels(d$sd.growing.season.group)) {\rdt \u0026lt;- d[d$sd.growing.season.group == group, ]\rplot(log_lpc ~ mean.growing.season,\rdata = dt, col = rangi2, xlim = c(min(d$mean.growing.season), max(d$mean.growing.season)), ylim = c(min(d$log_lpc), max(d$log_lpc)),\rmain = paste(\u0026quot;SD GS = \u0026quot;, group), xlab = \u0026quot;Mean GS\u0026quot;\r)\rmu \u0026lt;- link(m.H4c,\rdata = data.frame(mean.growing.season = mean.growing.season.seq, sd.growing.season = mean(dt$sd.growing.season), log_area.c = 0),\rrefresh = 0\r)\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.97)\rlines(mean.growing.season.seq, mu.mean)\rlines(mean.growing.season.seq, mu.PI[1, ], lty = 2)\rlines(mean.growing.season.seq, mu.PI[2, ], lty = 2)\r}\r# Plot second row as SD against mean\rsd.growing.season.seq \u0026lt;- seq(from = min(d$sd.growing.season), to = max(d$sd.growing.season), length.out = 50)\rfor (group in levels(d$mean.growing.season.group)) {\rdt \u0026lt;- d[d$mean.growing.season.group == group, ]\rplot(log_lpc ~ sgs.c,\rdata = dt, col = rangi2, xlim = c(min(d$sd.growing.season), max(d$sd.growing.season)), ylim = c(min(d$log_lpc), max(d$log_lpc)),\rmain = paste(\u0026quot;Mean GS = \u0026quot;, group), xlab = \u0026quot;SD GS\u0026quot;\r)\rmu \u0026lt;- link(m.H4c,\rdata = data.frame(sd.growing.season = sd.growing.season.seq, mean.growing.season = mean(dt$mean.growing.season), log_area.c = 0),\rrefresh = 0\r)\rmu.mean \u0026lt;- apply(mu, 2, mean)\rmu.PI \u0026lt;- apply(mu, 2, PI, prob = 0.97)\rlines(sd.growing.season.seq, mu.mean)\rlines(sd.growing.season.seq, mu.PI[1, ], lty = 2)\rlines(sd.growing.season.seq, mu.PI[2, ], lty = 2)\r}\r These plots show that the association between mean length of growing season and language diversity is positive when SD length of growing season is low, but is basically zero when SD length of growing season is high. Similarly, the association between SD length of growing season and language diversity is basically zero when mean length of growing season is low, but is negative when mean length of growing season is high. This is consistent with the hypothesis presented in the question.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] viridis_0.6.0 viridisLite_0.4.0 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 R6_2.5.0 ## [11] backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 ## [21] jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 ## [31] pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 codetools_0.2-18 matrixStats_0.61.0\r## [41] fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 lifecycle_1.0.0 ## [51] DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.7 ## [61] rematch2_2.1.2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 ## [71] sass_0.3.1\r ","date":1613606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613674800,"objectID":"c6a2b32b1f0945af2eacac2dfcde1777","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-08/","publishdate":"2021-02-18T00:00:00Z","relpermalink":"/courses/rethinking/chapter-08/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 8 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 08","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some Lecture Slides  for this session.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4d0d944d1db77f7dd5db60069d8a0bc9","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/8_statistical-significance-in-biology-conventions-abstractions-and-the-future/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/8_statistical-significance-in-biology-conventions-abstractions-and-the-future/","section":"courses","summary":"I have prepared some Lecture Slides  for this session.","tags":null,"title":"Statistical Significance in Biology","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our third practical experience in R. Throughout the following notes, I will introduce you to a couple statistical correlation approaches that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.\nI have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;DescTools\u0026quot;, # Needed for Contingency Coefficient\r\u0026quot;ggplot2\u0026quot; # needed for data visualisation\r)\rsapply(package_vec, install.load.package)\r ## Loading required package: DescTools\r ## Loading required package: ggplot2\r ## DescTools ggplot2 ## TRUE TRUE\r Loading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Nominal Scale - Contingency Coefficient We can analyse correlations/dependencies of variables of the categorical kind using the contingency coefficient by calling the ContCoef() function of base R.\nKeep in mind that the contingency coefficient is not really a measure of correlation but merely of association of variables. A value of $c \\approx 0$ indicates independent variables.\nPredation Are colour morphs of Passer domesticus linked to predator presence and/or predator type?\nThis analysis builds on our findings within our previous exercise (Nominal Tests - Analysing The Sparrow Data Set). Remember that, using the two-sample situation Chi-Squared Test, we found no change in treatment effects (as far as colour polymorphism went) for predator type values but did so regarding the presence of predators. Let\u0026rsquo;s repeat this here:\ntable(Data_df$Colour, Data_df$Predator.Presence)\r ## ## No Yes\r## Black 64 292\r## Brown 211 87\r## Grey 82 331\r ContCoef(table(Data_df$Colour, Data_df$Predator.Presence))\r ## [1] 0.4421914\r table(Data_df$Colour, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Black 197 95\r## Brown 60 27\r## Grey 233 98\r ContCoef(table(Data_df$Colour, Data_df$Predator.Type))\r ## [1] 0.02957682\r Here, we find the same results as when using the Chi-Squared statistic and conclude that colour morphs of the common house sparrow are likely to be driven by predator presence but not the type of predator that is present.\nAre nesting sites of Passer domesticus linked to predator presence and/or predator type?\nAgain, following our two-sample situation Chi-Squared analysis from last exercise, we want to test whether nesting site and predator presence/predator type are linked. The Chi-Squared analyses identified a possible link of nesting site and predator type but nor predator presence.\ntable(Data_df$Nesting.Site, Data_df$Predator.Presence)\r ## ## No Yes\r## Shrub 87 205\r## Tree 94 137\r ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Presence))\r ## [1] 0.1130328\r table(Data_df$Nesting.Site, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Shrub 182 23\r## Tree 49 88\r ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Type))\r ## [1] 0.4851588\r Whilst there doesn\u0026rsquo;t seem to be any strong evidence linking nesting site and predator presence, predator type seems to be linked to what kind of nesting site Passer domesticus prefers thus supporting our Chi-Squared results.\nSexual Dimorphism Are sex ratios of Passer domesticus related to climate types?\nRecall that, in our last exercise, we found no discrepancy of proportions of the sexes among the entire data set using a binomial test. What we didn\u0026rsquo;t check yet was whether the sexes are distributed across the sites somewhat homogeneously or whether the sex ratios might be skewed according to climate types. Let\u0026rsquo;s do this:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\r# select all data belonging to the stations at which all parameters except for climate type are held constant\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,]\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r# analysis\rtable(Data_df$Sex, Data_df$Climate)\r ## ## Coastal Continental\r## Female 91 76\r## Male 72 78\r ContCoef(table(Data_df$Sex, Data_df$Climate))\r ## [1] 0.06470702\r Quite obviously, they aren\u0026rsquo;t and, if there are any patterns in sex ratios to emerge, these are not likely to stem from climate types. Also keep in mind that we have a plethora of other variables at play whilst the information contained within the climate type variable is somewhat constrained and, in this case, bordering on uninformative (i.e. a coastal site in the Arctic might be more closely resembled by a continental mid-latitude site than by a tropical coastal site).\nOrdinal Scale - Kendall\u0026rsquo;s Tau Climate Warming/Extremes Do heavier sparrows have heavier/less eggs?\nA heavier weight of individual females alludes to a higher pool of resources being allocated by said individuals. There are multiple ways they might make use of it, one of them being investment in reproduction. To test how heavier females of Passer domesticus utilise their resources in reproduction, we use a Kendall\u0026rsquo;s Tau approach to finding links between female weight and average egg weight per nest/number of eggs per nest.\nObviously, both weight variables are metric in nature and so we could use other methods as well. On top of that, we first need to convert these into ranks before being able to run a Kendall\u0026rsquo;s Tau analysis as follows:\n# overwriting changes in Data_df with base data\rData_df \u0026lt;- Data_df_base\r# Establishing Ranks of Egg Weight\rRankedEggWeight \u0026lt;- rank(Data_df$Egg.Weight[which(Data_df$Sex == \u0026quot;Female\u0026quot;)],\rties.method = \u0026quot;average\u0026quot;)\r# Establishing Ranks of Female Weight\rRankedWeight_Female \u0026lt;- rank(Data_df$Weight[which(Data_df$Sex == \u0026quot;Female\u0026quot;)],\rties.method = \u0026quot;average\u0026quot;)\r# Extracting Numbers of Eggs\rRankedEggs \u0026lt;- Data_df$Number.of.Eggs[which(Data_df$Sex == \u0026quot;Female\u0026quot;)]\r Luckily enough, the number of eggs per nest already represent a ranked (ordinal) variable and so we can move straight on to running our analyses:\n# Test ranked female weight vs. ranked egg weight\rcor.test(x = RankedWeight_Female, y = RankedEggWeight, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;kendall\u0026quot;)\r ## ## Kendall's rank correlation tau\r## ## data: RankedWeight_Female and RankedEggWeight\r## z = 19.771, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true tau is not equal to 0\r## sample estimates:\r## tau ## 0.5804546\r There is strong evidence to suggest that heavier females tend to lay heavier eggs (tau = 0.5804546 at p $\\approx$ 0).\n# Test ranked female weight vs. number of eggs\rcor.test(x = RankedWeight_Female, y = RankedEggs, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;kendall\u0026quot;)\r ## ## Kendall's rank correlation tau\r## ## data: RankedWeight_Female and RankedEggs\r## z = -21.787, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true tau is not equal to 0\r## sample estimates:\r## tau ## -0.6880932\r Additionally, the heavier a female of Passer domesticus, the less eggs she produces (tau = -0.6880932 at p $\\approx$ 0).\nNow we can visualise the underlying patterns:\nplot_df \u0026lt;- data.frame(RankedWeight = RankedWeight_Female,\rRankedEggWeight = RankedEggWeight,\rRankedEggNumber = RankedEggs)\r# plot ranked female weight vs. ranked egg weight\rggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggWeight)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Ranked female weight of Passer domesticus vs. Ranked weigt of eggs\u0026quot;)\r ## `geom_smooth()` using formula 'y ~ x'\r # plot ranked female weight vs. number of eggs\rggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggNumber)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Ranked female weight of Passer domesticus vs. Ranked number of eggs\u0026quot;)\r ## `geom_smooth()` using formula 'y ~ x'\r This highlights an obvious and intuitive trade-off in nature and has us reject the null hypotheses.\nMetric and Ordinal Scales Metric scale correlation analyses call for:\n Spearman correlation test (non-parametric) Pearson correlation test (parametric, requires data to be normal distributed)  Testing for Normality DISCLAIMER: I do not expect you to do it this way as of right now but wanted to give you reference material of how to automate this testing step.\nSince most of our following analyses are focussing on latitude effects (i.e. \u0026ldquo;climate warming\u0026rdquo;), we need to alter our base data. Before we can run the analyses, we need to eliminate the sites that we have set aside for testing climate extreme effects on (Siberia, United Kingdom, Reunion and Australia) from the data set. We are also not interested in all variables and so reduce the data set further.\nData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index != \u0026quot;SI\u0026quot; \u0026amp; Index != \u0026quot;UK\u0026quot; \u0026amp; Index != \u0026quot;RE\u0026quot; \u0026amp; Index != \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,c(\u0026quot;Index\u0026quot;, \u0026quot;Latitude\u0026quot;, \u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Nesting.Height\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;, \u0026quot;Egg.Weight\u0026quot;)]\r In order to know which test we can use with which variable, we need to first identify whether our data is normal distributed using the Shapiro-Test (Seminar 3) as follows:\nNormal_df \u0026lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)\rfor(i in 2:length(colnames(Data_df))){\rNormal_df[1,i] \u0026lt;- colnames(Data_df)[i]\rNormal_df[2,i] \u0026lt;- round(shapiro.test(as.numeric(Data_df[,i]))$p.value, 2)\r}\rcolnames(Normal_df) \u0026lt;- c()\rrownames(Normal_df) \u0026lt;- c(\u0026quot;Variable\u0026quot;, \u0026quot;p\u0026quot;)\rNormal_df \u0026lt;- Normal_df[,-1] # removing superfluous Index column\rNormal_df\r ## ## Variable Latitude Weight Height Wing.Chord Nesting.Height Number.of.Eggs\r## p 0 0 0 0 0 0\r## ## Variable Egg.Weight\r## p 0\r Unfortunately, none of these variables seem to be normal distributed (this was to be expected for some, to be fair) thus barring us from using Pearson correlation on the entire data set leaving us with the Spearman correlation method.\nSpearman Climate Warming/Extremes Height/Length Do height/length records of Passer domesticus and latitude correlate?\nFollowing Bergmann\u0026rsquo;s rule, we expect a positive correlation between sparrow height/length and absolute values of latitude:\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Height, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Height, :\r## Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Height\r## S = 128104735, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## -0.8219373\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Height)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Height of Passer domesticus vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula 'y ~ x'\r Interestingly enough, our analysis yields a negative correlation which would disproof Bermann\u0026rsquo;s rule. This is a good example to show how important biological background knowledge is when doing biostatistics. Whilst a pure statistician might now believe to have just dis-proven a big rule of biology, it should be apparent to any biologist that Bergmann spoke of \u0026ldquo;bigger\u0026rdquo; organisms in colder climates (higher latitudes) and not of \u0026ldquo;taller\u0026rdquo; individuals. What our sparrows lack in height, they might make up for in circumference. This is an example where we would reject the null hypothesis but shouldn\u0026rsquo;t accept the alternative hypothesis based on biological understanding.\nWeight Do weight records of Passer domesticus and latitude correlate?\nAgain, following Bergmann\u0026rsquo;s rule, we expect a positive correlation between sparrow weight and absolute values of latitude.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Weight, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Weight, :\r## Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Weight\r## S = 9349037, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## 0.8670357\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Weight)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Weight of Passer domesticus vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula 'y ~ x'\r Bergmann was obviously right and we reject the null hypothesis.\nWing Chord Do wing chord/wing span records of Passer domesticus and latitude correlate?\nWe would expect sparrows in higher latitudes (e.g. colder climates) to have smaller wings as to radiate less body heat.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord, :\r## Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Wing.Chord\r## S = 134573929, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## -0.9139437\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Wing.Chord)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Wing chord of Passer domesticus vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula 'y ~ x'\r And we were right! Sparrows have shorter wingspans in higher latitudes and we reject the null hypothesis.\nNumber of Eggs Do numbers of eggs per nest of Passer domesticus and latitude correlate?\nDue to resource constraints in colder climates, we expect female Passer domesticus individuals to invest in quality over quantity by prioritising caring your fledglings by educing the amount of eggs they produce.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Number.of.Eggs, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y =\r## Data_df$Number.of.Eggs, : Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Number.of.Eggs\r## S = 14501794, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## -0.92853\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Number.of.Eggs)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Number of eggs of Passer domesticus nests vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula 'y ~ x'\r ## Warning: Removed 394 rows containing non-finite values (stat_smooth).\r ## Warning: Removed 394 rows containing missing values (geom_point).\r We were right. Female house sparrows produce less eggs per capita in higher latitudes and we reject the null hypothesis.\nEgg Weight Does average weight of eggs per nest of Passer domesticus and latitude correlate?\nDue to the reduced investment in egg numbers that we have just proven, we expect females of Passer domesticus to allocate some of their saved resources into heavier eggs which may nurture unhatched offspring for longer and more effectively.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight, :\r## Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Egg.Weight\r## S = 1318221, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## 0.82321\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Egg.Weight)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Weight of Passer domesticus eggs vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula 'y ~ x'\r ## Warning: Removed 395 rows containing non-finite values (stat_smooth).\r ## Warning: Removed 395 rows containing missing values (geom_point).\r Indeed, the higher the latitude, the heavier the average egg per nest of Passer domesticus and we reject the null hypothesis.\nPearson We already know that we can\u0026rsquo;t analyse the entire data set at once for these two variables since their data values are not normal distirbuted. How about site-wise variable value distributions, though?\n# Further reducing the data set\rData_df \u0026lt;- Data_df[,c(\u0026quot;Index\u0026quot;, \u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;)]\r# establishing an empty data frame and an index vector that doesn't repeat\rNormal_df \u0026lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)\rIndices \u0026lt;- as.character(unique(Data_df_base$Index[Rows]))\r# site-wise shapiro test\rfor(i in 2:length(colnames(Data_df))){ # variables\rfor(k in 1:length(Indices)){ # sites\rNormal_df[i,k] \u0026lt;- round(shapiro.test(as.numeric(\rData_df[,i][which(Data_df_base$Index[Rows] == Indices[k])])\r)$p.value, 2)}} # site loop, variable loop\rrownames(Normal_df) \u0026lt;- colnames(Data_df)\rcolnames(Normal_df) \u0026lt;- Indices\rNormal_df[-1,] # remove superfluous index row\r ## NU MA LO BE FG SA FI\r## Weight 0.57 0.12 0.50 0.38 0.18 0.76 0.43\r## Height 0.23 0.03 0.19 0.59 0.88 0.27 0.86\r According to these results intra-site correlations of sparrow weight and height can be carried out! So, in order to show Pearson correlation, we run a simple, site-wise correlation analysis.\nDo weight and height records of Passer domesticus correlate within each site?\nTo shed some light on our previous findings, we might want to see whether weight and height of sparrows correlate. Without running the analysis, we can conclude that they do because both correlate with latitude and are thus what we call collinear. However, now we are running the analysis on a site level - does the correlation still exist?\nTake note that we are now using our entire data set again.\n# overwriting altered Data_df\rData_df \u0026lt;- Data_df_base\r# establishing an empty data frame and an index vector that doesn't repeat\rPearson_df \u0026lt;- data.frame(Pearson = as.character(), stringsAsFactors = FALSE)\rIndices \u0026lt;- as.character(unique(Data_df$Index))\r# site-internal correlation tests, weight and height\rfor(i in 1:length(unique(Data_df$Index))){\rWeights \u0026lt;- Data_df$Weight[which(Data_df$Index == Indices[i])]\rHeights \u0026lt;- Data_df$Height[which(Data_df$Index == Indices[i])]\rPearson_df[1,i] \u0026lt;- round(cor.test(x = Weights, y = Heights, use = \u0026quot;pairwise.complete.obs\u0026quot;)[[\u0026quot;estimate\u0026quot;]][[\u0026quot;cor\u0026quot;]], 2)\rPearson_df[2,i] \u0026lt;- round(cor.test(x = Weights, y = Heights, use = \u0026quot;pairwise.complete.obs\u0026quot;)$p.value, 2)}\rcolnames(Pearson_df) \u0026lt;- Indices\rrownames(Pearson_df) \u0026lt;- c(\u0026quot;r\u0026quot;, \u0026quot;p\u0026quot;)\rPearson_df\r ## SI UK AU RE NU MA LO BE FG SA FI\r## r 0.76 0.83 0.77 0.75 0.84 0.84 0.79 0.82 0.79 0.76 0.81\r## p 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\r Apparently, it does. Heavier birds are taller!\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"4ce506a084a1718dff5f8048a0fcdd1c","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/correlation-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/correlation-tests/","section":"courses","summary":"Welcome to our third practical experience in R. Throughout the following notes, I will introduce you to a couple statistical correlation approaches that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.","tags":["R","Statistics"],"title":"Correlation Tests","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our third practical experience in R. Throughout the following notes, I will introduce you to a couple statistical correlation approaches that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise. I have prepared some slides for this session: \nData Find the data for this exercise here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;DescTools\u0026quot;, # Needed for Contingency Coefficient\r\u0026quot;ggplot2\u0026quot; # needed for data visualisation\r)\rsapply(package_vec, install.load.package)\r ## Loading required package: DescTools\r ## Loading required package: ggplot2\r ## DescTools ggplot2 ## TRUE TRUE\r Loading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Nominal Scale - Contingency Coefficient We can analyse correlations/dependencies of variables of the categorical kind using the contingency coefficient by calling the ContCoef() function of base R.\nKeep in mind that the contingency coefficient is not really a measure of correlation but merely of association of variables. A value of $c \\approx 0$ indicates independent variables.\nPredation Are colour morphs of Passer domesticus linked to predator presence and/or predator type?\nThis analysis builds on our findings within our previous exercise (Nominal Tests - Analysing The Sparrow Data Set). Remember that, using the two-sample situation Chi-Squared Test, we found no change in treatment effects (as far as colour polymorphism went) for predator type values but did so regarding the presence of predators. Let\u0026rsquo;s repeat this here:\ntable(Data_df$Colour, Data_df$Predator.Presence)\r ## ## No Yes\r## Black 64 292\r## Brown 211 87\r## Grey 82 331\r ContCoef(table(Data_df$Colour, Data_df$Predator.Presence))\r ## [1] 0.4421914\r table(Data_df$Colour, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Black 197 95\r## Brown 60 27\r## Grey 233 98\r ContCoef(table(Data_df$Colour, Data_df$Predator.Type))\r ## [1] 0.02957682\r Here, we find the same results as when using the Chi-Squared statistic and conclude that colour morphs of the common house sparrow are likely to be driven by predator presence but not the type of predator that is present.\nAre nesting sites of Passer domesticus linked to predator presence and/or predator type?\nAgain, following our two-sample situation Chi-Squared analysis from last exercise, we want to test whether nesting site and predator presence/predator type are linked. The Chi-Squared analyses identified a possible link of nesting site and predator type but nor predator presence.\ntable(Data_df$Nesting.Site, Data_df$Predator.Presence)\r ## ## No Yes\r## Shrub 87 205\r## Tree 94 137\r ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Presence))\r ## [1] 0.1130328\r table(Data_df$Nesting.Site, Data_df$Predator.Type)\r ## ## Avian Non-Avian\r## Shrub 182 23\r## Tree 49 88\r ContCoef(table(Data_df$Nesting.Site, Data_df$Predator.Type))\r ## [1] 0.4851588\r Whilst there doesn\u0026rsquo;t seem to be any strong evidence linking nesting site and predator presence, predator type seems to be linked to what kind of nesting site Passer domesticus prefers thus supporting our Chi-Squared results.\nSexual Dimorphism Are sex ratios of Passer domesticus related to climate types?\nRecall that, in our last exercise, we found no discrepancy of proportions of the sexes among the entire data set using a binomial test. What we didn\u0026rsquo;t check yet was whether the sexes are distributed across the sites somewhat homogeneously or whether the sex ratios might be skewed according to climate types. Let\u0026rsquo;s do this:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\r# select all data belonging to the stations at which all parameters except for climate type are held constant\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,]\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r# analysis\rtable(Data_df$Sex, Data_df$Climate)\r ## ## Coastal Continental\r## Female 91 76\r## Male 72 78\r ContCoef(table(Data_df$Sex, Data_df$Climate))\r ## [1] 0.06470702\r Quite obviously, they aren\u0026rsquo;t and, if there are any patterns in sex ratios to emerge, these are not likely to stem from climate types. Also keep in mind that we have a plethora of other variables at play whilst the information contained within the climate type variable is somewhat constrained and, in this case, bordering on uninformative (i.e. a coastal site in the Arctic might be more closely resembled by a continental mid-latitude site than by a tropical coastal site).\nOrdinal Scale - Kendall\u0026rsquo;s Tau Climate Warming/Extremes Do heavier sparrows have heavier/less eggs?\nA heavier weight of individual females alludes to a higher pool of resources being allocated by said individuals. There are multiple ways they might make use of it, one of them being investment in reproduction. To test how heavier females of Passer domesticus utilise their resources in reproduction, we use a Kendall\u0026rsquo;s Tau approach to finding links between female weight and average egg weight per nest/number of eggs per nest.\nObviously, both weight variables are metric in nature and so we could use other methods as well. On top of that, we first need to convert these into ranks before being able to run a Kendall\u0026rsquo;s Tau analysis as follows:\n# overwriting changes in Data_df with base data\rData_df \u0026lt;- Data_df_base\r# Establishing Ranks of Egg Weight\rRankedEggWeight \u0026lt;- rank(Data_df$Egg.Weight[which(Data_df$Sex == \u0026quot;Female\u0026quot;)],\rties.method = \u0026quot;average\u0026quot;)\r# Establishing Ranks of Female Weight\rRankedWeight_Female \u0026lt;- rank(Data_df$Weight[which(Data_df$Sex == \u0026quot;Female\u0026quot;)],\rties.method = \u0026quot;average\u0026quot;)\r# Extracting Numbers of Eggs\rRankedEggs \u0026lt;- Data_df$Number.of.Eggs[which(Data_df$Sex == \u0026quot;Female\u0026quot;)]\r Luckily enough, the number of eggs per nest already represent a ranked (ordinal) variable and so we can move straight on to running our analyses:\n# Test ranked female weight vs. ranked egg weight\rcor.test(x = RankedWeight_Female, y = RankedEggWeight, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;kendall\u0026quot;)\r ## ## Kendall's rank correlation tau\r## ## data: RankedWeight_Female and RankedEggWeight\r## z = 19.771, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true tau is not equal to 0\r## sample estimates:\r## tau ## 0.5804546\r There is strong evidence to suggest that heavier females tend to lay heavier eggs (tau = 0.5804546 at p $\\approx$ 0).\n# Test ranked female weight vs. number of eggs\rcor.test(x = RankedWeight_Female, y = RankedEggs, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;kendall\u0026quot;)\r ## ## Kendall's rank correlation tau\r## ## data: RankedWeight_Female and RankedEggs\r## z = -21.787, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true tau is not equal to 0\r## sample estimates:\r## tau ## -0.6880932\r Additionally, the heavier a female of Passer domesticus, the less eggs she produces (tau = -0.6880932 at p $\\approx$ 0).\nNow we can visualise the underlying patterns:\nplot_df \u0026lt;- data.frame(RankedWeight = RankedWeight_Female,\rRankedEggWeight = RankedEggWeight,\rRankedEggNumber = RankedEggs)\r# plot ranked female weight vs. ranked egg weight\rggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggWeight)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Ranked female weight of Passer domesticus vs. Ranked weigt of eggs\u0026quot;)\r ## `geom_smooth()` using formula = 'y ~ x'\r # plot ranked female weight vs. number of eggs\rggplot(data = plot_df, aes(x = RankedWeight, y = RankedEggNumber)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Ranked female weight of Passer domesticus vs. Ranked number of eggs\u0026quot;)\r ## `geom_smooth()` using formula = 'y ~ x'\r This highlights an obvious and intuitive trade-off in nature and has us reject the null hypotheses.\nMetric and Ordinal Scales Metric scale correlation analyses call for:\n Spearman correlation test (non-parametric) Pearson correlation test (parametric, requires data to be normal distributed)  Testing for Normality DISCLAIMER: I do not expect you to do it this way as of right now but wanted to give you reference material of how to automate this testing step.\nSince most of our following analyses are focussing on latitude effects (i.e. \u0026ldquo;climate warming\u0026rdquo;), we need to alter our base data. Before we can run the analyses, we need to eliminate the sites that we have set aside for testing climate extreme effects on (Siberia, United Kingdom, Reunion and Australia) from the data set. We are also not interested in all variables and so reduce the data set further.\nData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index != \u0026quot;SI\u0026quot; \u0026amp; Index != \u0026quot;UK\u0026quot; \u0026amp; Index != \u0026quot;RE\u0026quot; \u0026amp; Index != \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,c(\u0026quot;Index\u0026quot;, \u0026quot;Latitude\u0026quot;, \u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Nesting.Height\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;, \u0026quot;Egg.Weight\u0026quot;)]\r In order to know which test we can use with which variable, we need to first identify whether our data is normal distributed using the Shapiro-Test (Seminar 3) as follows:\nNormal_df \u0026lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)\rfor(i in 2:length(colnames(Data_df))){\rNormal_df[1,i] \u0026lt;- colnames(Data_df)[i]\rNormal_df[2,i] \u0026lt;- round(shapiro.test(as.numeric(Data_df[,i]))$p.value, 2)\r}\rcolnames(Normal_df) \u0026lt;- c()\rrownames(Normal_df) \u0026lt;- c(\u0026quot;Variable\u0026quot;, \u0026quot;p\u0026quot;)\rNormal_df \u0026lt;- Normal_df[,-1] # removing superfluous Index column\rNormal_df\r ## ## Variable Latitude Weight Height Wing.Chord Nesting.Height Number.of.Eggs\r## p 0 0 0 0 0 0\r## ## Variable Egg.Weight\r## p 0\r Unfortunately, none of these variables seem to be normal distributed (this was to be expected for some, to be fair) thus barring us from using Pearson correlation on the entire data set leaving us with the Spearman correlation method.\nSpearman Climate Warming/Extremes Height/Length Do height/length records of Passer domesticus and latitude correlate?\nFollowing Bergmann\u0026rsquo;s rule, we expect a positive correlation between sparrow height/length and absolute values of latitude:\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Height, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Height, :\r## Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Height\r## S = 128104735, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## -0.8219373\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Height)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Height of Passer domesticus vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula = 'y ~ x'\r Interestingly enough, our analysis yields a negative correlation which would disproof Bermann\u0026rsquo;s rule. This is a good example to show how important biological background knowledge is when doing biostatistics. Whilst a pure statistician might now believe to have just dis-proven a big rule of biology, it should be apparent to any biologist that Bergmann spoke of \u0026ldquo;bigger\u0026rdquo; organisms in colder climates (higher latitudes) and not of \u0026ldquo;taller\u0026rdquo; individuals. What our sparrows lack in height, they might make up for in circumference. This is an example where we would reject the null hypothesis but shouldn\u0026rsquo;t accept the alternative hypothesis based on biological understanding.\nWeight Do weight records of Passer domesticus and latitude correlate?\nAgain, following Bergmann\u0026rsquo;s rule, we expect a positive correlation between sparrow weight and absolute values of latitude.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Weight, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Weight, :\r## Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Weight\r## S = 9349037, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## 0.8670357\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Weight)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Weight of Passer domesticus vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula = 'y ~ x'\r Bergmann was obviously right and we reject the null hypothesis.\nWing Chord Do wing chord/wing span records of Passer domesticus and latitude correlate?\nWe would expect sparrows in higher latitudes (e.g. colder climates) to have smaller wings as to radiate less body heat.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Wing.Chord,\r## : Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Wing.Chord\r## S = 134573929, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## -0.9139437\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Wing.Chord)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Wing chord of Passer domesticus vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula = 'y ~ x'\r And we were right! Sparrows have shorter wingspans in higher latitudes and we reject the null hypothesis.\nNumber of Eggs Do numbers of eggs per nest of Passer domesticus and latitude correlate?\nDue to resource constraints in colder climates, we expect female Passer domesticus individuals to invest in quality over quantity by prioritising caring your fledglings by educing the amount of eggs they produce.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Number.of.Eggs, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y =\r## Data_df$Number.of.Eggs, : Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Number.of.Eggs\r## S = 14501794, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## -0.92853\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Number.of.Eggs)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Number of eggs of Passer domesticus nests vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula = 'y ~ x'\r ## Warning: Removed 394 rows containing non-finite values (`stat_smooth()`).\r ## Warning: Removed 394 rows containing missing values (`geom_point()`).\r We were right. Female house sparrows produce less eggs per capita in higher latitudes and we reject the null hypothesis.\nEgg Weight Does average weight of eggs per nest of Passer domesticus and latitude correlate?\nDue to the reduced investment in egg numbers that we have just proven, we expect females of Passer domesticus to allocate some of their saved resources into heavier eggs which may nurture unhatched offspring for longer and more effectively.\ncor.test(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight, use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;spearman\u0026quot;)\r ## Warning in cor.test.default(x = abs(Data_df$Latitude), y = Data_df$Egg.Weight,\r## : Cannot compute exact p-value with ties\r ## ## Spearman's rank correlation rho\r## ## data: abs(Data_df$Latitude) and Data_df$Egg.Weight\r## S = 1318221, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true rho is not equal to 0\r## sample estimates:\r## rho ## 0.82321\r ggplot(data = Data_df, aes(x = abs(Latitude), y = Egg.Weight)) +\rgeom_point() + theme_bw() + stat_smooth(method = \u0026quot;lm\u0026quot;) + labs(title = \u0026quot;Weight of Passer domesticus eggs vs. Latitude\u0026quot;)\r ## `geom_smooth()` using formula = 'y ~ x'\r ## Warning: Removed 395 rows containing non-finite values (`stat_smooth()`).\r ## Warning: Removed 395 rows containing missing values (`geom_point()`).\r Indeed, the higher the latitude, the heavier the average egg per nest of Passer domesticus and we reject the null hypothesis.\nPearson We already know that we can\u0026rsquo;t analyse the entire data set at once for these two variables since their data values are not normal distirbuted. How about site-wise variable value distributions, though?\n# Further reducing the data set\rData_df \u0026lt;- Data_df[,c(\u0026quot;Index\u0026quot;, \u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;)]\r# establishing an empty data frame and an index vector that doesn't repeat\rNormal_df \u0026lt;- data.frame(Normality = as.character(), stringsAsFactors = FALSE)\rIndices \u0026lt;- as.character(unique(Data_df_base$Index[Rows]))\r# site-wise shapiro test\rfor(i in 2:length(colnames(Data_df))){ # variables\rfor(k in 1:length(Indices)){ # sites\rNormal_df[i,k] \u0026lt;- round(shapiro.test(as.numeric(\rData_df[,i][which(Data_df_base$Index[Rows] == Indices[k])])\r)$p.value, 2)}} # site loop, variable loop\rrownames(Normal_df) \u0026lt;- colnames(Data_df)\rcolnames(Normal_df) \u0026lt;- Indices\rNormal_df[-1,] # remove superfluous index row\r ## NU MA LO BE FG SA FI\r## Weight 0.57 0.12 0.50 0.38 0.18 0.76 0.43\r## Height 0.23 0.03 0.19 0.59 0.88 0.27 0.86\r According to these results intra-site correlations of sparrow weight and height can be carried out! So, in order to show Pearson correlation, we run a simple, site-wise correlation analysis.\nDo weight and height records of Passer domesticus correlate within each site?\nTo shed some light on our previous findings, we might want to see whether weight and height of sparrows correlate. Without running the analysis, we can conclude that they do because both correlate with latitude and are thus what we call collinear. However, now we are running the analysis on a site level - does the correlation still exist?\nTake note that we are now using our entire data set again.\n# overwriting altered Data_df\rData_df \u0026lt;- Data_df_base\r# establishing an empty data frame and an index vector that doesn't repeat\rPearson_df \u0026lt;- data.frame(Pearson = as.character(), stringsAsFactors = FALSE)\rIndices \u0026lt;- as.character(unique(Data_df$Index))\r# site-internal correlation tests, weight and height\rfor(i in 1:length(unique(Data_df$Index))){\rWeights \u0026lt;- Data_df$Weight[which(Data_df$Index == Indices[i])]\rHeights \u0026lt;- Data_df$Height[which(Data_df$Index == Indices[i])]\rPearson_df[1,i] \u0026lt;- round(cor.test(x = Weights, y = Heights, use = \u0026quot;pairwise.complete.obs\u0026quot;)[[\u0026quot;estimate\u0026quot;]][[\u0026quot;cor\u0026quot;]], 2)\rPearson_df[2,i] \u0026lt;- round(cor.test(x = Weights, y = Heights, use = \u0026quot;pairwise.complete.obs\u0026quot;)$p.value, 2)}\rcolnames(Pearson_df) \u0026lt;- Indices\rrownames(Pearson_df) \u0026lt;- c(\u0026quot;r\u0026quot;, \u0026quot;p\u0026quot;)\rPearson_df\r ## SI UK AU RE NU MA LO BE FG SA FI\r## r 0.76 0.83 0.77 0.75 0.84 0.84 0.79 0.82 0.79 0.76 0.81\r## p 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\r Apparently, it does. Heavier birds are taller!\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"16b00e89733d5cb83032e0288196a0fe","permalink":"https://www.erikkusch.com/courses/biostat101/correlation-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/correlation-tests/","section":"courses","summary":"Welcome to our third practical experience in R. Throughout the following notes, I will introduce you to a couple statistical correlation approaches that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.","tags":["R","Statistics"],"title":"Correlation Tests","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"\rKrigR is currently undergoing development. As a result, this part of the workshop has become deprecated. Please refer to the setup quick guide portions of this material as these are up-to-date. \r\r\r\rThis part of the workshop is dependant on set-up and preparation done previously here.\r\r\rFirst, we load KrigR:\nlibrary(KrigR)\r \rDownloads and data processing with KrigR are staged and executed with the download_ERA()function.\r\r\rdownload_ERA() is a very versatile function and I will show you it\u0026rsquo;s capabilities throughout this material.\n\rWe will start with a simple calls to KrigR and subsequently make them more sophisticated during this workshop.\r\r\rDownloading Climate Data Let\u0026rsquo;s start with a very basic call to download_ERA().\nFor this part of the workshop, we download air temperature for my birth month (January 1995) using the extent of our target region.\nSee the code chunk below for explanations on each function argument. If you want to know about the defaults for any argument in download_ERA() simply run ?download_ERA(). Doing so should make it obvious why we specify the function as we do below.\n\rNotice that the downloading of ERA-family reanalysis data may take a short while to start as the download request gets queued with the CDS of the ECMWF before it is executed.\r\r\r\rClick here for file if download takes too long:\rDownload FirstDL.nc and place it into your data directory.\r FirstDL \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;, # the variable we want to obtain data for\rDataSet = \u0026quot;era5-land\u0026quot;, # the data set we want to obtain data from\rDateStart = \u0026quot;1995-01-01\u0026quot;, # the starting date of our time-window\rDateStop = \u0026quot;1995-01-31\u0026quot;, # the final date of our time-window\rExtent = Extent_ext, # the spatial preference we are after\rDir = Dir.Data, # where to store the downloaded data\rFileName = \u0026quot;FirstDL\u0026quot;, # a name for our downloaded file\rAPI_User = API_User, # your API User Number\rAPI_Key = API_Key # your API User Key\r)\r ## download_ERA() is starting. Depending on your specifications, this can take a significant time.\r ## User 39340 for cds service added successfully in keychain\r ## Staging 1 download(s).\r ## 0001_FirstDL.nc download queried\r ## Requesting data to the cds service with username 39340\r ## - staging data transfer at url endpoint or request id:\r ## e48f036d-0979-4db4-bc4e-9d08be01c9d6\r ## - timeout set to 10.0 hours\r ## - polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r## Downloading file\r ## | | | 0%\r| |================================================================================| 100%\r ## - moved temporary file to -\u0026gt; /Users/erikkus/Documents/HomePage/content/courses/krigr/Data/0001_FirstDL.nc\r## - Delete data from queue for url endpoint or request id:\r## https://cds.climate.copernicus.eu/api/v2/tasks/e48f036d-0979-4db4-bc4e-9d08be01c9d6\r## ## Checking for known data issues.\r## Loading downloaded data for masking and aggregation.\r## Aggregating to temporal resolution of choice\r As you can see the download_ERA() function updates you on what it is currently working on at each major step. I implemented this to make sure people don\u0026rsquo;t get too anxious staring at an empty console in R. If this feature is not appealing to you, you can turn this progress tracking off by setting verbose = FALSE in the function call to download_ERA().\n\rFor the rest of this workshop, I suppress messages from download_ERA() via other means so that when you execute, you get progress tracking.\r\r\rI will make exceptions to this rule when there are special things I want to demonstrate.\nNow, let\u0026rsquo;s look at the raster that was produced:\nFirstDL\r ## class : RasterStack ## dimensions : 34, 54, 1836, 1 (nrow, ncol, ncell, nlayers)\r## resolution : 0.09999999, 0.09999998 (x, y)\r## extent : 9.72, 15.12, 49.74, 53.14 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## names : X1995.01.01\r One layer (i.e., one month) worth of data. That seems to have worked. If you are keen-eyed, you will notice that the extent on this object does not align with the extent we supplied with Extent_ext. The reason? To download the data, we need to snap to the nearest full cell in the data set from which we query our downloads. KrigR always ends up widening the extent to ensure all the data you desire will be downloaded.\nFinally, let\u0026rsquo;s visualise our downloaded data with one of our user-defined plotting functions:\nPlot_Raw(FirstDL, Dates = \u0026quot;01-1995\u0026quot;)\r That is all there is to downloading ERA5(-Land) data with KrigR. You can already see how, even at the relatively course resolution of ERA5-Land, the mountain ridges along the German-Czech border are showing up. This will become a lot clearer of a pattern once we downscale our data.\n\rdownload_ERA() provides you with a lot more functionality than just access to the ERA5(-Land) data sets.\r\r\r\rWith download_ERA(), you can also carry out processing of the downloaded data. Data processing with download_ERA() includes:\n Spatial Limitation to cut down on the data that is stored on your end. Temporal Aggregation to establish data at the temporal resolution you desire.  \r\rSpatial Limitation Let\u0026rsquo;s start with spatial limitation. As discussed previously, download_ERA() can handle a variety of inputs describing spatial preferences.\n\rKrigR is capable of learning about your spatial preferences in three ways:\n As an extent input (a rectangular box). As a SpatialPolygons input (a polygon or set of polygons). As a set of locations stored in a data.frame.  These spatial preferences are registered in KrigR functions using the Extent argument.\n\r\rYou might now ask yourself: How does KrigR achieve spatial limitation of the data? Couldn\u0026rsquo;t we just simply download only the data we are interested in?\nThe ECMWF CDS gives us tremendous capability of retrieving only the data we want. However, the CDS only recognises rectangular boxes (i.e., extents) for spatial limitation. Consequently, we always have to download data corresponding to a rectangular box in space. When informing KrigR of your spatial preferences using a data.frame or SpatialPolygons, download_ERA() automatically (1) identifies the smallest extent required by your input, (2) downloads data corresponding to this extent, and (3) masks our any data not queried by you.\n\rUsing KrigR\u0026rsquo;s spatial limitation features ensures faster computation and smaller file sizes (depending on file type).\r\r\rIn the following, I demonstrate how to use the Extent argument in download_ERA().\nShape (SpatialPolygons) Let me show you how SpatialPolygons show up in our data with download_ERA(). Remember that these SpatialPolygons originate here. First, we query our download as follows:\n\rClick here for file if download takes too long:\rDownload SpatialPolygons_DL.nc and place it into your data directory.\r SpatialPolygons_DL \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5-land\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-31\u0026quot;,\rExtent = Shape_shp, # we simply switch the Extent Argument\rDir = Dir.Data,\rFileName = \u0026quot;SpatialPolygons_DL\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r) Plot_Raw(SpatialPolygons_DL, Dates = \u0026quot;01-1995\u0026quot;, Shp = Shape_shp)\r You will find that the data retained with the spatial limitation in download_ERA() contains all raster cells of which even a fraction falls within the bounds of the SpatialPolygons you supplied. This is different from standard raster masking through which only cells whose centroids fall within the SpatialPolygons are retained.\n\rraster masking in KrigR always ensures that the entire area of your spatial preferences are retained.\r\r\rPoints (data.frame) Now we move on to point-locations. Often times, we are researching very specific sets of coordinates, rather than entire regions. download_ERA() is capable of limiting data to only small areas (of a size of your choosing) around your point-locations. For our purposes here, we make use of a set of mountain-top coordinates throughout our study region. Remember that these coordinates (stored in a data.frame) originate here.\nThis time around, we need to tell download_ERA() about not just the Extent, but also specify how much of a buffer (Buffer in $°$) to retain data for around each individual (ID) location.\n\rThe data.frame input to the Extent must contain a column called Lat and a column called Lon:\nIn addition, one must also specify:\n A Buffer in $°$ to be drawn around each location. The name of the ID column in your data.frame which indexes each individual location.  \r\r\rOur development goals include support for a broader range of point-location specifications.\r\r\rLet\u0026rsquo;s stage such a download:\n\rClick here for file if download takes too long:\rDownload points_DL.nc and place it into your data directory.\r points_DL \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5-land\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-31\u0026quot;,\rExtent = Mountains_df, # our data.frame with Lat and Lon columns\rBuffer = 0.5, # a half-degree buffer\rID = \u0026quot;Mountain\u0026quot;, # the ID column in our data.frame\rDir = Dir.Data,\rFileName = \u0026quot;points_DL\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\rPlot_Raw(points_DL, Dates = \u0026quot;01-1995\u0026quot;) + geom_point(aes(x = Lon, y = Lat), data = Mountains_df, colour = \u0026quot;green\u0026quot;, size = 10, pch = 14)\r Above you can see how the mountain tops we are interested in lie exactly at the centre of the retained data. As we will see later, such spatial limitation greatly reduces computation cost of statistical downscaling procedures.\nTemporal Aggregation So far, we have downloaded a single layer of data (i.e., one monthly average layer) from the CDS. However, ERA5(-Land) products come at hourly temporal resolutions from which we can generate climate data at almost any temporal resolution we may require. This is what temporal aggregation in download_ERA() is for.\n\rWith temporal aggregation in download_ERA() you can achieve almost any temporal resolution and aggregate metric you may desire.\r\r\r\rTemporal aggregation with download_ERA() uses the arguments:\n TResolution and TStep to achieve desired temporal resolutions FUN to calculate desired aggregate metrics  \r\rTemporal Resolution (TResolution and TStep) Let\u0026rsquo;s start by querying data at non-CDS temporal resolutions.\n\rThe download_ERA() function in the KrigR package accepts the following arguments which you can use to control the temporal resolution of your climate data:\n TResolution controls the time-line that TStep indexes. You can specify anything from the following: 'hour', 'day', 'month', or 'year'. The default is 'month'. TStep controls how many time-steps to aggregate into one layer of data each. Aggregation is done via taking the mean per cell in each raster comprising time steps that go into the final, aggregated time-step. The default is 1.  \r\rFor now, let\u0026rsquo;s download hourly data from the CDS (this achieved by specifying a TResolution of \u0026quot;hour\u0026quot; or \u0026quot;day\u0026quot;) and aggregate these to 1-day intervals. To make the result easier to visualise, we focus only on the first four days of January 1995:\n\rClick here for file if download takes too long:\rDownload TimeSeries.nc and place it into your data directory.\r TimeSeries \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5-land\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-04\u0026quot;,\rTResolution = \u0026quot;day\u0026quot;, # aggregate to days\rTStep = 1, # aggregate to 1 day each\rExtent = Shape_shp,\rDir = Dir.Data,\rFileName = \u0026quot;TimeSeries\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\rPlot_Raw(TimeSeries, Dates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;, \u0026quot;03-1995\u0026quot;, \u0026quot;04-1995\u0026quot;),\rShp = Shape_shp)\r Looks like a cold front rolled over my home area at the beginning of 1995.\n\rKrigR automatically identifies which data set to download from given your temporal aggregation specification.\r\r\rAs soon as TResolution is set to 'month' or 'year', the package automatically downloads monthly mean data from the CDS. We do this to make the temporal aggregation calculation more light-weight on your computing units and to make downloads less heavy.\nLet\u0026rsquo;s run through a few examples to make clear how desired temporal resolution of data can be achieved using the KrigR package:\n\r\rWhat We Want\rTResolution \rTStep\r\r\rHourly intervals\rhour\r1\r\r\r6-hour intervals\rhour\r6\r\r\rHalf-day intervals\rhour\r12\r\r\rDaily intervals \rday\r1\r\r\r3-day intervals\rday\r3\r\r\rWeekly intervals\rday\r7\r\r\rMonthly aggregates\rmonth\r1\r\r\r4-month intervals\rmonth\r4\r\r\rAnnual intervals\ryear\r1\r\r\r10-year intervals\ryear\r10\r\r \rSpecifying TResolution of 'month' will result in the download of full month aggregates for every month included in your time series.\r\r\rFor example, DateStart = \u0026quot;2000-01-20\u0026quot;, DateStop = \u0026quot;2000-02-20\u0026quot; with TResolution = 'month', and TStep = 1 does not result in the mean aggregate for the month between the 20/01/200 and the 20/02/2000, but does result in the monthly aggregates for January and February 2000. If you desire the former, you would need to specify DateStart = \u0026quot;2000-01-20\u0026quot;, DateStop = \u0026quot;2000-02-20\u0026quot; with TResolution = 'day', and TStep = 32 (the number of days between the two dates).\nAggregate Metrics (FUN) Aggregate metrics can be particularly useful for certain study settings when climate variability or exposure to extreme events are sought after.\n\rThe FUN argument in download_ERA() controls which values to calculate for the temporal aggregates, e.g.: 'min', 'max', or 'mean' (default).\nAny function which returns a single value when fed a vector of values is supported.\n\r\rLet\u0026rsquo;s say we are interested in the variability of temperature across our study region in daily intervals. Again, we shorten our time-series to just four days:\n\rClick here for file if download takes too long:\rDownload TimeSeriesSD.nc and place it into your data directory.\r TimeSeriesSD \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5-land\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-04\u0026quot;,\rTResolution = \u0026quot;day\u0026quot;,\rTStep = 1,\rFUN = sd, # query standard deviation\rExtent = Shape_shp,\rDir = Dir.Data,\rFileName = \u0026quot;TimeSeriesSD\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\rPlot_Raw(TimeSeriesSD, Dates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;, \u0026quot;03-1995\u0026quot;, \u0026quot;04-1995\u0026quot;),\rShp = Shape_shp)\r Seems like the temperatures fluctuated most on the third and fourth of January, but the area of temperature fluctuations changed location between those two days.\n\rYou should now be able to query data for any location you study and achieve temporal resolutions and aggregate metrics which your study requires.\r\r\rDynamical Data Uncertainty With climate reanalyses, you also gain access to uncertainty flags of the data stored in the reanalysis product. For the ERA5-family of products, this uncertainty can be obtained by assessing the standard deviation of the 10 ensemble members which make up the underlying ERA5 model exercise.\nWith download_ERA() you can obtain this information as follows:\n\rClick here for file if download takes too long:\rDownload SpatialPolygonsEns_DL.nc and place it into your data directory.\r SpatialPolygonsEns_DL \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5\u0026quot;,\rType = \u0026quot;ensemble_members\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-02\u0026quot;,\rTResolution = \u0026quot;day\u0026quot;,\rTStep = 1,\rFUN = sd,\rExtent = Shape_shp,\rDir = Dir.Data,\rFileName = \u0026quot;SpatialPolygonsEns_DL\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\rPlot_Raw(SpatialPolygonsEns, Dates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;),\rShp = Shape_shp, COL = rev(viridis(100)))\r As you can see here, there is substantial disagreement between the ensemble members of daily average temperatures across our study region. This uncertainty among ensemble members is greatest at high temporal resolution and becomes negligible at coarse temporal resolution. We document this phenomenon in this publication (Figure 1).\nFinal Downloads for Workshop Progress Now that we know how to use spatial limitation and temporal aggregation with download_ERA() it is time to generate the data products we will use for the rest of this workshop material.\nClimate Data \rTo streamline this workshop material, I will focus on just three short-time series of data with different spatial limitations. I visualise them all side-by-side further down.\r\r\r Click here for download calls \rextent Data \rClick here for file if download takes too long:\rDownload ExtentRaw.nc and place it into your data directory.\r Extent_Raw \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5-land\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-04\u0026quot;,\rTResolution = \u0026quot;day\u0026quot;,\rTStep = 1,\rExtent = Extent_ext,\rDir = Dir.Data,\rFileName = \u0026quot;ExtentRaw\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\r SpatialPolygons Data \rClick here for file if download takes too long:\rDownload SpatialPolygonsRaw.nc and place it into your data directory.\r SpatialPolygonsRaw \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5-land\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-04\u0026quot;,\rTResolution = \u0026quot;day\u0026quot;,\rTStep = 1,\rExtent = Shape_shp,\rDir = Dir.Data,\rFileName = \u0026quot;SpatialPolygonsRaw\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\r Point(data.frame) Data \rClick here for file if download takes too long:\rDownload PointsRaw.nc and place it into your data directory.\r Points_Raw \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5-land\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-4\u0026quot;,\rTResolution = \u0026quot;day\u0026quot;,\rTStep = 1,\rExtent = Mountains_df,\rBuffer = 0.5,\rID = \u0026quot;Mountain\u0026quot;,\rDir = Dir.Data,\rFileName = \u0026quot;PointsRaw\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\r \rNow let\u0026rsquo;s visualise these data for a better understanding of what they contain:\nExtent_gg \u0026lt;- Plot_Raw(Extent_Raw[[1]], Dates = \u0026quot;Extent\u0026quot;)\rSP_gg \u0026lt;- Plot_Raw(SpatialPolygonsRaw[[1]], Dates = \u0026quot;SpatialPolygons\u0026quot;)\rPoints_gg \u0026lt;- Plot_Raw(Points_Raw[[1]], Dates = \u0026quot;SpatialPolygons\u0026quot;)\rplot_grid(Extent_gg, SP_gg, Points_gg, ncol = 3)\r Dynamical Data Uncertainty \rFor an aggregate understanding of data uncertainty, we also obtain dynamical uncertainty for our target region and time frame. For simplicity, we do so only for the SpatialPolygons specification.\r\r\r Click here for download call \r\rClick here for file if download takes too long:\rDownload SpatialPolygonsEns.nc and place it into your data directory.\r SpatialPolygonsEns \u0026lt;- download_ERA(\rVariable = \u0026quot;2m_temperature\u0026quot;,\rDataSet = \u0026quot;era5\u0026quot;,\rType = \u0026quot;ensemble_members\u0026quot;,\rDateStart = \u0026quot;1995-01-01\u0026quot;,\rDateStop = \u0026quot;1995-01-04\u0026quot;,\rTResolution = \u0026quot;day\u0026quot;,\rTStep = 1,\rFUN = sd,\rExtent = Shape_shp,\rDir = Dir.Data,\rFileName = \u0026quot;SpatialPolygonsEns\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key\r)\r  Plot_Raw(SpatialPolygonsEns, Dates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;, \u0026quot;03-1995\u0026quot;, \u0026quot;04-1995\u0026quot;),\rShp = Shape_shp, COL = rev(viridis(100)))\r We will see how these uncertainties stack up against other sources of uncertainty when we arrive at aggregate uncertainty of our final product.\nConsiderations for download_ERA() download_ERA() is a complex function with many things happening under the hood. To make sure you have the best experience with this interface to the ERA5(-Land) products through R, I have compiled a few bits of good-to-know information about the workings of download_ERA().\nEffeciency Download speeds with download_ERA() are largely tied to CDS queue time, but there are some things worth considering when querying downloads of time-series data.\n\rThe download_ERA() function automatically breaks down download requests into monthly intervals thus circumventing the danger of running into making a download request that is too big for the CDS.\r\r\rFor example, DateStart = \u0026quot;2000-01-20\u0026quot;, DateStop = \u0026quot;2000-02-20\u0026quot; with TResolution = 'day', and TStep = 8 will lead to two download requests to the CDS: (1) hourly data in the range 20/01/2000 00:00 to 31/01/2000 23:00, and (2) hourly data in the range 01/02/2000 00:00 to 20/02/2000 23:00. These data sets are subsequently fused in R, aggregated to daily aggregates, and finally, aggregated to four big aggregates.\nThis gives you a lot of flexibility, but always keep in mind that third-party data sets might not account for leap-years so make sure the dates of third-party data (should you chose to use some) lines up with the ones as specified by your calls to the functions of the KrigR package.\nSingularDL ECMWF CDS downloads come with a hard limit of 100,000 layers worth of data. This corresponds to more than 1 month worth of data. As a matter of fact, even ar hourly time-scales, you could theoretically download ~11 years worth of data without hitting this limit. In this particular case, download_ERA() stages, by default, 132 individual downloads (1 per month) when the CDS would be just fine accepting the download request for all the data in one download call.\nIs there any way to bypass the monthly downloads in download_ERA()? Yes, there is. With the SingularDL argument.\n\rSetting SingularDL = TRUE in download_ERA() bypasses the automatic month-wise download staging. A pre-staging check breaks the operation if you query more than the CDS hard limit on data.\r\r\r\rOur development goals include changing month-wise default downloads to downloads of 100,000 layers at a time.\r\r\rCores Continuing on from the previous point, let\u0026rsquo;s consider you want to obtain more than 100,000 layers worth of data for your analysis and thus can\u0026rsquo;t make use of the SingularDL argument. By default download_ERA() stages downloads sequentially. Most modern PCs come with multiple cores each of which could theoretically stage it\u0026rsquo;s own download in parallel. Couldn\u0026rsquo;t we make use of this for more efficient download staging? Yes, we can with the Cores argument.\n\rUsing the Cores argument in download_ERA() you can specify how many downloads to stage in parallel rather than sequentially.\r\r\rDisk Space KrigR uses NETCDF (.nc) files as they represent the standard in climate science. NETCDF file size is not connected to data content in the raster but number of cells. Other formats, such as GeoTiff (.tif) do however scale in file size with non-NA cell number in the saved rasters.\n\rOur development goals include giving the user control over the file type as which KrigR-derived products are saved.\r\r\rFor example, the file size of the above FirstDL raster is 7kb while the SpatialPolygons and data.frame driven data is saved as GeoTiffs of 4kb and 3kb, respectively.\n\rIf you need to optimise storage space, particularly when using spatial limitation with KrigR, I can thus recommend re-saving KrigR outputs as GeoTiffs.\r\r\rCummulative Variables (PrecipFix) \rSome variables in the ERA5(-Land) data sets are stored as cumulative records for pre-set time-windows, but temporal aggregation in download-ERA() cannot handle such data.\r\r\rConsequently, cumulative records need to be transformed into single-time-step records with respect to their base temporal resolution and cumulative aggregation interval like so:\n\rTo make cumulatively stored variables compatible with temporal aggregation in download_ERA() simple toggle PrecipFix = TRUE in the function call.\r\r\r\rTo identify which variables are stored cumulatively, we recommend searching for variables listed as \u0026ldquo;This variable is accumulated from the beginning of the forecast time to the end of the forecast step.\u0026rdquo; on the data set documentation page (e.g., ERA5-Land).\r\r\r\rOur development goals include an error check for specification of PrecipFix = TRUE on non-cumulatively stored variables.\r\r\rStability download_ERA() requires a stable connection to the ECWMF CDS. Sometimes, however, a connection may drop or the CDS queue is so long that our downloads just fail. To mitigate the annoyance caused by these issues, I have implemented to extra arguments to the download_ERA() function call:\nTimeOut TimeOut is a numeric argument which specifies how many seconds to wait for the CDS to return the queried data. The default equates to 10 hours.\nTryDown TryDown is a numeric argument which specifies how often to retry a download before giving up and moving on or stopping the execution of download_ERA(). The default is 10.\nSession Info sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] mapview_2.11.0 rnaturalearthdata_0.1.0 rnaturalearth_0.3.2 ## [4] gimms_1.2.1 ggmap_3.0.2 cowplot_1.1.1 ## [7] viridis_0.6.2 viridisLite_0.4.1 ggplot2_3.4.1 ## [10] tidyr_1.3.0 KrigR_0.1.2 terra_1.7-21 ## [13] httr_1.4.5 stars_0.6-0 abind_1.4-5 ## [16] fasterize_1.0.4 sf_1.0-12 lubridate_1.9.2 ## [19] automap_1.1-9 doSNOW_1.0.20 snow_0.4-4 ## [22] doParallel_1.0.17 iterators_1.0.14 foreach_1.5.2 ## [25] rgdal_1.6-5 raster_3.6-20 sp_1.6-0 ## [28] stringr_1.5.0 keyring_1.3.1 ecmwfr_1.5.0 ## [31] ncdf4_1.21 ## ## loaded via a namespace (and not attached):\r## [1] leafem_0.2.0 colorspace_2.1-0 class_7.3-21 ## [4] leaflet_2.1.2 satellite_1.0.4 base64enc_0.1-3 ## [7] rstudioapi_0.14 proxy_0.4-27 farver_2.1.1 ## [10] fansi_1.0.4 codetools_0.2-19 cachem_1.0.7 ## [13] knitr_1.42 jsonlite_1.8.4 png_0.1-8 ## [16] Kendall_2.2.1 compiler_4.2.3 assertthat_0.2.1 ## [19] fastmap_1.1.1 cli_3.6.0 htmltools_0.5.4 ## [22] tools_4.2.3 gtable_0.3.1 glue_1.6.2 ## [25] dplyr_1.1.0 Rcpp_1.0.10 jquerylib_0.1.4 ## [28] vctrs_0.6.1 blogdown_1.16 crosstalk_1.2.0 ## [31] lwgeom_0.2-11 xfun_0.37 timechange_0.2.0 ## [34] lifecycle_1.0.3 rnaturalearthhires_0.2.1 zoo_1.8-11 ## [37] scales_1.2.1 gstat_2.1-0 yaml_2.3.7 ## [40] curl_5.0.0 memoise_2.0.1 gridExtra_2.3 ## [43] sass_0.4.5 reshape_0.8.9 stringi_1.7.12 ## [46] highr_0.10 e1071_1.7-13 boot_1.3-28.1 ## [49] intervals_0.15.3 RgoogleMaps_1.4.5.3 rlang_1.1.0 ## [52] pkgconfig_2.0.3 bitops_1.0-7 evaluate_0.20 ## [55] lattice_0.20-45 purrr_1.0.1 htmlwidgets_1.6.1 ## [58] labeling_0.4.2 tidyselect_1.2.0 plyr_1.8.8 ## [61] magrittr_2.0.3 bookdown_0.33 R6_2.5.1 ## [64] generics_0.1.3 DBI_1.1.3 pillar_1.8.1 ## [67] withr_2.5.0 units_0.8-1 xts_0.13.0 ## [70] tibble_3.2.1 spacetime_1.2-8 KernSmooth_2.23-20 ## [73] utf8_1.2.3 rmarkdown_2.20 jpeg_0.1-10 ## [76] grid_4.2.3 zyp_0.11-1 FNN_1.1.3.2 ## [79] digest_0.6.31 classInt_0.4-9 webshot_0.5.4 ## [82] stats4_4.2.3 munsell_0.5.0 bslib_0.4.2\r ","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"76eb2876a29ff0bf597fa383a0259eac","permalink":"https://www.erikkusch.com/courses/krigr/download/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/download/","section":"courses","summary":"Download specifications and considerations with `KrigR`.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Downloading \u0026 Processing","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Markov Chain Monte Carlo Material  \rSlides Chapter 9  Introduction These are answers and solutions to the exercises at the end of chapter 9 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Taras Svirskyi, William Wolf, and Corrie Bartelheimer as well as the solutions provided to instructors by Richard McElreath himself.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(rstan)\rlibrary(ggplot2)\rlibrary(tidybayes)\r Easy Exercises Practice E1 Question: Which of the following is a requirement of the simple Metropolis algorithm?\n The parameters must be discrete. The likelihood function must be Gaussian. The proposal distribution must be symmetric.  Answer:\n Not a requirement. Metropolis can accommodate continuous and discrete parameters. Not a requirement. Distribution could be any symmetric distribution. Not just Gaussian. This is a requirement.  Practice E2 Question: Gibbs sampling is more efficient than the Metropolis algorithm. How does it achieve this extra efficiency? Are there any limitations to the Gibbs sampling strategy?\nAnswer: Gibbs uses adaptive proposals when considering which location in the posterior to sample next. This makes it more efficient because less proposed steps are rejected.\nPractice E3 Question: Which sort of parameters can Hamiltonian Monte Carlo not handle? Can you explain why?\nAnswer: Discrete parameters. HMC depends on gradients which to explore using a physics simulation. Discrete parameters would not allow for the construction of any gradients.\nPractice E4 Question: Explain the difference between the effective number of samples, n_eff as calculated by Stan, and the actual number of samples.\nAnswer: Effective sample number (n_eff) identifies the number of \u0026lsquo;ideal\u0026rsquo; (i.e. uncorrelated) samples. Since MCMC algorithms explore the posterior as a chain of samples, each sample is usually correlated with the previous one to some extent. Conclusively, n_eff identifies the number of samples used for estimating the posterior mean/distribution whereas actual number of samples is simply the number of data points we have.\nn_eff is usually smaller than the actual number of samples (unless we have anti-correlated MCMC samples).\nPractice E5 Question: Which value should Rhat approach, when a chain is sampling the posterior distribution correctly?\nAnswer: $\\hat{R}$ or Rhat, in R, reflects variance within a chain versus variance between chains. If these are the same, $\\hat{R}$ will be $1.0$ - i.e.: it does not matter from which chain we would infere parameters and predictions. Values higher than 1.0 can indicate problems in the model. Values much higher than 1 indicate serious issues.\nPractice E6 Question: Sketch a good trace plot for a Markov chain, one that is effectively sampling from the posterior distribution. What is good about its shape? Then sketch a trace plot for a malfunctioning Markov chain. What about its shape indicates malfunction?\nAnswer:\nGood trace plot\ny \u0026lt;- rnorm(1e4, mean = 1, sd = 2)\rm.E6Good \u0026lt;- ulam(\ralist(\ry ~ dnorm(mu, sigma),\rmu \u0026lt;- alpha,\ralpha ~ dnorm(0, 10),\rsigma ~ dcauchy(0, 1)\r),\rdata = list(y = y),\rcores = 2,\rchains = 2,\rstart = list(\ralpha = 0,\rsigma = 1\r)\r)\rtraceplot(m.E6Good)\r ## [1] 1000\r## [1] 1\r## [1] 1000\r These trace plots show that the chains quickly find the region with highest posterior probability and stay there.\nBad trace plot\ny \u0026lt;- rnorm(1e4, mean = 1, sd = 2)\rm.E6Bad \u0026lt;- ulam(\ralist(\ry ~ dnorm(mu, sigma),\rmu \u0026lt;- a1 + a2,\ra1 ~ dnorm(0, 10),\ra2 ~ dnorm(0, 10),\rsigma ~ dcauchy(0, 1)\r),\rdata = list(y = y),\rchains = 2,\rcores = 2,\rstart = list(\ra1 = 0,\ra2 = 0,\rsigma = 1\r),\r)\rtraceplot(m.E6Bad)\r ## [1] 1000\r## [1] 1\r## [1] 1000\r This is a problem of unidentifiable parameters as a1 and a2 can cancel each other out to arrive at the correct mu and so we see non-stationary behaviour in the trace plots of a1 and a2 while the trace plot for sigma is doing alright.\nMedium Exercises Practice M1 Question: Re-estimate the terrain ruggedness model from the chapter, but now using a uniform prior and an exponential prior for the standard deviation, sigma. The uniform prior should be dunif(0,10) and the exponential should be dexp(1). Do the different priors have any detectable influence on the posterior distribution?\nAnswer: The ruggedness model in question is m8.3 in the book (or m9.1 in ulam() specification). First, I prepare the data like I did previously.\ndata(rugged)\rd \u0026lt;- rugged\rd$log_gdp \u0026lt;- log(d$rgdppc_2000)\rd \u0026lt;- d[complete.cases(d$rgdppc_2000), ]\rd$log_gdp_std \u0026lt;- d$log_gdp / mean(d$log_gdp)\rd$rugged_std \u0026lt;- d$rugged / max(d$rugged)\rd$cid \u0026lt;- ifelse(d$cont_africa == 1, 1, 2)\rdd.trim \u0026lt;- list(\rlog_gdp_std = d$log_gdp_std,\rrugged_std = d$rugged_std,\rcid = as.integer(d$cid)\r)\r Let\u0026rsquo;s fit that model with the different priors:\n## Exponential prior for sigma\rm.M1Exp \u0026lt;- ulam(\ralist(\rlog_gdp_std ~ dnorm(mu, sigma),\rmu \u0026lt;- a[cid] + b[cid] * (rugged_std - 0.215),\ra[cid] ~ dnorm(1, 0.1),\rb[cid] ~ dnorm(0, 0.3),\rsigma ~ dexp(1)\r),\rdata = dd.trim,\rchains = 4,\rcores = 4,\r)\r## Uniform prior for sigma\rm.M1Uni \u0026lt;- ulam(\ralist(\rlog_gdp_std ~ dnorm(mu, sigma),\rmu \u0026lt;- a[cid] + b[cid] * (rugged_std - 0.215),\ra[cid] ~ dnorm(1, 0.1),\rb[cid] ~ dnorm(0, 0.3),\rsigma ~ dnorm(0, 10)\r),\rdata = dd.trim,\rchains = 4,\rcores = 4,\r)\r Now on to inspect the model. Let\u0026rsquo;s start with the parameter estimates in comparison\ncoeftab(m.M1Exp, m.M1Uni)\r ## m.M1Exp m.M1Uni\r## a[1] 0.89 0.89\r## a[2] 1.05 1.05\r## b[1] 0.13 0.13\r## b[2] -0.14 -0.14\r## sigma 0.11 0.11\r## nobs 170 170\r These are strikingly the same. What about the individual model outputs in more detail?\nprecis(m.M1Exp, depth = 2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a[1] 0.8870817 0.015625699 0.86196179 0.91173540 2453.919 0.9995577\r## a[2] 1.0507770 0.009968219 1.03527611 1.06640703 2834.441 0.9988734\r## b[1] 0.1344067 0.074307822 0.01486287 0.25218389 2786.188 0.9993677\r## b[2] -0.1413442 0.054855132 -0.22964887 -0.05187494 2324.832 0.9983652\r## sigma 0.1117154 0.006171670 0.10228974 0.12208002 2725.266 0.9988256\r precis(m.M1Uni, depth = 2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a[1] 0.8865936 0.015580736 0.86128553 0.91082334 2489.074 0.9989360\r## a[2] 1.0501777 0.010010613 1.03404118 1.06614541 2152.883 1.0007549\r## b[1] 0.1312147 0.074609926 0.01239339 0.24998421 2244.528 0.9993558\r## b[2] -0.1420136 0.054996077 -0.22957192 -0.05372842 2023.621 0.9987402\r## sigma 0.1115782 0.006224722 0.10188964 0.12166315 3600.101 0.9990594\r Again, these are very similar aside from the effective number of samples (n_eff) which is much higher for all parameter estimates in the model with the exponential prior on sigma (m.M1Exp) except for sigma itself, which boasts a higher n_eff in the uniform-prior model (m.M1Uni). As such, we conclude that while the different priors have an impact on n_eff, they do not change the posterior distributions. Let me visualise this:\nPlot_df \u0026lt;- data.frame(\rPosteriors = c(\rextract.samples(m.M1Exp, n = 1e4)$sigma,\rextract.samples(m.M1Uni, n = 1e4)$sigma\r),\rName = rep(c(\u0026quot;Exp\u0026quot;, \u0026quot;Uni\u0026quot;), each = 1e4),\rModel = rep(c(\u0026quot;m.M1Exp\u0026quot;, \u0026quot;m.M1Uni\u0026quot;), each = 1e4)\r)\rggplot(Plot_df, aes(y = Model, x = Posteriors)) +\rstat_halfeye() +\rlabs(x = \u0026quot;Parameter Estimate\u0026quot;, y = \u0026quot;Model\u0026quot;) +\rtheme_bw()\r That really does look the same to me.\nPractice M2 Question: The Cauchy and exponential priors from the terrain ruggedness model are very weak. They can be made more informative by reducing their scale. Compare the dcauchy and dexp priors for progressively smaller values of the scaling parameter. As these priors become stronger, how does each influence the posterior distribution?\nAnswer: I write a for loop here to minimise code needs:\nRepTimes \u0026lt;- 4 # how many steps I want to try\rScalingFactor \u0026lt;- 10 # by what factor to make priors stronger\r# empty lists to store models in\rExplist \u0026lt;- as.list(rep(NA, RepTimes))\rCaulist \u0026lt;- as.list(rep(NA, RepTimes))\r# Loop over all models\rfor (Mod_Iter in 0:(RepTimes - 1)) {\rdd.trim$ScalingFactor \u0026lt;- ScalingFactor\rdd.trim$Mod_Iter \u0026lt;- Mod_Iter\r## Exponential prior for sigma\rm.M2Exp \u0026lt;- ulam(\ralist(\rlog_gdp_std ~ dnorm(mu, sigma),\rmu \u0026lt;- a[cid] + b[cid] * (rugged_std - 0.215),\ra[cid] ~ dnorm(1, 0.1),\rb[cid] ~ dnorm(0, 0.3),\rsigma ~ dexp(1 * ScalingFactor^Mod_Iter)\r),\rdata = dd.trim,\rchains = 4,\rcores = 4,\r)\rExplist[[Mod_Iter + 1]] \u0026lt;- m.M2Exp\r## Cauchy prior for sigma\rm.M2Cau \u0026lt;- ulam(\ralist(\rlog_gdp_std ~ dnorm(mu, sigma),\rmu \u0026lt;- a[cid] + b[cid] * (rugged_std - 0.215),\ra[cid] ~ dnorm(1, 0.1),\rb[cid] ~ dnorm(0, 0.3),\rsigma ~ dcauchy(0, 1 / ScalingFactor^Mod_Iter)\r),\rdata = dd.trim,\rchains = 4,\rcores = 4,\r)\rCaulist[[Mod_Iter + 1]] \u0026lt;- m.M2Cau\r}\rcoeftab(Explist[[1]], Explist[[2]], Explist[[3]], Explist[[4]])\r ## Explist[[1]] Explist[[2]] Explist[[3]] Explist[[4]]\r## a[1] 0.89 0.89 0.89 0.89 ## a[2] 1.05 1.05 1.05 1.05 ## b[1] 0.13 0.13 0.13 0.13 ## b[2] -0.14 -0.14 -0.14 -0.15 ## sigma 0.11 0.11 0.11 0.09 ## nobs 170 170 170 170\r coeftab(Caulist[[1]], Caulist[[2]], Caulist[[3]], Caulist[[4]])\r ## Caulist[[1]] Caulist[[2]] Caulist[[3]] Caulist[[4]]\r## a[1] 0.89 0.89 0.89 0.89 ## a[2] 1.05 1.05 1.05 1.05 ## b[1] 0.14 0.13 0.13 0.13 ## b[2] -0.14 -0.14 -0.14 -0.14 ## sigma 0.11 0.11 0.11 0.11 ## nobs 170 170 170 170\r The more restrictive exponential priors decrease the estimate for sigma. On the other hand, the more restrictive cauchy priors have no effect, it seems.\nLet\u0026rsquo;s explore why this is by looking at the priors themselves:\npar(mfrow = c(1, 2))\rcurve(dexp(x, 1),\rfrom = 0, to = 5, ylab = \u0026quot;Density\u0026quot;, xlab = \u0026quot;sigma\u0026quot;,\rcol = \u0026quot;royalblue4\u0026quot;\r)\rcurve(dexp(x, 10), from = 0, to = 5, add = T)\rcurve(dexp(x, 100), from = 0, to = 5, add = T, col = col.desat(\u0026quot;red\u0026quot;))\rcurve(dexp(x, 1000), from = 0, to = 5, add = T, col = col.desat(\u0026quot;green\u0026quot;))\rmtext(\u0026quot;Exponential Prior\u0026quot;)\rlegend(\u0026quot;topright\u0026quot;,\rcol = c(\u0026quot;royalblue4\u0026quot;, \u0026quot;black\u0026quot;, col.desat(\u0026quot;red\u0026quot;), col.desat(\u0026quot;green\u0026quot;)),\rlty = c(1, 1, 1), legend = c(\u0026quot;Exp(1)\u0026quot;, \u0026quot;Exp(10)\u0026quot;, \u0026quot;Exp(100)\u0026quot;, \u0026quot;Exp(1000)\u0026quot;), bty = \u0026quot;n\u0026quot;\r)\rcurve(2 * dcauchy(x, 0, 1),\rfrom = 0, to = 5, ylab = \u0026quot;Density\u0026quot;, xlab = \u0026quot;sigma\u0026quot;,\rcol = \u0026quot;royalblue4\u0026quot;\r)\rcurve(2 * dcauchy(x, 0, 0.1), from = 0, to = 5, add = T, col = \u0026quot;black\u0026quot;)\rcurve(2 * dcauchy(x, 0, 0.01), from = 0, to = 5, add = T, col = col.desat(\u0026quot;red\u0026quot;))\rcurve(2 * dcauchy(x, 0, 0.001), from = 0, to = 5, add = T, col = col.desat(\u0026quot;green\u0026quot;))\rmtext(\u0026quot;Cauchy Prior\u0026quot;)\rlegend(\u0026quot;topright\u0026quot;,\rcol = c(\u0026quot;royalblue4\u0026quot;, \u0026quot;black\u0026quot;, col.desat(\u0026quot;red\u0026quot;), col.desat(\u0026quot;green\u0026quot;)),\rlty = c(1, 1, 1), legend = c(\u0026quot;Cauchy(0, 1)\u0026quot;, \u0026quot;Cauchy(0, 0.1)\u0026quot;, \u0026quot;Cauchy(0, 0.01)\u0026quot;, \u0026quot;Cauchy(0, 0.001)\u0026quot;), bty = \u0026quot;n\u0026quot;\r)\r The cauchy distributions show thicker tails while the exponential distributions quickly concentrate. Hence why a concentrated Cauchy prior allow more flexibility that a concentrated exponential prior.\nPractice M3 Question: Re-estimate one of the Stan models from the chapter, but at different numbers of warmup iterations. Be sure to use the same number of sampling iterations in each case. Compare the n_eff values.\nAnswer: The ruggedness model was fine so far so I continue with that one. Here, I build this model with a fixed run length and fixed starting values for each run with changing warmup values:\nstart \u0026lt;- list(a = c(1, 1), b = c(0, 0), sigma = 1) # use fixed start values for comparability of runs\rm.M3 \u0026lt;- ulam(\ralist(\rlog_gdp_std ~ dnorm(mu, sigma),\rmu \u0026lt;- a[cid] + b[cid] * (rugged_std - 0.215),\ra[cid] ~ dnorm(1, 0.1),\rb[cid] ~ dnorm(0, 0.3),\rsigma ~ dexp(1)\r),\rdata = dd.trim,\rstart = start,\rchains = 2, cores = 2,\riter = 100\r)\rwarm_list \u0026lt;- c(5, 10, 100, 500, 1000) # define warmup values to run through\rn_eff \u0026lt;- matrix(NA, nrow = length(warm_list), ncol = 5) # first make matrix to hold n_eff results\rfor (i in 1:length(warm_list)) { # loop over warm_list and collect n_eff\rw \u0026lt;- warm_list[i]\rm_temp \u0026lt;- ulam(m.M3, chains = 2, cores = 2, iter = 1000 + w, warmup = w, start = start)\rn_eff[i, ] \u0026lt;- precis(m_temp, 2)$n_eff\r}\rcolnames(n_eff) \u0026lt;- rownames(precis(m_temp, 2))\rrownames(n_eff) \u0026lt;- warm_list\rn_eff # columns show parameters, rows show n_eff\r ## a[1] a[2] b[1] b[2] sigma\r## 5 2.314186 1.587251 2.713325 1.270369 1.776862\r## 10 2243.084776 2157.086156 737.957589 1010.214712 953.010860\r## 100 1725.334719 2294.576251 878.481785 1177.016946 1122.495229\r## 500 2999.738299 3282.963810 2292.173710 2737.037252 2200.949134\r## 1000 2485.029304 3406.341675 2372.274092 2772.175825 2607.552453\r As we can see, past just 10 warmup samples, n_eff does not change much (in terms of how useful our samples are). In this case, we could be quite happy with a warmup of 10.\nHard Exercises Practice H1 Question: Run the model below and then inspect the posterior distribution and explain what it is accomplishing.\nmp \u0026lt;- map2stan(\ralist(\ra ~ dnorm(0, 1),\rb ~ dcauchy(0, 1)\r),\rdata = list(y = 1),\rstart = list(a = 0, b = 0),\riter = 1e4,\rchains = 2, cores = 2,\rwarmup = 100,\rWAIC = FALSE\r)\r Compare the samples for the parameters a and b. Can you explain the different trace plots, using what you know about the Cauchy distribution?\nAnswer: First of all, let\u0026rsquo;s inspect the posterior:\nprecis(mp)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a 0.0003388167 0.9988213 -1.601441 1.590561 12762.761 1.000120\r## b -0.1918181852 13.8995715 -5.379742 5.346423 3892.011 1.000517\r Oof. Those uncertainties don\u0026rsquo;t look good at all! So what does the model even do? It simply just samples a from a normal distribution with mean 0 and standard deviation 1. b is sampled from a cauchy distribution. Let\u0026rsquo;s look at the traceplot for this:\nplot(mp, n_cols = 1, col = \u0026quot;royalblue4\u0026quot;)\r As we can see, there are quite some outliers in the sampling of the cauchy distribution (b). Why is that? Because the cauchy distribution has very heavy tails thus making it more likely to jump to a value that is far out there in terms of posterior probability. Note that this also decreases n_eff. lp in the above is the log-posterior.\nNow let\u0026rsquo;s see how the samples we drew measure up against the underlying functions of a and b, respectively:\npost \u0026lt;- extract.samples(mp)\rpar(mfrow = c(1, 2))\rdens(post$a)\rcurve(dnorm(x, 0, 1), from = -4, to = 4, add = T, lty = 2)\rlegend(\u0026quot;topright\u0026quot;, lty = c(1, 2), legend = c(\u0026quot;Sample\u0026quot;, \u0026quot;Exact density\u0026quot;), bty = \u0026quot;n\u0026quot;)\rmtext(\u0026quot;Normal\u0026quot;)\rdens(post$b, col = \u0026quot;royalblue4\u0026quot;, xlim = c(-10, 10))\rcurve(dcauchy(x, 0, 1),\rfrom = -10, to = 10, add = T, lty = 2,\rcol = \u0026quot;royalblue4\u0026quot;\r)\rmtext(\u0026quot;Cauchy\u0026quot;)\r As we can see, the normal distribution has been reconstructed well. The cauchy distributions hasn\u0026rsquo;t.\nPractice H2 Question: Recall the divorce rate example from Chapter 5. Repeat that analysis, using ulam() this time, fitting models m5.1, m5.2, and m5.3. Use compare to compare the models on the basis of WAIC or PSIS. Explain the results.\nAnswer: First, I need to load the data and prepare it for ulam():\ndata(WaffleDivorce)\rd \u0026lt;- WaffleDivorce\rd$D \u0026lt;- standardize(d$Divorce)\rd$M \u0026lt;- standardize(d$Marriage)\rd$A \u0026lt;- standardize(d$MedianAgeMarriage)\rd_trim \u0026lt;- list(D = d$D, M = d$M, A = d$A)\r Now I fit the models with ulam():\nm5.1_stan \u0026lt;- ulam(\ralist(\rD ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bA * A,\ra ~ dnorm(0, 0.2),\rbA ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d_trim,\rchains = 4, cores = 4,\rlog_lik = TRUE # this is needed to get the terms for calculating PSIS or WAIC\r)\rm5.2_stan \u0026lt;- ulam(\ralist(\rD ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bM * M,\ra ~ dnorm(0, 0.2),\rbM ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d_trim,\rchains = 4, cores = 4,\rlog_lik = TRUE # this is needed to get the terms for calculating PSIS or WAIC\r)\rm5.3_stan \u0026lt;- ulam(\ralist(\rD ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bA * A + bM * M,\ra ~ dnorm(0, 0.2),\rbA ~ dnorm(0, 0.5),\rbM ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = d_trim,\rchains = 4, cores = 4,\rlog_lik = TRUE # this is needed to get the terms for calculating PSIS or WAIC\r)\r Now we compare the models:\ncompare(m5.1_stan, m5.2_stan, m5.3_stan, func = PSIS)\r ## PSIS SE dPSIS dSE pPSIS weight\r## m5.1_stan 125.7210 12.708327 0.000000 NA 3.630705 0.7253039155\r## m5.3_stan 127.6690 12.852350 1.947996 0.6705316 4.773054 0.2738533387\r## m5.2_stan 139.2364 9.936093 13.515361 9.1363047 2.923975 0.0008427459\r compare(m5.1_stan, m5.2_stan, m5.3_stan, func = WAIC)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m5.1_stan 125.7778 12.641919 0.000000 NA 3.659072 0.6960655494\r## m5.3_stan 127.4407 12.591741 1.662916 0.6770545 4.658881 0.3030766321\r## m5.2_stan 139.1754 9.813604 13.397613 9.2109285 2.893468 0.0008578185\r WAIC tells a similar story as PSIS, but the model only containing age (m5.1_stan) wins. The model with both predictors (m5.3_stan) does almost as well. However, their respective PSIS and WAIC values are nearly identical. Furthermore, both models get assigned all of the WAIC weight. Let\u0026rsquo;s call these equal in performance and investigate why:\nprecis(m5.3_stan)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.0001904293 0.10140928 -0.1591984 0.1619373 1877.251 1.0002239\r## bA -0.6023698429 0.16025804 -0.8510854 -0.3467602 1085.019 1.0007578\r## bM -0.0550634908 0.16034205 -0.3109204 0.2015101 1187.780 0.9998155\r## sigma 0.8275838910 0.08826874 0.7028130 0.9779113 1474.265 1.0028212\r While m5.3_stan contains the marriage predictor, it is very unsure of it\u0026rsquo;s influence. In practical terms, this means that m5.1_stan and m5.3_stan make basically the same predictions\nPractice H3 Question: Sometimes changing a prior for one parameter has unanticipated effects on other parameters. This is because when a parameter is highly correlated with another parameter in the posterior, the prior influences both parameters. Here’s an example to work and think through.\nGo back to the leg length example in Chapter 5. Here is the code again, which simulates height and leg lengths for 100 imagined individuals:\nN \u0026lt;- 100 # number of individuals\rheight \u0026lt;- rnorm(N, 10, 2) # sim total height of each\rleg_prop \u0026lt;- runif(N, 0.4, 0.5) # leg as proportion of height\rleg_left \u0026lt;- leg_prop * height + rnorm(N, 0, 0.02) # sim left leg as proportion + error\rleg_right \u0026lt;- leg_prop * height + rnorm(N, 0, 0.02) # sim right leg as proportion + error\rd \u0026lt;- data.frame(height, leg_left, leg_right) # combine into data frame\r And below is the model you fit before, resulting in a highly correlated posterior for the two beta parameters. This time, fit the model using ulam():\nm5.8s \u0026lt;- ulam(\ralist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bl * leg_left + br * leg_right,\ra ~ dnorm(10, 100),\rbl ~ dnorm(2, 10),\rbr ~ dnorm(2, 10),\rsigma ~ dexp(1)\r),\rdata = d,\rchains = 4,\rcores = 4,\rstart = list(\ra = 10,\rbl = 0,\rbr = 0.1,\rsigma = 1\r)\r)\r Compare the posterior distribution produced by the code above to the posterior distribution produced when you change the prior for br so that it is strictly positive:\nm5.8s2 \u0026lt;- ulam(\ralist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bl * leg_left + br * leg_right,\ra ~ dnorm(10, 100),\rbl ~ dnorm(2, 10),\rbr ~ dnorm(2, 10),\rsigma ~ dexp(1)\r),\rdata = d,\rchains = 4,\rcores = 4,\rconstraints = list(br = \u0026quot;lower=0\u0026quot;),\rstart = list(\ra = 10,\rbl = 0,\rbr = 0.1,\rsigma = 1\r)\r)\r Note the constraints list. What this does is constrain the prior distribution of br so that it has positive probability only above zero. In other words, that prior ensures that the posterior distribution for br will have no probability mass below zero.\nCompare the two posterior distributions for m5.8s and m5.8s2. What has changed in the posterior distribution of both beta parameters? Can you explain the change induced by the change in prior?\nAnswer: It\u0026rsquo;s probably easiest to just look at the posterior distributions of the beta prameters through the pairs() function:\npairs(m5.8s, main = \u0026quot;Model 1\u0026quot;)\r pairs(m5.8s2, main = \u0026quot;Model 2\u0026quot;)\r As we can see, the beta distributions have shifted drastically between the different models. Interestingly, bl and br were perfectly symmetric in m5.8s, but are skewed in m5.8s2. Given how the height of a person is approximated in both models (a + bl*leg_left + br*leg_right), the distributions of leg lengths are necessarily negatively correlated (you can be of the same height with a short right leg and long left leg, long left leg and short right leg, or two medium-length legs). Thus, by setting br to be strictly positive in m5.8s2 and made it skewed, we have forced bl to be equally skewed in a mirror image of br.\nPractice H4 Question: For the two models fit in the previous problem, use WAIC or PSIS to compare the effective numbers of parameters for each model. You will need to use log_lik=TRUE to instruct ulam() to compute the terms that both WAIC and PSIS need. Which model has more effective parameters? Why?\nAnswer: Let\u0026rsquo;s run the models:\nm.H4_1 \u0026lt;- ulam(\ralist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bl * leg_left + br * leg_right,\ra ~ dnorm(10, 100),\rbl ~ dnorm(2, 10),\rbr ~ dnorm(2, 10),\rsigma ~ dexp(1)\r),\rdata = d,\rchains = 4,\rcores = 4,\rstart = list(\ra = 10,\rbl = 0,\rbr = 0.1,\rsigma = 1\r),\rlog_lik = TRUE\r)\rm.H4_2 \u0026lt;- ulam(\ralist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bl * leg_left + br * leg_right,\ra ~ dnorm(10, 100),\rbl ~ dnorm(2, 10),\rbr ~ dnorm(2, 10),\rsigma ~ dexp(1)\r),\rdata = d,\rchains = 4,\rcores = 4,\rconstraints = list(br = \u0026quot;lower=0\u0026quot;),\rstart = list(\ra = 10,\rbl = 0,\rbr = 0.1,\rsigma = 1\r),\rlog_lik = TRUE\r)\r Now we compare them with WAIC:\ncompare(m.H4_1, m.H4_2)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m.H4_1 182.1474 10.21060 0.0000000 NA 2.961292 0.6063273\r## m.H4_2 183.0112 9.88398 0.8638001 2.349502 2.382919 0.3936727\r The models are pretty much tied. The model with truncated priors (m.H4_2) is less flexible as indicated by pWAIC. This is because the prior is more informative and the variance in the posterior distribution is smaller as a result.\nPractice H5 Question: Modify the Metropolis algorithm code from the chapter to handle the case that the island populations have a different distribution than the island labels. This means the island’s number will not be the same as its population.\nAnswer: First of all, we need our 10 islands with population sizes of 1-10, but in random order:\npop_size \u0026lt;- sample(1:10)\r Now we can use the code from the chapter almost unaltered safe for one exception - we need to use indexing to translate island location into population size:\nnum_weeks \u0026lt;- 1e5\rpositions \u0026lt;- rep(NA, num_weeks)\rcurrent \u0026lt;- 10\rfor (i in 1:num_weeks) {\rpositions[i] \u0026lt;- current # record current position\rproposal \u0026lt;- current + sample(c(-1, 1), size = 1) # flip coin to generate proposal\r# now make sure he loops around the archipelago\rif (proposal \u0026lt; 1) proposal \u0026lt;- 10\rif (proposal \u0026gt; 10) proposal \u0026lt;- 1\rprob_move \u0026lt;- pop_size[proposal] / pop_size[current] # move?\rcurrent \u0026lt;- ifelse(runif(1) \u0026lt; prob_move, proposal, current)\r}\r To see if this works, we can plot population size against frequency of visit by the king:\nf \u0026lt;- table(positions) # compute frequencies\rplot(as.vector(f), pop_size,\rtype = \u0026quot;n\u0026quot;, # plot frequencies against relative population sizes\rxlab = \u0026quot;frequency\u0026quot;, ylab = \u0026quot;population size\u0026quot;\r) # empty plot\rtext(x = f, y = pop_size, labels = names(f)) # add names of islands / their positions\r Practice H6 Question: Modify the Metropolis algorithm code from the chapter to write your own simple MCMC estimator for globe tossing data and model from Chapter 2.\nAnswer: We want to fit the following model:\n$$w∼Binom(θ,n)$$ $$θ∼Unif(0,1)$$ Our Metropolis algorithm looks like this:\nset.seed(42)\r# the globe tossing data\rw \u0026lt;- 6\rn \u0026lt;- 9\r# prior on p\rp_prior \u0026lt;- function(p) dunif(p, min = 0, max = 1)\r# initializing MCMC\riter \u0026lt;- 1e4\rp_sample \u0026lt;- rep(0, iter)\rp_current \u0026lt;- 0.5 # start value\rfor (i in 1:iter) {\rp_sample[i] \u0026lt;- p_current # # record current p\rp_proposal \u0026lt;- runif(1, min = 0, max = 1) # generate proposal\r# compute likelihood for current and proposal\rlkhd_current \u0026lt;- dbinom(w, n, p_current)\rlkhd_proposal \u0026lt;- dbinom(w, n, p_proposal)\rprob_proposal \u0026lt;- lkhd_proposal * p_prior(p_proposal)\rprob_current \u0026lt;- lkhd_current * p_prior(p_current)\rprob_accept \u0026lt;- prob_proposal / prob_current\rp_current \u0026lt;- ifelse(runif(1) \u0026lt; prob_accept, p_proposal, p_current)\r}\r Let\u0026rsquo;s visualise what happened here:\nplot(p_sample, type = \u0026quot;l\u0026quot;, col = \u0026quot;royalblue4\u0026quot;)\r Finally, let\u0026rsquo;s plot the posterior distribution:\ndens(p_sample, col = \u0026quot;royalblue4\u0026quot;, adj = 1)\rcurve(dbeta(x, w + 1, n - w + 1), from = 0, to = 1, add = T, lty = 2)\rabline(v = median(p_sample))\r Session Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] tidybayes_2.3.1 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 tidyr_1.1.3 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 ## [10] V8_3.4.1 plyr_1.8.6 R6_2.5.0 backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 ## [19] pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 ## [28] labeling_0.4.2 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 ## [37] htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 arrayhelpers_1.1-0 codetools_0.2-18 matrixStats_0.61.0 fansi_0.4.2 ## [46] crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 distributional_0.2.2 ggdist_2.4.0 grid_4.0.5 jsonlite_1.7.2 ## [55] gtable_0.3.0 lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 KernSmooth_2.23-18 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 ## [64] farver_2.1.0 bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.7 rematch2_2.1.2 forcats_0.5.1 tools_4.0.5 svUnit_1.0.6 ## [73] R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1614211200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614279600,"objectID":"90169b82c4cb2faa3d61425d046a06c9","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-09/","publishdate":"2021-02-25T00:00:00Z","relpermalink":"/courses/rethinking/chapter-09/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 9 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 09","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some Lecture Slides  for this session.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"e2389571296766d127a48e04bc012d05","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/9_rmarkdown-manuscript-workflow-revisited/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/9_rmarkdown-manuscript-workflow-revisited/","section":"courses","summary":"I have prepared some Lecture Slides  for this session.","tags":null,"title":"RMarkdown - Manuscript Workflow Revisited","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our fourth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.\nI have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c()\rsapply(package_vec, install.load.package)\r ## list()\r As you can see, we don\u0026rsquo;t need any packages for our analyses in this practical.\nLoading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Mann-Whitney U Test We can analyse the significance of two population/sample medians of metric variables which are independent of one another using the wilcox.test() function in base R whilst specifying paired = FALSE.\nClimate Warming/Extremes Does morphology of Passer domesticus depend on climate?\nLogically, we\u0026rsquo;d expect morphological aspects of Passer domesticus to change given different frequencies and severities of climate extremes. Don\u0026rsquo;t forget, however, that our statistical procedures are usually built on the null hypothesis of no differences or correlations being present and so is the Mann-Whitney U Test.\nOur data set recorded three aspects of sparrow morphology and three climate levels (). Remember, however, that we set aside four stations (Siberia, United Kingdom, Reunion and Australia) to test climate effects on which are strictly limited to continental and coastal climate types. We need to exclude all other sites records from our data:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,]\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r Sparrow Weight Let\u0026rsquo;s start with the weight of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\n# Analysis\rwith(Data_df, wilcox.test(x = Weight[Climate == \u0026quot;Continental\u0026quot;], y = Weight[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Weight[Climate == \u0026quot;Continental\u0026quot;] and Weight[Climate != \u0026quot;Continental\u0026quot;]\r## W = 22104, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Weight[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Weight[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] TRUE\r Quite obviously, the weight of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $1.7179744\\times 10^{-32}$) and reject the null hypothesis. Weights of sparrows in continental climates are, on average, heavier than respective weights of their peers in coastal climates.\nSparrow Height # Analysis\rwith(Data_df, wilcox.test(x = Height[Climate == \u0026quot;Continental\u0026quot;], y = Height[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Height[Climate == \u0026quot;Continental\u0026quot;] and Height[Climate != \u0026quot;Continental\u0026quot;]\r## W = 11498, p-value = 0.1971\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Height[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Height[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] FALSE\r We conclude that the height of sparrows seems to not be dependent on the type of climate the individuals are suspected to (p = $0.1970959$) and accept the null hypothesis. Sparrows in continental climates are, on average, smaller than their peers in coastal climates but not to a statistically significant degree.\nSparrow Wing Chord # Analysis\rwith(Data_df, wilcox.test(x = Wing.Chord[Climate == \u0026quot;Continental\u0026quot;], y = Wing.Chord[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Wing.Chord[Climate == \u0026quot;Continental\u0026quot;] and Wing.Chord[Climate != \u0026quot;Continental\u0026quot;]\r## W = 10505, p-value = 0.01213\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Wing.Chord[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Wing.Chord[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] FALSE\r Apparently, the wing chord of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $0.0121264$) and reject the null hypothesis. Sparrows in continental climates have, generally speaking, shorter wings than their peers in coastal climates.\nPredation Does nesting height of nest sites of Passer domesticus depend on predator characteristics?\nIn our second practical (Nominal Tests), we used a Chi-Squared approach in a two-sample situation to identify whether predator presence and type had any influence over the nesting sites that individuals of Passer domesticus preferred. Our findings showed that they did and so we should expect similar results here when using Nesting Site as our response variable instead of Nesting Height as these two are highly related to each other.\nAdditionally, to save some space in these notes, I am not showing how to identify the direction of the effect via code any more for now. We may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Predator Presence First, we start with a possible link to predator presence and nesting height chosen by common house sparrows:\nwith(Data_df, wilcox.test(x = Nesting.Height[Predator.Presence == \u0026quot;Yes\u0026quot;], y = Nesting.Height[Predator.Presence != \u0026quot;Yes\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Nesting.Height[Predator.Presence == \u0026quot;Yes\u0026quot;] and Nesting.Height[Predator.Presence != \u0026quot;Yes\u0026quot;]\r## W = 25420, p-value = 0.0007678\r## alternative hypothesis: true location shift is not equal to 0\r ## [1] FALSE\r The nesting height of sparrows depends on whether a predator is present or not (p = $7.6777684\\times 10^{-4}$) thus rejecting the null hypothesis. Sparrows tend to go for nesting sites in more elevated positions when no predator is present.\nPredator Type Again, we might want to check whether the position of a given nest might be related to what kind of predator is present:\nwith(Data_df, wilcox.test(x = Nesting.Height[Predator.Type == \u0026quot;Avian\u0026quot;], y = Nesting.Height[Predator.Type != \u0026quot;Avian\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Nesting.Height[Predator.Type == \u0026quot;Avian\u0026quot;] and Nesting.Height[Predator.Type != \u0026quot;Avian\u0026quot;]\r## W = 5228, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true location shift is not equal to 0\r ## [1] FALSE\r We conclude that the nesting height of sparrows depends on what kind of predator is present (p = $7.4380407\\times 10^{-19}$) conclusively rejecting the null hypothesis. Therefore, we are confident in stating that sparrows tend to go for nesting sites in more elevated positions when non-avian predators are present.\nCompetition Do home ranges of Passer domesticus depend on climate?\nWe might expect different behaviour of Passer domesticus given different climate types. Since Home Range is on an ordinal scale () we can run a Mann-Whitney U Test on these whilst taking Climate into account as our predictor variable.\nTake note that we need to limit our analysis to our climate type testing sites again as follows:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,]\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r To be able to use the wilcox.test() function on Home Range, we need to transform its elements into a numeric type. Luckily, this is as easy as using the as.numeric() function on the data since it will assign every factor level a number corresponding to its position in levels() as follows:\nlevels(factor(Data_df$Home.Range))\r ## [1] \u0026quot;Large\u0026quot; \u0026quot;Medium\u0026quot; \u0026quot;Small\u0026quot;\r HR_vec \u0026lt;- as.numeric(factor((Data_df$Home.Range)))\r As you can see, the levels of Home.Range are ordered alphabetically. The as.numeric() command will thus transform every record of \u0026quot;Large\u0026quot; into 1, every record of \u0026quot;Medium\u0026quot; into 2 and every record of \u0026quot;Small\u0026quot; into 3.\nWe are ready to run the analysis:\n# Analysis\rwith(Data_df, wilcox.test(x = HR_vec[Climate == \u0026quot;Continental\u0026quot;], y = HR_vec[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: HR_vec[Climate == \u0026quot;Continental\u0026quot;] and HR_vec[Climate != \u0026quot;Continental\u0026quot;]\r## W = 11897, p-value = 0.3666\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(HR_vec[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(HR_vec[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] FALSE\r According to the output of our analysis, the home ranges of Passer domesticus do not depend on the climate characteristics of their respective habitats (p = $0.2766088$). Thus, we accept the null hypothesis.\nAs you can see, the median of numeric home ranges is smaller in continental climates (just not statistically significant). Remember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that climates force common house sparrows to adapt to bigger home ranges.\nSexual Dimorphism Does morphology of Passer domesticus depend on sex?\nIf we assume a sexual dimorphism to have manifested itself in Passer domesticus over evolutionary time, we\u0026rsquo;d expect different morphological features of males and females. In our second practical (Nominal Tests) we already assessed this using a Chi-Squared approach in a two-sample situation on colour morphs of the common house sparrows. At the time, we concluded that colouring is not equal for the sexes. So what about characteristics of our sparrows we can put into a meaningful order?\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Sparrow Weight We start by assessing the median weight of sparrows again, as driven by their sexes:\n# Analysis\rwith(Data_df, wilcox.test(x = Weight[Sex == \u0026quot;Male\u0026quot;], y = Weight[Sex != \u0026quot;Male\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Weight[Sex == \u0026quot;Male\u0026quot;] and Weight[Sex != \u0026quot;Male\u0026quot;]\r## W = 187772, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Weight[which(Data_df$Sex == \u0026quot;Male\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Weight[which(Data_df$Sex != \u0026quot;Male\u0026quot;)], na.rm = TRUE)\r ## [1] TRUE\r We already identified Climate to be a major driver of median sparrow weight within this practical. Now, we need to add Sex to the list of drivers of sparrow weight (p = $8.2580833\\times 10^{-20}$) and reject the null hypothesis that sparrow weights do not differ according to Sex. Males tend to be heavier than females.\nSparrow Height Let\u0026rsquo;s move on and see if the height/length of our observed sparrows are dependent on their sexes:\nwith(Data_df, wilcox.test(x = Height[Sex == \u0026quot;Male\u0026quot;], y = Height[Sex != \u0026quot;Male\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Height[Sex == \u0026quot;Male\u0026quot;] and Height[Sex != \u0026quot;Male\u0026quot;]\r## W = 141956, p-value = 0.9525\r## alternative hypothesis: true location shift is not equal to 0\r We already identified Climate to be a major driver of median sparrow height within this practical. Sparrow Sex does not seem to be an informative characteristic when trying to understand sparrow heights (p = $0.9524599$). So we accept the null hypothesis and don\u0026rsquo;t identify any direction of effects since there is no effect.\nSparrow Wing Chord with(Data_df, wilcox.test(x = Wing.Chord[Sex == \u0026quot;Male\u0026quot;], y = Wing.Chord[Sex != \u0026quot;Male\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Wing.Chord[Sex == \u0026quot;Male\u0026quot;] and Wing.Chord[Sex != \u0026quot;Male\u0026quot;]\r## W = 141637, p-value = 0.9021\r## alternative hypothesis: true location shift is not equal to 0\r According to our previous analysis within this practical, Climate has been determined to be a major driver wing chords of common house sparrows. With our current analysis in mind, we can conclude that the Sex of any given Passer domesticus individual does not influence the wing chord of said individual (p = $0.9020933$). Therefore we accept the null hypothesis and don\u0026rsquo;t identify any direction of effects since there is no effect.\nWilcoxon Signed Rank Test We can analyse the significance of two population/sample medians of metric variables which are dependent of one another using the wilcox.test() function in base R whilst specifying paired = TRUE.\nPreparing Data Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.\nConclusively, we need an additional data set with truly paired records of sparrows. Within our study set-up, think of a resettling experiment, were you take Passer domesticus individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.\nTo this end, presume we have taken the entire Passer domesticus population found at our Siberian research station and moved them to the United Kingdom. Whilst this keeps the latitude stable, the sparrows now experience a coastal climate instead of a continental one. After some time (let\u0026rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.\nYou will find the corresponding new data in 2b - Sparrow_ResettledSIUK_READY.rds. Take note that this set only contains records for the transferred individuals in the same order as in the old data set.\nData_df_Resettled \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2b - Sparrow_ResettledSIUK_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\r With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their plasticity.\nClimate Warming/Extremes Does morphology of Passer domesticus depend on climate?\nWe have already concluded that the overall morphological aspects of populations of Passer domesticus are shaped by climate, but what happens if we take birds from one climate and resettle them to another climate?\nSparrow Weight First, let\u0026rsquo;s see how the average weight of our individual sparrows changed a year after they were relocated from Siberia to the UK:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Weight, y = Data_df_Resettled$Weight, paired = TRUE))\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: Weight and Data_df_Resettled$Weight\r## V = 2044, p-value = 2.073e-09\r## alternative hypothesis: true location shift is not equal to 0\r Apparently, the weight of the individual sparrows have significantly changed following their relocation (p = $2.0725016\\times 10^{-9}$) and we reject the null hypothesis.\nEarlier, we identified sparrows to be heavier in continental climates when compared to coastal climates - does this sentiment hold true with relocated birds?\n# Direction of effect\rmedian(Data_df$Weight[which(Data_df$Index == \u0026quot;SI\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df_Resettled$Weight, na.rm = TRUE)\r ## [1] TRUE\r Yes, it does. The resettled birds have reduced their median weight (probably not a conscious decision on behalf of the sparrows).\nSparrow Height Secondly, have our relocated sparrows become taller or shorter?\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Height, y = Data_df_Resettled$Height, paired = TRUE))\r ## Warning in wilcox.test.default(x = Height, y = Data_df_Resettled$Height, :\r## cannot compute exact p-value with zeroes\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: Height and Data_df_Resettled$Height\r## V = 0, p-value = NA\r## alternative hypothesis: true location shift is not equal to 0\r Interestingly enough, we do not receive either meaningful W (V) statistic nor an informative p-value (NA).\nThis could only be due to one reason:\nunique(Data_df$Height[which(Data_df$Index == \u0026quot;SI\u0026quot;)] == Data_df_Resettled$Height)\r ## [1] TRUE\r Our sparrows have not become any shorter or taller! In fact, no height/length record has changed for any of the sparrows we relocated. This may usually be indicative of a data handling error but, in this case, makes a lot of sense when considering how difficult it may be for mature individuals to change in size.\nSparrow Wing Chord Third, let\u0026rsquo;s check whether wing chords have changed across the board. We can expect them to behave just like height records did:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Wing.Chord, y = Data_df_Resettled$Wing.Chord, paired = TRUE))\r ## Warning in wilcox.test.default(x = Wing.Chord, y =\r## Data_df_Resettled$Wing.Chord, : cannot compute exact p-value with zeroes\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: Wing.Chord and Data_df_Resettled$Wing.Chord\r## V = 0, p-value = NA\r## alternative hypothesis: true location shift is not equal to 0\r unique(Data_df$Wing.Chord[which(Data_df$Index == \u0026quot;SI\u0026quot;)] == Data_df_Resettled$Wing.Chord)\r ## [1] TRUE\r Indeed, none of the wing chord records have changed.\nPredation Does nesting height of nest sites of Passer domesticus depend on predator characteristics?\nWe have already identified predator characteristics at our sites to be influential in the overall nesting site and height of Passer domesticus. Does this trend hold true when considering a relocation experiment?\nFirstly, we will test whether nesting heights have changed after the relocation. Before we do so, we should first check whether we\u0026rsquo;d expect a change based on whether predator presence is different between Siberia and the UK:\nPP_Sib \u0026lt;- unique(Data_df$Predator.Presence[which(Data_df$Index == \u0026quot;SI\u0026quot;)])\rPP_UK \u0026lt;- unique(Data_df_Resettled$Predator.Presence)\rPP_Sib == PP_UK\r ## [1] TRUE\r Apparently, predators are present at both of these sites and so we would not expect a significant change in nesting height. Let\u0026rsquo;s check this:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Nesting.Height, y = Data_df_Resettled$Nesting.Height, paired = TRUE))\r ## ## Wilcoxon signed rank exact test\r## ## data: Nesting.Height and Data_df_Resettled$Nesting.Height\r## V = 65, p-value = 7.404e-05\r## alternative hypothesis: true location shift is not equal to 0\r There actually is an effect after the resettling! Therefore, we have to reject the null hypothesis (p = $7.4040145\\times 10^{-5}$)! How can this be?\nMaybe it has to do with the kind of predator at each site:\nunique(Data_df$Predator.Type[which(Data_df$Index == \u0026quot;SI\u0026quot;)])\r ## [1] Avian\r## Levels: Avian Non-Avian\r unique(Data_df_Resettled$Predator.Type)\r ## [1] Non-Avian\r## Levels: Avian Non-Avian\r As you can see, Siberian sparrows are subject to avian predation whilst the sparrow populations that we monitored in the UK are experiencing non-avian predator presence. A causal link between nesting height and predator type seems to be logical!\nWhich direction is the effect headed? Earlier within this practical, we hypothesized that avian predation forces lower nesting heights in Passer domesticus - does this hold true?\nNH_Sib \u0026lt;- mean(Data_df$Nesting.Height[which(Data_df$Index == \u0026quot;SI\u0026quot;)], na.rm = TRUE) NH_UK \u0026lt;- mean(Data_df_Resettled$Nesting.Height, na.rm = TRUE)\rNH_Sib \u0026lt; NH_UK\r ## [1] TRUE\r Yes, it does!\nCompetition Do home ranges of Passer domesticus depend on climate?\nEarlier in this practical, we have shown that home ranges of flocks of Passer domesticus are affected by the climate conditions they are experiencing. Let\u0026rsquo;s see if our relocated sparrows have altered their behaviour:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = as.numeric(factor(Home.Range)), y = as.numeric(factor(Data_df_Resettled$Home.Range)), paired = TRUE))\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: as.numeric(factor(Home.Range)) and as.numeric(factor(Data_df_Resettled$Home.Range))\r## V = 348.5, p-value = 0.002891\r## alternative hypothesis: true location shift is not equal to 0\r ## [1] 0.002890788\r However, they haven\u0026rsquo;t! Given the p-value of 7.4040145\\times 10^{-5}, we accept the null hypothesis and conclude that home ranges of our flocks of sparrows have not changed significantly after the relocation to the UK.\nDue to our earlier analysis, we would expect smaller home ranges of sparrows in the UK when compared to their previous home ranges in Siberia. Before testing this, remember that, when converted to numeric records, low values indicate larger home ranges:\nHR_Sib \u0026lt;- as.numeric(Data_df$Home.Range[which(Data_df$Index == \u0026quot;SI\u0026quot;)])\r ## Warning: NAs introduced by coercion\r HR_UK \u0026lt;- as.numeric(Data_df_Resettled$Home.Range)\rmedian(HR_Sib, na.rm = TRUE) \u0026lt; median(HR_UK, na.rm = TRUE)\r ## [1] NA\r We were right! The assignment of home ranges did shift to accommodate smaller home ranges in the coastal climate of the UK it is just not intense enough for statistical significance - this will be further evaluated in our next seminar.\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"ff74d0240100d520ed2cfdda8774082b","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/ordinal-metric-tests-two-sample-situations/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/ordinal-metric-tests-two-sample-situations/","section":"courses","summary":"Welcome to our fourth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.","tags":["R","Statistics"],"title":"Ordinal \u0026 Metric Tests (Two-Sample Situations)","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our fourth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise. I have prepared some slides for this session: \nData Find the data for this exercise here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c()\rsapply(package_vec, install.load.package)\r ## list()\r As you can see, we don\u0026rsquo;t need any packages for our analyses in this practical.\nLoading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Mann-Whitney U Test We can analyse the significance of two population/sample medians of metric variables which are independent of one another using the wilcox.test() function in base R whilst specifying paired = FALSE.\nClimate Warming/Extremes Does morphology of Passer domesticus depend on climate?\nLogically, we\u0026rsquo;d expect morphological aspects of Passer domesticus to change given different frequencies and severities of climate extremes. Don\u0026rsquo;t forget, however, that our statistical procedures are usually built on the null hypothesis of no differences or correlations being present and so is the Mann-Whitney U Test.\nOur data set recorded three aspects of sparrow morphology and three climate levels (). Remember, however, that we set aside four stations (Siberia, United Kingdom, Reunion and Australia) to test climate effects on which are strictly limited to continental and coastal climate types. We need to exclude all other sites records from our data:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,]\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r Sparrow Weight Let\u0026rsquo;s start with the weight of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\n# Analysis\rwith(Data_df, wilcox.test(x = Weight[Climate == \u0026quot;Continental\u0026quot;], y = Weight[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Weight[Climate == \u0026quot;Continental\u0026quot;] and Weight[Climate != \u0026quot;Continental\u0026quot;]\r## W = 22104, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Weight[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Weight[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] TRUE\r Quite obviously, the weight of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $1.7179744\\times 10^{-32}$) and reject the null hypothesis. Weights of sparrows in continental climates are, on average, heavier than respective weights of their peers in coastal climates.\nSparrow Height # Analysis\rwith(Data_df, wilcox.test(x = Height[Climate == \u0026quot;Continental\u0026quot;], y = Height[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Height[Climate == \u0026quot;Continental\u0026quot;] and Height[Climate != \u0026quot;Continental\u0026quot;]\r## W = 11498, p-value = 0.1971\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Height[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Height[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] FALSE\r We conclude that the height of sparrows seems to not be dependent on the type of climate the individuals are suspected to (p = $0.1970959$) and accept the null hypothesis. Sparrows in continental climates are, on average, smaller than their peers in coastal climates but not to a statistically significant degree.\nSparrow Wing Chord # Analysis\rwith(Data_df, wilcox.test(x = Wing.Chord[Climate == \u0026quot;Continental\u0026quot;], y = Wing.Chord[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Wing.Chord[Climate == \u0026quot;Continental\u0026quot;] and Wing.Chord[Climate != \u0026quot;Continental\u0026quot;]\r## W = 10505, p-value = 0.01213\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Wing.Chord[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Wing.Chord[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] FALSE\r Apparently, the wing chord of sparrows seems to be dependent on the type of climate the individuals are suspected to (p = $0.0121264$) and reject the null hypothesis. Sparrows in continental climates have, generally speaking, shorter wings than their peers in coastal climates.\nPredation Does nesting height of nest sites of Passer domesticus depend on predator characteristics?\nIn our second practical (Nominal Tests), we used a Chi-Squared approach in a two-sample situation to identify whether predator presence and type had any influence over the nesting sites that individuals of Passer domesticus preferred. Our findings showed that they did and so we should expect similar results here when using Nesting Site as our response variable instead of Nesting Height as these two are highly related to each other.\nAdditionally, to save some space in these notes, I am not showing how to identify the direction of the effect via code any more for now. We may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Predator Presence First, we start with a possible link to predator presence and nesting height chosen by common house sparrows:\nwith(Data_df, wilcox.test(x = Nesting.Height[Predator.Presence == \u0026quot;Yes\u0026quot;], y = Nesting.Height[Predator.Presence != \u0026quot;Yes\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Nesting.Height[Predator.Presence == \u0026quot;Yes\u0026quot;] and Nesting.Height[Predator.Presence != \u0026quot;Yes\u0026quot;]\r## W = 25420, p-value = 0.0007678\r## alternative hypothesis: true location shift is not equal to 0\r ## [1] FALSE\r The nesting height of sparrows depends on whether a predator is present or not (p = $7.6777684\\times 10^{-4}$) thus rejecting the null hypothesis. Sparrows tend to go for nesting sites in more elevated positions when no predator is present.\nPredator Type Again, we might want to check whether the position of a given nest might be related to what kind of predator is present:\nwith(Data_df, wilcox.test(x = Nesting.Height[Predator.Type == \u0026quot;Avian\u0026quot;], y = Nesting.Height[Predator.Type != \u0026quot;Avian\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Nesting.Height[Predator.Type == \u0026quot;Avian\u0026quot;] and Nesting.Height[Predator.Type != \u0026quot;Avian\u0026quot;]\r## W = 5228, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true location shift is not equal to 0\r ## [1] FALSE\r We conclude that the nesting height of sparrows depends on what kind of predator is present (p = $7.4380407\\times 10^{-19}$) conclusively rejecting the null hypothesis. Therefore, we are confident in stating that sparrows tend to go for nesting sites in more elevated positions when non-avian predators are present.\nCompetition Do home ranges of Passer domesticus depend on climate?\nWe might expect different behaviour of Passer domesticus given different climate types. Since Home Range is on an ordinal scale () we can run a Mann-Whitney U Test on these whilst taking Climate into account as our predictor variable.\nTake note that we need to limit our analysis to our climate type testing sites again as follows:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; )\rData_df \u0026lt;- Data_df[Rows,]\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r To be able to use the wilcox.test() function on Home Range, we need to transform its elements into a numeric type. Luckily, this is as easy as using the as.numeric() function on the data since it will assign every factor level a number corresponding to its position in levels() as follows:\nlevels(factor(Data_df$Home.Range))\r ## [1] \u0026quot;Large\u0026quot; \u0026quot;Medium\u0026quot; \u0026quot;Small\u0026quot;\r HR_vec \u0026lt;- as.numeric(factor((Data_df$Home.Range)))\r As you can see, the levels of Home.Range are ordered alphabetically. The as.numeric() command will thus transform every record of \u0026quot;Large\u0026quot; into 1, every record of \u0026quot;Medium\u0026quot; into 2 and every record of \u0026quot;Small\u0026quot; into 3.\nWe are ready to run the analysis:\n# Analysis\rwith(Data_df, wilcox.test(x = HR_vec[Climate == \u0026quot;Continental\u0026quot;], y = HR_vec[Climate != \u0026quot;Continental\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: HR_vec[Climate == \u0026quot;Continental\u0026quot;] and HR_vec[Climate != \u0026quot;Continental\u0026quot;]\r## W = 11897, p-value = 0.3666\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(HR_vec[which(Data_df$Climate == \u0026quot;Continental\u0026quot;)], na.rm = TRUE) \u0026gt; median(HR_vec[which(Data_df$Climate != \u0026quot;Continental\u0026quot;)], na.rm = TRUE)\r ## [1] FALSE\r According to the output of our analysis, the home ranges of Passer domesticus do not depend on the climate characteristics of their respective habitats (p = $0.2766088$). Thus, we accept the null hypothesis.\nAs you can see, the median of numeric home ranges is smaller in continental climates (just not statistically significant). Remember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that climates force common house sparrows to adapt to bigger home ranges.\nSexual Dimorphism Does morphology of Passer domesticus depend on sex?\nIf we assume a sexual dimorphism to have manifested itself in Passer domesticus over evolutionary time, we\u0026rsquo;d expect different morphological features of males and females. In our second practical (Nominal Tests) we already assessed this using a Chi-Squared approach in a two-sample situation on colour morphs of the common house sparrows. At the time, we concluded that colouring is not equal for the sexes. So what about characteristics of our sparrows we can put into a meaningful order?\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Sparrow Weight We start by assessing the median weight of sparrows again, as driven by their sexes:\n# Analysis\rwith(Data_df, wilcox.test(x = Weight[Sex == \u0026quot;Male\u0026quot;], y = Weight[Sex != \u0026quot;Male\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Weight[Sex == \u0026quot;Male\u0026quot;] and Weight[Sex != \u0026quot;Male\u0026quot;]\r## W = 187772, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true location shift is not equal to 0\r # Direction of effect\rmedian(Data_df$Weight[which(Data_df$Sex == \u0026quot;Male\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df$Weight[which(Data_df$Sex != \u0026quot;Male\u0026quot;)], na.rm = TRUE)\r ## [1] TRUE\r We already identified Climate to be a major driver of median sparrow weight within this practical. Now, we need to add Sex to the list of drivers of sparrow weight (p = $8.2580833\\times 10^{-20}$) and reject the null hypothesis that sparrow weights do not differ according to Sex. Males tend to be heavier than females.\nSparrow Height Let\u0026rsquo;s move on and see if the height/length of our observed sparrows are dependent on their sexes:\nwith(Data_df, wilcox.test(x = Height[Sex == \u0026quot;Male\u0026quot;], y = Height[Sex != \u0026quot;Male\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Height[Sex == \u0026quot;Male\u0026quot;] and Height[Sex != \u0026quot;Male\u0026quot;]\r## W = 141956, p-value = 0.9525\r## alternative hypothesis: true location shift is not equal to 0\r We already identified Climate to be a major driver of median sparrow height within this practical. Sparrow Sex does not seem to be an informative characteristic when trying to understand sparrow heights (p = $0.9524599$). So we accept the null hypothesis and don\u0026rsquo;t identify any direction of effects since there is no effect.\nSparrow Wing Chord with(Data_df, wilcox.test(x = Wing.Chord[Sex == \u0026quot;Male\u0026quot;], y = Wing.Chord[Sex != \u0026quot;Male\u0026quot;], paired = FALSE)\r)\r ## ## Wilcoxon rank sum test with continuity correction\r## ## data: Wing.Chord[Sex == \u0026quot;Male\u0026quot;] and Wing.Chord[Sex != \u0026quot;Male\u0026quot;]\r## W = 141636, p-value = 0.9021\r## alternative hypothesis: true location shift is not equal to 0\r According to our previous analysis within this practical, Climate has been determined to be a major driver wing chords of common house sparrows. With our current analysis in mind, we can conclude that the Sex of any given Passer domesticus individual does not influence the wing chord of said individual (p = $0.9020933$). Therefore we accept the null hypothesis and don\u0026rsquo;t identify any direction of effects since there is no effect.\nWilcoxon Signed Rank Test We can analyse the significance of two population/sample medians of metric variables which are dependent of one another using the wilcox.test() function in base R whilst specifying paired = TRUE.\nPreparing Data Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.\nConclusively, we need an additional data set with truly paired records of sparrows. Within our study set-up, think of a resettling experiment, were you take Passer domesticus individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.\nTo this end, presume we have taken the entire Passer domesticus population found at our Siberian research station and moved them to the United Kingdom. Whilst this keeps the latitude stable, the sparrows now experience a coastal climate instead of a continental one. After some time (let\u0026rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.\nYou will find the corresponding new data in 2b - Sparrow_ResettledSIUK_READY.rds. Take note that this set only contains records for the transferred individuals in the same order as in the old data set.\nData_df_Resettled \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2b - Sparrow_ResettledSIUK_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\r With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their plasticity.\nClimate Warming/Extremes Does morphology of Passer domesticus depend on climate?\nWe have already concluded that the overall morphological aspects of populations of Passer domesticus are shaped by climate, but what happens if we take birds from one climate and resettle them to another climate?\nSparrow Weight First, let\u0026rsquo;s see how the average weight of our individual sparrows changed a year after they were relocated from Siberia to the UK:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Weight, y = Data_df_Resettled$Weight, paired = TRUE))\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: Weight and Data_df_Resettled$Weight\r## V = 2044, p-value = 2.073e-09\r## alternative hypothesis: true location shift is not equal to 0\r Apparently, the weight of the individual sparrows have significantly changed following their relocation (p = $2.0725016\\times 10^{-9}$) and we reject the null hypothesis.\nEarlier, we identified sparrows to be heavier in continental climates when compared to coastal climates - does this sentiment hold true with relocated birds?\n# Direction of effect\rmedian(Data_df$Weight[which(Data_df$Index == \u0026quot;SI\u0026quot;)], na.rm = TRUE) \u0026gt; median(Data_df_Resettled$Weight, na.rm = TRUE)\r ## [1] TRUE\r Yes, it does. The resettled birds have reduced their median weight (probably not a conscious decision on behalf of the sparrows).\nSparrow Height Secondly, have our relocated sparrows become taller or shorter?\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Height, y = Data_df_Resettled$Height, paired = TRUE))\r ## Warning in wilcox.test.default(x = Height, y = Data_df_Resettled$Height, :\r## cannot compute exact p-value with zeroes\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: Height and Data_df_Resettled$Height\r## V = 0, p-value = NA\r## alternative hypothesis: true location shift is not equal to 0\r Interestingly enough, we do not receive either meaningful W (V) statistic nor an informative p-value (NA).\nThis could only be due to one reason:\nunique(Data_df$Height[which(Data_df$Index == \u0026quot;SI\u0026quot;)] == Data_df_Resettled$Height)\r ## [1] TRUE\r Our sparrows have not become any shorter or taller! In fact, no height/length record has changed for any of the sparrows we relocated. This may usually be indicative of a data handling error but, in this case, makes a lot of sense when considering how difficult it may be for mature individuals to change in size.\nSparrow Wing Chord Third, let\u0026rsquo;s check whether wing chords have changed across the board. We can expect them to behave just like height records did:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Wing.Chord, y = Data_df_Resettled$Wing.Chord, paired = TRUE))\r ## Warning in wilcox.test.default(x = Wing.Chord, y =\r## Data_df_Resettled$Wing.Chord, : cannot compute exact p-value with zeroes\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: Wing.Chord and Data_df_Resettled$Wing.Chord\r## V = 0, p-value = NA\r## alternative hypothesis: true location shift is not equal to 0\r unique(Data_df$Wing.Chord[which(Data_df$Index == \u0026quot;SI\u0026quot;)] == Data_df_Resettled$Wing.Chord)\r ## [1] TRUE\r Indeed, none of the wing chord records have changed.\nPredation Does nesting height of nest sites of Passer domesticus depend on predator characteristics?\nWe have already identified predator characteristics at our sites to be influential in the overall nesting site and height of Passer domesticus. Does this trend hold true when considering a relocation experiment?\nFirstly, we will test whether nesting heights have changed after the relocation. Before we do so, we should first check whether we\u0026rsquo;d expect a change based on whether predator presence is different between Siberia and the UK:\nPP_Sib \u0026lt;- unique(Data_df$Predator.Presence[which(Data_df$Index == \u0026quot;SI\u0026quot;)])\rPP_UK \u0026lt;- unique(Data_df_Resettled$Predator.Presence)\rPP_Sib == PP_UK\r ## [1] TRUE\r Apparently, predators are present at both of these sites and so we would not expect a significant change in nesting height. Let\u0026rsquo;s check this:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = Nesting.Height, y = Data_df_Resettled$Nesting.Height, paired = TRUE))\r ## ## Wilcoxon signed rank exact test\r## ## data: Nesting.Height and Data_df_Resettled$Nesting.Height\r## V = 65, p-value = 7.404e-05\r## alternative hypothesis: true location shift is not equal to 0\r There actually is an effect after the resettling! Therefore, we have to reject the null hypothesis (p = $7.4040145\\times 10^{-5}$)! How can this be?\nMaybe it has to do with the kind of predator at each site:\nunique(Data_df$Predator.Type[which(Data_df$Index == \u0026quot;SI\u0026quot;)])\r ## [1] Avian\r## Levels: Avian Non-Avian\r unique(Data_df_Resettled$Predator.Type)\r ## [1] Non-Avian\r## Levels: Avian Non-Avian\r As you can see, Siberian sparrows are subject to avian predation whilst the sparrow populations that we monitored in the UK are experiencing non-avian predator presence. A causal link between nesting height and predator type seems to be logical!\nWhich direction is the effect headed? Earlier within this practical, we hypothesized that avian predation forces lower nesting heights in Passer domesticus - does this hold true?\nNH_Sib \u0026lt;- mean(Data_df$Nesting.Height[which(Data_df$Index == \u0026quot;SI\u0026quot;)], na.rm = TRUE) NH_UK \u0026lt;- mean(Data_df_Resettled$Nesting.Height, na.rm = TRUE)\rNH_Sib \u0026lt; NH_UK\r ## [1] TRUE\r Yes, it does!\nCompetition Do home ranges of Passer domesticus depend on climate?\nEarlier in this practical, we have shown that home ranges of flocks of Passer domesticus are affected by the climate conditions they are experiencing. Let\u0026rsquo;s see if our relocated sparrows have altered their behaviour:\nwith(Data_df[which(Data_df$Index == \u0026quot;SI\u0026quot;),], wilcox.test(x = as.numeric(factor(Home.Range)), y = as.numeric(factor(Data_df_Resettled$Home.Range)), paired = TRUE))\r ## ## Wilcoxon signed rank test with continuity correction\r## ## data: as.numeric(factor(Home.Range)) and as.numeric(factor(Data_df_Resettled$Home.Range))\r## V = 348.5, p-value = 0.002891\r## alternative hypothesis: true location shift is not equal to 0\r ## [1] 0.002890788\r However, they haven\u0026rsquo;t! Given the p-value of 7.4040145\\times 10^{-5}, we accept the null hypothesis and conclude that home ranges of our flocks of sparrows have not changed significantly after the relocation to the UK.\nDue to our earlier analysis, we would expect smaller home ranges of sparrows in the UK when compared to their previous home ranges in Siberia. Before testing this, remember that, when converted to numeric records, low values indicate larger home ranges:\nHR_Sib \u0026lt;- as.numeric(Data_df$Home.Range[which(Data_df$Index == \u0026quot;SI\u0026quot;)])\r ## Warning: NAs introduced by coercion\r HR_UK \u0026lt;- as.numeric(Data_df_Resettled$Home.Range)\rmedian(HR_Sib, na.rm = TRUE) \u0026lt; median(HR_UK, na.rm = TRUE)\r ## [1] NA\r We were right! The assignment of home ranges did shift to accommodate smaller home ranges in the coastal climate of the UK it is just not intense enough for statistical significance - this will be further evaluated in our next seminar.\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"4eaab397e07e5c32a32d925e1cfeef7f","permalink":"https://www.erikkusch.com/courses/biostat101/ordinal-metric-tests-two-sample-situations/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/ordinal-metric-tests-two-sample-situations/","section":"courses","summary":"Welcome to our fourth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.","tags":["R","Statistics"],"title":"Ordinal \u0026 Metric Tests (Two-Sample Situations)","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"God Spiked The Integers Material  \rSlides Chapter 10 \rSlides Chapter 11  Introduction These are answers and solutions to the exercises at the end of chapter 11 in Satistical Rethinking 2 by Richard McElreath. For anyone reading through these in order and wondering why I skipped chapter 10: chapter 10 did not contain any exercises (to my dismay, as you can imagine). I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from Taras Svirskyi, William Wolf, and Corrie Bartelheimer as well as the solutions provided to instructors by Richard McElreath himself.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(rstan)\rlibrary(ggplot2)\rlibrary(tidybayes)\r Easy Exercises Practice E1 Question: If an event has probability 0.35, what are the log-odds of this event?\nAnswer: When $p = 0.35$ then the log-odds are $log\\frac{0.35}{1-0.35}$, or in R:\nlog(0.35 / (1 - 0.35))\r ## [1] -0.6190392\r Practice E2 Question: If an event has log-odds 3.2, what is the probability of this event?\nAnswer: To transform log-odds into probability space, we want to use the inv_logit() function:\ninv_logit(3.2)\r ## [1] 0.9608343\r Practice E3 Question: Suppose that a coefficient in a logistic regression has value 1.7. What does this imply about the proportional change in odds of the outcome?\nAnswer:\nexp(1.7)\r ## [1] 5.473947\r Each one-unit increase in the predictor linked to this coefficient results in a multiplication of the odds of the event occurring by 5.47.\nThe linear model behind the logistic regression simply represents the log-odds of an event happening. The odds of the events happening can thus be shown as $exp(odds)$. Comparing how the odds change when increasing the predictor variable by one unit comes down to solving this equation then:\n$$exp(α + βx)Z = exp(α + β(x + 1))$$ Solving this for $z$ results in:\n$$z = exp(\\beta)$$\nwhich is how we derived the answer to this question.\nPractice E4 Question: Why do Poisson regressions sometimes require the use of an offset? Provide an example.\nAnswer: When study regimes aren\u0026rsquo;t rigidly standardised, we may end up with count data collected over different time/distance intervals. Comparing these data without accounting for the difference in the underlying sampling frequency will inevitably lead to horribly inadequate predictions of our model(s).\nAs an example, think of how many ants leave a hive in a certain interval. If we recorded numbers of ants leaving to forage on a minute-by-minute basis, we would obtain much smaller counts than if our sampling regime dictated hourly observation periods. Any poisson model we want to run between differing sampling regimes has to account for the heterogeneity in the observation period lengths. We do so as follows:\n$$Ants_i∼Poisson(λ)$$ $$log(λ)=log(period_i)+α+βHive_i$$\nMedium Exercises Practice M1 Question: As explained in the chapter, binomial data can be organized in aggregated and disaggregated forms, without any impact on inference. But the likelihood of the data does change when the data are converted between the two formats. Can you explain why?\nAnswer: Think back to the Card Drawing Example from chapter 2. We know a certain outcome. Let\u0026rsquo;s assume two black face, and one white face card are drawn.\nIn the aggregated form of the data, we obtain the probability of our observation as $3p(1-p)$ (a binomial distribution with $3$ trials and a rate of black face cards of $p = \\frac{2}{3}$). This tells us how many ways there are to get two black-face cards out of three pulls of cards. The order is irrelevant.\nWith disaggregated data, we do not cope with any order, but simply predict the result of each draw of a card by itself and finally multiply our predictions together to form a joint probability according to $p(1-p)$.\nIn conclusion, aggregated data is modelled with an extra constant to handle permutations. This does not change our inference, but merely changes the likelihood and log-likelihood.\nPractice M2 Question: If a coefficient in a Poisson regression has value 1.7, what does this imply about the change in the outcome?\nAnswer: A basic Poisson regression is expressed as such: $$log(λ) = α + βx$$ $$λ = exp(α + βx)$$\nIn this specific case $\\beta = 1.7$. So what happens to $\\lambda$ when $x$ increases by $1$? To solve this, we write a formula for the change in $\\lambda$:\n$$Δλ = exp(α + β(x + 1)) − exp(α + βx)$$ $$Δλ = exp(α + βx)(exp(β) − 1)$$\nUnfortunately, this is about as far as we can take solving this formula. The change in $\\lambda$ depends on all contents of the model. But about the ratio of $\\lambda$ following a one-unit increase in $x$ compared to $\\lambda$ a t base-level? We can compute this ratio as:\n$$\\frac{λ_{x+1}}{λx} = \\frac{exp(α + β(x + 1))}{exp(α + βx)} = exp(β)$$\nThis is reminiscent of the proportional change in odds for logistic regressions. Conclusively, a coefficient of $\\beta = 1.7$ in a Poisson model results in a proportional change in the expected count of exp(1.7) = 5.47 when the corresponding predictor variable increases by one unit.\nPractice M3 Question: Explain why the logit link is appropriate for a binomial generalized linear model.\nAnswer: With a binomial generalised linear model, we are interested in an outcome space between 0 and 1. With the outcome space denoting probabilities of an event transpiring. Our underlying linear model has no qualms about estimating parameter values outside of this interval. The logit link maps such probability space into $ℝ$ (linear model space).\nPractice M4 Question: Explain why the log link is appropriate for a Poisson generalized linear model.\nAnswer: Poisson generalised linear models are producing strictly non-negative outputs (negative counts are impossible). As such, the underlying linear model space needs to be matched to the outcome space which is strictly non-negative. The log function maps positive value onto $ℝ$ and thus the function links count values (positive values) to a linear model.\nPractice M5 Question: What would it imply to use a logit link for the mean of a Poisson generalized linear model? Can you think of a real research problem for which this would make sense?\nAnswer: Using a logit link in a Poisson model implies that the mean of the Poisson distribution lies between 0 and 1:\n$$y_i ∼ Poisson(μ_i)$$ $$logit(μ_i) = α + βx_i$$ This would imply that there is at most one event per time interval. This might be the case for very rare or extremely cyclical events such as counting the number of El Niño events every four years or so.\nPractice M6 Question: State the constraints for which the binomial and Poisson distributions have maximum entropy. Are the constraints different at all for binomial and Poisson? Why or why not?\nAnswer: For binomial and Poisson distributions to have maximum entropy, we need to meet the following assumptions:\n Discrete, binary outcomes Constant probability of event occurring across al trials (this is the same as a constant expected value)  Both distributions have the same constraints as Poisson is a simplified form of the binomial.\nHard Exercises Practice H1 Question: Use quap to construct a quadratic approximate posterior distribution for the chimpanzee model that includes a unique intercept for each actor, m11.4 (page 338). Compare the quadratic approximation to the posterior distribution produced instead from MCMC. Can you explain both the differences and the similarities between the approximate and the MCMC distributions?\nAnswer: Here are the models according to the book:\ndata(chimpanzees)\rd \u0026lt;- chimpanzees\rd$treatment \u0026lt;- 1 + d$prosoc_left + 2 * d$condition\rdat_list \u0026lt;- list(\rpulled_left = d$pulled_left,\ractor = d$actor,\rtreatment = as.integer(d$treatment)\r)\r## MCMC model\rm11.4 \u0026lt;- ulam(\ralist(\rpulled_left ~ dbinom(1, p),\rlogit(p) \u0026lt;- a[actor] + b[treatment],\ra[actor] ~ dnorm(0, 1.5),\rb[treatment] ~ dnorm(0, 0.5)\r),\rdata = dat_list, chains = 4, log_lik = TRUE\r)\r ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 1).\r## Chain 1: ## Chain 1: Gradient evaluation took 0.001 seconds\r## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.\r## Chain 1: Adjust your expectations accordingly!\r## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 1: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 1: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 1: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 1: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 1: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 1: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 1: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 1: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 1: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 1: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 1: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 1: ## Chain 1: Elapsed Time: 1.57 seconds (Warm-up)\r## Chain 1: 1.629 seconds (Sampling)\r## Chain 1: 3.199 seconds (Total)\r## Chain 1: ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 2).\r## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds\r## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 2: Adjust your expectations accordingly!\r## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 2: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 2: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 2: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 2: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 2: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 2: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 2: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 2: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 2: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 2: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 2: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 2: ## Chain 2: Elapsed Time: 1.667 seconds (Warm-up)\r## Chain 2: 1.211 seconds (Sampling)\r## Chain 2: 2.878 seconds (Total)\r## Chain 2: ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 3).\r## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds\r## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 3: Adjust your expectations accordingly!\r## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 3: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 3: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 3: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 3: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 3: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 3: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 3: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 3: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 3: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 3: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 3: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 3: ## Chain 3: Elapsed Time: 1.639 seconds (Warm-up)\r## Chain 3: 2.718 seconds (Sampling)\r## Chain 3: 4.357 seconds (Total)\r## Chain 3: ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 4).\r## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds\r## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 4: Adjust your expectations accordingly!\r## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 4: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 4: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 4: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 4: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 4: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 4: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 4: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 4: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 4: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 4: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 4: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 4: ## Chain 4: Elapsed Time: 2.031 seconds (Warm-up)\r## Chain 4: 2.195 seconds (Sampling)\r## Chain 4: 4.226 seconds (Total)\r## Chain 4:\r precis(m11.4, depth = 2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a[1] -0.45075443 0.3331248 -0.98953991 0.06075382 698.8809 1.005361\r## a[2] 3.91891754 0.8083257 2.74211339 5.24785152 901.5623 0.998913\r## a[3] -0.75442240 0.3312761 -1.28541454 -0.24524706 699.9722 1.003839\r## a[4] -0.76567679 0.3369675 -1.30127846 -0.23894487 857.8075 1.003696\r## a[5] -0.44359742 0.3267862 -0.97201306 0.07594653 674.2582 1.005466\r## a[6] 0.46443104 0.3317285 -0.05869988 0.99613901 810.7556 1.003976\r## a[7] 1.96593450 0.4242551 1.31622570 2.65044970 899.8839 1.001162\r## b[1] -0.03793442 0.2858597 -0.49368201 0.42539507 686.8362 1.005492\r## b[2] 0.48704573 0.2866880 0.03296044 0.95020885 703.0115 1.004415\r## b[3] -0.38805106 0.2815222 -0.82364579 0.06867557 639.3679 1.004886\r## b[4] 0.37075102 0.2834843 -0.08070002 0.83024441 623.7355 1.006236\r ## Quap Model\rm11.4quap \u0026lt;- quap(\ralist(\rpulled_left ~ dbinom(1, p),\rlogit(p) \u0026lt;- a[actor] + b[treatment],\ra[actor] ~ dnorm(0, 1.5),\rb[treatment] ~ dnorm(0, 0.5)\r),\rdata = dat_list\r)\r plot(coeftab(m11.4, m11.4quap),\rlabels = paste(rep(rownames(coeftab(m11.4, m11.4quap)@coefs), each = 2),\rrep(c(\u0026quot;MCMC\u0026quot;, \u0026quot;quap\u0026quot;), nrow(coeftab(m11.4, m11.4quap)@coefs) * 2),\rsep = \u0026quot;-\u0026quot;\r)\r)\r Looking at these parameter estimates, it is apparent that quadratic approximation is doing a good job in this case. The only noticeable difference lies with a[2] which shows a higher estimate with the ulam model. Let\u0026rsquo;s look at the densities of the estimates of this parameter:\npost \u0026lt;- extract.samples(m11.4)\rpostq \u0026lt;- extract.samples(m11.4quap)\rdens(post$a[, 2], lwd = 2)\rdens(postq$a[, 2], add = TRUE, lwd = 2, col = rangi2)\r The ulam model (in black) placed more probability mass in the upper end of the tail which ends up pushing the mean of this posterior distribution further to the right when compared to that of the quadratic approximation model. This is because the quadratic approximation assumes the posterior distribution to be Gaussian thus producing a symmetric distribution with less probability mass in the upper tail.\nPractice H2 Question: Use WAIC to compare the chimpanzee model that includes a unique intercept for each actor, m11.4 (page 338), to the simpler models fit in the same section.\nAnswer: The models in question are:\n Intercept only model:  m11.1 \u0026lt;- quap(\ralist(\rpulled_left ~ dbinom(1, p),\rlogit(p) \u0026lt;- a,\ra ~ dnorm(0, 10)\r),\rdata = d\r)\r Intercept and Treatment model:  m11.3 \u0026lt;- quap(\ralist(\rpulled_left ~ dbinom(1, p),\rlogit(p) \u0026lt;- a + b[treatment],\ra ~ dnorm(0, 1.5),\rb[treatment] ~ dnorm(0, 0.5)\r),\rdata = d\r)\r Individual Intercept and Treatment model:  m11.4 \u0026lt;- ulam(\ralist(\rpulled_left ~ dbinom(1, p),\rlogit(p) \u0026lt;- a[actor] + b[treatment],\ra[actor] ~ dnorm(0, 1.5),\rb[treatment] ~ dnorm(0, 0.5)\r),\rdata = dat_list, chains = 4, log_lik = TRUE\r)\r ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 1).\r## Chain 1: ## Chain 1: Gradient evaluation took 0 seconds\r## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 1: Adjust your expectations accordingly!\r## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 1: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 1: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 1: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 1: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 1: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 1: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 1: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 1: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 1: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 1: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 1: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 1: ## Chain 1: Elapsed Time: 0.978 seconds (Warm-up)\r## Chain 1: 0.775 seconds (Sampling)\r## Chain 1: 1.753 seconds (Total)\r## Chain 1: ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 2).\r## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds\r## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 2: Adjust your expectations accordingly!\r## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 2: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 2: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 2: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 2: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 2: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 2: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 2: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 2: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 2: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 2: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 2: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 2: ## Chain 2: Elapsed Time: 0.865 seconds (Warm-up)\r## Chain 2: 0.834 seconds (Sampling)\r## Chain 2: 1.699 seconds (Total)\r## Chain 2: ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 3).\r## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds\r## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 3: Adjust your expectations accordingly!\r## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 3: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 3: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 3: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 3: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 3: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 3: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 3: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 3: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 3: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 3: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 3: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 3: ## Chain 3: Elapsed Time: 0.857 seconds (Warm-up)\r## Chain 3: 0.612 seconds (Sampling)\r## Chain 3: 1.469 seconds (Total)\r## Chain 3: ## ## SAMPLING FOR MODEL '80e2b6267e3dc4ff0c2916d0cf0879e8' NOW (CHAIN 4).\r## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds\r## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 4: Adjust your expectations accordingly!\r## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 4: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 4: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 4: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 4: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 4: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 4: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 4: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 4: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 4: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 4: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 4: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 4: ## Chain 4: Elapsed Time: 0.919 seconds (Warm-up)\r## Chain 4: 0.937 seconds (Sampling)\r## Chain 4: 1.856 seconds (Total)\r## Chain 4:\r To compare these, we can run:\n(comp \u0026lt;- compare(m11.1, m11.3, m11.4))\r ## WAIC SE dWAIC dSE pWAIC weight\r## m11.4 532.4794 18.927161 0.0000 NA 8.572123 1.000000e+00\r## m11.3 682.4152 8.973761 149.9358 18.37892 3.553310 2.765987e-33\r## m11.1 687.9540 6.994012 155.4746 18.91781 1.004840 1.734267e-34\r plot(comp)\r This shows clearly that the model accounting for individual intercepts as well as treatment effects (m11.4) outperforms the simpler models.\nPractice H3 Question: The data contained in library(MASS);data(eagles) are records of salmon pirating attempts by Bald Eagles in Washington State. See ?eagles for details. While one eagle feeds, sometimes another will swoop in and try to steal the salmon from it. Call the feeding eagle the “victim” and the thief the “pirate.” Use the available data to build a binomial GLM of successful pirating attempts.\nAnswer:\nlibrary(MASS)\rdata(eagles)\rd \u0026lt;- eagles\r Part A Question: Consider the following model:\n$$y_i ∼ Binomial(n_i, p_i)$$ $$log\\frac{p_i}{1 − p_i} = α + β_PP_i + β_VV_i + β_AA_i $$ $$α ∼ Normal(0, 1.5)$$ $$β_P ∼ Normal(0, 0.5)$$ $$β_V ∼ Normal(0, 0.5)$$ $$β_A ∼ Normal(0, 0.5)$$ where $y$ is the number of successful attempts, $n$ is the total number of attempts, $P$ is a dummy variable indicating whether or not the pirate had large body size, $V$ is a dummy variable indicating whether or not the victim had large body size, and finally $A$ is a dummy variable indicating whether or not the pirate was an adult.\nFit the model above to the eagles data, using both quap and ulam. Is the quadratic approximation okay?\nAnswer: First, we have to make our dummy variables:\nd$pirateL \u0026lt;- ifelse(d$P == \u0026quot;L\u0026quot;, 1, 0)\rd$victimL \u0026lt;- ifelse(d$V == \u0026quot;L\u0026quot;, 1, 0)\rd$pirateA \u0026lt;- ifelse(d$A == \u0026quot;A\u0026quot;, 1, 0)\r Fitting the models is now trivial:\n# define model list specification\rf \u0026lt;- alist(\ry ~ dbinom(n, p),\rlogit(p) \u0026lt;- a + bP * pirateL + bV * victimL + bA * pirateA,\ra ~ dnorm(0, 1.5),\rbP ~ dnorm(0, .5),\rbV ~ dnorm(0, .5),\rbA ~ dnorm(0, .5)\r)\r## quap model\rmH3quap \u0026lt;- quap(f, data = d)\r## ulam model\rmH3ulam \u0026lt;- ulam(f, data = d, chains = 4, log_lik = TRUE)\r ## ## SAMPLING FOR MODEL '4eaf24dd51e5e9fce10e2cc7d32e0b01' NOW (CHAIN 1).\r## Chain 1: ## Chain 1: Gradient evaluation took 0 seconds\r## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 1: Adjust your expectations accordingly!\r## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 1: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 1: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 1: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 1: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 1: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 1: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 1: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 1: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 1: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 1: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 1: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 1: ## Chain 1: Elapsed Time: 0.07 seconds (Warm-up)\r## Chain 1: 0.066 seconds (Sampling)\r## Chain 1: 0.136 seconds (Total)\r## Chain 1: ## ## SAMPLING FOR MODEL '4eaf24dd51e5e9fce10e2cc7d32e0b01' NOW (CHAIN 2).\r## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds\r## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 2: Adjust your expectations accordingly!\r## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 2: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 2: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 2: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 2: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 2: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 2: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 2: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 2: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 2: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 2: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 2: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 2: ## Chain 2: Elapsed Time: 0.08 seconds (Warm-up)\r## Chain 2: 0.109 seconds (Sampling)\r## Chain 2: 0.189 seconds (Total)\r## Chain 2: ## ## SAMPLING FOR MODEL '4eaf24dd51e5e9fce10e2cc7d32e0b01' NOW (CHAIN 3).\r## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds\r## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 3: Adjust your expectations accordingly!\r## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 3: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 3: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 3: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 3: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 3: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 3: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 3: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 3: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 3: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 3: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 3: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 3: ## Chain 3: Elapsed Time: 0.114 seconds (Warm-up)\r## Chain 3: 0.084 seconds (Sampling)\r## Chain 3: 0.198 seconds (Total)\r## Chain 3: ## ## SAMPLING FOR MODEL '4eaf24dd51e5e9fce10e2cc7d32e0b01' NOW (CHAIN 4).\r## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds\r## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 4: Adjust your expectations accordingly!\r## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 4: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 4: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 4: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 4: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 4: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 4: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 4: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 4: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 4: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 4: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 4: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 4: ## Chain 4: Elapsed Time: 0.101 seconds (Warm-up)\r## Chain 4: 0.098 seconds (Sampling)\r## Chain 4: 0.199 seconds (Total)\r## Chain 4:\r Again, we visualise the parameter estimates\nplot(coeftab(mH3quap, mH3ulam),\rlabels = paste(rep(rownames(coeftab(mH3quap, mH3ulam)@coefs), each = 2),\rrep(c(\u0026quot;MCMC\u0026quot;, \u0026quot;quap\u0026quot;), nrow(coeftab(mH3quap, mH3ulam)@coefs) * 2),\rsep = \u0026quot;-\u0026quot;\r)\r)\r These are pretty similar looking to me.\nPart B Question: Now interpret the estimates. If the quadratic approximation turned out okay, then it’s okay to use the quap estimates. Otherwise stick to ulam estimates. Then plot the posterior predictions. Compute and display both (1) the predicted probability of success and its 89% interval for each row ($i$) in the data, as well as (2) the predicted success count and its 89% interval. What different information does each type of posterior prediction provide?\nAnswer: Personally, I don\u0026rsquo;t think there\u0026rsquo;s much difference between the model estimates. Here, I am sticking to the ulam model, because I feel like it. No other reason.\nLet\u0026rsquo;s start by getting a baseline understanding of how often a non-adult, small-bodied pirate is able to fetch a salmon from a small-bodied victim(all dummy variables are at value 0) - this is our intercept a. These are log-odds:\npost \u0026lt;- extract.samples(mH3ulam)\rmean(logistic(post$a))\r ## [1] 0.5695376\r We expect about 0.57% of all of our immature, small pirates to be successful when pirating on small victims.\nNow that we are armed with our baseline, we are ready to look at how our slope parameters affect what\u0026rsquo;s happening in our model.\nFirst, we start with the effect of pirate-body-size (bP):\nmean(logistic(post$a + post$bP))\r ## [1] 0.8678798\r Damn. Large-bodied pirates win almost all of the time! We could repeat this for all slope parameters, but I find it prudent to move on to our actual task:\n Probability of success:  d$psuccess \u0026lt;- d$y / d$n # successes divided by attempts\rp \u0026lt;- link(mH3ulam) # success probability with inverse link\r## Mean and Interval Calculation\rp.mean \u0026lt;- apply(p, 2, mean)\rp.PI \u0026lt;- apply(p, 2, PI)\r# plot raw proportions success for each case\rplot(d$psuccess,\rcol = rangi2,\rylab = \u0026quot;successful proportion\u0026quot;, xlab = \u0026quot;case\u0026quot;, xaxt = \u0026quot;n\u0026quot;,\rxlim = c(0.75, 8.25), pch = 16\r)\r# label cases on horizontal axis\raxis(1,\rat = 1:8,\rlabels = c(\u0026quot;LLA\u0026quot;, \u0026quot;LSA\u0026quot;, \u0026quot;LLI\u0026quot;, \u0026quot;LSI\u0026quot;, \u0026quot;SLA\u0026quot;, \u0026quot;SSA\u0026quot;, \u0026quot;SLI\u0026quot;, \u0026quot;SSI\u0026quot;) # same order as in data frame d\r)\r# display posterior predicted proportions successful\rpoints(1:8, p.mean)\rfor (i in 1:8) lines(c(i, i), p.PI[, i])\r Counts of successes:  y \u0026lt;- sim(mH3ulam) # simulate posterior for counts of successes\r## Mean and Interval Calculation\ry.mean \u0026lt;- apply(y, 2, mean)\ry.PI \u0026lt;- apply(y, 2, PI)\r# plot raw counts success for each case\rplot(d$y,\rcol = rangi2,\rylab = \u0026quot;successful attempts\u0026quot;, xlab = \u0026quot;case\u0026quot;, xaxt = \u0026quot;n\u0026quot;,\rxlim = c(0.75, 8.25), pch = 16\r)\r# label cases on horizontal axis\raxis(1,\rat = 1:8,\rlabels = c(\u0026quot;LAL\u0026quot;, \u0026quot;LAS\u0026quot;, \u0026quot;LIL\u0026quot;, \u0026quot;LIS\u0026quot;, \u0026quot;SAL\u0026quot;, \u0026quot;SAS\u0026quot;, \u0026quot;SIL\u0026quot;, \u0026quot;SIS\u0026quot;)\r)\r# display posterior predicted successes\rpoints(1:8, y.mean)\rfor (i in 1:8) lines(c(i, i), y.PI[, i])\r In conclusion, the probability plot makes the different settings of predictor variables more comparable because the number of piracy attempts are ignored in setting the y-axis. The count plot, however, shows the additional uncertainty stemming from the underlying sample size.\nPart C Question: Now try to improve the model. Consider an interaction between the pirate’s size and age(immature or adult). Compare this model to the previous one, using WAIC. Interpret.\nAnswer: Let\u0026rsquo;s fit a model with ulam containing the interaction effect we were asked for:\nmH3c \u0026lt;- ulam(\ralist(\ry ~ dbinom(n, p),\rlogit(p) \u0026lt;- a + bP * pirateL + bV * victimL + bA * pirateA + bPA * pirateL * pirateA,\ra ~ dnorm(0, 1.5),\rbP ~ dnorm(0, .5),\rbV ~ dnorm(0, .5),\rbA ~ dnorm(0, .5),\rbPA ~ dnorm(0, .5)\r),\rdata = d, chains = 4, log_lik = TRUE\r)\r ## ## SAMPLING FOR MODEL '3f6607198507ea4881438baca721629d' NOW (CHAIN 1).\r## Chain 1: ## Chain 1: Gradient evaluation took 0 seconds\r## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 1: Adjust your expectations accordingly!\r## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 1: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 1: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 1: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 1: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 1: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 1: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 1: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 1: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 1: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 1: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 1: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 1: ## Chain 1: Elapsed Time: 0.162 seconds (Warm-up)\r## Chain 1: 0.118 seconds (Sampling)\r## Chain 1: 0.28 seconds (Total)\r## Chain 1: ## ## SAMPLING FOR MODEL '3f6607198507ea4881438baca721629d' NOW (CHAIN 2).\r## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds\r## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 2: Adjust your expectations accordingly!\r## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 2: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 2: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 2: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 2: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 2: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 2: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 2: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 2: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 2: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 2: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 2: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 2: ## Chain 2: Elapsed Time: 0.142 seconds (Warm-up)\r## Chain 2: 0.124 seconds (Sampling)\r## Chain 2: 0.266 seconds (Total)\r## Chain 2: ## ## SAMPLING FOR MODEL '3f6607198507ea4881438baca721629d' NOW (CHAIN 3).\r## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds\r## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 3: Adjust your expectations accordingly!\r## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 3: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 3: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 3: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 3: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 3: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 3: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 3: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 3: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 3: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 3: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 3: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 3: ## Chain 3: Elapsed Time: 0.141 seconds (Warm-up)\r## Chain 3: 0.119 seconds (Sampling)\r## Chain 3: 0.26 seconds (Total)\r## Chain 3: ## ## SAMPLING FOR MODEL '3f6607198507ea4881438baca721629d' NOW (CHAIN 4).\r## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds\r## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 4: Adjust your expectations accordingly!\r## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 4: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 4: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 4: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 4: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 4: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 4: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 4: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 4: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 4: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 4: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 4: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 4: ## Chain 4: Elapsed Time: 0.107 seconds (Warm-up)\r## Chain 4: 0.12 seconds (Sampling)\r## Chain 4: 0.227 seconds (Total)\r## Chain 4:\r compare(mH3ulam, mH3c)\r ## WAIC SE dWAIC dSE pWAIC weight\r## mH3ulam 59.09875 11.34469 0.000000 NA 8.303613 0.6932173\r## mH3c 60.72916 11.90457 1.630407 1.467142 9.165510 0.3067827\r This is quite obviously a tie. So what about the model estimates?\nplot(coeftab(mH3ulam, mH3c),\rlabels = paste(rep(rownames(coeftab(mH3ulam, mH3c)@coefs), each = 2),\rrep(c(\u0026quot;Base\u0026quot;, \u0026quot;Interac\u0026quot;), nrow(coeftab(mH3ulam, mH3c)@coefs) * 2),\rsep = \u0026quot;-\u0026quot;\r)\r)\r Jup, there\u0026rsquo;s not really much of a difference here. For the interaction model: the log-odds of successful piracy is just weakly bigger when the pirating individual is large and an adult. That is counter-intuitive, isn\u0026rsquo;t it? It is worth pointing out that the individual parameters for these conditions show the expected effects and the identified negative effect of their interaction may be down to the sparsity of the underlying data and we are also highly uncertain of it\u0026rsquo;s sign to begin with.\nPractice H4 Question: The data contained in data(salamanders) are counts of salamanders (Plethodon elongatus) from 47 different 49$m^2$ plots in northern California. The column SALAMAN is the count in each plot, and the columns PCTCOVER and FORESTAGE are percent of ground cover and age of trees in the plot, respectively. You will model SALAMAN as a Poisson variable.\nPart A Question: Model the relationship between density and percent cover, using a log-link (same as the ex- ample in the book and lecture). Use weakly informative priors of your choosing. Check the quadratic approximation again, by comparing quap to ulam. Then plot the expected counts and their 89% interval against percent cover. In which ways does the model do a good job? In which ways does it do a bad job?\nAnswer: First, we load the data and standardise the predictors to get around their inconvenient scales which do not overlap well with each other:\ndata(salamanders)\rd \u0026lt;- salamanders\rd$C \u0026lt;- standardize(d$PCTCOVER)\rd$A \u0026lt;- standardize(d$FORESTAGE)\r Now it is time to write our Poisson model:\nf \u0026lt;- alist(\rSALAMAN ~ dpois(lambda),\rlog(lambda) \u0026lt;- a + bC * C,\ra ~ dnorm(0, 1),\rbC ~ dnorm(0, 1)\r)\r That was easy enough, but do those priors make sense? Let\u0026rsquo;s simulate:\nN \u0026lt;- 50 # 50 samples from prior\ra \u0026lt;- rnorm(N, 0, 1)\rbC \u0026lt;- rnorm(N, 0, 1)\rC_seq \u0026lt;- seq(from = -2, to = 2, length.out = 30)\rplot(NULL,\rxlim = c(-2, 2), ylim = c(0, 20),\rxlab = \u0026quot;cover(stanardized)\u0026quot;, ylab = \u0026quot;salamanders\u0026quot;\r)\rfor (i in 1:N) {\rlines(C_seq, exp(a[i] + bC[i] * C_seq), col = grau(), lwd = 1.5)\r}\r While not terrible (the prior allows your some explosive trends, but mostly sticks to a reasonable count of individuals), we may want to consider making the prior a bit more informative:\nbC \u0026lt;- rnorm(N, 0, 0.5)\rplot(NULL,\rxlim = c(-2, 2), ylim = c(0, 20),\rxlab = \u0026quot;cover(stanardized)\u0026quot;, ylab = \u0026quot;salamanders\u0026quot;\r)\rfor (i in 1:N) {\rlines(C_seq, exp(a[i] + bC[i] * C_seq), col = grau(), lwd = 1.5)\r}\r Yup - I am happy with that.\nLet\u0026rsquo;s update the model specification and run it:\nf \u0026lt;- alist(\rSALAMAN ~ dpois(lambda),\rlog(lambda) \u0026lt;- a + bC * C,\ra ~ dnorm(0, 1),\rbC ~ dnorm(0, 0.5)\r)\rmH4a \u0026lt;- ulam(f, data = d, chains = 4)\r ## ## SAMPLING FOR MODEL 'ce27f50b1ba56f91eaeb68bb1bf4432c' NOW (CHAIN 1).\r## Chain 1: ## Chain 1: Gradient evaluation took 0 seconds\r## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 1: Adjust your expectations accordingly!\r## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 1: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 1: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 1: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 1: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 1: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 1: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 1: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 1: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 1: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 1: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 1: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 1: ## Chain 1: Elapsed Time: 0.045 seconds (Warm-up)\r## Chain 1: 0.046 seconds (Sampling)\r## Chain 1: 0.091 seconds (Total)\r## Chain 1: ## ## SAMPLING FOR MODEL 'ce27f50b1ba56f91eaeb68bb1bf4432c' NOW (CHAIN 2).\r## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds\r## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 2: Adjust your expectations accordingly!\r## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 2: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 2: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 2: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 2: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 2: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 2: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 2: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 2: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 2: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 2: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 2: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 2: ## Chain 2: Elapsed Time: 0.054 seconds (Warm-up)\r## Chain 2: 0.062 seconds (Sampling)\r## Chain 2: 0.116 seconds (Total)\r## Chain 2: ## ## SAMPLING FOR MODEL 'ce27f50b1ba56f91eaeb68bb1bf4432c' NOW (CHAIN 3).\r## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds\r## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 3: Adjust your expectations accordingly!\r## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 3: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 3: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 3: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 3: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 3: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 3: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 3: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 3: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 3: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 3: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 3: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 3: ## Chain 3: Elapsed Time: 0.052 seconds (Warm-up)\r## Chain 3: 0.051 seconds (Sampling)\r## Chain 3: 0.103 seconds (Total)\r## Chain 3: ## ## SAMPLING FOR MODEL 'ce27f50b1ba56f91eaeb68bb1bf4432c' NOW (CHAIN 4).\r## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds\r## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 4: Adjust your expectations accordingly!\r## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 4: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 4: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 4: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 4: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 4: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 4: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 4: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 4: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 4: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 4: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 4: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 4: ## Chain 4: Elapsed Time: 0.065 seconds (Warm-up)\r## Chain 4: 0.058 seconds (Sampling)\r## Chain 4: 0.123 seconds (Total)\r## Chain 4:\r mH4aquap \u0026lt;- quap(f, data = d)\rplot(coeftab(mH4a, mH4aquap),\rlabels = paste(rep(rownames(coeftab(mH4a, mH4aquap)@coefs), each = 2),\rrep(c(\u0026quot;MCMC\u0026quot;, \u0026quot;quap\u0026quot;), nrow(coeftab(mH4a, mH4aquap)@coefs) * 2),\rsep = \u0026quot;-\u0026quot;\r)\r)\r Again, both models are doing fine and we continue to our plotting of expected counts and their interval with the ulam model:\nplot(d$C, d$SALAMAN,\rcol = rangi2, lwd = 2,\rxlab = \u0026quot;cover(standardized)\u0026quot;, ylab = \u0026quot;salamanders observed\u0026quot;\r)\rC_seq \u0026lt;- seq(from = -2, to = 2, length.out = 30)\rl \u0026lt;- link(mH4a, data = list(C = C_seq))\rlines(C_seq, colMeans(l))\rshade(apply(l, 2, PI), C_seq)\r Well that model doesn\u0026rsquo;t fit all that nicely and the data seems over-dispersed to me.\nPart B Question: Can you improve the model by using the other predictor, FORESTAGE? Try any models you think useful. Can you explain why FORESTAGE helps or does not help with prediction?\nAnswer: Forest cover might be confounded by forest age. The older a forest, the bigger its coverage? A model to investigate this could look like this:\nf2 \u0026lt;- alist(\rSALAMAN ~ dpois(lambda),\rlog(lambda) \u0026lt;- a + bC * C + bA * A,\ra ~ dnorm(0, 1),\rc(bC, bA) ~ dnorm(0, 0.5)\r)\rmH4b \u0026lt;- ulam(f2, data = d, chains = 4)\r ## ## SAMPLING FOR MODEL '4850e2c86bda45f77f837aaee26a4da5' NOW (CHAIN 1).\r## Chain 1: ## Chain 1: Gradient evaluation took 0 seconds\r## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 1: Adjust your expectations accordingly!\r## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 1: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 1: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 1: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 1: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 1: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 1: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 1: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 1: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 1: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 1: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 1: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 1: ## Chain 1: Elapsed Time: 0.066 seconds (Warm-up)\r## Chain 1: 0.067 seconds (Sampling)\r## Chain 1: 0.133 seconds (Total)\r## Chain 1: ## ## SAMPLING FOR MODEL '4850e2c86bda45f77f837aaee26a4da5' NOW (CHAIN 2).\r## Chain 2: ## Chain 2: Gradient evaluation took 0 seconds\r## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 2: Adjust your expectations accordingly!\r## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 2: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 2: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 2: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 2: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 2: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 2: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 2: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 2: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 2: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 2: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 2: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 2: ## Chain 2: Elapsed Time: 0.068 seconds (Warm-up)\r## Chain 2: 0.079 seconds (Sampling)\r## Chain 2: 0.147 seconds (Total)\r## Chain 2: ## ## SAMPLING FOR MODEL '4850e2c86bda45f77f837aaee26a4da5' NOW (CHAIN 3).\r## Chain 3: ## Chain 3: Gradient evaluation took 0 seconds\r## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 3: Adjust your expectations accordingly!\r## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 3: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 3: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 3: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 3: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 3: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 3: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 3: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 3: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 3: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 3: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 3: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 3: ## Chain 3: Elapsed Time: 0.064 seconds (Warm-up)\r## Chain 3: 0.062 seconds (Sampling)\r## Chain 3: 0.126 seconds (Total)\r## Chain 3: ## ## SAMPLING FOR MODEL '4850e2c86bda45f77f837aaee26a4da5' NOW (CHAIN 4).\r## Chain 4: ## Chain 4: Gradient evaluation took 0 seconds\r## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r## Chain 4: Adjust your expectations accordingly!\r## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 1000 [ 0%] (Warmup)\r## Chain 4: Iteration: 100 / 1000 [ 10%] (Warmup)\r## Chain 4: Iteration: 200 / 1000 [ 20%] (Warmup)\r## Chain 4: Iteration: 300 / 1000 [ 30%] (Warmup)\r## Chain 4: Iteration: 400 / 1000 [ 40%] (Warmup)\r## Chain 4: Iteration: 500 / 1000 [ 50%] (Warmup)\r## Chain 4: Iteration: 501 / 1000 [ 50%] (Sampling)\r## Chain 4: Iteration: 600 / 1000 [ 60%] (Sampling)\r## Chain 4: Iteration: 700 / 1000 [ 70%] (Sampling)\r## Chain 4: Iteration: 800 / 1000 [ 80%] (Sampling)\r## Chain 4: Iteration: 900 / 1000 [ 90%] (Sampling)\r## Chain 4: Iteration: 1000 / 1000 [100%] (Sampling)\r## Chain 4: ## Chain 4: Elapsed Time: 0.076 seconds (Warm-up)\r## Chain 4: 0.058 seconds (Sampling)\r## Chain 4: 0.134 seconds (Total)\r## Chain 4:\r precis(mH4b)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a 0.48361398 0.13609701 0.2618982 0.6896444 873.3384 1.003115\r## bA 0.01904618 0.09647959 -0.1361230 0.1679860 1102.3547 1.002465\r## bC 1.04260846 0.17335950 0.7795899 1.3262340 919.5342 1.000832\r Fascinating! The estimate for bA is nearly $0$ with a lot of certainty (i.e. a small interval) behind it. While conditioning on percent cover, forest age does not influence salamander count. This looks like a post-treatment effect to me.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] MASS_7.3-53.1 tidybayes_2.3.1 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 tidyr_1.1.3 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 ## [10] V8_3.4.1 plyr_1.8.6 R6_2.5.0 backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 ## [19] pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 ## [28] stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 ## [37] tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 arrayhelpers_1.1-0 codetools_0.2-18 matrixStats_0.61.0 fansi_0.4.2 crayon_1.4.1 ## [46] dplyr_1.0.5 withr_2.4.2 R.methodsS3_1.8.1 distributional_0.2.2 ggdist_2.4.0 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 lifecycle_1.0.0 ## [55] DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 farver_2.1.0 bslib_0.2.4 ellipsis_0.3.2 ## [64] generics_0.1.0 vctrs_0.3.7 rematch2_2.1.2 forcats_0.5.1 tools_4.0.5 svUnit_1.0.6 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 ## [73] processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1616025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616094000,"objectID":"54709dcfc9cb15656ae040d47780df86","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-11/","publishdate":"2021-03-18T00:00:00Z","relpermalink":"/courses/rethinking/chapter-11/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 11 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 10 \u0026 11","type":"docs"},{"authors":null,"categories":null,"content":"I have prepared some Lecture Slides  for this session.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"13286a4e1bf10347f4bc96e42ea221e0","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/10_troubleshooting_r-isolating-issues-and-asking-questions/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/10_troubleshooting_r-isolating-issues-and-asking-questions/","section":"courses","summary":"I have prepared some Lecture Slides  for this session.","tags":null,"title":"Troubleshooting R - Isolating Issues and Asking Questions","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our fifth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare more than two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.\nI have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here, here, and here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c()\rsapply(package_vec, install.load.package)\r ## list()\r As you can see, we don\u0026rsquo;t need any packages for our analyses in this practical. Take note that I am not using ggplot2 for data visualisation today. Personally, I find it cumbersome for \u0026ldquo;behind-the-scenes\u0026rdquo; boxplots (which is what I\u0026rsquo;ll use a lot today) and so I am presenting you with the base R alternative.\nLoading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Kruskal-Wallis Test Climate Warming/Extremes Does morphology of Passer domesticus depend on climate?\nUsing the Mann-Witney U Test in our last practical, we concluded that climate (when recorded as \u0026ldquo;Continental\u0026rdquo; and \u0026ldquo;Non-Continental\u0026rdquo;) is an important driver of Passer domesticus morphology. Now we will see whether this holds true when considering non-continental climates as coastal and semi-coastal ones.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Weight Let\u0026rsquo;s start with weight records of common house sparrows:\nWeightCont \u0026lt;- with(Data_df, Weight[which(Climate == \u0026quot;Continental\u0026quot;)])\rWeightSemi \u0026lt;- with(Data_df, Weight[which(Climate == \u0026quot;Semi-Coastal\u0026quot;)])\rWeightCoast \u0026lt;- with(Data_df, Weight[which(Climate == \u0026quot;Coastal\u0026quot;)])\rWeights_vec \u0026lt;- c(WeightCont, WeightSemi, WeightCoast)\rClimates \u0026lt;- c(\rrep(\u0026quot;Continental\u0026quot;, length(WeightCont)),\rrep(\u0026quot;Semi-Coastal\u0026quot;, length(WeightSemi)),\rrep(\u0026quot;Coastal\u0026quot;, length(WeightCoast))\r)\rClimates \u0026lt;- as.factor(Climates)\rkruskal.test(Weights_vec, Climates)\r ## ## Kruskal-Wallis rank sum test\r## ## data: Weights_vec and Climates\r## Kruskal-Wallis chi-squared = 150.98, df = 2, p-value \u0026lt; 2.2e-16\r We conclude that the three-level climate variable is an important source of information to understand what drives weight records of Passer domesticus and thus reject the null hypothesis (p = $1.6418184\\times 10^{-33}$).\nboxplot(Weights_vec ~ Climates)\r Looking at the boxplot, we can understand the distribution of weight records as grouped by climate types and identify weight records to be biggest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of weight records of Passer domesticus with a markedly lower median than the two previous categories.\nHeight Secondly, let\u0026rsquo;s repeat the above Kruskal-Wallis Test for the height/length records of our Passer domesticus individuals:\nHeightCont \u0026lt;- with(Data_df, Height[which(Climate == \u0026quot;Continental\u0026quot;)])\rHeightSemi \u0026lt;- with(Data_df, Height[which(Climate == \u0026quot;Semi-Coastal\u0026quot;)])\rHeightCoast \u0026lt;- with(Data_df, Height[which(Climate == \u0026quot;Coastal\u0026quot;)])\rHeights_vec \u0026lt;- c(HeightCont, HeightSemi, HeightCoast)\rClimates \u0026lt;- c(\rrep(\u0026quot;Continental\u0026quot;, length(HeightCont)),\rrep(\u0026quot;Semi-Coastal\u0026quot;, length(HeightSemi)),\rrep(\u0026quot;Coastal\u0026quot;, length(HeightCoast))\r)\rClimates \u0026lt;- as.factor(Climates)\rkruskal.test(Heights_vec, Climates)\r ## ## Kruskal-Wallis rank sum test\r## ## data: Heights_vec and Climates\r## Kruskal-Wallis chi-squared = 15.635, df = 2, p-value = 0.0004027\r boxplot(Heights_vec ~ Climates)\r We conclude that the three-level climate variable is an important source of information to understand what drives height records of Passer domesticus and thus reject the null hypothesis (p = $4.0267296\\times 10^{-4}$).\nLooking at the boxplot, we can understand the distribution of height records as grouped by climate types and identify height records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of height records of Passer domesticus with a markedly higher median than the two previous categories.\nWing Chord Third, we will test whether climate is a good predictor for wing chord of common house sparrows:\nWing.ChordCont \u0026lt;- with(Data_df, Wing.Chord[which(Climate == \u0026quot;Continental\u0026quot;)])\rWing.ChordSemi \u0026lt;- with(Data_df, Wing.Chord[which(Climate == \u0026quot;Semi-Coastal\u0026quot;)])\rWing.ChordCoast \u0026lt;- with(Data_df, Wing.Chord[which(Climate == \u0026quot;Coastal\u0026quot;)])\rWing.Chords_vec \u0026lt;- c(Wing.ChordCont, Wing.ChordSemi, Wing.ChordCoast)\rClimates \u0026lt;- c(\rrep(\u0026quot;Continental\u0026quot;, length(Wing.ChordCont)),\rrep(\u0026quot;Semi-Coastal\u0026quot;, length(Wing.ChordSemi)),\rrep(\u0026quot;Coastal\u0026quot;, length(Wing.ChordCoast))\r)\rClimates \u0026lt;- as.factor(Climates)\rkruskal.test(Wing.Chords_vec, Climates)\r ## ## Kruskal-Wallis rank sum test\r## ## data: Wing.Chords_vec and Climates\r## Kruskal-Wallis chi-squared = 41.539, df = 2, p-value = 9.548e-10\r boxplot(Wing.Chords_vec ~ Climates)\r We conclude that the three-level climate variable is an important source of information to understand what drives wing chord records of Passer domesticus and thus reject the null hypothesis (p = $9.5482279\\times 10^{-10}$).\nLooking at the boxplot, we can understand the distribution of wing chord records as grouped by climate types and identify wing chord records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of wing chord records of Passer domesticus with a markedly higher median than the two previous categories.\nAutomating the Analysis As we have seen, running seperate tests for every research question may be a bit cumbersome and so we may want to automate the analysis by establishing our own user-defined function as follows:\nAutomatedKruskal \u0026lt;- function(Variables, Groups, Plotting){\r# establish data frame to save results to\rExport \u0026lt;- data.frame(\rVariables = Variables,\rGrouped_by = rep(Groups, length(Variables)),\rChi_Squared = rep(NA, length(Variables)),\rDF = rep(NA, length(Variables)),\rp_value = rep(NA, length(Variables))\r)\rfor(i in 1:length(Variables)){\r# extract data and groups from data frame\rYData \u0026lt;- Data_df[,which(colnames(Data_df)==Variables[i])]\rXData \u0026lt;- Data_df[,which(colnames(Data_df)==Groups)]\r# establish a list holding our groups for our data\rData \u0026lt;- list()\rGrouping \u0026lt;- list()\rfor(k in 1:length(unique(XData))){\rData[[k]] \u0026lt;- YData[which(XData == unique(XData)[k])]\rGrouping[[k]] \u0026lt;- rep(unique(XData)[k], length = length(Data[[k]]))\r} # end of k-loop\rData \u0026lt;- unlist(Data)\rGrouping \u0026lt;- unlist(Grouping)\r# fill data frame\rExport[i, 3] \u0026lt;- kruskal.test(Data, Grouping)[[\u0026quot;statistic\u0026quot;]][[\u0026quot;Kruskal-Wallis chi-squared\u0026quot;]]\rExport[i, 4] \u0026lt;- kruskal.test(Data, Grouping)[[\u0026quot;parameter\u0026quot;]]\rExport[i, 5] \u0026lt;- kruskal.test(Data, Grouping)[[\u0026quot;p.value\u0026quot;]]\r# optional plotting\rif(Plotting == TRUE){\rplot(Data ~ factor(Grouping), ylab = Variables[i])\r}\r} # end of i loop\r# return data frame to R outside of function\rreturn(Export)\r} # end of function\r This function is named AutomatedKruskal() and takes three arguments: (1) Variables - a vector of character typed identifiers for the variables we want to have tested, (2) Groups - a character string identifying the grouping variable, (3) Plotting - a logical statement (TRUE or FALSE) whether boxplots shall be produced.\nThe function then proceeds to establish an empty data frame which it will store the results of our Kurskal-Wallis Tests in. Afterwards, it cycles through all variables contained within the Variables statement, extracts the relevant data, grouping it according to the specified grouping variable (Groups), runs the test, fills the data frame and plots the data if Plotting has been set to TRUE.\nLet\u0026rsquo;s re-run our earlier test on sparrow morphology as influenced by climate using this function by calling it:\npar(mfrow = c(3,1)) # adjust plotting panes\rAutomatedKruskal(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Groups = \u0026quot;Climate\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Weight Climate 150.97901 2 1.641818e-33\r## 2 Height Climate 15.63477 2 4.026730e-04\r## 3 Wing.Chord Climate 41.53899 2 9.548228e-10\r As we can see from the results above, our function works flawlessly and we can use it going ahead.\nFurthermore, we can confirm some of the results of our Mann-Whitney U Test from last seminar.\nPredation Does nesting height depend on predator characteristics?\nAgain, using the Mann-WHitney U Test in our last exercise, we identified both predator presence as well as predator type to be important predictors for nesting height of Passer domesticus.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Using the Kruskal-Wallis Test, we can combine these two predictors by turning every record of predator type that is recorded as NA into \u0026ldquo;None\u0026rdquo; which will then serve as an identifier for the absence of any predators effectively making the predator presence variable redundant:\n# changing levels in predator type\rlevels(Data_df$Predator.Type) \u0026lt;- c(levels(Data_df$Predator.Type), \u0026quot;None\u0026quot;)\rData_df$Predator.Type[which(is.na(Data_df$Predator.Type))] \u0026lt;- \u0026quot;None\u0026quot;\r# running analysis\rAutomatedKruskal(Variables = \u0026quot;Nesting.Height\u0026quot;, Groups = \u0026quot;Predator.Type\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Nesting.Height Predator.Type 88.81797 2 5.169206e-20\r Using our Automated Kruskal() function, we can conclude that the aggregation of predator presence to predator type records serve as an excellent predictor for sparrow nesting height and reject the null hypothesis (p = $5.169206\\times 10^{-20}$).\nTherefore, we can argue that avian predation forces sparrows into low nesting sites, non-avian predation leads to more elevated nesting sites in Passer domesticus and absence of predators seems to not force nesting height in any direction or restricting its spread.\nCompetition Does home range depend on climate?\nHaving used the Mann-Whitney U Test to identify possible climate-driven changes in home ranges of Passer domesticus in our last seminar, we concluded that climate types largely affect home ranges of the common house sparrow.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Let\u0026rsquo;s test this for our three-level climate variable:\nData_df$Home.Range \u0026lt;- as.numeric(factor(Data_df$Home.Range))\rAutomatedKruskal(Variables = \u0026quot;Home.Range\u0026quot;, Groups = \u0026quot;Climate\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Home.Range Climate 6.243918 2 0.04407075\r Using our Automated Kruskal() function, we can conclude that the three-loevel climate variable serves as an excellent predictor for sparrow home range and reject the null hypothesis (p = $0.0440707$) thus being at odds with our Mann-Whitney U results (that were only based on two climate types).\nRemember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that climates force common house sparrows to adapt to bigger home ranges.\nFriedman Test We can analyse the significance of more than two population/sample medians of metric variables which are dependent of one another using the friedman.test() function in base R.\nPreparing Data Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.\nConclusively, we need additional data sets with truly paired records of sparrows. Within our study set-up, think of a resettling experiment, were you take Passer domesticus individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.\nTo this end, presume we have taken the entire Passer domesticus population found at our Siberian research station and moved them to Manitoba. After a given time at their new location, we are again moving the population from Manitoba to the United Kingdom. Whilst this keeps the latitude stable, the sparrows now experience a semi-coastal climate followed by a coastal one instead of a continental one. After some time (let\u0026rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again. Within our data, none of the original individuals have gone missing or died throghout our study period. This is usually not the case in nature and such records would need to be deleted from the data set.\nYou will find the corresponding new data in 2a - Sparrow_ResettledSIMA_READY.rds (Siberia to Manitoba) and 2b - Sparrow_ResettledSIUK_READY.rds (former SIberian population from manitoba to the UK). Take note that these sets only contain records for the transferred individuals in the same order as in the old data set.\nData_df_SIMA \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2a - Sparrow_ResettledSIMA_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df_SIUK \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2b - Sparrow_ResettledSIUK_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\r With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their plasticity.\nAs such, this program is very reminiscent of the resettling program in our last exercise when using Wilcoxon Signed Rank Test to account for plasticity of our sparrow individuals. This new program includes the additional step of transferring sparrows via Manitoba first. Why have we chosen this order of resettlements?\n Our stations SI, MA and UK are all on roughly the same latitude. Moving the sparrows from SI to UK via MA results in them experiencing a gradient from continental to semi-coastal to coastal climate. Whilst Siberia is populated by avian predators, no predators are present at Manitoba and our sparrows are subject to non-avian predation in the UK.  All of this serves to maximise variation that we want to research whilst minising constraining factors.\nClimate Warming/Extremes Does sparrow morphology change depend on climate?\nThinking back to out Wilcoxon Signed Rank test, we can already argue that weight records of sparrows should change according to climate whilst height and wing chord records should remain unaltered for every individual.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Since this involves testing three seperate criterions of sparrow morphology, we again establish a user-defined function. This one is called AutomatedFried() and has dropped the Groups argument that was present in AutomatedKruskal() since the grouping will always be our three stations:\nAutomatedFried \u0026lt;- function(Variables, Plotting){\r# establish data frame to save results to\rExport \u0026lt;- data.frame(\rVariables = Variables,\rGrouped_by = rep(\u0026quot;Resettling\u0026quot;, length(Variables)),\rChi_Squared = rep(NA, length(Variables)),\rDF = rep(NA, length(Variables)),\rp_value = rep(NA, length(Variables))\r)\rfor(i in 1:length(Variables)){\r# extract data and groups from data frame\rYDataSI \u0026lt;- Data_df[,which(colnames(Data_df)==Variables[i])]\rYDataMA \u0026lt;- Data_df_SIMA[,which(colnames(Data_df)==Variables[i])]\rYDataUK \u0026lt;- Data_df_SIUK[,which(colnames(Data_df)==Variables[i])]\rData \u0026lt;- matrix(c(YDataSI[which(Data_df$Index == \u0026quot;SI\u0026quot;)],\rYDataMA, YDataUK), nrow = dim(Data_df_SIMA)[1],\rbyrow = FALSE, dimnames = list(1:dim(Data_df_SIMA)[1], c(\u0026quot;SI\u0026quot;, \u0026quot;MA\u0026quot;, \u0026quot;UK\u0026quot;))\r)\r# fill data frame\rExport[i, 3] \u0026lt;- friedman.test(Data)[[\u0026quot;statistic\u0026quot;]][[\u0026quot;Friedman chi-squared\u0026quot;]]\rExport[i, 4] \u0026lt;- friedman.test(Data)[[\u0026quot;parameter\u0026quot;]]\rExport[i, 5] \u0026lt;- friedman.test(Data)[[\u0026quot;p.value\u0026quot;]]\r# optional plotting\rif(Plotting == TRUE){\r# prepare plotting data\rPlotData \u0026lt;- as.vector(Data)\rGrouping \u0026lt;- as.factor(\rrep(c(\u0026quot;SI\u0026quot;, \u0026quot;MA\u0026quot;, \u0026quot;UK\u0026quot;), each = dim(Data_df_SIMA)[1])\r)\r# plotting\rplot(PlotData ~ Grouping, ylab = Variables[i])\r}\r} # end of i loop\r# return data frame to R outside of function\rreturn(Export)\r} # end of function\r As such, the above function operates a lot like the earlier user-defined counterpart for the Kruskal-Wallis Test. It returns the important test characteristics and allows for plots. Internally, however, it is built on a matrix rather than vectors.\nLet\u0026rsquo;s get to testing our prediction:\npar(mfrow = c(3,1)) # adjust plotting panes\rAutomatedFried(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Weight Resettling 97.84848 2 5.655506e-22\r## 2 Height Resettling NaN 2 NaN\r## 3 Wing.Chord Resettling NaN 2 NaN\r Indeed, whilst climate is a good predictor for the weight of resettled sparrows (weight in continental climates is higher than in semi-coastal or coastal ones), height and wing chord records couldn\u0026rsquo;t be properly tested on using the friedman.test() function since they have remained unalterd. Thetrefore, we reject the null hypothesis for weight records of Passer domesticus and accept the null hypothesis for height and wing chord records.\nPredation Does nesting height depend on predator characteristics?\nAccording to the results of our last practical, we would assume Passer doemsticus to adhere to local conditions when chosing a nesting site and corresponding nesting height depending on predator presence:\nAutomatedFried(Variables = \u0026quot;Nesting.Height\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Nesting.Height Resettling 10.864 2 0.004374338\r Just like we expected, nesting height of resettled sparrows depends hugely on predator presence at the sties they have been moved to (p = $7.3991389\\times 10^{-19}$) and we reject the null hypothesis.\nCompetition Does home range depend on climate?\nAs we\u0026rsquo;ve seen in our last seminar, a statistically signficant change in home ranges did not occur when resettling Siberian sparrows directly to the UK. How about when we resettle them via Manitoba?\nData_df_SIMA$Home.Range \u0026lt;- as.numeric(Data_df_SIMA$Home.Range)\rData_df_SIUK$Home.Range \u0026lt;- as.numeric(Data_df_SIUK$Home.Range)\rAutomatedFried(Variables = \u0026quot;Home.Range\u0026quot;, Plotting = TRUE)\r ## Warning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Home.Range Resettling 132 2 2.170522e-29\r With our three-step resettling program we do record a statistically significant change in home ranges of our sparrow flocks and reject the null hypothesis (p = $2.170522\\times 10^{-29}$).\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"75783a42fbc5d3660ead9283afa8b976","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/ordinal-metric-tests-more-than-two-sample-situations/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/ordinal-metric-tests-more-than-two-sample-situations/","section":"courses","summary":"Welcome to our fifth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare more than two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.","tags":["R","Statistics"],"title":"Ordinal \u0026 Metric Tests (More-Than-Two-Sample Situations)","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our fifth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare more than two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise. I have prepared some slides for this session: \nData Find the data for this exercise here, here, and here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c()\rsapply(package_vec, install.load.package)\r ## list()\r As you can see, we don\u0026rsquo;t need any packages for our analyses in this practical. Take note that I am not using ggplot2 for data visualisation today. Personally, I find it cumbersome for \u0026ldquo;behind-the-scenes\u0026rdquo; boxplots (which is what I\u0026rsquo;ll use a lot today) and so I am presenting you with the base R alternative.\nLoading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r Kruskal-Wallis Test Climate Warming/Extremes Does morphology of Passer domesticus depend on climate?\nUsing the Mann-Witney U Test in our last practical, we concluded that climate (when recorded as \u0026ldquo;Continental\u0026rdquo; and \u0026ldquo;Non-Continental\u0026rdquo;) is an important driver of Passer domesticus morphology. Now we will see whether this holds true when considering non-continental climates as coastal and semi-coastal ones.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Weight Let\u0026rsquo;s start with weight records of common house sparrows:\nWeightCont \u0026lt;- with(Data_df, Weight[which(Climate == \u0026quot;Continental\u0026quot;)])\rWeightSemi \u0026lt;- with(Data_df, Weight[which(Climate == \u0026quot;Semi-Coastal\u0026quot;)])\rWeightCoast \u0026lt;- with(Data_df, Weight[which(Climate == \u0026quot;Coastal\u0026quot;)])\rWeights_vec \u0026lt;- c(WeightCont, WeightSemi, WeightCoast)\rClimates \u0026lt;- c(\rrep(\u0026quot;Continental\u0026quot;, length(WeightCont)),\rrep(\u0026quot;Semi-Coastal\u0026quot;, length(WeightSemi)),\rrep(\u0026quot;Coastal\u0026quot;, length(WeightCoast))\r)\rClimates \u0026lt;- as.factor(Climates)\rkruskal.test(Weights_vec, Climates)\r ## ## Kruskal-Wallis rank sum test\r## ## data: Weights_vec and Climates\r## Kruskal-Wallis chi-squared = 150.98, df = 2, p-value \u0026lt; 2.2e-16\r We conclude that the three-level climate variable is an important source of information to understand what drives weight records of Passer domesticus and thus reject the null hypothesis (p = $1.6418184\\times 10^{-33}$).\nboxplot(Weights_vec ~ Climates)\r Looking at the boxplot, we can understand the distribution of weight records as grouped by climate types and identify weight records to be biggest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of weight records of Passer domesticus with a markedly lower median than the two previous categories.\nHeight Secondly, let\u0026rsquo;s repeat the above Kruskal-Wallis Test for the height/length records of our Passer domesticus individuals:\nHeightCont \u0026lt;- with(Data_df, Height[which(Climate == \u0026quot;Continental\u0026quot;)])\rHeightSemi \u0026lt;- with(Data_df, Height[which(Climate == \u0026quot;Semi-Coastal\u0026quot;)])\rHeightCoast \u0026lt;- with(Data_df, Height[which(Climate == \u0026quot;Coastal\u0026quot;)])\rHeights_vec \u0026lt;- c(HeightCont, HeightSemi, HeightCoast)\rClimates \u0026lt;- c(\rrep(\u0026quot;Continental\u0026quot;, length(HeightCont)),\rrep(\u0026quot;Semi-Coastal\u0026quot;, length(HeightSemi)),\rrep(\u0026quot;Coastal\u0026quot;, length(HeightCoast))\r)\rClimates \u0026lt;- as.factor(Climates)\rkruskal.test(Heights_vec, Climates)\r ## ## Kruskal-Wallis rank sum test\r## ## data: Heights_vec and Climates\r## Kruskal-Wallis chi-squared = 15.635, df = 2, p-value = 0.0004027\r boxplot(Heights_vec ~ Climates)\r We conclude that the three-level climate variable is an important source of information to understand what drives height records of Passer domesticus and thus reject the null hypothesis (p = $4.0267296\\times 10^{-4}$).\nLooking at the boxplot, we can understand the distribution of height records as grouped by climate types and identify height records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of height records of Passer domesticus with a markedly higher median than the two previous categories.\nWing Chord Third, we will test whether climate is a good predictor for wing chord of common house sparrows:\nWing.ChordCont \u0026lt;- with(Data_df, Wing.Chord[which(Climate == \u0026quot;Continental\u0026quot;)])\rWing.ChordSemi \u0026lt;- with(Data_df, Wing.Chord[which(Climate == \u0026quot;Semi-Coastal\u0026quot;)])\rWing.ChordCoast \u0026lt;- with(Data_df, Wing.Chord[which(Climate == \u0026quot;Coastal\u0026quot;)])\rWing.Chords_vec \u0026lt;- c(Wing.ChordCont, Wing.ChordSemi, Wing.ChordCoast)\rClimates \u0026lt;- c(\rrep(\u0026quot;Continental\u0026quot;, length(Wing.ChordCont)),\rrep(\u0026quot;Semi-Coastal\u0026quot;, length(Wing.ChordSemi)),\rrep(\u0026quot;Coastal\u0026quot;, length(Wing.ChordCoast))\r)\rClimates \u0026lt;- as.factor(Climates)\rkruskal.test(Wing.Chords_vec, Climates)\r ## ## Kruskal-Wallis rank sum test\r## ## data: Wing.Chords_vec and Climates\r## Kruskal-Wallis chi-squared = 41.539, df = 2, p-value = 9.548e-10\r boxplot(Wing.Chords_vec ~ Climates)\r We conclude that the three-level climate variable is an important source of information to understand what drives wing chord records of Passer domesticus and thus reject the null hypothesis (p = $9.5482279\\times 10^{-10}$).\nLooking at the boxplot, we can understand the distribution of wing chord records as grouped by climate types and identify wing chord records to be smallest for continental climates followed by semi-coastal ones with similar spreads. Coastal climates, on the other hand, show a remarkable spread of wing chord records of Passer domesticus with a markedly higher median than the two previous categories.\nAutomating the Analysis As we have seen, running seperate tests for every research question may be a bit cumbersome and so we may want to automate the analysis by establishing our own user-defined function as follows:\nAutomatedKruskal \u0026lt;- function(Variables, Groups, Plotting){\r# establish data frame to save results to\rExport \u0026lt;- data.frame(\rVariables = Variables,\rGrouped_by = rep(Groups, length(Variables)),\rChi_Squared = rep(NA, length(Variables)),\rDF = rep(NA, length(Variables)),\rp_value = rep(NA, length(Variables))\r)\rfor(i in 1:length(Variables)){\r# extract data and groups from data frame\rYData \u0026lt;- Data_df[,which(colnames(Data_df)==Variables[i])]\rXData \u0026lt;- Data_df[,which(colnames(Data_df)==Groups)]\r# establish a list holding our groups for our data\rData \u0026lt;- list()\rGrouping \u0026lt;- list()\rfor(k in 1:length(unique(XData))){\rData[[k]] \u0026lt;- YData[which(XData == unique(XData)[k])]\rGrouping[[k]] \u0026lt;- rep(unique(XData)[k], length = length(Data[[k]]))\r} # end of k-loop\rData \u0026lt;- unlist(Data)\rGrouping \u0026lt;- unlist(Grouping)\r# fill data frame\rExport[i, 3] \u0026lt;- kruskal.test(Data, Grouping)[[\u0026quot;statistic\u0026quot;]][[\u0026quot;Kruskal-Wallis chi-squared\u0026quot;]]\rExport[i, 4] \u0026lt;- kruskal.test(Data, Grouping)[[\u0026quot;parameter\u0026quot;]]\rExport[i, 5] \u0026lt;- kruskal.test(Data, Grouping)[[\u0026quot;p.value\u0026quot;]]\r# optional plotting\rif(Plotting == TRUE){\rplot(Data ~ factor(Grouping), ylab = Variables[i])\r}\r} # end of i loop\r# return data frame to R outside of function\rreturn(Export)\r} # end of function\r This function is named AutomatedKruskal() and takes three arguments: (1) Variables - a vector of character typed identifiers for the variables we want to have tested, (2) Groups - a character string identifying the grouping variable, (3) Plotting - a logical statement (TRUE or FALSE) whether boxplots shall be produced.\nThe function then proceeds to establish an empty data frame which it will store the results of our Kurskal-Wallis Tests in. Afterwards, it cycles through all variables contained within the Variables statement, extracts the relevant data, grouping it according to the specified grouping variable (Groups), runs the test, fills the data frame and plots the data if Plotting has been set to TRUE.\nLet\u0026rsquo;s re-run our earlier test on sparrow morphology as influenced by climate using this function by calling it:\npar(mfrow = c(3,1)) # adjust plotting panes\rAutomatedKruskal(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Groups = \u0026quot;Climate\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Weight Climate 150.97901 2 1.641818e-33\r## 2 Height Climate 15.63477 2 4.026730e-04\r## 3 Wing.Chord Climate 41.53899 2 9.548228e-10\r As we can see from the results above, our function works flawlessly and we can use it going ahead.\nFurthermore, we can confirm some of the results of our Mann-Whitney U Test from last seminar.\nPredation Does nesting height depend on predator characteristics?\nAgain, using the Mann-WHitney U Test in our last exercise, we identified both predator presence as well as predator type to be important predictors for nesting height of Passer domesticus.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Using the Kruskal-Wallis Test, we can combine these two predictors by turning every record of predator type that is recorded as NA into \u0026ldquo;None\u0026rdquo; which will then serve as an identifier for the absence of any predators effectively making the predator presence variable redundant:\n# changing levels in predator type\rlevels(Data_df$Predator.Type) \u0026lt;- c(levels(Data_df$Predator.Type), \u0026quot;None\u0026quot;)\rData_df$Predator.Type[which(is.na(Data_df$Predator.Type))] \u0026lt;- \u0026quot;None\u0026quot;\r# running analysis\rAutomatedKruskal(Variables = \u0026quot;Nesting.Height\u0026quot;, Groups = \u0026quot;Predator.Type\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Nesting.Height Predator.Type 88.81797 2 5.169206e-20\r Using our Automated Kruskal() function, we can conclude that the aggregation of predator presence to predator type records serve as an excellent predictor for sparrow nesting height and reject the null hypothesis (p = $5.169206\\times 10^{-20}$).\nTherefore, we can argue that avian predation forces sparrows into low nesting sites, non-avian predation leads to more elevated nesting sites in Passer domesticus and absence of predators seems to not force nesting height in any direction or restricting its spread.\nCompetition Does home range depend on climate?\nHaving used the Mann-Whitney U Test to identify possible climate-driven changes in home ranges of Passer domesticus in our last seminar, we concluded that climate types largely affect home ranges of the common house sparrow.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Let\u0026rsquo;s test this for our three-level climate variable:\nData_df$Home.Range \u0026lt;- as.numeric(factor(Data_df$Home.Range))\rAutomatedKruskal(Variables = \u0026quot;Home.Range\u0026quot;, Groups = \u0026quot;Climate\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Home.Range Climate 6.243918 2 0.04407075\r Using our Automated Kruskal() function, we can conclude that the three-loevel climate variable serves as an excellent predictor for sparrow home range and reject the null hypothesis (p = $0.0440707$) thus being at odds with our Mann-Whitney U results (that were only based on two climate types).\nRemember that small numeric ranges mean large actual ranges in this set-up and so we can conclude that climates force common house sparrows to adapt to bigger home ranges.\nFriedman Test We can analyse the significance of more than two population/sample medians of metric variables which are dependent of one another using the friedman.test() function in base R.\nPreparing Data Obviously, none of our data records are paired as such. Whilst one may want to make the argument that many characteristics of individuals that group together might be dependant on the expressions of themselves found throughout said group, we will not concentrate on this possibility within these practicals.\nConclusively, we need additional data sets with truly paired records of sparrows. Within our study set-up, think of a resettling experiment, were you take Passer domesticus individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.\nTo this end, presume we have taken the entire Passer domesticus population found at our Siberian research station and moved them to Manitoba. After a given time at their new location, we are again moving the population from Manitoba to the United Kingdom. Whilst this keeps the latitude stable, the sparrows now experience a semi-coastal climate followed by a coastal one instead of a continental one. After some time (let\u0026rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again. Within our data, none of the original individuals have gone missing or died throghout our study period. This is usually not the case in nature and such records would need to be deleted from the data set.\nYou will find the corresponding new data in 2a - Sparrow_ResettledSIMA_READY.rds (Siberia to Manitoba) and 2b - Sparrow_ResettledSIUK_READY.rds (former SIberian population from manitoba to the UK). Take note that these sets only contain records for the transferred individuals in the same order as in the old data set.\nData_df_SIMA \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2a - Sparrow_ResettledSIMA_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df_SIUK \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2b - Sparrow_ResettledSIUK_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\r With these data records, we can now re-evaluate how the characteristics of sparrows can change when subjected to different conditions than previously thus shedding light on their plasticity.\nAs such, this program is very reminiscent of the resettling program in our last exercise when using Wilcoxon Signed Rank Test to account for plasticity of our sparrow individuals. This new program includes the additional step of transferring sparrows via Manitoba first. Why have we chosen this order of resettlements?\n Our stations SI, MA and UK are all on roughly the same latitude. Moving the sparrows from SI to UK via MA results in them experiencing a gradient from continental to semi-coastal to coastal climate. Whilst Siberia is populated by avian predators, no predators are present at Manitoba and our sparrows are subject to non-avian predation in the UK.  All of this serves to maximise variation that we want to research whilst minising constraining factors.\nClimate Warming/Extremes Does sparrow morphology change depend on climate?\nThinking back to out Wilcoxon Signed Rank test, we can already argue that weight records of sparrows should change according to climate whilst height and wing chord records should remain unaltered for every individual.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Since this involves testing three seperate criterions of sparrow morphology, we again establish a user-defined function. This one is called AutomatedFried() and has dropped the Groups argument that was present in AutomatedKruskal() since the grouping will always be our three stations:\nAutomatedFried \u0026lt;- function(Variables, Plotting){\r# establish data frame to save results to\rExport \u0026lt;- data.frame(\rVariables = Variables,\rGrouped_by = rep(\u0026quot;Resettling\u0026quot;, length(Variables)),\rChi_Squared = rep(NA, length(Variables)),\rDF = rep(NA, length(Variables)),\rp_value = rep(NA, length(Variables))\r)\rfor(i in 1:length(Variables)){\r# extract data and groups from data frame\rYDataSI \u0026lt;- Data_df[,which(colnames(Data_df)==Variables[i])]\rYDataMA \u0026lt;- Data_df_SIMA[,which(colnames(Data_df)==Variables[i])]\rYDataUK \u0026lt;- Data_df_SIUK[,which(colnames(Data_df)==Variables[i])]\rData \u0026lt;- matrix(c(YDataSI[which(Data_df$Index == \u0026quot;SI\u0026quot;)],\rYDataMA, YDataUK), nrow = dim(Data_df_SIMA)[1],\rbyrow = FALSE, dimnames = list(1:dim(Data_df_SIMA)[1], c(\u0026quot;SI\u0026quot;, \u0026quot;MA\u0026quot;, \u0026quot;UK\u0026quot;))\r)\r# fill data frame\rExport[i, 3] \u0026lt;- friedman.test(Data)[[\u0026quot;statistic\u0026quot;]][[\u0026quot;Friedman chi-squared\u0026quot;]]\rExport[i, 4] \u0026lt;- friedman.test(Data)[[\u0026quot;parameter\u0026quot;]]\rExport[i, 5] \u0026lt;- friedman.test(Data)[[\u0026quot;p.value\u0026quot;]]\r# optional plotting\rif(Plotting == TRUE){\r# prepare plotting data\rPlotData \u0026lt;- as.vector(Data)\rGrouping \u0026lt;- as.factor(\rrep(c(\u0026quot;SI\u0026quot;, \u0026quot;MA\u0026quot;, \u0026quot;UK\u0026quot;), each = dim(Data_df_SIMA)[1])\r)\r# plotting\rplot(PlotData ~ Grouping, ylab = Variables[i])\r}\r} # end of i loop\r# return data frame to R outside of function\rreturn(Export)\r} # end of function\r As such, the above function operates a lot like the earlier user-defined counterpart for the Kruskal-Wallis Test. It returns the important test characteristics and allows for plots. Internally, however, it is built on a matrix rather than vectors.\nLet\u0026rsquo;s get to testing our prediction:\npar(mfrow = c(3,1)) # adjust plotting panes\rAutomatedFried(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Weight Resettling 97.84848 2 5.655506e-22\r## 2 Height Resettling NaN 2 NaN\r## 3 Wing.Chord Resettling NaN 2 NaN\r Indeed, whilst climate is a good predictor for the weight of resettled sparrows (weight in continental climates is higher than in semi-coastal or coastal ones), height and wing chord records couldn\u0026rsquo;t be properly tested on using the friedman.test() function since they have remained unalterd. Thetrefore, we reject the null hypothesis for weight records of Passer domesticus and accept the null hypothesis for height and wing chord records.\nPredation Does nesting height depend on predator characteristics?\nAccording to the results of our last practical, we would assume Passer doemsticus to adhere to local conditions when chosing a nesting site and corresponding nesting height depending on predator presence:\nAutomatedFried(Variables = \u0026quot;Nesting.Height\u0026quot;, Plotting = TRUE)\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Nesting.Height Resettling 10.864 2 0.004374338\r Just like we expected, nesting height of resettled sparrows depends hugely on predator presence at the sties they have been moved to (p = $7.3991389\\times 10^{-19}$) and we reject the null hypothesis.\nCompetition Does home range depend on climate?\nAs we\u0026rsquo;ve seen in our last seminar, a statistically signficant change in home ranges did not occur when resettling Siberian sparrows directly to the UK. How about when we resettle them via Manitoba?\nData_df_SIMA$Home.Range \u0026lt;- as.numeric(Data_df_SIMA$Home.Range)\rData_df_SIUK$Home.Range \u0026lt;- as.numeric(Data_df_SIUK$Home.Range)\rAutomatedFried(Variables = \u0026quot;Home.Range\u0026quot;, Plotting = TRUE)\r ## Warning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion\r ## Variables Grouped_by Chi_Squared DF p_value\r## 1 Home.Range Resettling 132 2 2.170522e-29\r With our three-step resettling program we do record a statistically significant change in home ranges of our sparrow flocks and reject the null hypothesis (p = $2.170522\\times 10^{-29}$).\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"b1f25db0c434a6cebf786b25f4586fd1","permalink":"https://www.erikkusch.com/courses/biostat101/ordinal-metric-tests-more-than-two-sample-situations/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/ordinal-metric-tests-more-than-two-sample-situations/","section":"courses","summary":"Welcome to our fifth practical experience in R. Throughout the following notes, I will introduce you to a couple statistical approaches for metric or ordinal data when wanting to compare more than two samples/populations that might be useful to you and are, to varying degrees, often used in biology. To do so, I will enlist the sparrow data set we handled in our first exercise.","tags":["R","Statistics"],"title":"Ordinal \u0026 Metric Tests (More-Than-Two-Sample Situations)","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Monsters \u0026amp; Mixtures Material  \rSlides Chapter 12  Introduction These are answers and solutions to the exercises at the end of chapter 12 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from\nthe solutions provided to instructors by Richard McElreath himself.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(rstan)\rlibrary(ggplot2)\rlibrary(tidybayes)\r Easy Exercises Practice E1 Question: What is the difference between an ordered categorical variable and an unordered one? Define and then give an example of each.\nAnswer:\nOrdered categorical variables are those which are expressed on ordinal scales. Not very helpful, right? Well, these are variables which establish a pre-defined number of distinct outcomes. These may be expressed as numbers, but don\u0026rsquo;t have to be. What\u0026rsquo;s special about these variables is that their values (i.e. categories) can be ordered meaningfully from one extreme to the another without implying equal distances between the values. As an example, think of sparrow (Passer domesticus) weight. We may have measured these in grams (as a continuous variable), but now want to model simply whether our sparrows are light-, medium-, or heavy-weights. This is an ordered categorical variable because we now how they can be ordered from one extreme to another, but we don\u0026rsquo;t assume that a sparrow has to become heavier by the same margin to classify as medium-weight instead of light-weight than to classify as heavy-weight instead of medium-weight.\nUnordered categorical variables are much like their ordered counterpart, but come with an important distinction: we cannot order these in any meaningful way. Again, think of the common house sparrow (Passer domesticus) and their colouration patterns. We may want to record them as overall black, brown, or grey. These are categories, but we certainly cannot order these from one extreme to another.\nPractice E2 Question: What kind of link function does an ordered logistic regression employ? How does it differ from an ordinary logit link?\nAnswer:\nCumulative logit - $OrdLogit( = \\phi, K)$. This link function defines a number of $K-1$ cumulative, proportional probabilities ($\\phi$) of each outcome category. The $K-1$ $\\phi_i$ sum up to 1 so that the $\\phi_K = 1$ and can subsequently be dropped from the model. The link thus states that the linear model defines the log-cumulative odds of an event.\nPractice E3 Question: When count data are zero-inflated, using a model that ignores zero-inflation will tend to induce which kind of inferential error?\nAnswer:\nUnder-prediction of the true rate of events. Zero-inflation means that counts of zero arise through more than one process at least one of which is not accounted for in our model. Subsequently our estimate of the true rate will be pushed closer to 0 than it truly is.\nPractice E4 Question: Over-dispersion is common in count data. Give an example of a natural process that might produce over-dispersed counts. Can you also give an example of a process that might produce under- dispersed counts?\nAnswer:\nOver-dispersion often comes about as a result of heterogeneity in rates across different sampling units/systems. As an example, think of lizard counts in different patches of a dryland area over a given period of time. The resulting count data will likely be over-dispersed since the rate at which lizards are observed will vary strongly across the different study sites.\nUnder-dispersion, on the other hand, shows less variation in the rates than would be expected. This is often the case when autocrrelation plays a role. For example, if we track our lizard abundances at each patch through time in half-day intervals, we are likely to end up with highly autocorrelated and under-dispersed counts/rates for each study site.\nMedium Exercises Practice M1 Question: At a certain university, employees are annually rated from 1 to 4 on their productivity, with 1 being least productive and 4 most productive. In a certain department at this certain university in a certain year, the numbers of employees receiving each rating were (from 1 to 4): 12, 36, 7, 41. Compute the log cumulative odds of each rating.\nAnswer:\nn \u0026lt;- c(12, 36, 7, 41) # assignment\rq \u0026lt;- n / sum(n) # proportions\rp \u0026lt;- cumsum(q) # cumulative proportions\ro \u0026lt;- p / (1 - p) # cumulative odds\rlog(o) # log-cumulative odds\r ## [1] -1.9459101 0.0000000 0.2937611 Inf\r Practice M2 Question: Make a version of Figure 12.5 for the employee ratings data given just above.\nAnswer:\n# plot raw proportions\rplot(1:4, p,\rxlab = \u0026quot;rating\u0026quot;, ylab = \u0026quot;cumulative proportion\u0026quot;,\rxlim = c(0.7, 4.3), ylim = c(0, 1), xaxt = \u0026quot;n\u0026quot;, cex = 3\r)\raxis(1, at = 1:4, labels = 1:4)\r# plot gray cumulative probability lines\rfor (x in 1:4) lines(c(x, x), c(0, p[x]), col = \u0026quot;gray\u0026quot;, lwd = 4)\r# plot blue discrete probability segments\rfor (x in 1:4) lines(c(x, x) + 0.1, c(p[x] - q[x], p[x]), col = \u0026quot;slateblue\u0026quot;, lwd = 4)\r# add number labels\rtext(1:4 + 0.2, p - q / 2, labels = 1:4, col = \u0026quot;slateblue\u0026quot;, cex = 3)\r Practice M3 Question: Can you modify the derivation of the zero-inflated Poisson distribution (ZIPoisson) from the chapter to construct a zero-inflated binomial distribution?\nAnswer:\nLet\u0026rsquo;s remind ourselves of the ZI-Poisson distribution from the chapter:\n$$ ZIPoisson(p, \\lambda) $$\nwith:\n p = probability of no count generating process occurring λ = rate at which counts are produced when process occurs  This is an extension of the Poisson distribution which is in itself a special version of the Binomial distribution with many trials and a low success rate. The zero-inflated Poisson may also be expressed as ($F$ and $S$ indicate binomial process has succeeded or failed in prohibiting the poisson process from happening, respectively):\n$$Pr(0|p_0, λ) = Pr(F|p_0) + Pr(S|p_0)*Pr(0|λ) = p_0 + (1 − p_0) * exp(−λ)$$ For zero-observations.\n$$Pr(y|y\u0026gt;0,p_0,\\lambda) = Pr(S|p_0)(0) + Pr(F|p_0)*Pr(y|\\lambda) = (1-p_0)\\frac{\\lambda^yexp(-\\lambda)}{y!}$$ For non zero-observations.\nSo how do we now get to a binomial specification here? By changing the Poisson likelihood ($exp(−λ)$) to a Binomial likelihood ($(1 − q)^n$ with $q$ denoting the probability of success):\n$$Pr(0|p_0, q, n) = p_0 + (1 − p_0)(1 − q)^n$$ For zero-observations.\n$$Pr(y|p_0, q, n) = (1 − p_0) Binom(y, n, q) = (1 − p_0) \\frac{n!}{y!(n − y)!}*q^y(1 − q)^{n−y}$$ For non zero-observations.\nHard Exercises Practice H1 Question: In 2014, a paper was published that was entitled “Female hurricanes are deadlier than male hurricanes.” As the title suggests, the paper claimed that hurricanes with female names have caused greater loss of life, and the explanation given is that people unconsciously rate female hurricanes as less dangerous and so are less likely to evacuate. Statisticians severely criticized the paper after publication. Here, you’ll explore the complete data used in the paper and consider the hypothesis that hurricanes with female names are deadlier. Load the data with:\nlibrary(rethinking)\rdata(Hurricanes)\r Acquaint yourself with the columns by inspecting the help ?Hurricanes. In this problem, you’ll focus on predicting deaths using femininity of each hurricane’s name.\nFit and interpret the simplest possible model, a Poisson model of deaths using femininity as a predictor. You can use quap or ulam. Compare the model to an intercept-only Poisson model of deaths. How strong is the association between femininity of name and deaths? Which storms does the model fit (retrodict) well? Which storms does it fit poorly?\nAnswer: First, let\u0026rsquo;s prepare the data:\nd \u0026lt;- Hurricanes # load data on object called d\rd$fem_std \u0026lt;- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity\rdat \u0026lt;- list(D = d$deaths, F = d$fem_std)\r Now that we have standardised data for the feminity of our hurricane names which makes priors easier to formulate, we can specify our initial model idea:\n# model formula\rf \u0026lt;- alist(\rD ~ dpois(lambda), # poisson outcome distribution\rlog(lambda) \u0026lt;- a + bF * F, # log-link for lambda with linear model\r# priors in log-space, 0 corresponds to outcome of 1\ra ~ dnorm(1, 1),\rbF ~ dnorm(0, 1)\r)\r But are these priors any good? Let\u0026rsquo;s simulate them why don\u0026rsquo;t we:\nN \u0026lt;- 1e3\ra \u0026lt;- rnorm(N, 1, 1)\rbF \u0026lt;- rnorm(N, 0, 1)\rF_seq \u0026lt;- seq(from = -2, to = 2, length.out = 30) # sequence from -2 to 2 because femininity data is standardised\rplot(NULL,\rxlim = c(-2, 2), ylim = c(0, 500),\rxlab = \u0026quot;name femininity (std)\u0026quot;, ylab = \u0026quot;deaths\u0026quot;\r)\rfor (i in 1:N) {\rlines(F_seq,\rexp(a[i] + bF[i] * F_seq), # inverse link to get outcome scale\rcol = grau(), lwd = 1.5\r)\r}\r I\u0026rsquo;d think that\u0026rsquo;s pretty alright. We allow for both positive and negative trends between death toll and femininity of hurricane name, but don\u0026rsquo;t have a lot of explosive trends in our priors. These strong trends are quite unintuitive. Our vast majority of trends however are very ambiguous and so I proceed with these priors and run the model:\nmH1 \u0026lt;- ulam(f, data = dat, chains = 4, cores = 4, log_lik = TRUE)\rprecis(mH1)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a 2.9994821 0.02344260 2.9612043 3.0356100 1145.726 0.9982237\r## bF 0.2386957 0.02488145 0.1994521 0.2784917 1371.036 0.9996256\r So according to this, there is a positive relationship between hurricane name femininity and death toll. Which hurricanes do we actually retrodict well, though? Let\u0026rsquo;s plot, this:\n# plot raw data\rplot(dat$F, dat$D,\rpch = 16, lwd = 2,\rcol = rangi2, xlab = \u0026quot;femininity (std)\u0026quot;, ylab = \u0026quot;deaths\u0026quot;\r)\r# compute model-based trend\rpred_dat \u0026lt;- list(F = seq(from = -2, to = 2, length.out = 1e2))\rlambda \u0026lt;- link(mH1, data = pred_dat) # predict deaths\rlambda.mu \u0026lt;- apply(lambda, 2, mean) # get mean prediction\rlambda.PI \u0026lt;- apply(lambda, 2, PI) # get prediction interval\r# superimpose trend\rlines(pred_dat$F, lambda.mu)\rshade(lambda.PI, pred_dat$F)\r# compute sampling distribution\rdeaths_sim \u0026lt;- sim(mH1, data = pred_dat) # simulate posterior observations\rdeaths_sim.PI \u0026lt;- apply(deaths_sim, 2, PI) # get simulation interval\r# superimpose sampling interval as dashed lines\rlines(pred_dat$F, deaths_sim.PI[1, ], lty = 2)\rlines(pred_dat$F, deaths_sim.PI[2, ], lty = 2)\r Ok. There is quite a bit to unpack here. First of all, our model does not retrodict many of the hurricanes well even though it is quite certain of its predictions (grey shaded area which is hardly visible). Quite obviously, this model misses many of the hurricane death tolls to the right hand side of the above plot. This is a clear sign of over-dispersion which our model failed to account for. The weak, positive trend we are seeing here seems to be informed largely by these highly influential data points. We can assess whether and how influential some data points are with the Paraeto-K values (anything above 1 indicates an influential data point) following:\nggplot(as.data.frame(PSISk(mH1)), aes(x = PSISk(mH1))) +\rstat_halfeye() +\rtheme_bw() +\rlabs(title = \u0026quot;Paraeto-K values\u0026quot;, subtitle = \u0026quot;Values \u0026gt; 1 indicate highly influential data\u0026quot;)\r Boy! Some hurricanes really do drive our model to a big extent!\nPractice H2 Question: Counts are nearly always over-dispersed relative to Poisson. So fit a gamma-Poisson (aka negative-binomial) model to predict deaths using femininity. Show that the over-dispersed model no longer shows as precise a positive association between femininity and deaths, with an 89% interval that overlaps zero. Can you explain why the association diminished in strength?\nAnswer: To start this off, I load the library and data again, so much of the exercise and my solutions can stand by itself:\nlibrary(rethinking)\rdata(Hurricanes)\rd \u0026lt;- Hurricanes # load data on object called d\rd$fem_std \u0026lt;- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity\rdat \u0026lt;- list(D = d$deaths, F = d$fem_std)\r Again, with the data prepared, we fit our model - the same model as before just with a different outcome distribution:\nmH2 \u0026lt;- ulam(\ralist(\rD ~ dgampois(lambda, scale),\rlog(lambda) \u0026lt;- a + bF * F,\ra ~ dnorm(1, 1),\rbF ~ dnorm(0, 1),\rscale ~ dexp(1) # strictly positive hence why exponential prior\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE\r)\rprecis(mH2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a 2.9780290 0.15272205 2.73722408 3.2334449 1908.835 0.9989114\r## bF 0.2107239 0.15442227 -0.04075382 0.4566408 1737.246 0.9993676\r## scale 0.4532751 0.06226293 0.35889278 0.5579919 1897.214 1.0003374\r Cool. Our previously identified positive relationship between standardised femininity of hurricane name and death toll is still there albeit slightly diminished in magnitude. However, the credible interval around it has widened considerably and overlaps zero now.\nLet\u0026rsquo;s compare the estimates of our models side by side:\nplot(coeftab(mH1, mH2))\r These shows quite clearly how our new model is much more uncertain of the parameters.\nSo what about the predictions of this new model? I plot them the exact same way as previously:\n# plot raw data\rplot(dat$F, dat$D,\rpch = 16, lwd = 2,\rcol = rangi2, xlab = \u0026quot;femininity (std)\u0026quot;, ylab = \u0026quot;deaths\u0026quot;\r)\r# compute model-based trend\rpred_dat \u0026lt;- list(F = seq(from = -2, to = 2, length.out = 1e2))\rlambda \u0026lt;- link(mH2, data = pred_dat)\rlambda.mu \u0026lt;- apply(lambda, 2, mean)\rlambda.PI \u0026lt;- apply(lambda, 2, PI)\r# superimpose trend\rlines(pred_dat$F, lambda.mu)\rshade(lambda.PI, pred_dat$F)\r# compute sampling distribution\rdeaths_sim \u0026lt;- sim(mH2, data = pred_dat)\rdeaths_sim.PI \u0026lt;- apply(deaths_sim, 2, PI)\r# superimpose sampling interval as dashed lines\rlines(pred_dat$F, deaths_sim.PI[1, ], lty = 2)\rlines(pred_dat$F, deaths_sim.PI[2, ], lty = 2)\r What\u0026rsquo;s there left to say other than: \u0026ldquo;Look at that increased uncertainty of our model\u0026rdquo; at this point? Well, we can talk about the accuracy of our predictions. They still blow. The uncertainty of our model is nice and all, but with a predictive accuracy like this why would we trust the model?\nFor now, let\u0026rsquo;s turn to the conceptual part of this exercise: \u0026ldquo;Why has the association diminished with the new model?\u0026rdquo; The question comes down to understanding what the gamma distribution does to our model. The gamma distribution allows for a death rate to be calculated for each outcome individually rather than one overall death rate for all hurricanes. These individual rates are sampled from a common distribution which is a function of the femininity of hurricane names. As a matter of fact, we can plot this:\npost \u0026lt;- extract.samples(mH2)\rpar(mfrow = c(1, 3))\rfor (fem in -1:1) {\rfor (i in 1:1e2) {\rcurve(dgamma2(\rx, # where to calculate density\rexp(post$a[i] + post$bF[i] * fem), # linear model with inverse link applied\rpost$scale[i] # scale for gamma\r),\rfrom = 0, to = 70, xlab = \u0026quot;mean deaths\u0026quot;, ylab = \u0026quot;Density\u0026quot;,\rylim = c(0, 0.19), col = col.alpha(\u0026quot;black\u0026quot;, 0.2),\radd = ifelse(i == 1, FALSE, TRUE)\r)\r}\rmtext(concat(\u0026quot;femininity = \u0026quot;, fem))\r}\r These are the gamma distributions samples from the posterior distribution of death rates when assuming same femininity of name for all of them at three different levels of femininity. Yes, a distribution sampled from another distribution. The above plots simply show the uncertainty of which gamma distribution to settle on.\nSince our model and gamma distributions are informed by a, bF, and the scale for the gamma distribution at the same time many combinations of a and bF are consistent with the data which results in a wider posterior distribution.\nFinally, let\u0026rsquo;s look at Paraeto-K values and potentially influential data again:\nggplot(as.data.frame(PSISk(mH2)), aes(x = PSISk(mH2))) +\rstat_halfeye() +\rtheme_bw() +\rlabs(title = \u0026quot;Paraeto-K values\u0026quot;, subtitle = \u0026quot;Values \u0026gt; 1 indicate highly influential data\u0026quot;)\r MUCH BETTER than before!\nPractice H3 Question: In order to infer a strong association between deaths and femininity, it’s necessary to include an interaction effect. In the data, there are two measures of a hurricane’s potential to cause death: damage_norm and min_pressure. Consult ?Hurricanes for their meanings. It makes some sense to imagine that femininity of a name matters more when the hurricane is itself deadly. This implies an interaction between femininity and either or both of damage_norm and min_pressure. Fit a series of models evaluating these interactions. Interpret and compare the models. In interpreting the estimates, it may help to generate counterfactual predictions contrasting hurricanes with masculine and feminine names. Are the effect sizes plausible?\nAnswer: To start this off, I load the library and data again, so much of the exercise and my solutions can stand by itself:\nlibrary(rethinking)\rdata(Hurricanes)\rd \u0026lt;- Hurricanes # load data on object called d\rd$fem_std \u0026lt;- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity\rdat \u0026lt;- list(D = d$deaths, F = d$fem_std)\rdat$P \u0026lt;- standardize(d$min_pressure)\rdat$S \u0026lt;- standardize(d$damage_norm)\r The data is ready and I step into my model fitting procedure. Here, I start with a basic model which builds on the previous gamma-Poisson model by adding an interaction between femininity and min_pressure:\nmH3a \u0026lt;- ulam(\ralist(\rD ~ dgampois(lambda, scale),\rlog(lambda) \u0026lt;- a + bF * F + bP * P + bFP * F * P,\ra ~ dnorm(1, 1),\rc(bF, bP, bFP) ~ dnorm(0, 1),\rscale ~ dexp(1)\r),\rdata = dat, cores = 4, chains = 4, log_lik = TRUE\r)\rprecis(mH3a)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a 2.7499528 0.13739615 2.53479738 2.9731015 2057.085 0.9990744\r## bFP 0.2991240 0.14883183 0.06678460 0.5242145 1849.512 1.0007366\r## bP -0.6715712 0.13597028 -0.88624645 -0.4539281 1894.311 1.0002580\r## bF 0.3027293 0.14148646 0.08381879 0.5332170 1953.726 0.9999575\r## scale 0.5523986 0.08078761 0.42818191 0.6867295 1985.855 0.9987496\r As minimum pressure gets lower, a storm grows stronger (I was confused by that myself when answering these exercises). Quite obviously, the lower the pressure in a storm, the more severe the storm, and the more people die which is reflected by the negative value in bP. bF is still estimated to be positive. This time, the interval doesn\u0026rsquo;t even overlap zero. Meanwhile, the interaction effect bFP is positive. I find it hard to interpret this so I\u0026rsquo;d rather plot some predictions against real data:\nP_seq \u0026lt;- seq(from = -3, to = 2, length.out = 1e2) # pressure sequence\r# 'masculine' storms\rd_pred \u0026lt;- data.frame(F = -1, P = P_seq)\rlambda_m \u0026lt;- link(mH3a, data = d_pred)\rlambda_m.mu \u0026lt;- apply(lambda_m, 2, mean)\rlambda_m.PI \u0026lt;- apply(lambda_m, 2, PI)\r# 'feminine' storms\rd_pred \u0026lt;- data.frame(F = 1, P = P_seq)\rlambda_f \u0026lt;- link(mH3a, data = d_pred)\rlambda_f.mu \u0026lt;- apply(lambda_f, 2, mean)\rlambda_f.PI \u0026lt;- apply(lambda_f, 2, PI)\r# Plotting, sqrt() to make differences easier to spot, can't use log because there are storm with zero deaths\rplot(dat$P, sqrt(dat$D),\rpch = 1, lwd = 2, col = ifelse(dat$F \u0026gt; 0, \u0026quot;red\u0026quot;, \u0026quot;dark gray\u0026quot;),\rxlab = \u0026quot;minimum pressure (std)\u0026quot;, ylab = \u0026quot;sqrt(deaths)\u0026quot;\r)\rlines(P_seq, sqrt(lambda_m.mu), lty = 2)\rshade(sqrt(lambda_m.PI), P_seq)\rlines(P_seq, sqrt(lambda_f.mu), lty = 1, col = \u0026quot;red\u0026quot;)\rshade(sqrt(lambda_f.PI), P_seq, col = col.alpha(\u0026quot;red\u0026quot;, 0.2))\r Our model expects masculine (grey) storms to be less deadly, on average, than feminine (red) ones. As pressure drops (toward the rightward side of the plot above), these differences become smaller and smaller. Quite evidently, some of these storms are influencing what our model predicts much more so than others:\nggplot(as.data.frame(PSISk(mH3a)), aes(x = PSISk(mH3a))) +\rstat_halfeye() +\rtheme_bw() +\rlabs(title = \u0026quot;Paraeto-K values\u0026quot;, subtitle = \u0026quot;Values \u0026gt; 1 indicate highly influential data\u0026quot;)\r Let\u0026rsquo;s turn to the second variable we may want to add damage_norm - the damage caused by each storm:\nmH3b \u0026lt;- ulam(\ralist(\rD ~ dgampois(lambda, scale),\rlog(lambda) \u0026lt;- a + bF * F + bS * S + bFS * F * S,\ra ~ dnorm(1, 1),\rc(bF, bS, bFS) ~ dnorm(0, 1),\rscale ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE\r)\rprecis(mH3b)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a 2.56677402 0.12946975 2.36261687 2.7748946 1903.061 0.9995145\r## bFS 0.30853835 0.20499020 -0.04173134 0.6265386 2243.101 0.9994129\r## bS 1.25058627 0.21057791 0.92538673 1.5951083 1956.116 1.0003102\r## bF 0.08485749 0.12501328 -0.11660977 0.2820823 1963.489 1.0005148\r## scale 0.68529101 0.09803179 0.53525802 0.8466209 2165.010 0.9990485\r That just eradicated the effect of femininity of hurricane name (bF)! The newly added interaction parameter bFS is incredibly strong and positive. Again, let\u0026rsquo;s visualise this:\nS_seq \u0026lt;- seq(from = -1, to = 5.5, length.out = 1e2) # damage sequence\r# 'masculine' storms\rd_pred \u0026lt;- data.frame(F = -1, S = S_seq)\rlambda_m \u0026lt;- link(mH3b, data = d_pred)\rlambda_m.mu \u0026lt;- apply(lambda_m, 2, mean)\rlambda_m.PI \u0026lt;- apply(lambda_m, 2, PI)\r# 'feminine' storms\rd_pred \u0026lt;- data.frame(F = 1, S = S_seq)\rlambda_f \u0026lt;- link(mH3b, data = d_pred)\rlambda_f.mu \u0026lt;- apply(lambda_f, 2, mean)\rlambda_f.PI \u0026lt;- apply(lambda_f, 2, PI)\r# plot\rplot(dat$S, sqrt(dat$D),\rpch = 1, lwd = 2, col = ifelse(dat$F \u0026gt; 0, \u0026quot;red\u0026quot;, \u0026quot;dark gray\u0026quot;),\rxlab = \u0026quot;normalized damage (std)\u0026quot;, ylab = \u0026quot;sqrt(deaths)\u0026quot;\r)\rlines(S_seq, sqrt(lambda_m.mu), lty = 2)\rshade(sqrt(lambda_m.PI), S_seq)\rlines(S_seq, sqrt(lambda_f.mu), lty = 1, col = \u0026quot;red\u0026quot;)\rshade(sqrt(lambda_f.PI), S_seq, col = col.alpha(\u0026quot;red\u0026quot;, 0.2))\r We can clearly see how our model makes less of a distinction between masculine and feminine hurricanes overall at this point. Damage norm scales multiplicatively. The distances grow fast as we approach the rightward side of the plot. This is difficult for the model to account for. Hence why the model is underwhelming.\nSo why is the interaction effect so strong? Probably because of those 3-4 highly influential feminine storms at the upper-righthand corner of our plot above which implies that feminine storms are especially deadly when they are damaging to begin with. Personally, I don\u0026rsquo;t trust this association and would argue that there is no logical reason for it and most likely an artefact of the limited data availability.\nPractice H4 Question: In the original hurricanes paper, storm damage (damage_norm) was used directly. This assumption implies that mortality increases exponentially with a linear increase in storm strength, because a Poisson regression uses a log link. So it’s worth exploring an alternative hypothesis: that the logarithm of storm strength is what matters. Explore this by using the logarithm of damage_norm as a predictor. Using the best model structure from the previous problem, compare a model that uses log(damage_norm) to a model that uses damage_norm directly. Compare their DIC/WAIC values as well as their implied predictions. What do you conclude?\nAnswer: To start this off, I load the library and data again, so much of the exercise and my solutions can stand by itself:\nlibrary(rethinking)\rdata(Hurricanes)\rd \u0026lt;- Hurricanes # load data on object called d\rd$fem_std \u0026lt;- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity\rdat \u0026lt;- list(D = d$deaths, F = d$fem_std)\rdat$S2 \u0026lt;- standardize(log(d$damage_norm))\r Let\u0026rsquo;s fit the model as before and compare it to the previously identified best model:\nmH4 \u0026lt;- ulam(\ralist(\rD ~ dgampois(lambda, scale),\rlog(lambda) \u0026lt;- a + bF * F + bS * S2 + bFS * F * S2,\ra ~ dnorm(1, 1),\rc(bF, bS, bFS) ~ dnorm(0, 1),\rscale ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE\r)\rcompare(mH3b, mH4, func = PSIS)\r ## PSIS SE dPSIS dSE pPSIS weight\r## mH4 630.7019 31.19102 0.00000 NA 5.376913 1.000000e+00\r## mH3b 670.6361 34.19897 39.93425 13.67922 6.857192 2.130043e-09\r Model mH4 clearly outperforms the earlier (non-logarithmic) model mH3b. How do the parameter estimates look in comparison?\nplot(coeftab(mH3b, mH4),\rlabels = paste(rep(rownames(coeftab(mH3b, mH4)@coefs), each = 2),\rrep(c(\u0026quot;Norm\u0026quot;, \u0026quot;Log\u0026quot;), nrow(coeftab(mH3b, mH4)@coefs) * 2),\rsep = \u0026quot;-\u0026quot;\r)\r)\r With the log-transformed input, bFS has increased in magnitude. What do the resulting predictions look like?\nS2_seq \u0026lt;- seq(from = -3, to = 1.8, length.out = 1e2)\r# 'masculine' storms\rd_pred \u0026lt;- data.frame(F = -1, S2 = S2_seq)\rlambda_m \u0026lt;- link(mH4, data = d_pred)\rlambda_m.mu \u0026lt;- apply(lambda_m, 2, mean)\rlambda_m.PI \u0026lt;- apply(lambda_m, 2, PI)\r# 'feminine' storms\rd_pred \u0026lt;- data.frame(F = 1, S2 = S2_seq)\rlambda_f \u0026lt;- link(mH4, data = d_pred)\rlambda_f.mu \u0026lt;- apply(lambda_f, 2, mean)\rlambda_f.PI \u0026lt;- apply(lambda_f, 2, PI)\r# plot\rplot(dat$S2, sqrt(dat$D),\rpch = 1, lwd = 2, col = ifelse(dat$F \u0026gt; 0, \u0026quot;red\u0026quot;, \u0026quot;dark gray\u0026quot;),\rxlab = \u0026quot;normalized damage (std)\u0026quot;, ylab = \u0026quot;sqrt(deaths)\u0026quot;\r)\rlines(S2_seq, sqrt(lambda_m.mu), lty = 2)\rshade(sqrt(lambda_m.PI), S2_seq)\rlines(S2_seq, sqrt(lambda_f.mu), lty = 1, col = \u0026quot;red\u0026quot;)\rshade(sqrt(lambda_f.PI), S2_seq, col = col.alpha(\u0026quot;red\u0026quot;, 0.2))\r Now this model fits the data much better! Still not perfect, but much better.\nPractice H5 Question: One hypothesis from developmental psychology, usually attributed to Carol Gilligan, proposes that women and men have different average tendencies in moral reasoning. Like most hypotheses in social psychology, it is merely descriptive. The notion is that women are more concerned with care (avoiding harm), while men are more concerned with justice and rights. Culture-bound nonsense? Yes. Descriptively accurate? Maybe.\nEvaluate this hypothesis, using the Trolley data, supposing that contact provides a proxy for physical harm. Are women more or less bothered by contact than are men, in these data? Figure out the model(s) that is needed to address this question.\nAnswer: Again, let\u0026rsquo;s start by preparing the data:\nlibrary(rethinking)\rdata(Trolley)\rd \u0026lt;- Trolley\rdat \u0026lt;- list(\rR = d$response,\rA = d$action,\rI = d$intention,\rC = d$contact\r)\rdat$Gid \u0026lt;- ifelse(d$male == 1, 1L, 2L)\r Now for a model. We use the same model skeleton as provided in the book. However, this time around, we want cutpoints in our ordered, cumulative logit for both genders separately:\ndat$F \u0026lt;- 1L - d$male # indicator of femaleness to turn intercepts on and off\rmH5 \u0026lt;- ulam(\ralist(\rR ~ dordlogit(phi, cutpoints),\rphi \u0026lt;- a * F + bA[Gid] * A + bC[Gid] * C + BI * I,\rBI \u0026lt;- bI[Gid] + bIA[Gid] * A + bIC[Gid] * C,\rc(bA, bI, bC, bIA, bIC)[Gid] ~ dnorm(0, 0.5),\ra ~ dnorm(0, 0.5),\rcutpoints ~ dnorm(0, 1.5)\r),\rdata = dat, chains = 4, cores = 4\r)\rprecis(mH5, depth = 2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## bIC[1] -1.29000860 0.13002100 -1.50109161 -1.07614615 1348.3365 1.000146\r## bIC[2] -1.14842366 0.13434342 -1.36319985 -0.93345115 1163.2537 1.006455\r## bIA[1] -0.43821462 0.10411766 -0.60427628 -0.27043071 1201.4372 1.003107\r## bIA[2] -0.42253949 0.11300405 -0.59891439 -0.23526558 1156.5531 1.005345\r## bC[1] -0.47691217 0.09253044 -0.62813726 -0.32838280 1294.9094 1.000744\r## bC[2] -0.20730657 0.09595489 -0.36193206 -0.06036975 1207.3517 1.004505\r## bI[1] -0.33520753 0.07772555 -0.46098056 -0.20740598 1075.2158 1.003142\r## bI[2] -0.25819201 0.08096287 -0.39036524 -0.12766901 1026.1192 1.006898\r## bA[1] -0.59363382 0.07036947 -0.70451058 -0.48492259 1075.2269 1.005641\r## bA[2] -0.33605523 0.07724757 -0.45859501 -0.21053675 1205.2000 1.005800\r## a -0.78364935 0.08006100 -0.90628106 -0.65659045 948.2152 1.003790\r## cutpoints[1] -3.02124197 0.06328453 -3.11858791 -2.91868150 1181.9794 1.002080\r## cutpoints[2] -2.32745650 0.06074323 -2.42260517 -2.23098876 1175.2672 1.001935\r## cutpoints[3] -1.72766666 0.05885444 -1.82181068 -1.63431341 1123.8787 1.002648\r## cutpoints[4] -0.67165728 0.05700586 -0.76381567 -0.58315767 1112.3527 1.003052\r## cutpoints[5] 0.01889978 0.05633424 -0.07146169 0.10708376 1122.8518 1.003504\r## cutpoints[6] 0.94926239 0.05853165 0.85602268 1.04283590 1166.1198 1.002682\r The parameter estimates of interest here are:\n a (-0.78) - main effect of being female on cumulative log-odds. On average women, have more moral qualms about the trolley problem it seems. bC[2] (-0.21) - the interaction effect of being both female and in a contact scenario as opposed to bc[1] (-0.48) which is the same scenario but for men. Women in our set-up had less moral issues with contact events.  The latter goes against the previously stated hypothesis. Why is that? Because the people in our study are much more complex than just their genders.\nPractice H6 Question: The data in data(Fish) are records of visits to a national park. See ?Fish for details. The question of interest is how many fish an average visitor takes per hour, when fishing. The problem is that not everyone tried to fish, so the fish_caught numbers are zero-inflated. As with the monks example in the chapter, there is a process that determines who is fishing (working) and another process that determines fish per hour (manuscripts per day), conditional on fishing (working). We want to model both. Otherwise we’ll end up with an underestimate of rate of fish extraction from the park.\nYou will model these data using zero-inflated Poisson GLMs. Predict fish_caught as a function of any of the other variables you think are relevant. One thing you must do, however, is use a proper Poisson offset/exposure in the Poisson portion of the zero-inflated model. Then use the hours variable to construct the offset. This will adjust the model for the differing amount of time individuals spent in the park.\nAnswer: One last time, for this week, we prepare some data:\nlibrary(rethinking)\rdata(Fish)\rd \u0026lt;- Fish\rstr(d)\r ## 'data.frame':\t250 obs. of 6 variables:\r## $ fish_caught: int 0 0 0 0 1 0 0 0 0 1 ...\r## $ livebait : int 0 1 1 1 1 1 1 1 0 1 ...\r## $ camper : int 0 1 0 1 0 1 0 0 1 1 ...\r## $ persons : int 1 1 1 2 1 4 3 4 3 1 ...\r## $ child : int 0 0 0 1 0 2 1 3 2 0 ...\r## $ hours : num 21.124 5.732 1.323 0.548 1.695 ...\r The model I want to build will look at the following variables:\n fish_caught. This is our response variable. livebait. I suggest that using livebait increases number of fish caught. camper. I assume that being a camper increases the chances that one goes fishing, but not necessarily the number of fish caught. persons. I assume that the number of people in a group increases how many fish are caught. child. Being a child should reasonably determine both whether one fishes (I assume children fish less - call it personal bias) and also that they are less effective than adults. hours. How long one fishes surely determines how many fish are caught. I want to include the base rate of these into my model of fish caught. Since said model will be log-linked, I log-transform them.  Let me fit that model:\nd$loghours \u0026lt;- log(d$hours)\rmH6 \u0026lt;- ulam(\ralist(\r# outcome distribution\rfish_caught ~ dzipois(p, mu),\r# linear model for probability of fishing\rlogit(p) \u0026lt;- a0 + bC0 * camper + bc0 * child,\r# linear model of catching a number of fish\rlog(mu) \u0026lt;- a + bb * livebait + bp * persons + bc * child + bl * loghours,\rc(a0, a) ~ dnorm(0, 1),\rc(bC0, bc0, bb, bp, bc, bl) ~ dnorm(0, 0.5)\r),\rdata = d, chains = 4, cores = 4, log_lik = TRUE\r)\rprecis(mH6)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -2.0839466 0.24408479 -2.4814597 -1.6945336 899.9998 1.0016629\r## a0 -0.4650216 0.28849629 -0.9436559 -0.0177434 1191.0483 1.0015268\r## bl 0.1701858 0.03428906 0.1134792 0.2254237 1255.6829 0.9985511\r## bc -0.8280833 0.10732217 -0.9969186 -0.6569452 1218.3750 1.0024020\r## bp 0.8625626 0.04553091 0.7919523 0.9330040 1479.7715 0.9990951\r## bb 1.4076543 0.19237711 1.1106049 1.7217943 1169.0384 1.0032455\r## bc0 0.9787908 0.23529584 0.6059568 1.3537809 1292.4802 0.9994360\r## bC0 -0.6597597 0.29791643 -1.1313113 -0.1803763 1413.3364 1.0017523\r Remember that $p$ stands for the probability of not going to fish. Overall, park visitors are pretty likely to fish (a0 =-0.47, logit scale). In line with my intuition, campers are more likely to fish (bC0) while children are less likely to fish (bc0).\nOnce one is actually fishing, one is not likely to catch much fish (a=-2.08). The parameters pertaining to number of fish caught are expressed on log-scale and so transforming a into the outcome scale (counts of fish) by exponentiating, an adult who fishes by themselves without livebait (this is what a refers to) catches around 0.1249302 fish on average. More people catch more fish (bp). Using livebait is effective (bb). In line with my intuition, children catch less fish than adults (bc). Lastly, the more time one spends fishing, the more fish one catches (bl).\nLet\u0026rsquo;s turn to some actual model predictions of p and mu:\nzip_link \u0026lt;- link(mH6)\rstr(zip_link)\r ## List of 2\r## $ p : num [1:2000, 1:250] 0.403 0.388 0.469 0.382 0.443 ...\r## $ mu: num [1:2000, 1:250] 0.588 0.543 0.537 0.592 0.488 ...\r p cases provide estimates for additional zeros not obtained through the actual Poisson-process behind fishing catches whose output lies with mu.\nFor example, if $p =$0.39 (the inverse logit of a0 in the model above) and $μ = 1$ (much higher than a in the model above for ease here), then the implied predictive distribution is:\nzeros \u0026lt;- rbinom(\rn = 1e4, # number of samples\rsize = 1,\rprob = inv_logit(precis(mH6)[2, 1]) # probability of going fishing\r)\robs_fish \u0026lt;- (1 - zeros) * rpois(1e4, 1)\rsimplehist(obs_fish)\r Let\u0026rsquo;s see what our model would predict given the estimated parameters:\nfish_sim \u0026lt;- sim(mH6)\rstr(fish_sim)\r ## num [1:1000, 1:250] 0 0 1 1 0 0 0 2 0 1 ...\r This now contains a simulation output for each sample in our data! We could now plot ourselves into oblivion with counterfactual plots. We can also produce counterfactual posterior predictions. As an example, I assume a party of 1 adult spending 1 hour in the park without any use of livebait and not staying the night as a camper:\n# new data\rpred_dat \u0026lt;- list(\rloghours = log(1), # note that this is zero, the baseline rate\rpersons = 1,\rchild = 0,\rlivebait = 0,\rcamper = 0\r)\r# sim predictions - want expected number of fish, but must use both processes\rfish_link \u0026lt;- link(mH6, data = pred_dat)\r# summarize\rp \u0026lt;- fish_link$p\rmu \u0026lt;- fish_link$mu\r(expected_fish_mean \u0026lt;- mean((1 - p) * mu))\r ## [1] 0.1838057\r (expected_fish_PI \u0026lt;- PI((1 - p) * mu))\r ## 5% 94% ## 0.1261989 0.2553580\r This tells us that this hypothetical person is expected to catch 0.1838057 fish with the interval displayed above.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] tidybayes_2.3.1 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 tidyr_1.1.3 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 ## [10] V8_3.4.1 plyr_1.8.6 R6_2.5.0 backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 ## [19] pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 ## [28] labeling_0.4.2 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 ## [37] htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 arrayhelpers_1.1-0 codetools_0.2-18 matrixStats_0.61.0 fansi_0.4.2 ## [46] crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 distributional_0.2.2 ggdist_2.4.0 grid_4.0.5 jsonlite_1.7.2 ## [55] gtable_0.3.0 lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 farver_2.1.0 ## [64] bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.7 rematch2_2.1.2 forcats_0.5.1 tools_4.0.5 svUnit_1.0.6 R.cache_0.14.0 ## [73] glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1616630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616698800,"objectID":"a9cbfed30cba2804b1453cbdf227c313","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-12/","publishdate":"2021-03-25T00:00:00Z","relpermalink":"/courses/rethinking/chapter-12/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 12 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 12","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our sixth practical experience in R. Throughout the following notes, I will introduce you to a couple of simple parametric test. Whilst parametric tests are used extremely often in biological statistics, they can be somewhat challenging to fit to your data as you will see soon. To do so, I will enlist the sparrow data set we handled in our first exercise. Additionally, todays seminar is showing plotting via base plot instead of ggplot2 to highlight the usefulness of base plot and show you the base notation.\nI have prepared some Lecture Slides  for this session.\nData Find the data for this exercise here and here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;car\u0026quot;) # needed for the Levene Test for Homogeneity\rsapply(package_vec, install.load.package)\r ## Loading required package: car\r ## Loading required package: carData\r ## car ## TRUE\r Loading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r t-Test (unpaired) Assumptions of the unpaired t-Test:\n Predictor variable is binary Response variable is metric and normal distributed within their groups Variable values are independent (not paired)  In addition, test whether variance of response variable values in groups are equal (var.test()) and adjust t.test() argument var.equal accordingly.\nTesting For Normality And Homogeneity We need to test the distribution of our response variables within each predictor variable group for their normality and variance. Since this involves two Shapiro tests and one variance test per variable for each response variable, we might want to write our own function to do so:\nShapiroTest \u0026lt;- function(Variables, Grouping){\rOutput \u0026lt;- data.frame(x = Variables)\rfor(i in 1:length(Variables)){\rX \u0026lt;- Data_df[,Variables[i]]\rLevels \u0026lt;- levels(factor(Data_df[,Grouping]))\rOutput[i,2] \u0026lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[1])])$p.value\rOutput[i,3] \u0026lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[2])])$p.value\rOutput[i,4] \u0026lt;- var.test(x = X[which(Data_df[,Grouping] == Levels[1])], y = X[which(Data_df[,Grouping] == Levels[2])])$p.value\r}\rcolnames(Output) \u0026lt;- c(\u0026quot;Variable\u0026quot;, \u0026quot;P.value1\u0026quot;, \u0026quot;P.value2\u0026quot;, \u0026quot;Var.Test\u0026quot;)\rreturn(Output)\r}\r This function (ShapiroTest()) takes two arguments: (1) Variables - a vector of characters holding the names of the variables we want to have tested, and (2) Grouping - the binary variable by which to group our variables. The function returns a data frame holding the p-values of the Shapiro tests on each variable group values as well as the var.test() p-value.\nClimate Warming/Extremes Does sparrow morphology change depend on climate?\nUsing multiple different methods (i.e. Kruskal-Wallis and Mann-Whitney U Test), we have already identified climate (be it in its binary form or when recorded as a three-level variable) is a strong driving force of sparrow morphology. We expect the same results when using a t-Test.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Testing for Normality and Variance Before we can make use of our data with a t-Test, we need to do an assumption check. To this end, we first turn Climate records into a binary variable by turning records of a semi-coastal climate into a coastal one.\n# Make climate binary\rData_df$Climate[which(Data_df$Climate == \u0026quot;Semi-Coastal\u0026quot;)] \u0026lt;- \u0026quot;Coastal\u0026quot;\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r Let\u0026rsquo;s make sure our assumptions are met:\nShapiroTest(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;)\r ## Variable P.value1 P.value2 Var.Test\r## 1 Weight 0.1699442 0.2521182 0.326240416\r## 2 Height 0.1676977 0.3645040 0.010632158\r## 3 Wing.Chord 0.0538642 0.1722528 0.002942433\r Luckily, all of our variables allow for the calculation of t-Test. Take note though that some need different specification of the var.equal argument than others.\nAnalyses Sparrow Weight\nLet\u0026rsquo;s start with the weight of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\nt.test(Data_df$Weight ~ Data_df$Climate, var.equal = TRUE)\r ## ## Two Sample t-test\r## ## data: Data_df$Weight by Data_df$Climate\r## t = -14.852, df = 381, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## -2.428439 -1.860640\r## sample estimates:\r## mean in group Coastal mean in group Continental ## 31.23383 33.37837\r According to our analysis, which has us reject the null hypothesis, we conclude that binary climate records are valuable information criteria for predicting sparrow weight with sparrows in coastal climates being lighter than sparrows in continental ones thus effectively varifying the results of our non-parametric approaches (Kruskal-Wallis, Mann-Whitney U).\nSparrow Height\nLet\u0026rsquo;s move on to the height of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\nt.test(Data_df$Height ~ Data_df$Climate, var.equal = FALSE)\r ## ## Welch Two Sample t-test\r## ## data: Data_df$Height by Data_df$Climate\r## t = -0.27916, df = 365.69, p-value = 0.7803\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## -0.2329126 0.1750052\r## sample estimates:\r## mean in group Coastal mean in group Continental ## 13.91670 13.94565\r Confirming the results of our Mann-Whitney U Test, we accept the null hypothesis.\nSparrow Wing Chord\nLastly, we test the wing chords of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\nt.test(Data_df$Wing.Chord ~ Data_df$Climate, var.equal = FALSE)\r ## ## Welch Two Sample t-test\r## ## data: Data_df$Wing.Chord by Data_df$Climate\r## t = -0.12285, df = 370.22, p-value = 0.9023\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## -0.03985039 0.03516377\r## sample estimates:\r## mean in group Coastal mean in group Continental ## 6.898696 6.901039\r Without confirming the results of our Mann-Whitney U Test, we accept the null hypothesis.\nConclusion\nHere\u0026rsquo;s what we\u0026rsquo;ve learned from the t-Test so far:\n Sparrow weight depends on (binary) climate types Sparrow height does not depend on (binary) climate types Sparrow wing chord does not depend on (binary) climate types  Let\u0026rsquo;s end this by viusalising all of the data:\npar(mfrow=c(2,2))\rplot(Data_df$Weight ~ Data_df$Climate)\rplot(Data_df$Height ~ Data_df$Climate)\rplot(Data_df$Wing.Chord ~ Data_df$Climate)\r Sexual Dimorphism Does sparrow morphology change depend on Sex?\nUsing the Mann-Whitney U Test, we have already identified the sex of Passer domesticus is a good information criterion for understanding sparrow weight but not sparrow height or wing chord. Let\u0026rsquo;s see if we can reproduce this using a t-Test approach.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Testing for Normality and Variance Again, before we can use our data in a t-Test for this purpose, we have to make sure that our assumptions are met. To this end, we can make use of our user defined ShapiroTest() function as follows:\nShapiroTest(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Grouping = \u0026quot;Sex\u0026quot;)\r ## Variable P.value1 P.value2 Var.Test\r## 1 Weight 2.878769e-21 1.744517e-21 0.7475085\r## 2 Height 4.028475e-17 6.600273e-19 0.4006799\r## 3 Wing.Chord 3.438104e-25 1.628147e-26 0.5554935\r As it turns out, our data does not allow for any t-Test (this happens often in real studies). However, we can create sex-driven subgroups within each site and test whether these meet the requirements for our t-Test. This is out of the scope of this course though and so we will skip it. Spoler alert: I have done this and the findings did not reveal anything we didn\u0026rsquo;t uncover so far.\nt-Test (paired) Assumptions of the paired t-Test:\n Predictor variable is binary Response variable is metric Difference of response variable pairs is normal distributed Variable values are dependent (paired)  Preparing Data For this purpose, we need an additional data set with truly paired records of sparrows and so we implement the same solution as we\u0026rsquo;ve used within our fourth seminar using the Wilcoxon Signed Rank Test. Within our study set-up, think of a resettling experiment, were you take Passer domesticus individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.\nTo this end, presume we have taken the entire Passer domesticus population found at our Siberian research station and moved them to the United Kingdom. Whilst this keeps the latitude stable, the sparrows now experience a coastal climate instead of a continental one. After some time (let\u0026rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.\nYou will find the corresponding new data in 2b - Sparrow_ResettledSIUK_READY.rds. Take note that this set only contains records for the transferred individuals in the same order as in the old data set.\nData_df_Resettled \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2b - Sparrow_ResettledSIUK_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\r Since earlier analysis such as the Wilcoxon Signed Rank test (fourth practical) and the Friedman Test (fifth practical) showed that height and wing chord records do not change when sparrows are resettled at all, we have excluded these here and focus solely on sparrow weight.\nTesting for Normality Before being able to run our paired t-Test, we must make sure that the difference of response variable pairs is normal distributed. We can do so using the shapiro.test() of base R as follows:\n# selecting pre-resettling weights\rDataSI \u0026lt;- Data_df$Weight[which(Data_df$Index == \u0026quot;SI\u0026quot;)]\r# calculating difference of before and after resettling weights\rWeightDiff \u0026lt;- DataSI-Data_df_Resettled$Weight\r# shapiro test\rshapiro.test(WeightDiff)\r ## ## Shapiro-Wilk normality test\r## ## data: WeightDiff\r## W = 0.97361, p-value = 0.1716\r Thankfully, the assumption of normality is met.\nNow let\u0026rsquo;s visualise that using a qqplot:\nqqnorm(WeightDiff)\rqqline(WeightDiff)\r Climate Warming/Extremes Does sparrow morphology change depend on climate?\nNow let\u0026rsquo;s go on to test whether sparrow weights change significantly per individual due to our relocation experiment (we expect this from future test in our practicals):\nt.test(DataSI, Data_df_Resettled$Weight, paired = TRUE)\r ## ## Paired t-test\r## ## data: DataSI and Data_df_Resettled$Weight\r## t = 8.4762, df = 65, p-value = 4.17e-12\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## 1.583629 2.559914\r## sample estimates:\r## mean of the differences ## 2.071771\r We were right, individual sparrow weights change significantly after our relocation experiment and we reject the null hypothesis. This is in accordance with the results of the Wilcoxon Signed Rank Test as well as the Friedman Test.\nLet\u0026rsquo;s go on to visualise our data to make better sense of what is going on here:\n# Select the sparrow weights\rWeights \u0026lt;- c(DataSI, Data_df_Resettled$Weight)\r# Select the sites\rSites \u0026lt;- factor(rep(c(\u0026quot;SI\u0026quot;, \u0026quot;SI_UK\u0026quot;), each = length(DataSI)))\r# Plot\rplot(Weights ~ Sites)\r Quite obviously sparrows observed in Siberia are heavier than when they are resettled to the United Kingdom (this may be due to the more forgiving climate in the UK). Just like the test stated, the difference of the average weights is roughly 2g between the sparrows at the two sites.\nOne-Way ANOVA Assumptions of the One-Way ANOVA:\n Predictor variable is categorical Response variable is metric Response variable residuals are normal distributed Variance of populations/samples are equal (homogeneity) Variable values are independent (not paired)  Testing For Assumptions Firstly, we need to test the assumptions of our One-Way ANOVA. For this purpose, we write another user-defined function.\n# User-defined function\rANOVACheck \u0026lt;- function(Variables, Grouping, data, plotting){\rOutput \u0026lt;- data.frame(x = NA)\rfor(i in 1:length(Variables)){\r# data\rY \u0026lt;- as.numeric(factor(data[,Variables[i]]))\rX \u0026lt;- data[,Grouping]\rLevels \u0026lt;- levels(factor(Data_df[,Grouping]))\r# Residuals?\rmodel \u0026lt;- lm(Y ~ X)\rOutput[1,i] \u0026lt;- shapiro.test(residuals(model))$p.value\r# Homgeneity?\rLevene \u0026lt;- leveneTest(Y ~ X, center = median, data = data)\rOutput[2,i] \u0026lt;- Levene[1,3]\r# Plotting\rif(plotting == TRUE){\rplot(model, 2)# Normality\rplot(model, 3)# Homogeneity\r}\r}\rcolnames(Output) \u0026lt;- Variables\rrownames(Output) \u0026lt;- c(\u0026quot;Residual Normality\u0026quot;, \u0026quot;Homogeneity of Variances\u0026quot;)\rreturn(Output)\r}\r This ANOVACheck() function takes four arguments: (1) Variables - a vector of characters holding the names of the variables we want to have tested, (2) Grouping - the categorical variable by which to group our variables, (3) data - the data frame which contains the Variables and the Grouping factor, and (4) plotting - a logical indicator of whether to produce plots visualising the test results or not.\nThe function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (Residual Normality), and the p-values indexing whether variances between groups are homogeneous or not (Homogeneity of Variances).\nClimate Warming/Extremes Does sparrow morphology change depend on climate?\nUsing the Kruskal-Wallis Test in our last exercise, we already identified climate to be an important factor in determining Passer domesticus morphology. Let\u0026rsquo;s see if this holds true.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Assumption Check Let\u0026rsquo;s use the ANOVACheck() function on our data:\npar(mfrow=c(3,2))\rANOVACheck(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;, data = Data_df, plotting = TRUE)\r ## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\r## factor.\r## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\r## factor.\r## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\r## factor.\r ## Weight Height Wing.Chord\r## Residual Normality 0.002521771 2.671414e-05 0.001685579\r## Homogeneity of Variances 0.110120912 1.896577e-01 0.013575440\r Unfortunately, neither weight nor wing chord records fullfil our requirements.\nAnalysis Let\u0026rsquo;s run our analysis for height as grouped by the three-level climate variable:\nmodel \u0026lt;- lm(Data_df$Height ~ Data_df$Climate)\ranova(model)\r ## Analysis of Variance Table\r## ## Response: Data_df$Height\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Data_df$Climate 2 14.99 7.4942 7.2494 0.0008129 ***\r## Residuals 381 393.87 1.0338 ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r According to this, climate is a meaningful predictor of height of sparrows and we reject the null hypothesis thus confirming the results of our Kruskall-Wallis analysis.\nNow, let\u0026rsquo;s analyse the output a bit more in-depth:\nsummary(model)\r ## ## Call:\r## lm(formula = Data_df$Height ~ Data_df$Climate)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -2.98994 -0.69815 -0.01475 0.67142 2.37045 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 14.07994 0.07964 176.800 \u0026lt; 2e-16 ***\r## Data_df$ClimateContinental -0.13429 0.11426 -1.175 0.24060 ## Data_df$ClimateSemi-Coastal -0.56039 0.14755 -3.798 0.00017 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.017 on 381 degrees of freedom\r## Multiple R-squared: 0.03666,\tAdjusted R-squared: 0.0316 ## F-statistic: 7.249 on 2 and 381 DF, p-value: 0.0008129\r  The mean sparrow height in coastal climates is 14.0799387cm (this is our Intercept/Baseline) The mean sparrow height in continental climates is -0.1342893cm bigger than the Intercept The mean sparrow height in semi-coastal climates is -0.5603864cm bigger than the Intercept Only the estimates in coastal and semi-coastal climates are statistically significant  Personally, I would not place too much confidence in these results due to a couple of reasons:\n Our only semi-coastal site is on the northern hemisphere whereas two of our stations are located in the southern hemisphere Confounding factors such as population status might have an effect which we are not considering here  Let\u0026rsquo;s end this by plotting all of our data:\npar(mfrow=c(2,2))\rplot(Data_df$Weight ~ factor(Data_df$Climate))\rplot(Data_df$Height ~ factor(Data_df$Climate))\rplot(Data_df$Wing.Chord ~ factor(Data_df$Climate))\r As you can see, the variances are definitely not equal between our groups which explains why part of our assumption test failed.\nPredation Does nesting height depend on predator characteristics?\nAgain, using the Kruskal-Wallis Test in our last exercise, we already identified predator characteristics to be an important factor in determining Passer domesticus nesting height. Let\u0026rsquo;s see if this holds true.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Assumption Check Let\u0026rsquo;s use our ANOVACeck() function to test whether we can run our analysis. Before we can do so, however, we need to slightly adjust our predator type variable just like we did in our last exercise and as follows:\n# changing levels in predator type\rlevels(Data_df$Predator.Type) \u0026lt;- c(levels(Data_df$Predator.Type), \u0026quot;None\u0026quot;)\rData_df$Predator.Type[which(is.na(Data_df$Predator.Type))] \u0026lt;- \u0026quot;None\u0026quot;\r# Assumption Check\rpar(mfrow=c(1,2))\rANOVACheck(Variables = \u0026quot;Nesting.Height\u0026quot;, Grouping = \u0026quot;Predator.Type\u0026quot;, data = Data_df, plotting = TRUE)\r ## Nesting.Height\r## Residual Normality 0.0017160318\r## Homogeneity of Variances 0.0005845899\r Again, our data fails the assumption check. The residuals are definitely not normal distributed and the variance of nesting height records within our groups are not equal.\nAnalysis Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone:\nplot(Data_df$Nesting.Height ~ Data_df$Predator.Type)\r Once more, we can see why our homogeneity of variances test failed.\nTwo-Way ANOVA Assumptions of the Two-Way ANOVA:\n Predictor variables are categorical Response variable is metric Response variable residuals are normal distributed Variance of populations/samples are equal (homogeneity) Variable values are independent (not paired)  Testing For Assumptions Yet again, we need to check if our assumptions are met first. Automating this procedure is definitely a good idea and only needs slight modification from our ANOVACheck() function.\n# User-defined function\rANOVACheck_TWO \u0026lt;- function(Formulas, data, plotting){\rOutput \u0026lt;- data.frame(x = NA)\rfor(i in 1:length(Formulas)){\r# Check how many formulas there are\rif(length(Formulas) == 1){\rExpression \u0026lt;- Formulas[[1]]\r}else{\rExpression \u0026lt;- Formulas[[i]]\r}\r# Residuals?\rmodel \u0026lt;- lm(formula = Expression, data = data)\rOutput[1,i] \u0026lt;- shapiro.test(residuals(model))$p.value\r# Homgeneity?\rLevene \u0026lt;- leveneTest(Expression, center = median, data = data)\rOutput[2,i] \u0026lt;- Levene[1,3]\r# Plotting\rif(plotting == TRUE){\rplot(model, 2)# Normality\rplot(model, 3)# Homogeneity\r}\r}\rcolnames(Output) \u0026lt;- as.character(Formulas)\rrownames(Output) \u0026lt;- c(\u0026quot;RN\u0026quot;, \u0026quot;HoV\u0026quot;)\rreturn(Output)\r}\r This ANOVACheck_TWO() function takes four arguments: (1) Formulas - a vector of formula specification for our ANOVA models we want to have tested, (2) data - the data frame which contains the variables and the grouping factor called upon in our Formulas, and (3) plotting - a logical indicator of whether to produce plots visualising the test results or not.\nThe function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (RN), and the p-values indexing whether variances between groups are homogeneous or not (HoV).\nSexual Dimorphism Does sparrow morphology depend on population status and sex?\nGiven different factors affecting invasive species, we might expect different patterns of sexual dimorphism for invasive and native populations. Take note that we keep using the northern hemisphere subset our cimate testing sites as these present us with a nice set of invasive/native population records already whilst keeping confounding factors to a minimum.\nAssumption Check First, we need to check our assumptions:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r# analysis\rpar(mfrow=c(3,2))\rANOVACheck_TWO(Formulas = c(Weight ~ Population.Status*Sex, Height ~ Population.Status*Sex,\rWing.Chord ~ Population.Status*Sex)\r, data = Data_df, plotting = TRUE)\r ## Weight ~ Population.Status * Sex Height ~ Population.Status * Sex\r## RN 0.287959531 0.2171916\r## HoV 0.004492103 0.9057774\r## Wing.Chord ~ Population.Status * Sex\r## RN 0.1907782\r## HoV 0.9174340\r Again our assumptions are not met except for sparrow height and wing chord as a product of sex and population status.\nAnalysis Let\u0026rsquo;s run our analysis:\n# height model\rmodel \u0026lt;- lm(Height ~ Population.Status*Sex, data = Data_df)\ranova(model)\r ## Analysis of Variance Table\r## ## Response: Height\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F)\r## Population.Status 1 0.338 0.33820 0.3190 0.5729\r## Sex 1 0.179 0.17896 0.1688 0.6816\r## Population.Status:Sex 1 1.786 1.78585 1.6844 0.1959\r## Residuals 197 208.865 1.06023\r # wing chord model\rmodel \u0026lt;- lm(Wing.Chord ~ Population.Status*Sex, data = Data_df)\ranova(model)\r ## Analysis of Variance Table\r## ## Response: Wing.Chord\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F)\r## Population.Status 1 0.0047 0.004669 0.1955 0.6589\r## Sex 1 0.0041 0.004125 0.1727 0.6782\r## Population.Status:Sex 1 0.0399 0.039856 1.6688 0.1979\r## Residuals 197 4.7049 0.023883\r # plotting\rpar(mfrow=c(1,2))\rboxplot(Height ~ Population.Status*Sex, data = Data_df, col = c(\u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;))\rboxplot(Wing.Chord ~ Population.Status*Sex, data = Data_df, col = c(\u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;))\r As it turns out, population status and sex are no viable predictors for sparrow height or wing chord and so we accept the null hypothesis.\nANCOVA Assumptions of the ANCOVA:\n Predictor variables are categorical or continuous Response variable is metric Response variable residuals are normal distributed Variance of populations/samples are equal (homogeneity) Variable values are independent (not paired) Relationship between the response and covariate is linear.  Climate Warming/Extremes Do sparrow characteristics depend on climate and latitude?\nLatitude may have masked some effects of climate on sparrow morphology in our preceding analyses and vice-versa. At times, we have been able to account for this by including our site records, which can be seen as binned versions of latitude records. Let\u0026rsquo;s test if the inclusion of raw latitude records are meaningful.\nAssumption Check Again, we need to do an assumption check. However, we need a new function for this, since we now need to test whether our response variable and the covariate are linear or not:\n# overwriting prior changes in Data_df\rData_df \u0026lt;- Data_df_base\rData_df$Latitude \u0026lt;- abs(Data_df$Latitude)\r# User-defined function\rANCOVACheck \u0026lt;- function(Variables, Grouping, Covariate, data, plotting){\rOutput \u0026lt;- data.frame(x = NA)\rfor(i in 1:length(Variables)){\r# data\rY \u0026lt;- as.numeric(factor(data[,Variables[i]]))\rX \u0026lt;- factor(data[,Grouping])\rZ \u0026lt;- data[, Covariate]\r# Residuals?\rmodel \u0026lt;- lm(Y ~ X*Z)\rOutput[1,i] \u0026lt;- shapiro.test(residuals(model))$p.value\r# Homgeneity?\rLevene \u0026lt;- leveneTest(Y ~ X, center = median, data = data)\rOutput[2,i] \u0026lt;- Levene[1,3]\r# Plotting\rif(plotting == TRUE){\rplot(model, 1)# Linearity\rplot(model, 2)# Normality\rplot(model, 3)# Homogeneity\r}\r}\rcolnames(Output) \u0026lt;- Variables\rrownames(Output) \u0026lt;- c(\u0026quot;RN\u0026quot;, \u0026quot;HoV\u0026quot;)\rreturn(Output)\r}\r This ANCOVACheck() function takes five arguments: (1) Variables - a vector of response variables used in our models, (2) Grouping - the categorical variable by which to group our variables, (3) Covariate - the covariate of our analysis, (4)data - the data frame which contains the variables, the grouping factor and our covariate, and (5) plotting - a logical indicator of whether to produce plots visualising the test results or not.\nThe function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (RN), and the p-values indexing whether variances between groups are homogeneous or not (HoV).\nANCOVACheck(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Nesting.Height\u0026quot;, \u0026quot;Egg.Weight\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;, \u0026quot;Home.Range\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;, Covariate = \u0026quot;Latitude\u0026quot;, data = Data_df, plotting = FALSE)\r ## Weight Height Wing.Chord Nesting.Height Egg.Weight\r## RN 2.082300e-02 1.502944e-04 4.535941e-07 5.190971e-06 2.943560e-03\r## HoV 9.937376e-24 1.929783e-22 1.561040e-33 2.004612e-01 4.816355e-09\r## Number.of.Eggs Home.Range\r## RN 1.809197e-09 3.629841e-20\r## HoV 2.750100e-14 1.157673e-08\r The assumptions aren\u0026rsquo;t met. I have set the plotting argument to FALSE tu suppress the plotting of model checking visualisation. The would be useful to judge linearity but not necessary here since the other two important assumptions (Homogeneity of variances and Normality of residuals) aren\u0026rsquo;t met to begin with.\nAnalysis Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone. We need a new function for this to do our plotting easily and automatically with some colours indicating our grouping factors whilst plotting response variables versus covariates.\nPlotAncovas \u0026lt;- function(Variables, Grouping, Covariate, data){\rfor(i in 1:length(Variables)){\rY \u0026lt;- Data_df[,Variables[i]]\rif(class(Y) == \u0026quot;character\u0026quot;){Y \u0026lt;- factor(Y)}\rX \u0026lt;- Data_df[,Covariate]\rG \u0026lt;- factor(Data_df[, Grouping])\rplot(X, Y, col = G, xlab = Covariate, ylab = Variables[i])\rlegend(\u0026quot;top\u0026quot;, # place legend at the top\rinset = -0.35, # move legend away from plot centre\rxpd = TRUE, # allow legend outside of plot area\rlegend=levels(G), # what to include in legend\rbg = \u0026quot;white\u0026quot;, col = unique(G), ncol=length(levels(G)), # colours\rpch = 1, # plotting symbols\rtitle = Variables[i] # title of legend\r)\r}\r}\r The PlotAncovas() returns a scatter plot and takes four arguments: (1) Variables - a vector of response variables, (2) Grouping - the name of the grouping factor according to which to colour the symbols in our plot, (3) Covariate - the covariate against which to plot individuals variables, and (4) data - the data frame which holds our variables.\nLet\u0026rsquo;s use our function:\npar(mfrow=c(1,2))\rPlotAncovas(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Nesting.Height\u0026quot;, \u0026quot;Egg.Weight\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;, \u0026quot;Home.Range\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;, Covariate = \u0026quot;Latitude\u0026quot;, data = Data_df)\r I will not interpret these plots here in text and leave this to you.\nTake note that this could\u0026rsquo;ve been achieved much easier with ggplot2!\nSparrow Characteristics And Sites This was not part of what we set out to do according to the lecture slides but has been included as a logical conclusion to an earlier analysis.\nUnfortunately, our previous attempt at an ANCOVA didn\u0026rsquo;t work. So what other covariate do we have available for sparrow characteristics?\n Latitude doesn\u0026rsquo;t make sense to include when grouping by site index as these two are synonymous Longitude doesn\u0026rsquo;t make sense to include when grouping by site index as these two are synonymous Weight is well explained by other variables and we know the causal links Height is not that well explained by other variables Wing.Chord is not that well explained by other variables  Of course, there are more within our data set but it has become apparent that Weight may make for an important covariate in our site-wise ANCOVA set-up. Using the Pearson correlation (third practical), we already identified a causal link between sparrow Weight and Height per site.\nAssumption Check Firstly, we test whether assumptions are met. For brevities sake, we only test four variables:\npar(mfrow=c(1,3))\rANCOVACheck(Variables = c(\u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Egg.Weight\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;), Grouping = \u0026quot;Index\u0026quot;, Covariate = \u0026quot;Weight\u0026quot;, data = Data_df, plotting = TRUE)\r ## Height Wing.Chord Egg.Weight Number.of.Eggs\r## RN 1.499909e-06 5.251393e-08 0.1565038171 9.220862e-07\r## HoV 3.594021e-13 2.434880e-01 0.0002015813 2.660146e-02\r As it turns out, we can run our ANCOVA on Egg.Weight when grouped by site Index and driven by Weight.\nAnalysis First, let\u0026rsquo;s visualise our data:\nPlotAncovas(Variables = \u0026quot;Egg.Weight\u0026quot;, Grouping = \u0026quot;Index\u0026quot;, Covariate = \u0026quot;Weight\u0026quot;, data = Data_df)\r Quite obviously, Belize (BE) records are very different from the other stations, whose egg weight and weight records are grouped together. There seems to be some evidence for an overall linkage of sparrow weight and egg weight (a positive correlation).\nNow we run the analysis:\nLM_fit5 \u0026lt;- lm(Egg.Weight ~ Weight*Index, data = Data_df)\ranova(LM_fit5)\r ## Analysis of Variance Table\r## ## Response: Egg.Weight\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Weight 1 52.531 52.531 1442.5616 \u0026lt;2e-16 ***\r## Index 10 8.087 0.809 22.2064 \u0026lt;2e-16 ***\r## Weight:Index 10 0.129 0.013 0.3536 0.9653 ## Residuals 455 16.569 0.036 ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r The above ANCOVA output tells us that there is no interaction effect between sites and sparrow weights when determining mean egg weight per nest of Passer domesticus and so we do another iteration of our model and remove the postulated interaction:\nLM_fit6 \u0026lt;- lm(Egg.Weight ~ Weight+Index, data = Data_df)\ranova(LM_fit6)\r ## Analysis of Variance Table\r## ## Response: Egg.Weight\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Weight 1 52.531 52.531 1462.898 \u0026lt; 2.2e-16 ***\r## Index 10 8.087 0.809 22.519 \u0026lt; 2.2e-16 ***\r## Residuals 465 16.698 0.036 ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r By now, all of our model coefficients are significant and we can go on to interpret them:\nsummary(LM_fit6)\r ## ## Call:\r## lm(formula = Egg.Weight ~ Weight + Index, data = Data_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.58887 -0.13146 -0.00621 0.12033 0.55135 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 3.345984 0.280826 11.915 \u0026lt; 2e-16 ***\r## Weight 0.001081 0.008614 0.125 0.900203 ## IndexBE -0.708478 0.054864 -12.913 \u0026lt; 2e-16 ***\r## IndexFG -1.281168 0.099135 -12.923 \u0026lt; 2e-16 ***\r## IndexFI -0.625287 0.057442 -10.885 \u0026lt; 2e-16 ***\r## IndexLO -0.550137 0.051754 -10.630 \u0026lt; 2e-16 ***\r## IndexMA -0.513645 0.051352 -10.003 \u0026lt; 2e-16 ***\r## IndexNU -0.517015 0.053365 -9.688 \u0026lt; 2e-16 ***\r## IndexRE -0.612632 0.051418 -11.915 \u0026lt; 2e-16 ***\r## IndexSA -0.806045 0.056685 -14.220 \u0026lt; 2e-16 ***\r## IndexSI -0.272580 0.077868 -3.501 0.000509 ***\r## IndexUK -0.511667 0.051404 -9.954 \u0026lt; 2e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 0.1895 on 465 degrees of freedom\r## (590 observations deleted due to missingness)\r## Multiple R-squared: 0.784,\tAdjusted R-squared: 0.7789 ## F-statistic: 153.5 on 11 and 465 DF, p-value: \u0026lt; 2.2e-16\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"d96dc1ec32a37fc03888b2364cdf343a","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/simple-parametric-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/simple-parametric-tests/","section":"courses","summary":"Welcome to our sixth practical experience in R. Throughout the following notes, I will introduce you to a couple of simple parametric test. Whilst parametric tests are used extremely often in biological statistics, they can be somewhat challenging to fit to your data as you will see soon. To do so, I will enlist the sparrow data set we handled in our first exercise. Additionally, todays seminar is showing plotting via base plot instead of `ggplot2` to highlight the usefulness of base plot and show you the base notation.","tags":["R","Statistics"],"title":"Simple Parametric Tests","type":"docs"},{"authors":["Erik Kusch"],"categories":["An Introduction to Biostatistics"],"content":"Theory Welcome to our sixth practical experience in R. Throughout the following notes, I will introduce you to a couple of simple parametric test. Whilst parametric tests are used extremely often in biological statistics, they can be somewhat challenging to fit to your data as you will see soon. To do so, I will enlist the sparrow data set we handled in our first exercise. Additionally, todays seminar is showing plotting via base plot instead of ggplot2 to highlight the usefulness of base plot and show you the base notation. I have prepared some slides for this session: \nData Find the data for this exercise here and here.\nPreparing Our Procedure To ensure others can reproduce our analysis we run the following three lines of code at the beginning of our R coding file.\nrm(list=ls()) # clearing environment\rDir.Base \u0026lt;- getwd() # soft-coding our working directory\rDir.Data \u0026lt;- paste(Dir.Base, \u0026quot;Data\u0026quot;, sep=\u0026quot;/\u0026quot;) # soft-coding our data directory  Packages Using the following, user-defined function, we install/load all the necessary packages into our current R session.\n# function to load packages and install them if they haven't been installed yet\rinstall.load.package \u0026lt;- function(x) {\rif (!require(x, character.only = TRUE))\rinstall.packages(x)\rrequire(x, character.only = TRUE)\r}\rpackage_vec \u0026lt;- c(\u0026quot;car\u0026quot;) # needed for the Levene Test for Homogeneity\rsapply(package_vec, install.load.package)\r ## Loading required package: car\r ## Loading required package: carData\r ## car ## TRUE\r Loading Data During our first exercise (Data Mining and Data Handling - Fixing The Sparrow Data Set) we saved our clean data set as an RDS file. To load this, we use the readRDS() command that comes with base R.\nData_df_base \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/1 - Sparrow_Data_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\rData_df \u0026lt;- Data_df_base # duplicate and save initial data on a new object\r t-Test (unpaired) Assumptions of the unpaired t-Test:\n Predictor variable is binary Response variable is metric and normal distributed within their groups Variable values are independent (not paired)  In addition, test whether variance of response variable values in groups are equal (var.test()) and adjust t.test() argument var.equal accordingly.\nTesting For Normality And Homogeneity We need to test the distribution of our response variables within each predictor variable group for their normality and variance. Since this involves two Shapiro tests and one variance test per variable for each response variable, we might want to write our own function to do so:\nShapiroTest \u0026lt;- function(Variables, Grouping){\rOutput \u0026lt;- data.frame(x = Variables)\rfor(i in 1:length(Variables)){\rX \u0026lt;- Data_df[,Variables[i]]\rLevels \u0026lt;- levels(factor(Data_df[,Grouping]))\rOutput[i,2] \u0026lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[1])])$p.value\rOutput[i,3] \u0026lt;- shapiro.test(X[which(Data_df[,Grouping] == Levels[2])])$p.value\rOutput[i,4] \u0026lt;- var.test(x = X[which(Data_df[,Grouping] == Levels[1])], y = X[which(Data_df[,Grouping] == Levels[2])])$p.value\r}\rcolnames(Output) \u0026lt;- c(\u0026quot;Variable\u0026quot;, \u0026quot;P.value1\u0026quot;, \u0026quot;P.value2\u0026quot;, \u0026quot;Var.Test\u0026quot;)\rreturn(Output)\r}\r This function (ShapiroTest()) takes two arguments: (1) Variables - a vector of characters holding the names of the variables we want to have tested, and (2) Grouping - the binary variable by which to group our variables. The function returns a data frame holding the p-values of the Shapiro tests on each variable group values as well as the var.test() p-value.\nClimate Warming/Extremes Does sparrow morphology change depend on climate?\nUsing multiple different methods (i.e. Kruskal-Wallis and Mann-Whitney U Test), we have already identified climate (be it in its binary form or when recorded as a three-level variable) is a strong driving force of sparrow morphology. We expect the same results when using a t-Test.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Testing for Normality and Variance Before we can make use of our data with a t-Test, we need to do an assumption check. To this end, we first turn Climate records into a binary variable by turning records of a semi-coastal climate into a coastal one.\n# Make climate binary\rData_df$Climate[which(Data_df$Climate == \u0026quot;Semi-Coastal\u0026quot;)] \u0026lt;- \u0026quot;Coastal\u0026quot;\rData_df$Climate \u0026lt;- droplevels(factor(Data_df$Climate))\r Let\u0026rsquo;s make sure our assumptions are met:\nShapiroTest(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;)\r ## Variable P.value1 P.value2 Var.Test\r## 1 Weight 0.1699442 0.2521182 0.326240416\r## 2 Height 0.1676977 0.3645040 0.010632158\r## 3 Wing.Chord 0.0538642 0.1722528 0.002942433\r Luckily, all of our variables allow for the calculation of t-Test. Take note though that some need different specification of the var.equal argument than others.\nAnalyses Sparrow Weight\nLet\u0026rsquo;s start with the weight of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\nt.test(Data_df$Weight ~ Data_df$Climate, var.equal = TRUE)\r ## ## Two Sample t-test\r## ## data: Data_df$Weight by Data_df$Climate\r## t = -14.852, df = 381, p-value \u0026lt; 2.2e-16\r## alternative hypothesis: true difference in means between group Coastal and group Continental is not equal to 0\r## 95 percent confidence interval:\r## -2.428439 -1.860640\r## sample estimates:\r## mean in group Coastal mean in group Continental ## 31.23383 33.37837\r According to our analysis, which has us reject the null hypothesis, we conclude that binary climate records are valuable information criteria for predicting sparrow weight with sparrows in coastal climates being lighter than sparrows in continental ones thus effectively varifying the results of our non-parametric approaches (Kruskal-Wallis, Mann-Whitney U).\nSparrow Height\nLet\u0026rsquo;s move on to the height of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\nt.test(Data_df$Height ~ Data_df$Climate, var.equal = FALSE)\r ## ## Welch Two Sample t-test\r## ## data: Data_df$Height by Data_df$Climate\r## t = -0.27916, df = 365.69, p-value = 0.7803\r## alternative hypothesis: true difference in means between group Coastal and group Continental is not equal to 0\r## 95 percent confidence interval:\r## -0.2329126 0.1750052\r## sample estimates:\r## mean in group Coastal mean in group Continental ## 13.91670 13.94565\r Confirming the results of our Mann-Whitney U Test, we accept the null hypothesis.\nSparrow Wing Chord\nLastly, we test the wing chords of Passer domesticus individuals as grouped by the climate type present at the site weights have been recorded at:\nt.test(Data_df$Wing.Chord ~ Data_df$Climate, var.equal = FALSE)\r ## ## Welch Two Sample t-test\r## ## data: Data_df$Wing.Chord by Data_df$Climate\r## t = -0.12285, df = 370.22, p-value = 0.9023\r## alternative hypothesis: true difference in means between group Coastal and group Continental is not equal to 0\r## 95 percent confidence interval:\r## -0.03985039 0.03516377\r## sample estimates:\r## mean in group Coastal mean in group Continental ## 6.898696 6.901039\r Without confirming the results of our Mann-Whitney U Test, we accept the null hypothesis.\nConclusion\nHere\u0026rsquo;s what we\u0026rsquo;ve learned from the t-Test so far:\n Sparrow weight depends on (binary) climate types Sparrow height does not depend on (binary) climate types Sparrow wing chord does not depend on (binary) climate types  Let\u0026rsquo;s end this by viusalising all of the data:\npar(mfrow=c(2,2))\rplot(Data_df$Weight ~ Data_df$Climate)\rplot(Data_df$Height ~ Data_df$Climate)\rplot(Data_df$Wing.Chord ~ Data_df$Climate)\r Sexual Dimorphism Does sparrow morphology change depend on Sex?\nUsing the Mann-Whitney U Test, we have already identified the sex of Passer domesticus is a good information criterion for understanding sparrow weight but not sparrow height or wing chord. Let\u0026rsquo;s see if we can reproduce this using a t-Test approach.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Testing for Normality and Variance Again, before we can use our data in a t-Test for this purpose, we have to make sure that our assumptions are met. To this end, we can make use of our user defined ShapiroTest() function as follows:\nShapiroTest(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Grouping = \u0026quot;Sex\u0026quot;)\r ## Variable P.value1 P.value2 Var.Test\r## 1 Weight 2.878769e-21 1.744517e-21 0.7475085\r## 2 Height 4.028475e-17 6.600273e-19 0.4006799\r## 3 Wing.Chord 3.438104e-25 1.628147e-26 0.5554935\r As it turns out, our data does not allow for any t-Test (this happens often in real studies). However, we can create sex-driven subgroups within each site and test whether these meet the requirements for our t-Test. This is out of the scope of this course though and so we will skip it. Spoler alert: I have done this and the findings did not reveal anything we didn\u0026rsquo;t uncover so far.\nt-Test (paired) Assumptions of the paired t-Test:\n Predictor variable is binary Response variable is metric Difference of response variable pairs is normal distributed Variable values are dependent (paired)  Preparing Data For this purpose, we need an additional data set with truly paired records of sparrows and so we implement the same solution as we\u0026rsquo;ve used within our fourth seminar using the Wilcoxon Signed Rank Test. Within our study set-up, think of a resettling experiment, were you take Passer domesticus individuals from one site, transfer them to another and check back with them after some time has passed to see whether some of their characteristics have changed in their expression.\nTo this end, presume we have taken the entire Passer domesticus population found at our Siberian research station and moved them to the United Kingdom. Whilst this keeps the latitude stable, the sparrows now experience a coastal climate instead of a continental one. After some time (let\u0026rsquo;s say: a year), we have come back and recorded all the characteristics for the same individuals again.\nYou will find the corresponding new data in 2b - Sparrow_ResettledSIUK_READY.rds. Take note that this set only contains records for the transferred individuals in the same order as in the old data set.\nData_df_Resettled \u0026lt;- readRDS(file = paste(Dir.Data, \u0026quot;/2b - Sparrow_ResettledSIUK_READY.rds\u0026quot;, sep=\u0026quot;\u0026quot;))\r Since earlier analysis such as the Wilcoxon Signed Rank test (fourth practical) and the Friedman Test (fifth practical) showed that height and wing chord records do not change when sparrows are resettled at all, we have excluded these here and focus solely on sparrow weight.\nTesting for Normality Before being able to run our paired t-Test, we must make sure that the difference of response variable pairs is normal distributed. We can do so using the shapiro.test() of base R as follows:\n# selecting pre-resettling weights\rDataSI \u0026lt;- Data_df$Weight[which(Data_df$Index == \u0026quot;SI\u0026quot;)]\r# calculating difference of before and after resettling weights\rWeightDiff \u0026lt;- DataSI-Data_df_Resettled$Weight\r# shapiro test\rshapiro.test(WeightDiff)\r ## ## Shapiro-Wilk normality test\r## ## data: WeightDiff\r## W = 0.97361, p-value = 0.1716\r Thankfully, the assumption of normality is met.\nNow let\u0026rsquo;s visualise that using a qqplot:\nqqnorm(WeightDiff)\rqqline(WeightDiff)\r Climate Warming/Extremes Does sparrow morphology change depend on climate?\nNow let\u0026rsquo;s go on to test whether sparrow weights change significantly per individual due to our relocation experiment (we expect this from future test in our practicals):\nt.test(DataSI, Data_df_Resettled$Weight, paired = TRUE)\r ## ## Paired t-test\r## ## data: DataSI and Data_df_Resettled$Weight\r## t = 8.4762, df = 65, p-value = 4.17e-12\r## alternative hypothesis: true mean difference is not equal to 0\r## 95 percent confidence interval:\r## 1.583629 2.559914\r## sample estimates:\r## mean difference ## 2.071771\r We were right, individual sparrow weights change significantly after our relocation experiment and we reject the null hypothesis. This is in accordance with the results of the Wilcoxon Signed Rank Test as well as the Friedman Test.\nLet\u0026rsquo;s go on to visualise our data to make better sense of what is going on here:\n# Select the sparrow weights\rWeights \u0026lt;- c(DataSI, Data_df_Resettled$Weight)\r# Select the sites\rSites \u0026lt;- factor(rep(c(\u0026quot;SI\u0026quot;, \u0026quot;SI_UK\u0026quot;), each = length(DataSI)))\r# Plot\rplot(Weights ~ Sites)\r Quite obviously sparrows observed in Siberia are heavier than when they are resettled to the United Kingdom (this may be due to the more forgiving climate in the UK). Just like the test stated, the difference of the average weights is roughly 2g between the sparrows at the two sites.\nOne-Way ANOVA Assumptions of the One-Way ANOVA:\n Predictor variable is categorical Response variable is metric Response variable residuals are normal distributed Variance of populations/samples are equal (homogeneity) Variable values are independent (not paired)  Testing For Assumptions Firstly, we need to test the assumptions of our One-Way ANOVA. For this purpose, we write another user-defined function.\n# User-defined function\rANOVACheck \u0026lt;- function(Variables, Grouping, data, plotting){\rOutput \u0026lt;- data.frame(x = NA)\rfor(i in 1:length(Variables)){\r# data\rY \u0026lt;- as.numeric(factor(data[,Variables[i]]))\rX \u0026lt;- data[,Grouping]\rLevels \u0026lt;- levels(factor(Data_df[,Grouping]))\r# Residuals?\rmodel \u0026lt;- lm(Y ~ X)\rOutput[1,i] \u0026lt;- shapiro.test(residuals(model))$p.value\r# Homgeneity?\rLevene \u0026lt;- leveneTest(Y ~ X, center = median, data = data)\rOutput[2,i] \u0026lt;- Levene[1,3]\r# Plotting\rif(plotting == TRUE){\rplot(model, 2)# Normality\rplot(model, 3)# Homogeneity\r}\r}\rcolnames(Output) \u0026lt;- Variables\rrownames(Output) \u0026lt;- c(\u0026quot;Residual Normality\u0026quot;, \u0026quot;Homogeneity of Variances\u0026quot;)\rreturn(Output)\r}\r This ANOVACheck() function takes four arguments: (1) Variables - a vector of characters holding the names of the variables we want to have tested, (2) Grouping - the categorical variable by which to group our variables, (3) data - the data frame which contains the Variables and the Grouping factor, and (4) plotting - a logical indicator of whether to produce plots visualising the test results or not.\nThe function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (Residual Normality), and the p-values indexing whether variances between groups are homogeneous or not (Homogeneity of Variances).\nClimate Warming/Extremes Does sparrow morphology change depend on climate?\nUsing the Kruskal-Wallis Test in our last exercise, we already identified climate to be an important factor in determining Passer domesticus morphology. Let\u0026rsquo;s see if this holds true.\nTake note that we need to limit our analysis to our climate type testing sites again as follows (we include Manitoba this time as it is at the same latitude as the UK and Siberia and holds a semi-coastal climate type):\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;RE\u0026quot; | Index == \u0026quot;AU\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r Assumption Check Let\u0026rsquo;s use the ANOVACheck() function on our data:\npar(mfrow=c(3,2))\rANOVACheck(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;, data = Data_df, plotting = TRUE)\r ## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\r## factor.\r## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\r## factor.\r## Warning in leveneTest.default(y = y, group = group, ...): group coerced to\r## factor.\r ## Weight Height Wing.Chord\r## Residual Normality 0.002521771 2.671414e-05 0.001685579\r## Homogeneity of Variances 0.110120912 1.896577e-01 0.013575440\r Unfortunately, neither weight nor wing chord records fullfil our requirements.\nAnalysis Let\u0026rsquo;s run our analysis for height as grouped by the three-level climate variable:\nmodel \u0026lt;- lm(Data_df$Height ~ Data_df$Climate)\ranova(model)\r ## Analysis of Variance Table\r## ## Response: Data_df$Height\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Data_df$Climate 2 14.99 7.4942 7.2494 0.0008129 ***\r## Residuals 381 393.87 1.0338 ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r According to this, climate is a meaningful predictor of height of sparrows and we reject the null hypothesis thus confirming the results of our Kruskall-Wallis analysis.\nNow, let\u0026rsquo;s analyse the output a bit more in-depth:\nsummary(model)\r ## ## Call:\r## lm(formula = Data_df$Height ~ Data_df$Climate)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -2.98994 -0.69815 -0.01475 0.67142 2.37045 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 14.07994 0.07964 176.800 \u0026lt; 2e-16 ***\r## Data_df$ClimateContinental -0.13429 0.11426 -1.175 0.24060 ## Data_df$ClimateSemi-Coastal -0.56039 0.14755 -3.798 0.00017 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 1.017 on 381 degrees of freedom\r## Multiple R-squared: 0.03666,\tAdjusted R-squared: 0.0316 ## F-statistic: 7.249 on 2 and 381 DF, p-value: 0.0008129\r  The mean sparrow height in coastal climates is 14.0799387cm (this is our Intercept/Baseline) The mean sparrow height in continental climates is -0.1342893cm bigger than the Intercept The mean sparrow height in semi-coastal climates is -0.5603864cm bigger than the Intercept Only the estimates in coastal and semi-coastal climates are statistically significant  Personally, I would not place too much confidence in these results due to a couple of reasons:\n Our only semi-coastal site is on the northern hemisphere whereas two of our stations are located in the southern hemisphere Confounding factors such as population status might have an effect which we are not considering here  Let\u0026rsquo;s end this by plotting all of our data:\npar(mfrow=c(2,2))\rplot(Data_df$Weight ~ factor(Data_df$Climate))\rplot(Data_df$Height ~ factor(Data_df$Climate))\rplot(Data_df$Wing.Chord ~ factor(Data_df$Climate))\r As you can see, the variances are definitely not equal between our groups which explains why part of our assumption test failed.\nPredation Does nesting height depend on predator characteristics?\nAgain, using the Kruskal-Wallis Test in our last exercise, we already identified predator characteristics to be an important factor in determining Passer domesticus nesting height. Let\u0026rsquo;s see if this holds true.\nWe may wish to use the entirety of our data set again for this purpose:\nData_df \u0026lt;- Data_df_base\r Assumption Check Let\u0026rsquo;s use our ANOVACeck() function to test whether we can run our analysis. Before we can do so, however, we need to slightly adjust our predator type variable just like we did in our last exercise and as follows:\n# changing levels in predator type\rlevels(Data_df$Predator.Type) \u0026lt;- c(levels(Data_df$Predator.Type), \u0026quot;None\u0026quot;)\rData_df$Predator.Type[which(is.na(Data_df$Predator.Type))] \u0026lt;- \u0026quot;None\u0026quot;\r# Assumption Check\rpar(mfrow=c(1,2))\rANOVACheck(Variables = \u0026quot;Nesting.Height\u0026quot;, Grouping = \u0026quot;Predator.Type\u0026quot;, data = Data_df, plotting = TRUE)\r ## Nesting.Height\r## Residual Normality 0.0017160318\r## Homogeneity of Variances 0.0005845899\r Again, our data fails the assumption check. The residuals are definitely not normal distributed and the variance of nesting height records within our groups are not equal.\nAnalysis Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone:\nplot(Data_df$Nesting.Height ~ Data_df$Predator.Type)\r Once more, we can see why our homogeneity of variances test failed.\nTwo-Way ANOVA Assumptions of the Two-Way ANOVA:\n Predictor variables are categorical Response variable is metric Response variable residuals are normal distributed Variance of populations/samples are equal (homogeneity) Variable values are independent (not paired)  Testing For Assumptions Yet again, we need to check if our assumptions are met first. Automating this procedure is definitely a good idea and only needs slight modification from our ANOVACheck() function.\n# User-defined function\rANOVACheck_TWO \u0026lt;- function(Formulas, data, plotting){\rOutput \u0026lt;- data.frame(x = NA)\rfor(i in 1:length(Formulas)){\r# Check how many formulas there are\rif(length(Formulas) == 1){\rExpression \u0026lt;- Formulas[[1]]\r}else{\rExpression \u0026lt;- Formulas[[i]]\r}\r# Residuals?\rmodel \u0026lt;- lm(formula = Expression, data = data)\rOutput[1,i] \u0026lt;- shapiro.test(residuals(model))$p.value\r# Homgeneity?\rLevene \u0026lt;- leveneTest(Expression, center = median, data = data)\rOutput[2,i] \u0026lt;- Levene[1,3]\r# Plotting\rif(plotting == TRUE){\rplot(model, 2)# Normality\rplot(model, 3)# Homogeneity\r}\r}\rcolnames(Output) \u0026lt;- as.character(Formulas)\rrownames(Output) \u0026lt;- c(\u0026quot;RN\u0026quot;, \u0026quot;HoV\u0026quot;)\rreturn(Output)\r}\r This ANOVACheck_TWO() function takes four arguments: (1) Formulas - a vector of formula specification for our ANOVA models we want to have tested, (2) data - the data frame which contains the variables and the grouping factor called upon in our Formulas, and (3) plotting - a logical indicator of whether to produce plots visualising the test results or not.\nThe function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (RN), and the p-values indexing whether variances between groups are homogeneous or not (HoV).\nSexual Dimorphism Does sparrow morphology depend on population status and sex?\nGiven different factors affecting invasive species, we might expect different patterns of sexual dimorphism for invasive and native populations. Take note that we keep using the northern hemisphere subset our cimate testing sites as these present us with a nice set of invasive/native population records already whilst keeping confounding factors to a minimum.\nAssumption Check First, we need to check our assumptions:\n# prepare climate type testing data\rData_df \u0026lt;- Data_df_base\rIndex \u0026lt;- Data_df$Index\rRows \u0026lt;- which(Index == \u0026quot;SI\u0026quot; | Index == \u0026quot;UK\u0026quot; | Index == \u0026quot;MA\u0026quot;)\rData_df \u0026lt;- Data_df[Rows,]\r# analysis\rpar(mfrow=c(3,2))\rANOVACheck_TWO(Formulas = c(Weight ~ Population.Status*Sex, Height ~ Population.Status*Sex,\rWing.Chord ~ Population.Status*Sex)\r, data = Data_df, plotting = TRUE)\r ## Weight ~ Population.Status * Sex Height ~ Population.Status * Sex\r## RN 0.287959531 0.2171916\r## HoV 0.004492103 0.9057774\r## Wing.Chord ~ Population.Status * Sex\r## RN 0.1907782\r## HoV 0.9174340\r Again our assumptions are not met except for sparrow height and wing chord as a product of sex and population status.\nAnalysis Let\u0026rsquo;s run our analysis:\n# height model\rmodel \u0026lt;- lm(Height ~ Population.Status*Sex, data = Data_df)\ranova(model)\r ## Analysis of Variance Table\r## ## Response: Height\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F)\r## Population.Status 1 0.338 0.33820 0.3190 0.5729\r## Sex 1 0.179 0.17896 0.1688 0.6816\r## Population.Status:Sex 1 1.786 1.78585 1.6844 0.1959\r## Residuals 197 208.865 1.06023\r # wing chord model\rmodel \u0026lt;- lm(Wing.Chord ~ Population.Status*Sex, data = Data_df)\ranova(model)\r ## Analysis of Variance Table\r## ## Response: Wing.Chord\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F)\r## Population.Status 1 0.0047 0.004669 0.1955 0.6589\r## Sex 1 0.0041 0.004125 0.1727 0.6782\r## Population.Status:Sex 1 0.0399 0.039856 1.6688 0.1979\r## Residuals 197 4.7049 0.023883\r # plotting\rpar(mfrow=c(1,2))\rboxplot(Height ~ Population.Status*Sex, data = Data_df, col = c(\u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;))\rboxplot(Wing.Chord ~ Population.Status*Sex, data = Data_df, col = c(\u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;))\r As it turns out, population status and sex are no viable predictors for sparrow height or wing chord and so we accept the null hypothesis.\nANCOVA Assumptions of the ANCOVA:\n Predictor variables are categorical or continuous Response variable is metric Response variable residuals are normal distributed Variance of populations/samples are equal (homogeneity) Variable values are independent (not paired) Relationship between the response and covariate is linear.  Climate Warming/Extremes Do sparrow characteristics depend on climate and latitude?\nLatitude may have masked some effects of climate on sparrow morphology in our preceding analyses and vice-versa. At times, we have been able to account for this by including our site records, which can be seen as binned versions of latitude records. Let\u0026rsquo;s test if the inclusion of raw latitude records are meaningful.\nAssumption Check Again, we need to do an assumption check. However, we need a new function for this, since we now need to test whether our response variable and the covariate are linear or not:\n# overwriting prior changes in Data_df\rData_df \u0026lt;- Data_df_base\rData_df$Latitude \u0026lt;- abs(Data_df$Latitude)\r# User-defined function\rANCOVACheck \u0026lt;- function(Variables, Grouping, Covariate, data, plotting){\rOutput \u0026lt;- data.frame(x = NA)\rfor(i in 1:length(Variables)){\r# data\rY \u0026lt;- as.numeric(factor(data[,Variables[i]]))\rX \u0026lt;- factor(data[,Grouping])\rZ \u0026lt;- data[, Covariate]\r# Residuals?\rmodel \u0026lt;- lm(Y ~ X*Z)\rOutput[1,i] \u0026lt;- shapiro.test(residuals(model))$p.value\r# Homgeneity?\rLevene \u0026lt;- leveneTest(Y ~ X, center = median, data = data)\rOutput[2,i] \u0026lt;- Levene[1,3]\r# Plotting\rif(plotting == TRUE){\rplot(model, 1)# Linearity\rplot(model, 2)# Normality\rplot(model, 3)# Homogeneity\r}\r}\rcolnames(Output) \u0026lt;- Variables\rrownames(Output) \u0026lt;- c(\u0026quot;RN\u0026quot;, \u0026quot;HoV\u0026quot;)\rreturn(Output)\r}\r This ANCOVACheck() function takes five arguments: (1) Variables - a vector of response variables used in our models, (2) Grouping - the categorical variable by which to group our variables, (3) Covariate - the covariate of our analysis, (4)data - the data frame which contains the variables, the grouping factor and our covariate, and (5) plotting - a logical indicator of whether to produce plots visualising the test results or not.\nThe function returns a data frames containing the p-values indexing whether to accept or reject the notion of the normality of residuals per variable (RN), and the p-values indexing whether variances between groups are homogeneous or not (HoV).\nANCOVACheck(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Nesting.Height\u0026quot;, \u0026quot;Egg.Weight\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;, \u0026quot;Home.Range\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;, Covariate = \u0026quot;Latitude\u0026quot;, data = Data_df, plotting = FALSE)\r ## Weight Height Wing.Chord Nesting.Height Egg.Weight\r## RN 2.082300e-02 1.502944e-04 4.535941e-07 5.190971e-06 2.943560e-03\r## HoV 9.937376e-24 1.929783e-22 1.561040e-33 2.004612e-01 4.816355e-09\r## Number.of.Eggs Home.Range\r## RN 1.809197e-09 3.629841e-20\r## HoV 2.750100e-14 1.157673e-08\r The assumptions aren\u0026rsquo;t met. I have set the plotting argument to FALSE tu suppress the plotting of model checking visualisation. The would be useful to judge linearity but not necessary here since the other two important assumptions (Homogeneity of variances and Normality of residuals) aren\u0026rsquo;t met to begin with.\nAnalysis Since none of our assumptions are met, we cannot run an ANOVA and therefore resort to data visualisation alone. We need a new function for this to do our plotting easily and automatically with some colours indicating our grouping factors whilst plotting response variables versus covariates.\nPlotAncovas \u0026lt;- function(Variables, Grouping, Covariate, data){\rfor(i in 1:length(Variables)){\rY \u0026lt;- Data_df[,Variables[i]]\rif(class(Y) == \u0026quot;character\u0026quot;){Y \u0026lt;- factor(Y)}\rX \u0026lt;- Data_df[,Covariate]\rG \u0026lt;- factor(Data_df[, Grouping])\rplot(X, Y, col = G, xlab = Covariate, ylab = Variables[i])\rlegend(\u0026quot;top\u0026quot;, # place legend at the top\rinset = -0.35, # move legend away from plot centre\rxpd = TRUE, # allow legend outside of plot area\rlegend=levels(G), # what to include in legend\rbg = \u0026quot;white\u0026quot;, col = unique(G), ncol=length(levels(G)), # colours\rpch = 1, # plotting symbols\rtitle = Variables[i] # title of legend\r)\r}\r}\r The PlotAncovas() returns a scatter plot and takes four arguments: (1) Variables - a vector of response variables, (2) Grouping - the name of the grouping factor according to which to colour the symbols in our plot, (3) Covariate - the covariate against which to plot individuals variables, and (4) data - the data frame which holds our variables.\nLet\u0026rsquo;s use our function:\npar(mfrow=c(1,2))\rPlotAncovas(Variables = c(\u0026quot;Weight\u0026quot;, \u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Nesting.Height\u0026quot;, \u0026quot;Egg.Weight\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;, \u0026quot;Home.Range\u0026quot;), Grouping = \u0026quot;Climate\u0026quot;, Covariate = \u0026quot;Latitude\u0026quot;, data = Data_df)\r I will not interpret these plots here in text and leave this to you.\nTake note that this could\u0026rsquo;ve been achieved much easier with ggplot2!\nSparrow Characteristics And Sites This was not part of what we set out to do according to the lecture slides but has been included as a logical conclusion to an earlier analysis.\nUnfortunately, our previous attempt at an ANCOVA didn\u0026rsquo;t work. So what other covariate do we have available for sparrow characteristics?\n Latitude doesn\u0026rsquo;t make sense to include when grouping by site index as these two are synonymous Longitude doesn\u0026rsquo;t make sense to include when grouping by site index as these two are synonymous Weight is well explained by other variables and we know the causal links Height is not that well explained by other variables Wing.Chord is not that well explained by other variables  Of course, there are more within our data set but it has become apparent that Weight may make for an important covariate in our site-wise ANCOVA set-up. Using the Pearson correlation (third practical), we already identified a causal link between sparrow Weight and Height per site.\nAssumption Check Firstly, we test whether assumptions are met. For brevities sake, we only test four variables:\npar(mfrow=c(1,3))\rANCOVACheck(Variables = c(\u0026quot;Height\u0026quot;, \u0026quot;Wing.Chord\u0026quot;, \u0026quot;Egg.Weight\u0026quot;, \u0026quot;Number.of.Eggs\u0026quot;), Grouping = \u0026quot;Index\u0026quot;, Covariate = \u0026quot;Weight\u0026quot;, data = Data_df, plotting = TRUE)\r ## Height Wing.Chord Egg.Weight Number.of.Eggs\r## RN 1.499909e-06 5.251393e-08 0.1565038171 9.220862e-07\r## HoV 3.594021e-13 2.434880e-01 0.0002015813 2.660146e-02\r As it turns out, we can run our ANCOVA on Egg.Weight when grouped by site Index and driven by Weight.\nAnalysis First, let\u0026rsquo;s visualise our data:\nPlotAncovas(Variables = \u0026quot;Egg.Weight\u0026quot;, Grouping = \u0026quot;Index\u0026quot;, Covariate = \u0026quot;Weight\u0026quot;, data = Data_df)\r Quite obviously, Belize (BE) records are very different from the other stations, whose egg weight and weight records are grouped together. There seems to be some evidence for an overall linkage of sparrow weight and egg weight (a positive correlation).\nNow we run the analysis:\nLM_fit5 \u0026lt;- lm(Egg.Weight ~ Weight*Index, data = Data_df)\ranova(LM_fit5)\r ## Analysis of Variance Table\r## ## Response: Egg.Weight\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Weight 1 52.531 52.531 1442.5616 \u0026lt;2e-16 ***\r## Index 10 8.087 0.809 22.2064 \u0026lt;2e-16 ***\r## Weight:Index 10 0.129 0.013 0.3536 0.9653 ## Residuals 455 16.569 0.036 ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r The above ANCOVA output tells us that there is no interaction effect between sites and sparrow weights when determining mean egg weight per nest of Passer domesticus and so we do another iteration of our model and remove the postulated interaction:\nLM_fit6 \u0026lt;- lm(Egg.Weight ~ Weight+Index, data = Data_df)\ranova(LM_fit6)\r ## Analysis of Variance Table\r## ## Response: Egg.Weight\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Weight 1 52.531 52.531 1462.898 \u0026lt; 2.2e-16 ***\r## Index 10 8.087 0.809 22.519 \u0026lt; 2.2e-16 ***\r## Residuals 465 16.698 0.036 ## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r By now, all of our model coefficients are significant and we can go on to interpret them:\nsummary(LM_fit6)\r ## ## Call:\r## lm(formula = Egg.Weight ~ Weight + Index, data = Data_df)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.58887 -0.13146 -0.00621 0.12033 0.55135 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 3.345984 0.280826 11.915 \u0026lt; 2e-16 ***\r## Weight 0.001081 0.008614 0.125 0.900203 ## IndexBE -0.708478 0.054864 -12.913 \u0026lt; 2e-16 ***\r## IndexFG -1.281168 0.099135 -12.923 \u0026lt; 2e-16 ***\r## IndexFI -0.625287 0.057442 -10.885 \u0026lt; 2e-16 ***\r## IndexLO -0.550137 0.051754 -10.630 \u0026lt; 2e-16 ***\r## IndexMA -0.513645 0.051352 -10.003 \u0026lt; 2e-16 ***\r## IndexNU -0.517015 0.053365 -9.688 \u0026lt; 2e-16 ***\r## IndexRE -0.612632 0.051418 -11.915 \u0026lt; 2e-16 ***\r## IndexSA -0.806045 0.056685 -14.220 \u0026lt; 2e-16 ***\r## IndexSI -0.272580 0.077868 -3.501 0.000509 ***\r## IndexUK -0.511667 0.051404 -9.954 \u0026lt; 2e-16 ***\r## ---\r## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r## ## Residual standard error: 0.1895 on 465 degrees of freedom\r## (590 observations deleted due to missingness)\r## Multiple R-squared: 0.784,\tAdjusted R-squared: 0.7789 ## F-statistic: 153.5 on 11 and 465 DF, p-value: \u0026lt; 2.2e-16\r ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"6e515cc10916d6719276b301226b9a1b","permalink":"https://www.erikkusch.com/courses/biostat101/simple-parametric-tests/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/courses/biostat101/simple-parametric-tests/","section":"courses","summary":"Welcome to our sixth practical experience in R. Throughout the following notes, I will introduce you to a couple of simple parametric test. Whilst parametric tests are used extremely often in biological statistics, they can be somewhat challenging to fit to your data as you will see soon. To do so, I will enlist the sparrow data set we handled in our first exercise. Additionally, todays seminar is showing plotting via base plot instead of `ggplot2` to highlight the usefulness of base plot and show you the base notation.","tags":["R","Statistics"],"title":"Simple Parametric Tests","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Models with Memory Material  \rSlides Chapter 13  Introduction These are answers and solutions to the exercises at the end of chapter 13 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from\nthe solutions provided to instructors by Richard McElreath himself.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(rstan)\rlibrary(ggplot2)\rlibrary(tidybayes)\rlibrary(cowplot)\r Easy Exercises Practice E1 Question: Which of the following priors will produce more shrinkage in the estimates?\n(a) $α_{tank} ∼ Normal(0, 1)$\n(b) $α_{tank} ∼ Normal(0, 2)$\nAnswer: Shrinkage is introduced by regularising/informative priors. This means that option (a) will introduce more shrinkage because it\u0026rsquo;s distribution is narrower than that of (b) and thus more informative/regularising.\nPractice E2 Question: Make the following model into a multilevel model.\n$$y_i ∼ Binomial(1, p_i)$$ $$logit(p_i) = α_{group[i]} + βx_i$$ $$α_{group} ∼ Normal(0, 10)$$ $$β ∼ Normal(0, 1)$$\nAnswer: To make the above model into a multi-level model, we need to assign some hyperpriors. These are priors on parameters of parameters. In this case, we express $\\alpha_{group[i]}$ (a parameter) through a prior with another set of parameters ($\\bar\\alpha, \\sigma_\\alpha$). These parameters, in turn, require priors themselves - so called hyperpriors.\n$$y_i ∼ Binomial(1, p_i)$$ $$logit(p_i) = α_{group[i]} + βx_i$$ $$α_{group} ∼ Normal(\\bar\\alpha, \\sigma_\\alpha)$$ $$\\bar\\alpha \\sim Normal(0, 2)$$ $$\\sigma_\\alpha \\sim Exponential(1)$$ $$β ∼ Normal(0, 1)$$\nThe numbers we feed into our hyperpriors here are difficult to assess for sensibility since we don\u0026rsquo;t have any data to test the performance of both models and their assumptions.\nPractice E3 Question: Make the following model into a multilevel model.\n$$y_i ∼ Normal(\\mu, \\sigma)$$ $$logit(p_i) = α_{group[i]} + βx_i$$ $$α_{group} ∼ Normal(0, 10)$$ $$\\beta \\sim Normal(0, 1)$$ $$\\sigma ∼ HalfCauchy(0, 2)$$\nAnswer: Well this is just a repeat of the previous problem:\n$$y_i ∼ Normal(\\mu_i, \\sigma)$$ $$logit(p_i) = α_{group[i]} + βx_i$$ $$α_{group} ∼ Normal(\\bar\\alpha, \\sigma_\\alpha)$$ $$\\bar\\alpha \\sim Normal(0, 2)$$ $$\\sigma_\\alpha \\sim Exponential(1)$$ $$\\beta \\sim Normal(0, 1)$$ $$\\sigma ∼ HalfCauchy(0, 2)$$\nPractice E4 Question: Write an example mathematical model formula for a Poisson regression with varying intercepts.\nAnswer: This is simply just the solution to E2 with a change to the outcome distribution (now Poisson) and link function (now log):\n$$y_i ∼ Poisson(\\lambda_i)$$ $$log(\\lambda_i) = α_{group[i]} + βx_i$$ $$α_{group} ∼ Normal(\\bar\\alpha, \\sigma_\\alpha)$$ $$\\bar\\alpha \\sim Normal(0, 2)$$ $$\\sigma_\\alpha \\sim Exponential(1)$$ $$β ∼ Normal(0, 1)$$\nAgain, I would like to highlight that I can\u0026rsquo;t set any meaningful priors here because I have no idea what we are analysing. These exercises are just about model structure, I wager.\nPractice E5 Question: Write an example mathematical model formula for a Poisson regression with two different kinds of varying intercepts, a cross-classified model.\nAnswer: I start with the solution to E4 and add another intercept group ($\\gamma$) which target a cluster of days like the example in the book:\n$$y_i ∼ Poisson(\\lambda_i)$$ $$log(\\lambda_i) = α_{group[i]}+ \\gamma_{day[i]} + βx_i$$ $$α_{group} ∼ Normal(\\bar\\alpha, \\sigma_\\alpha)$$ $$\\bar\\alpha \\sim Normal(0, 2)$$ $$\\sigma_\\alpha \\sim Exponential(1)$$ $$\\gamma_{day} ∼ Normal(\\bar\\gamma, \\sigma_\\gamma)$$ $$\\bar\\gamma \\sim Normal(0, 2)$$ $$\\sigma_\\gamma \\sim Exponential(1)$$\n$$β ∼ Normal(0, 1)$$\nMedium Exercises Practice M1 Question: Revisit the Reed frog survival data, data(reedfrogs), and add the predation and size treatment variables to the varying intercepts model. Consider models with either main effect alone, both main effects, as well as a model including both and their interaction. Instead of focusing on inferences about these two predictor variables, focus on the inferred variation across tanks. Explain why it changes as it does across models.\nAnswer: This corresponds to the multi-level tadpole example in the book (starting in section 13.1 on page 415). First, I load the data and prepare the data list as was done in the book and add in the data about predation (binary - yes/no) and size treatment (binary - small/large):\ndata(reedfrogs)\rd \u0026lt;- reedfrogs\rdat \u0026lt;- list(\rS = d$surv,\rn = d$density,\rtank = 1:nrow(d),\rpred = ifelse(d$pred == \u0026quot;no\u0026quot;, 0L, 1L),\rsize_ = ifelse(d$size == \u0026quot;small\u0026quot;, 1L, 2L)\r)\r ulam() doesn\u0026rsquo;t like when any data value is called size. That\u0026rsquo;s why I call it size_.\nNow, I can define the models. Note that I am running all of them with log_lik = TRUE so I can compare them later:\n Tank-only model which will serve as our baseline.  m_Tank \u0026lt;- ulam(\ralist(\rS ~ dbinom(n, p),\rlogit(p) \u0026lt;- a[tank],\ra[tank] ~ dnorm(a_bar, sigma),\ra_bar ~ dnorm(0, 1.5),\rsigma ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE, iter = 2e3\r)\r Predation model:  m_Pred \u0026lt;- ulam(\ralist(\rS ~ dbinom(n, p),\rlogit(p) \u0026lt;- a[tank] + bp * pred,\ra[tank] ~ dnorm(a_bar, sigma),\rbp ~ dnorm(-0.5, 1),\ra_bar ~ dnorm(0, 1.5),\rsigma ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE, iter = 2e3\r)\r Size model:  m_Size \u0026lt;- ulam(\ralist(\rS ~ dbinom(n, p),\rlogit(p) \u0026lt;- a[tank] + s[size_],\ra[tank] ~ dnorm(a_bar, sigma),\rs[size_] ~ dnorm(0, 0.5),\ra_bar ~ dnorm(0, 1.5),\rsigma ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE, iter = 2e3\r)\r Predation + Size model:  m_Additive \u0026lt;- ulam(\ralist(\rS ~ dbinom(n, p),\rlogit(p) \u0026lt;- a[tank] + bp * pred + s[size_],\ra[tank] ~ dnorm(a_bar, sigma),\rbp ~ dnorm(-0.5, 1),\rs[size_] ~ dnorm(0, 0.5),\ra_bar ~ dnorm(0, 1.5),\rsigma ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE, iter = 2e3\r)\r Predation-Size-Interaction model:  # this is a con-centred parametrisation for giggles:\rm_Interaction \u0026lt;- ulam(\ralist(\rS ~ dbinom(n, p),\rlogit(p) \u0026lt;- a_bar + a[tank] * sigma + bp[size_] * pred + s[size_], # interaction comes in via bP[size_]\ra[tank] ~ dnorm(0, 1),\rbp[size_] ~ dnorm(-0.5, 1),\rs[size_] ~ dnorm(0, 0.5),\ra_bar ~ dnorm(0, 1.5),\rsigma ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE, iter = 2e3\r)\r Now that we have all the models ready, we can assess the variation among tanks. This information is contained within the sigma parameter in all of the models:\nplot(coeftab(m_Tank, m_Pred, m_Size, m_Additive, m_Interaction),\rpars = \u0026quot;sigma\u0026quot;,\rlabels = c(\u0026quot;Tank\u0026quot;, \u0026quot;Predation\u0026quot;, \u0026quot;Size\u0026quot;, \u0026quot;Additive\u0026quot;, \u0026quot;Interaction\u0026quot;)\r)\r Quite evidently, omitting pred (predation) from our models assigns a lot of variation to the tank variable. Conclusively, we can say that predation explains a lot of the variation across tanks and helps to explain it. Omitting predation from our models simply assigns this variation to the tank intercepts without explaining it.\nPractice M2 Question: Compare the models you fit just above, using WAIC. Can you reconcile the differences in WAIC with the posterior distributions of the models?\nAnswer:\ncompare(m_Tank, m_Pred, m_Size, m_Additive, m_Interaction)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m_Interaction 199.0758 9.089561 0.0000000 NA 18.81776 0.2771353\r## m_Pred 199.5219 8.995153 0.4460306 3.177855 19.44211 0.2217367\r## m_Additive 199.9935 8.737508 0.9176872 2.209613 19.16555 0.1751534\r## m_Tank 200.0751 7.259051 0.9992752 6.180324 20.94365 0.1681520\r## m_Size 200.2019 7.140956 1.1260679 5.992834 20.97228 0.1578226\r Evidently, all of our models are expected to perform similarly in out-of-sample predictions. So how do the posterior samples look like? Here, I write a function to extract all parameter samples from the posterior given any of our models except the $\\alpha$ parameters and feed them into a ggplot using the beautiful stat_halfeye() from the tidybayes package:\nna.omit.list \u0026lt;- function(y) {\rreturn(y[!sapply(y, function(x) all(is.na(x)))])\r}\rHalfeyes_NoAs \u0026lt;- function(model = NULL, N = 1e4) {\rSamples \u0026lt;- extract.samples(model, n = N)\rlist \u0026lt;- as.list(rep(NA, sum(!startsWith(names(model@coef), \u0026quot;a[\u0026quot;))))\rnames(list) \u0026lt;- names(model@coef)[!startsWith(names(model@coef), \u0026quot;a[\u0026quot;)]\rfor (i in names(Samples)) {\rif (i == \u0026quot;a\u0026quot;) {\rnext\r} # skip all \u0026quot;a\u0026quot; parameters\rif (is.na(dim(Samples[[i]])[2])) {\rlist[[i]] \u0026lt;- data.frame(\rPosterior = Samples[[i]],\rParameter = rep(i, length(Samples[[i]]))\r)\r} else { # if there are multiple parameter levels\rlist[[i]] \u0026lt;- data.frame(\rPosterior = Samples[[i]][, 1],\rParameter = rep(paste(i, 1, sep = \u0026quot;_\u0026quot;), length(Samples[[i]]))\r)\rfor (k in 2:dim(Samples[[i]])[2]) {\rlist[[i]] \u0026lt;- rbind(\rlist[[i]],\rdata.frame(\rPosterior = Samples[[i]][, k],\rParameter = rep(paste(i, k, sep = \u0026quot;_\u0026quot;), length(Samples[[i]]))\r)\r)\r}\r}\r} # Samples-loop\rPlot_df \u0026lt;- do.call(\u0026quot;rbind\u0026quot;, na.omit.list(list))\rPlot_gg \u0026lt;- ggplot(Plot_df, aes(y = Parameter, x = Posterior)) +\rstat_halfeye() +\rlabs(x = \u0026quot;Parameter Estimate\u0026quot;, y = \u0026quot;Parameter\u0026quot;) +\rgeom_vline(xintercept = 0, color = \u0026quot;red\u0026quot;) +\rtheme_bw(base_size = 20)\rreturn(Plot_gg)\r}\r I don\u0026rsquo;t claim that this is beautiful code. There\u0026rsquo;s probably and easier way of doing this. Basically, this is a botch job. I am aware that it is, but it works for now.\nLet me apply this to our models and then show you the plots:\nplot_ls \u0026lt;- lapply(list(m_Tank, m_Pred, m_Size, m_Additive, m_Interaction), Halfeyes_NoAs, N = 1e4)\rplot_grid(\rplotlist = plot_ls, labels = c(\u0026quot;Tank\u0026quot;, \u0026quot;Predation\u0026quot;, \u0026quot;Size\u0026quot;, \u0026quot;Additive\u0026quot;, \u0026quot;Interaction\u0026quot;),\rncol = 1, vjust = 1.25, hjust = -0.1\r)\r These plots only tell us what our models have sampled from the posterior in terms of parameter estimates. They do not tell us how accurate the models are when predicting data. However, they do tell us loads about what the models use to make their predictions.\nFor now, I will focus on the posterior distributions of our predation parameter (bp) and size parameter (s). When inspecting these, it is apparent that the parameter estimates of bp are much further from 0 than those for s. This holds true across all models. In addition, anytime bp is contained in a model, sigma (the variation in tank intercepts) decreases drastically.\nThis is consistent with the model rankings. The tank-only model does not because size and predation are meaningless predictors. The posterior distributions above show us that they do contain important information. The tank-only model does well because there exists variation among tanks for a multitude of reasons. Prediction and inference of causality are not the same thing, after all.\nPractice M3 Question: Re-estimate the basic Reed frog varying intercept model, but now using a Cauchy distribution in place of the Gaussian distribution for the varying intercepts. That is, fit this model:\n$$s_i ∼ Binomial(n_i, p_i)$$ $$logit(p_i) = α_{tank[i]}$$ $$α_{tank} ∼ Cauchy(\\alpha, \\sigma)$$ $$\\alpha ∼ Normal(0, 1)$$ $$\\sigma ∼ Exponential(1)$$\nCompare the posterior means of the intercepts, $α_{tank}$, to the posterior means produced in the chapter, using the customary Gaussian prior. Can you explain the pattern of differences?\nAnswer: This is simply the m_Tank model we ran previously, but with a dcauchy() prior on $\\alpha_{tank}$. Because the Cauchy distribution comes with very long tails, we run into a few issues of divergent transitions with default parameters and so I add control=list(adapt_delta=0.99) to the call to ulam() for more measured sampling of the posterior space:\nm_TankCauchy \u0026lt;- ulam(\ralist(\rS ~ dbinom(n, p),\rlogit(p) \u0026lt;- a[tank],\ra[tank] ~ dcauchy(a_bar, sigma),\ra_bar ~ dnorm(0, 1.5),\rsigma ~ dexp(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE,\riter = 2e3, control = list(adapt_delta = 0.99)\r)\r Now let\u0026rsquo;s compare the posterior means of m_Tank and the new m_TankCauchy for their estimates of the $\\alpha_{tank}$ parameters:\na_Tank \u0026lt;- apply(extract.samples(m_Tank)$a, 2, mean)\ra_TankCauchy \u0026lt;- apply(extract.samples(m_TankCauchy)$a, 2, mean)\rplot(a_Tank, a_TankCauchy,\rpch = 16, col = rangi2,\rxlab = \u0026quot;intercept (Gaussian prior)\u0026quot;, ylab = \u0026quot; intercept (Cauchy prior)\u0026quot;\r)\rabline(a = 0, b = 1, lty = 2)\r For most of our intercepts ($\\alpha_{tank}$), both the Cauchy-prior model and the Gaussian-prior model are basically creating the same results (i.e. points on the dashed line). However, once we hit extreme $\\alpha_{tank}$ under the Gaussian prior, the $\\alpha_{tank}$ estimates of the Cauchy prior are even more extreme by comparison. This is because of how much adaptive shrinkage is going on. In the tanks on the right-hand side of the plot above, extreme proportions of tadpoles survived the experiment. These estimates are shrunk towards the population (i.e. all tanks) mean. Since the Gaussian distribution is more concentrated than the Cauchy distribution, the Gaussian estimates have more shrinkage applied to them and so fall to lower values.\nPractice M4 Question: Modify the cross-classified chimpanzees model m13.4 so that the adaptive prior for blocks contains a parameter $\\bar\\gamma$ for its mean:\n$$γ_i \\sim Normal(\\bar\\gamma, \\sigma_γ)$$ $$\\bar\\gamma \\sim Normal(0, 1.5)$$\nCompare this model to m13.4. What has including $\\bar\\gamma$ done?\nAnswer: First, I load the data again and prepare it like it was done in the book:\ndata(chimpanzees)\rd \u0026lt;- chimpanzees\rd$treatment \u0026lt;- 1 + d$prosoc_left + 2 * d$condition\rdat_list \u0026lt;- list(\rpulled_left = d$pulled_left,\ractor = d$actor,\rblock_id = d$block,\rtreatment = as.integer(d$treatment)\r)\r Here\u0026rsquo;s model m13.4 from the book:\nm13.4 \u0026lt;- ulam(\ralist(\rpulled_left ~ dbinom(1, p),\rlogit(p) \u0026lt;- a[actor] + g[block_id] + b[treatment],\rb[treatment] ~ dnorm(0, 0.5),\r## adaptive priors\ra[actor] ~ dnorm(a_bar, sigma_a),\rg[block_id] ~ dnorm(0, sigma_g),\r## hyper-priors\ra_bar ~ dnorm(0, 1.5),\rsigma_a ~ dexp(1),\rsigma_g ~ dexp(1)\r),\rdata = dat_list, chains = 4, cores = 4, log_lik = TRUE\r)\r Now for the modification with the adaptive prior on blocks with $\\bar\\gamma$ (g_bar):\nm_M4 \u0026lt;- ulam(\ralist(\rpulled_left ~ dbinom(1, p),\rlogit(p) \u0026lt;- a[actor] + g[block_id] + b[treatment],\rb[treatment] ~ dnorm(0, 0.5),\r## adaptive priors\ra[actor] ~ dnorm(a_bar, sigma_a),\rg[block_id] ~ dnorm(g_bar, sigma_g),\r## hyper-priors\ra_bar ~ dnorm(0, 1.5),\rg_bar ~ dnorm(0, 1.5),\rsigma_a ~ dexp(1),\rsigma_g ~ dexp(1)\r),\rdata = dat_list, chains = 4, cores = 4, log_lik = TRUE\r)\r Finally, let\u0026rsquo;s compare these two models:\nprecis(m13.4, 2, pars = c(\u0026quot;a_bar\u0026quot;, \u0026quot;b\u0026quot;))\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a_bar 0.5572916 0.7400381 -0.61815978 1.71465486 846.1133 1.000954\r## b[1] -0.1117336 0.3049828 -0.59688685 0.38352742 537.8580 1.005063\r## b[2] 0.4117441 0.3013615 -0.07603188 0.90041231 541.1696 1.004054\r## b[3] -0.4583805 0.3050711 -0.94912651 0.02402336 525.1723 1.003261\r## b[4] 0.3022693 0.2992465 -0.19185582 0.76269842 496.3259 1.002969\r precis(m_M4, 2, pars = c(\u0026quot;a_bar\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;g_bar\u0026quot;))\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a_bar 0.4579123 1.1562369 -1.32920915 2.276252493 288.8963 1.000056\r## b[1] -0.1180502 0.2922779 -0.58177755 0.345807340 623.5734 1.004741\r## b[2] 0.4021677 0.2935470 -0.08422107 0.874494410 653.4873 1.001191\r## b[3] -0.4628938 0.2963843 -0.93668728 -0.005844908 640.5164 1.004185\r## b[4] 0.2897304 0.2867230 -0.16069746 0.758941565 611.7289 1.002156\r## g_bar 0.1704292 1.1696618 -1.77806340 1.926636466 209.8574 1.001308\r Oof. That new model (m_M4) did not work well. I gleam that its sampling was extremely inefficient from looking at the number of effective samples (n_eff) and Gelman-Rubin statistic (Rhat) above. The numbers of effective samples are much worse for all of our parameters in m_M4 when compared to the original model (m13.4).\nWhy is that? Well, m_M4 is what is called over-parameterised. Both means of our intercepts (a[actor], g[block_id]) are defined via varying priors now. So since there are two parameters for our means, one inside each adaptive prior, we end up with an infinite number of combinations of values of $\\bar\\alpha$ and $\\bar\\gamma$ to produce the same sum. This makes the posterior poorly defined and hard to sample. It is worth pointing out, however, that the estimated parameters are almost exactly the same between the two models. Conclusively, over-parameterisation is inefficient in sampling, but will land on similar values if run long enough. We should still avoid coding our models this way in the first place, of course.\nHard Exercises Practice H1 Question: In 1980, a typical Bengali woman could have 5 or more children in her lifetime. By the year 2000, a typical Bengali woman had only 2 or 3. You’re going to look at a historical set of data, when contraception was widely available but many families chose not to use it. These data reside in data(bangladesh) and come from the 1988 Bangladesh Fertility Survey. Each row is one of 1934 women. There are six variables, but you can focus on three of them for this practice problem:\n(1) district: ID number of administrative district each woman resided in\n(2) use.contraception: An indicator (0/1) of whether the woman was using contraception\n(3) urban: An indicator (0/1) of whether the woman lived in a city, as opposed to living in a rural area\nThe first thing to do is ensure that the cluster variable, district, is a contiguous set of integers. Recall that these values will be index values inside the model. If there are gaps, you’ll have parameters for which there is no data to inform them. Worse, the model probably won’t run. Look at the unique values of the district variable:\ndata(bangladesh)\rd \u0026lt;- bangladesh\rsort(unique(d$district))\r ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 55 56 57 58 59 60 61\r District 54 is absent. So district isn\u0026rsquo;t yet a good index variable, because it’s not contiguous. This is easy to fix. Just make a new variable that is contiguous. This is enough to do it:\nd$district_id \u0026lt;- as.integer(as.factor(d$district))\rsort(unique(d$district_id))\r ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\r Now there are 60 values, contiguous integers 1 to 60. Now, focus on predicting use.contraception, clustered by district_id. Do not include urban just yet. Fit both (1) a traditional fixed-effects model that uses dummy variables for district and (2) a multilevel model with varying intercepts for district. Plot the predicted proportions of women in each district using contraception, for both the fixed-effects model and the varying-effects model. That is, make a plot in which district ID is on the horizontal axis and expected proportion using contraception is on the vertical. Make one plot for each model, or layer them on the same plot, as you prefer. How do the models disagree? Can you explain the pattern of disagreement? In particular, can you explain the most extreme cases of disagreement, both why they happen where they do and why the models reach different inferences?\nAnswer: First, I prep the data into a list:\ndat_list \u0026lt;- list(\rC = d$use.contraception,\rD = d$district_id\r)\r Now for the models:\n Fixed-Effect:  m_Fixed \u0026lt;- ulam(\ralist(\rC ~ bernoulli(p), # this is the same as dbinom(1, p)\rlogit(p) \u0026lt;- a[D],\ra[D] ~ dnorm(0, 1.5)\r),\rdata = dat_list, chains = 4, cores = 4, log_lik = TRUE\r)\r Varying-Intercept:  m_Varying \u0026lt;- ulam(\ralist(\rC ~ dbinom(1, p), # this is the same as bernoulli(p)\rlogit(p) \u0026lt;- a[D],\ra[D] ~ normal(a_bar, sigma),\ra_bar ~ normal(0, 1.5),\rsigma ~ exponential(1)\r),\rdata = dat_list, chains = 4, cores = 4, log_lik = TRUE\r)\r Now to make our predictions:\n## compute posterior means\rp_Fixed \u0026lt;- apply(inv_logit(extract.samples(m_Fixed)$a), 2, mean)\rp_Varying \u0026lt;- apply(inv_logit(extract.samples(m_Varying)$a), 2, mean)\r## compute raw estimate from data in each district\rtab \u0026lt;- table(d$use.contraception, d$district_id) # contraception no and yes per district\rn_per_district \u0026lt;- colSums(tab) # number of observations per district\rp_raw \u0026lt;- as.numeric(tab[2, ] / n_per_district) # raw proportion per district\rnd \u0026lt;- max(dat_list$D) # number of districts\rplot(NULL, xlim = c(1, nd), ylim = c(0, 1), ylab = \u0026quot;prob use contraception\u0026quot;, xlab = \u0026quot;district\u0026quot;)\rpoints(1:nd, p_Fixed, pch = 16, col = rangi2, cex = 3)\rpoints(1:nd, p_Varying, cex = 3)\rpoints(1:nd, p_raw, pch = 3, cex = 3)\rabline(\rh = mean(inv_logit(extract.samples(m_Varying)$a_bar)), # population mean\rlty = 2\r)\r As expected, the varying-intercept-estimates (open circles) are shrunk towards the population mean (dashed line) when compared to the fixed-intercept-estimates (blue circles) and the raw proportion (cross symbols). Some are shrunk more than others. Those which are shrunk more have been shrunk because:\n Their sample sizes were small Their raw proportions were far from the population mean  Shrinkage is also introduced due to large variation in the values within each clustering variable which is much easier to demonstrate with continuous observations rather than a binary outcome (contraception used: yes/no).\nPractice H2 Question: Return to the Trolley data, data(Trolley), from Chapter 12. Define and fit a varying intercepts model for these data. Cluster intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as ordinary terms. Compare the varying intercepts model and a model that ignores individuals, using both WAIC and posterior predictions. What is the impact of individual variation in these data?\nAnswer: Again, let\u0026rsquo;s start with loading the data and preparing it into a list:\ndata(Trolley)\rd \u0026lt;- Trolley\rdat \u0026lt;- list(\rR = d$response,\rA = d$action,\rI = d$intention,\rC = d$contact\r)\r To run the varying intercept model, the id variable needs to be a simple index variable. Currently that is not the case, so let fix that, too:\ndat$id \u0026lt;- coerce_index(d$id)\r Here\u0026rsquo;s the model from chapter 12 (m12.5) which will be our baseline model for comparison:\nm12.5 \u0026lt;- ulam(\ralist(\rR ~ dordlogit(phi, cutpoints),\rphi \u0026lt;- bA * A + bC * C + BI * I,\rBI \u0026lt;- bI + bIA * A + bIC * C,\rc(bA, bI, bC, bIA, bIC) ~ dnorm(0, 0.5),\rcutpoints ~ dnorm(0, 1.5)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE\r)\r Now for the varying intercepts model (I have added a new parameter: a[id]:\nm_H2 \u0026lt;- ulam(\ralist(\rR ~ dordlogit(phi, cutpoints),\rphi \u0026lt;- a[id] + bA * A + bC * C + BI * I,\rBI \u0026lt;- bI + bIA * A + bIC * C,\ra[id] ~ normal(0, sigma),\rc(bA, bI, bC, bIA, bIC) ~ dnorm(0, 0.5),\rcutpoints ~ dnorm(0, 1.5),\rsigma ~ exponential(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE\r)\r Let\u0026rsquo;s start comparing these two models by looking at their parameter estimates:\nprecis(m12.5)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## bIC -1.2332275 0.09736975 -1.3882391 -1.0769963 999.3059 1.000883\r## bIA -0.4325889 0.07986057 -0.5621930 -0.3043263 937.5476 1.000899\r## bC -0.3430801 0.06858197 -0.4535116 -0.2286056 999.4107 1.000974\r## bI -0.2919059 0.05770286 -0.3857312 -0.2020194 855.6081 1.001664\r## bA -0.4733247 0.05380776 -0.5606800 -0.3883240 892.1070 1.001730\r precis(m_H2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## bIC -1.6593276 0.10069140 -1.8242617 -1.4993492 1345.530 0.9989020\r## bIA -0.5524349 0.07997312 -0.6840528 -0.4238708 1185.324 0.9994280\r## bC -0.4584264 0.07028331 -0.5692494 -0.3468558 1299.616 0.9997609\r## bI -0.3892700 0.05888992 -0.4845553 -0.2932161 1044.587 0.9994699\r## bA -0.6511028 0.05543980 -0.7386650 -0.5631939 1256.216 0.9988687\r## sigma 1.9176768 0.08248496 1.7902506 2.0537969 2291.638 0.9997130\r When moving to varying intercepts, in this case, all parameter estimates have become stronger in magnitude while remaining negative in sign. Why is that? Because there is a lot of variation among the individual intercepts. sigma tells us that. Remember that is on the logit scale, so there is a lot of variation here in probability scale. Conclusively, the average formulation we explored in chapter 12 (m12.5) hid a lot of the effect of the different treatments.\nFinally, let\u0026rsquo;s compare our models using WAIC:\ncompare(m12.5, m_H2)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m_H2 31057.47 179.39150 0.000 NA 355.68843 1\r## m12.5 36929.69 80.66443 5872.216 173.5441 11.17174 0\r Now it\u0026rsquo;s official. Conditioning on the individual (id) really made a massive difference here in understanding the assignments of morality among our data. Effectively, this tells us that our few variables which we used previously to understand how people of different backgrounds and genders perceive morality are not enough to fully understand the matter at hand.\nPractice H3 Question: The Trolley data are also clustered by story, which indicates a unique narrative for each vignette. Define and fit a cross-classified varying intercepts model with both id and story. Use the same ordinary terms as in the previous problem. Compare this model to the previous models. What do you infer about the impact of different stories on responses?\nAnswer: I continue with the data as used before, but add the information about story which needs to be coerced into a proper index, too:\ndat$Sid \u0026lt;- coerce_index(d$story)\r Now for the cross-classified model. All I do here is just add a varying intercept for story/Sid. This is a non-centred parametrisation - it probably explores posterior space less efficiently than the centred counterpart, but I find it easier to write and am under a time crunch when writing these solutions:\nm_H3 \u0026lt;- ulam(\ralist(\rR ~ dordlogit(phi, cutpoints),\rphi \u0026lt;- z[id] * sigma + s[Sid] + bA * A + bC * C + BI * I,\rBI \u0026lt;- bI + bIA * A + bIC * C,\rz[id] ~ normal(0, 1),\rs[Sid] ~ normal(0, tau),\rc(bA, bI, bC, bIA, bIC) ~ dnorm(0, 0.5),\rcutpoints ~ dnorm(0, 1.5),\rsigma ~ exponential(1),\rtau ~ exponential(1)\r),\rdata = dat, chains = 4, cores = 4, log_lik = TRUE\r)\r precis(m_H3)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## bIC -1.2842990 0.11302619 -1.4633731 -1.1053741 1298.018 1.0012462\r## bIA -0.5259545 0.08510626 -0.6602232 -0.3885573 1328.205 0.9999519\r## bC -1.0802958 0.09536571 -1.2312331 -0.9262213 1306.242 0.9997597\r## bI -0.4587315 0.06843039 -0.5681288 -0.3517746 1287.560 1.0026441\r## bA -0.8941359 0.06928219 -1.0008664 -0.7831957 1316.376 1.0001676\r## sigma 1.9602712 0.08455294 1.8277702 2.0951087 170.422 1.0206646\r## tau 0.5404331 0.13271393 0.3704167 0.7853622 1857.443 0.9987709\r The treatment variable estimates (bIC, bIA, etc.) are changed from the previous model (m_H2). Interestingly, the estimate for sigma (variation among individuals) has not changed much. The added variation among stories (tau) is noticeable, albeit much smaller than sigma. Let\u0026rsquo;s visualise this:\nplot(coeftab(m_H2, m_H3), pars = c(\u0026quot;bIC\u0026quot;, \u0026quot;bIA\u0026quot;, \u0026quot;bC\u0026quot;, \u0026quot;bI\u0026quot;, \u0026quot;bA\u0026quot;, \u0026quot;sigma\u0026quot;, \u0026quot;tau\u0026quot;))\r This means that there is probably rather meaningful information contained within the story variable when trying to understand morality of decision in the trolley data. We cannot meaningfully compare these models using WAIC, however, and so this will remain a qualitative statement\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] cowplot_1.1.1 tidybayes_2.3.1 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 tidyr_1.1.3 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 ## [10] V8_3.4.1 plyr_1.8.6 R6_2.5.0 backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 ## [19] pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 ## [28] labeling_0.4.2 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 ## [37] htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 arrayhelpers_1.1-0 codetools_0.2-18 matrixStats_0.61.0 fansi_0.4.2 ## [46] crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 distributional_0.2.2 ggdist_2.4.0 grid_4.0.5 jsonlite_1.7.2 ## [55] gtable_0.3.0 lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 farver_2.1.0 ## [64] bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.7 rematch2_2.1.2 forcats_0.5.1 tools_4.0.5 svUnit_1.0.6 R.cache_0.14.0 ## [73] glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1617753600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617822000,"objectID":"8c4c9e0cc0e51ba9e33e3e13499575e7","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-13/","publishdate":"2021-04-07T00:00:00Z","relpermalink":"/courses/rethinking/chapter-13/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 13 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 13","type":"docs"},{"authors":null,"categories":null,"content":"I\u0026rsquo;m afraid, I haven\u0026rsquo;t found the time to create this one yet.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aac172f86c9f2c2b6414e56de41c6b2a","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/13-an-outlook-on-advanced-statistics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/13-an-outlook-on-advanced-statistics/","section":"courses","summary":"I\u0026rsquo;m afraid, I haven\u0026rsquo;t found the time to create this one yet.","tags":null,"title":"Closing \u0026 Summary","type":"docs"},{"authors":null,"categories":null,"content":"I\u0026rsquo;m afraid, I haven\u0026rsquo;t found the time to create this one yet.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"49421423360a003d9bf987856b6bb929","permalink":"https://www.erikkusch.com/courses/biostat101/13-an-outlook-on-advanced-statistics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/biostat101/13-an-outlook-on-advanced-statistics/","section":"courses","summary":"I\u0026rsquo;m afraid, I haven\u0026rsquo;t found the time to create this one yet.","tags":null,"title":"Closing \u0026 Summary","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Adventures in Covariance Material  \rSlides Chapter 14  Introduction These are answers and solutions to the exercises at the end of chapter 14 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from\nthe solutions provided to instructors by Richard McElreath himself.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(rstan)\rlibrary(MASS)\rlibrary(ellipse)\rlibrary(ape)\rlibrary(ggplot2)\rlibrary(tidybayes)\r Easy Exercises Practice E1 Question: Add to the following model varying slopes on the predictor $x$.\n$$y_i ∼ Normal(µi, σ)$$ $$µ_i = α_{group[i]} + βx_i$$ $$α_{group} ∼ Normal(α, σ_α)$$ $$α ∼ Normal(0, 10)$$ $$β ∼ Normal(0, 1)$$ $$σ ∼ HalfCauchy(0, 2)$$ $$σ_α ∼ HalfCauchy(0, 2)$$\nAnswer: To do this, our outcome distribution does not change. So keep it as is:\n$$y_i ∼ Normal(μ_i, σ)$$\nNext, we come to the linear model. This needs changing. Since we are now interested in a varying slope for each group ($\\beta_{group}$), we need to exchange the original $\\beta$ with $\\beta_{group}$:\n$$μ_i = α_{group[i]} + β_{group[i]}x_i$$\nConsequently, we also need to change our prior. Since $\\alpha_{group}$ and $\\beta_{group}$ now stem from a joint distribution, we need to express them as such. $\\alpha$ is still the average intercept. However, $\\beta$ now turns into the average slope. Both of these serve as the mean expectations for $\\alpha_{group}$ and $\\beta_{group}$ in a multivariate normal distribution ($MVNormal()$) with a covariance matrix ($S$) defining how they are linked.\n$$\\begin{bmatrix} \\alpha_{group} \\ \\beta_{group} \\ \\end{bmatrix} \\sim MVNormal \\left(\\begin{bmatrix} \\alpha \\ \\beta \\ \\end{bmatrix}, S \\right)$$\nSince we have just introduced the need for a covariance matrix, we now need to define it. A covariance matrix is the product of a variance matrix and a correlation matrix ($R$). What we can do when determining the covariance matrix ($S$) is setting our variances for $\\alpha$ and $\\beta$ - $\\sigma_\\alpha$ and $\\sigma_\\beta$, respectively - and subsequently multiplying this with the correlation matrix ($R$):\n$$S = \\begin{pmatrix} \\sigma_\\alpha \u0026amp; 0 \\ 0 \u0026amp; \\sigma_\\beta \\ \\end{pmatrix} R \\begin{pmatrix} \\sigma_\\alpha \u0026amp; 0 \\ 0 \u0026amp; \\sigma_\\beta \\ \\end{pmatrix} $$\nThe variances and correlation matrix referenced above need priors of their own - so called hyperpriors. Let\u0026rsquo;s start with the priors of the variances:\n$$σ_α ∼ HalfCauchy(0, 2)$$ $$σ_\\beta ∼ HalfCauchy(0, 2)$$\nAnd also add a somewhat regularising prior for $R$:\n$$R ∼ LKJcorr(2)$$\nLastly, we simply keep the priors for $\\alpha$, $\\beta$, and $\\sigma$ from the original model. $$α ∼ Normal(0, 10)$$ $$β ∼ Normal(0, 1)$$ $$σ ∼ HalfCauchy(0, 2)$$\nPractice E2 Question: Think up a context in which varying intercepts will be positively correlated with varying slopes. Provide a mechanistic explanation for the correlation.\nAnswer: A setting within which there is positive correlation between varying intercepts and varying slopes can be put in laymen-terms as: \u0026ldquo;A setting within which high intercepts come with steep slopes\u0026rdquo;. With that in mind, what could be such a setting?\nThere are many settings which would meet this criterion. I am a biologist by training and the first thing that came to mind was that of an ant colony. Let\u0026rsquo;s say we are interested studying ant hill size as a function of food availability. Ignoring the carrying capacity of a system, we can reasonably expect larger ant hills (higher intercepts) to benefit more strongly from increased food availability as their foraging will be much more efficient (steeper slope).\nOf course, I realise that this thought experiment ignores some crucial bits of biological reality such as diminishing returns and structural integrity of ant hills after a certain size is reached. For the sake of keeping this example simple, I neglect them.\nPractice E3 Question: When is it possible for a varying slopes model to have fewer effective parameters (as estimated by WAIC or DIC) than the corresponding model with fixed (unpooled) slopes? Explain.\nAnswer: When there is little or next-to-no variation among clusters. The absence of this among-cluster variation induces very strong shrinkage. As a result, albeit containing more actual parameters in the posterior distribution, the varying slopes model may end up less flexible in fitting to the data because of adaptive regularisation forcing strong shrinkage. Consequently, our number of effective parameters - a proxy of overfitting risk and posterior flexibility - decreases.\nFor an example, consult the comparison of models m13.1 and m13.2 in R Code 13.4 in the book.\nMedium Exercises Practice M1 Question: Repeat the café robot simulation from the beginning of the chapter. This time, set rho to zero, so that there is no correlation between intercepts and slopes. How does the posterior distribution of the correlation reflect this change in the underlying simulation?\nAnswer: This is what was done in the book. rho has been adjusted to be $0$ now:\n# set up parameters of population\ra \u0026lt;- 3.5 # average morning wait time\rb \u0026lt;- (-1) # average difference afternoon wait time\rsigma_a \u0026lt;- 1 # std dev in intercepts\rsigma_b \u0026lt;- 0.5 # std dev in slopes\rrho \u0026lt;- 0 # correlation between intercepts and slopes\rMu \u0026lt;- c(a, b)\rcov_ab \u0026lt;- sigma_a * sigma_b * rho\rSigma \u0026lt;- matrix(c(sigma_a^2, cov_ab, cov_ab, sigma_b^2), ncol = 2)\r# simulate observations\rN_cafes \u0026lt;- 20\rset.seed(6)\rvary_effects \u0026lt;- mvrnorm(N_cafes, Mu, Sigma)\ra_cafe \u0026lt;- vary_effects[, 1]\rb_cafe \u0026lt;- vary_effects[, 2]\rN_visits \u0026lt;- 10\rafternoon \u0026lt;- rep(0:1, N_visits * N_cafes / 2)\rcafe_id \u0026lt;- rep(1:N_cafes, each = N_visits)\rmu \u0026lt;- a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\rsigma \u0026lt;- 0.5 # std dev within cafes\rwait \u0026lt;- rnorm(N_visits * N_cafes, mu, sigma)\r# package into data frame\rd \u0026lt;- data.frame(cafe = cafe_id, afternoon = afternoon, wait = wait)\r And now to run our model (m14.1) with the exact same specification as in the book:\nm_M1 \u0026lt;- ulam(\ralist(\rwait ~ normal(mu, sigma),\rmu \u0026lt;- a_cafe[cafe] + b_cafe[cafe] * afternoon,\rc(a_cafe, b_cafe)[cafe] ~ multi_normal(c(a, b), Rho, sigma_cafe),\ra ~ normal(5, 2),\rb ~ normal(-1, 0.5),\rsigma_cafe ~ exponential(1),\rsigma ~ exponential(1),\rRho ~ lkj_corr(2)\r),\rdata = d, chains = 6, cores = 6\r)\r So what about that posterior distribution for Rho?\npost \u0026lt;- extract.samples(m_M1)\rggplot() +\rstat_halfeye(aes(x = post$Rho[, 1, 2])) +\rtheme_bw() +\rlabs(x = \u0026quot;Rho\u0026quot;)\r Jup. That accurately represents our underlying correlation of $0$. The precis output agrees:\nprecis(m_M1, pars = \u0026quot;Rho[1,2]\u0026quot;)\r ## result\r## mean 0.01110476\r## sd 0.23468860\r## 5.5% -0.36400650\r## 94.5% 0.38982346\r## n_eff 2833.41771477\r## Rhat 1.00023118\r Practice M2 Question: Fit this multilevel model to the simulated café data: $$W_i ∼ Normal(µ_i, σ)$$ $$µ_i = α_{café[i]} + β_{café[i]}A_i$$ $$α_{café} ∼ Normal(α, σ_α)$$ $$β_{café} ∼ Normal(β, σ_β)$$ $$α ∼ Normal(0, 10)$$ $$β ∼ Normal(0, 10)$$ $$σ ∼ HalfCauchy(0, 1)$$ $$σ_α ∼ HalfCauchy(0, 1)$$ $$σ_β ∼ HalfCauchy(0, 1)$$\nUse WAIC to compare this model to the model from the chapter, the one that uses a multi-variate Gaussian prior. Explain the result.\nAnswer: I am strongly assuming that this question is targeting the simulated café data used in the book. I create that data again here:\n# set up parameters of population\ra \u0026lt;- 3.5 # average morning wait time\rb \u0026lt;- -1 # average difference afternoon wait time\rsigma_a \u0026lt;- 1 # std dev in intercepts\rsigma_b \u0026lt;- 0.5 # std dev in slopes\rrho \u0026lt;- -0.7 # correlation between intercepts and slopes\rMu \u0026lt;- c(a, b)\rcov_ab \u0026lt;- sigma_a * sigma_b * rho\rSigma \u0026lt;- matrix(c(sigma_a^2, cov_ab, cov_ab, sigma_b^2), ncol = 2)\r# simulate observations\rN_cafes \u0026lt;- 20\rset.seed(42)\rvary_effects \u0026lt;- mvrnorm(N_cafes, Mu, Sigma)\ra_cafe \u0026lt;- vary_effects[, 1]\rb_cafe \u0026lt;- vary_effects[, 2]\rN_visits \u0026lt;- 10\rafternoon \u0026lt;- rep(0:1, N_visits * N_cafes / 2)\rcafe_id \u0026lt;- rep(1:N_cafes, each = N_visits)\rmu \u0026lt;- a_cafe[cafe_id] + b_cafe[cafe_id] * afternoon\rsigma \u0026lt;- 0.5 # std dev within cafes\rwait \u0026lt;- rnorm(N_visits * N_cafes, mu, sigma)\r# package into data frame\rd \u0026lt;- data.frame(cafe = cafe_id, afternoon = afternoon, wait = wait)\r With the data at hand, I now run our baseline model which is, again, m14.1:\nm_M2Baseline \u0026lt;- ulam(\ralist(\rwait ~ normal(mu, sigma),\rmu \u0026lt;- a_cafe[cafe] + b_cafe[cafe] * afternoon,\rc(a_cafe, b_cafe)[cafe] ~ multi_normal(c(a, b), Rho, sigma_cafe),\ra ~ normal(5, 2),\rb ~ normal(-1, 0.5),\rsigma_cafe ~ exponential(1),\rsigma ~ exponential(1),\rRho ~ lkj_corr(2)\r),\rdata = d, chains = 4, cores = 4\r)\r And now onto our new model for this task. What is already striking is the use of independent intercepts and slopes. There is no correlation parameter between them so the assumed correlation, by the model, is $0$:\nm_M2 \u0026lt;- ulam(\ralist(\rwait ~ dnorm(mu, sigma),\rmu \u0026lt;- a_cafe[cafe] + b_cafe[cafe] * afternoon,\ra_cafe[cafe] ~ dnorm(a, sigma_alpha),\rb_cafe[cafe] ~ dnorm(b, sigma_beta),\ra ~ dnorm(0, 10),\rb ~ dnorm(0, 10),\rsigma ~ dexp(1),\rsigma_alpha ~ dexp(1),\rsigma_beta ~ dexp(1)\r),\rdata = d, chains = 4, cores = 4\r)\r But what actually distinguishes the model outputs now? Let\u0026rsquo;s extract posterior samples for intercepts and slopes from both models and investigate visually:\npost_Base \u0026lt;- extract.samples(m_M2Baseline)\ra_Base \u0026lt;- apply(post_Base$a_cafe, 2, mean)\rb_Base \u0026lt;- apply(post_Base$b_cafe, 2, mean)\rpost_M2 \u0026lt;- extract.samples(m_M2)\ra_M2 \u0026lt;- apply(post_M2$a_cafe, 2, mean)\rb_M2 \u0026lt;- apply(post_M2$b_cafe, 2, mean)\rplot(a_M2, b_M2,\rxlab = \u0026quot;intercept\u0026quot;, ylab = \u0026quot;slope\u0026quot;,\rpch = 16, col = rangi2, ylim = c(min(b_M2) - 0.05, max(b_M2) + 0.05),\rxlim = c(min(a_M2) - 0.1, max(a_M2) + 0.1), cex = 2\r)\rpoints(a_Base, b_Base, pch = 1, cex = 2)\r I have stuck to McElreath\u0026rsquo;s colour scheme here once more. The filled circles represent samples from our new model, while the open circles represent samples from the posterior obtained via the model which accounts for correlation of slopes and intercepts. First and foremost, these are pretty similar I must say. This agreement is particularly pronounced towards the centre of the plot with increasing divergences of the posterior samples at the fringes of the intercept and slope ranges. This comes down to what the underlying models assume. Our baseline model assumes that slopes and intercepts are inherently related to one another and finds a negative correlation between them. This can be seen when looking at the lower right-hand and the upper left-hand corner of the plot above. Given the baseline model assumption, large intercepts are associated with strongly negative slopes and vice versa.\nThe correlation-informed model does better here because it leverages more information from the entire population and just so happens to exactly mirror the data generation process.\nPractice M3 Question: Re-estimate the varying slopes model for the UCBadmit data, now using a non-centered parametrization. Compare the efficiency of the forms of the model, using n_eff. Which is better? Which chain sampled faster?\nAnswer: Ok\u0026hellip; This is a headache because there is no varying slopes model for the UCBadmit data in the bookchapter. So let\u0026rsquo;s make one ourselves and then re-parameterise it.\nWe start by loading and preparing the data. By defining an indicator variable for male we make it easier to fit a varying slopes model based on gender of applicant:\ndata(UCBadmit)\rd \u0026lt;- UCBadmit\rdat_list \u0026lt;- list(\radmit = d$admit,\rapplications = d$applications,\rmale = ifelse(d$applicant.gender == \u0026quot;male\u0026quot;, 1, 0),\rdept_id = rep(1:6, each = 2)\r)\rstr(dat_list)\r ## List of 4\r## $ admit : int [1:12] 512 89 353 17 120 202 138 131 53 94 ...\r## $ applications: int [1:12] 825 108 560 25 325 593 417 375 191 393 ...\r## $ male : num [1:12] 1 0 1 0 1 0 1 0 1 0 ...\r## $ dept_id : int [1:12] 1 1 2 2 3 3 4 4 5 5 ...\r Now with the data in hand, we can fit our own model on varying slopes. Let\u0026rsquo;s think about this in theory first. What would this look like?\nWe start out with a binomial outcome distribution for our admitted applications:\n$$admit_i ∼ Binomial(Applications, p_i)$$\nOur next line is the linear model again. This time, the admittance rate ($p_i$) is a product of a department-specific intercept ($\\alpha_{deptId}$) and slope ($\\beta_{deptId}$):\n$$p_i = \\alpha_{deptID} + \\beta_{deptID}*male$$\nSince the varying slopes and intercepts are certain to be correlated, we specify a multivariate normal prior again:\n$$\\begin{bmatrix} \\alpha_{deptID} \\ \\beta_{deptID} \\ \\end{bmatrix} \\sim MVNormal \\left(\\begin{bmatrix} \\alpha \\ \\beta \\ \\end{bmatrix}, S \\right)$$\nAnd now for the covariance matrix:\n$$S = \\begin{pmatrix} \\sigma_\\alpha \u0026amp; 0 \\ 0 \u0026amp; \\sigma_\\beta \\ \\end{pmatrix} R \\begin{pmatrix} \\sigma_\\alpha \u0026amp; 0 \\ 0 \u0026amp; \\sigma_\\beta \\ \\end{pmatrix} $$\nFinally, we just need some priors and hyperpriors:\n$$σ_α ∼ Exponential(1)$$ $$σ_\\beta ∼ Exponential(1)$$\nAnd also add a somewhat regularising prior for $R$:\n$$R ∼ LKJcorr(2)$$\nLastly, we simply keep the priors for $\\alpha$, $\\beta$: $$α ∼ Normal(0, 1)$$ $$β ∼ Normal(0, 1)$$\nAnd now to do all of this in R:\nBegin_C \u0026lt;- Sys.time()\rm_M3 \u0026lt;- ulam(\ralist(\radmit ~ dbinom(applications, p),\rlogit(p) \u0026lt;- a[dept_id] + bm[dept_id] * male,\rc(a, bm)[dept_id] ~ multi_normal(c(a_bar, bm_bar), Rho, sigma_dept),\ra_bar ~ dnorm(0, 1),\rbm_bar ~ dnorm(0, 1),\rsigma_dept ~ dexp(1),\rRho ~ dlkjcorr(2)\r),\rdata = dat_list, chains = 4, cores = 4\r)\rEnd_C \u0026lt;- Sys.time()\rprecis(m_M3, 3)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## bm[1] -0.75467135 2.642890e-01 -1.1974575 -0.3419394 762.8361 1.0035396\r## bm[2] -0.21546963 3.141762e-01 -0.7172490 0.2702785 1444.8377 1.0007292\r## bm[3] 0.07788729 1.395628e-01 -0.1457046 0.3005848 1519.8738 1.0005234\r## bm[4] -0.09706014 1.389302e-01 -0.3171928 0.1276948 1760.1554 0.9999004\r## bm[5] 0.11606582 1.793774e-01 -0.1610577 0.4022199 1726.0739 1.0005376\r## bm[6] -0.10986997 2.643276e-01 -0.5302442 0.3009293 1397.2613 1.0030231\r## a[1] 1.27128456 2.477604e-01 0.8819218 1.6722364 778.7511 1.0032979\r## a[2] 0.74963140 3.154061e-01 0.2626239 1.2484753 1436.8953 1.0004966\r## a[3] -0.64605733 8.582742e-02 -0.7808221 -0.5086328 1617.3253 0.9995321\r## a[4] -0.61501279 1.019817e-01 -0.7774726 -0.4515837 1708.0376 0.9992410\r## a[5] -1.13005620 1.096386e-01 -1.3054035 -0.9559542 1993.4173 1.0004230\r## a[6] -2.60481876 2.045530e-01 -2.9411431 -2.2759003 1799.7746 1.0015531\r## a_bar -0.39106882 5.307969e-01 -1.2265922 0.4709463 1698.0086 0.9994382\r## bm_bar -0.16176143 2.137141e-01 -0.4947019 0.1694293 1403.2870 1.0018595\r## sigma_dept[1] 1.48653705 4.716297e-01 0.9088349 2.3531967 1292.0985 1.0008335\r## sigma_dept[2] 0.44566910 2.144169e-01 0.1819589 0.8410725 988.9796 1.0015728\r## Rho[1,1] 1.00000000 0.000000e+00 1.0000000 1.0000000 NaN NaN\r## Rho[1,2] -0.32154165 3.408218e-01 -0.8124723 0.2811236 1522.8640 1.0015113\r## Rho[2,1] -0.32154165 3.408218e-01 -0.8124723 0.2811236 1522.8640 1.0015113\r## Rho[2,2] 1.00000000 8.265587e-17 1.0000000 1.0000000 1811.6478 0.9979980\r Let\u0026rsquo;s just acknowledge that the precis() output is here, but move on for now to the re-parametrised model.\nI am not even going to attempt to come up with the mathematical notation of the non-centred version of the above model. Luckily, I don\u0026rsquo;t have to because ulam() has helper functions which can do this for me:\nBegin_NC \u0026lt;- Sys.time()\rm_M3NonCent \u0026lt;- ulam(\ralist(\radmit ~ dbinom(applications, p),\rlogit(p) \u0026lt;- a_bar + v[dept_id, 1] + (bm_bar + v[dept_id, 2]) * male,\rtranspars \u0026gt; matrix[dept_id, 2]:v \u0026lt;- compose_noncentered(sigma_dept, L_Rho, z),\rmatrix[2, dept_id]:z ~ dnorm(0, 1),\ra_bar ~ dnorm(0, 1.5),\rbm_bar ~ dnorm(0, 1),\rvector[2]:sigma_dept ~ dexp(1),\rcholesky_factor_corr[2]:L_Rho ~ lkj_corr_cholesky(2)\r),\rdata = dat_list, chains = 4, cores = 4\r)\rEnd_NC \u0026lt;- Sys.time()\rprecis(m_M3NonCent, 3)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## z[1,1] 1.27847990 0.5262323 0.4705305 2.13326205 727.0227 1.0011087\r## z[1,2] 0.88269092 0.4857079 0.1388867 1.68994558 719.7999 1.0031813\r## z[1,3] -0.12528283 0.3849925 -0.7106325 0.50669799 612.7119 1.0140975\r## z[1,4] -0.10433526 0.3866020 -0.6958663 0.51682268 601.9049 1.0154629\r## z[1,5] -0.48074322 0.4055438 -1.1153447 0.16675545 643.6182 1.0175388\r## z[1,6] -1.56200990 0.5688037 -2.4838992 -0.69872746 737.3167 1.0145782\r## z[2,1] -1.23644880 0.8164974 -2.6022559 0.05071129 1271.1801 1.0026798\r## z[2,2] 0.18312727 0.8096899 -1.0820859 1.45719856 1573.6340 1.0003249\r## z[2,3] 0.60192227 0.6276861 -0.3439741 1.64761142 1203.4125 1.0020469\r## z[2,4] 0.10146041 0.5799030 -0.8100848 1.01529134 1291.1294 1.0015204\r## z[2,5] 0.53484163 0.6684946 -0.4889643 1.64962250 1165.4873 1.0009753\r## z[2,6] -0.49127010 0.8038063 -1.8068248 0.74735922 1885.4880 1.0003286\r## a_bar -0.46792318 0.5611715 -1.3795380 0.39745615 588.0941 1.0121940\r## bm_bar -0.13969516 0.2136100 -0.4695941 0.18952741 799.7150 1.0034511\r## sigma_dept[1] 1.46852953 0.4505571 0.9255641 2.31989495 833.1351 1.0030067\r## sigma_dept[2] 0.44493698 0.2388977 0.1818530 0.86089979 757.1626 0.9991599\r## L_Rho[1,1] 1.00000000 0.0000000 1.0000000 1.00000000 NaN NaN\r## L_Rho[1,2] 0.00000000 0.0000000 0.0000000 0.00000000 NaN NaN\r## L_Rho[2,1] -0.31981947 0.3440124 -0.8022403 0.29104897 1687.4781 1.0001054\r## L_Rho[2,2] 0.87223636 0.1365401 0.5970006 0.99912792 1190.3266 1.0002817\r## v[1,1] 1.73536453 0.6011856 0.8128695 2.70174932 648.8099 1.0094272\r## v[1,2] -0.61370995 0.3128848 -1.1315494 -0.14674125 1028.2946 1.0005503\r## v[2,1] 1.19934441 0.6279810 0.2169330 2.22040335 675.6765 1.0101770\r## v[2,2] -0.06176349 0.3328516 -0.5897528 0.46209909 1539.0956 1.0001901\r## v[3,1] -0.17733549 0.5673456 -1.0542767 0.75415175 593.0556 1.0109594\r## v[3,2] 0.21846891 0.2395483 -0.1438607 0.60551012 1035.9533 1.0016130\r## v[4,1] -0.14832190 0.5675488 -1.0127159 0.76606136 575.1370 1.0125444\r## v[4,2] 0.04602378 0.2363775 -0.3298587 0.41695086 890.5646 1.0022504\r## v[5,1] -0.65983984 0.5702765 -1.5558841 0.26053379 610.1289 1.0114797\r## v[5,2] 0.25080258 0.2583262 -0.1081353 0.67319529 1159.0924 1.0024436\r## v[6,1] -2.12809664 0.5847887 -3.0186504 -1.19350046 633.0943 1.0111973\r## v[6,2] 0.02683558 0.3048067 -0.4676814 0.50643307 1645.9028 1.0004084\r First of all, we can see that the number of effective samples (n_eff) is higher for the centred model (m_M3) which is surprising to me. I thought that non-centred models were supposed to sample more efficiently. Maybe the underlying data just doesn\u0026rsquo;t suffer from abrupt changes in posterior slope?\nSo what about running time?\n# Centred\rEnd_C - Begin_C\r ## Time difference of 55.36985 secs\r # Non-Centred\rEnd_NC - Begin_NC\r ## Time difference of 51.25241 secs\r Ok. The non-centred model ran slightly faster.\nPractice M4 Question: Use WAIC to compare the Gaussian process model of Oceanic tools to the models fit to the same data in Chapter 11. Pay special attention to the effective numbers of parameters, as estimated by WAIC.\nAnswer: So this needed some digging. The models in question are m11.11 for the simpler model of CHapter 11 and m14.8 from Chapter 14.\nBefore we can do any modelling, we need to load and prepare the data:\ndata(Kline)\rd \u0026lt;- Kline\r# Chapter 11 stuff\rd$P \u0026lt;- scale(log(d$population))\rd$contact_id \u0026lt;- ifelse(d$contact == \u0026quot;high\u0026quot;, 2, 1)\r# Chapter 14 stuff\rd$society \u0026lt;- 1:10\rdata(islandsDistMatrix)\r With the data at hand, I simply use the exact same code as in the book to execute the respective models. Note that I have set the ulam() argument log_lik=TRUE for comparison with WAIC in the next step.\n## Chapter 11 Model\rdat2 \u0026lt;- list(T = d$total_tools, P = d$population, cid = d$contact_id)\rm11.11 \u0026lt;- ulam(\ralist(\rT ~ dpois(lambda),\rlambda \u0026lt;- exp(a[cid]) * P^b[cid] / g,\ra[cid] ~ dnorm(1, 1),\rb[cid] ~ dexp(1),\rg ~ dexp(1)\r),\rdata = dat2, chains = 4, cores = 4, log_lik = TRUE\r)\r## Chapter 14 Model\rdat_list \u0026lt;- list(T = d$total_tools, P = d$population, society = d$society, Dmat = islandsDistMatrix)\rm14.8 \u0026lt;- ulam(\ralist(\rT ~ dpois(lambda),\rlambda \u0026lt;- (a * P^b / g) * exp(k[society]),\rvector[10]:k ~ multi_normal(0, SIGMA),\rmatrix[10, 10]:SIGMA \u0026lt;- cov_GPL2(Dmat, etasq, rhosq, 0.01), c(a, b, g) ~ dexp(1), etasq ~ dexp(2), rhosq ~ dexp(0.5)\r),\rdata = dat_list, chains = 4, cores = 4, iter = 2000, log_lik = TRUE\r)\r We have both models at the ready, let\u0026rsquo;s do what the task asked of us and compare their out-of-sample accuracy predictions:\ncompare(m11.11, m14.8)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m14.8 67.87559 2.370998 0.00000 NA 4.196489 0.998336383\r## m11.11 80.66978 11.103427 12.79419 10.95919 5.148678 0.001663617\r The more complex model taking into account spatial distances of societies - m14.8 - outperforms the previously held \u0026ldquo;best\u0026rdquo; model (m11.11). We also see that the Gaussian process model has less effective parameters (pWAIC) than the simpler model. This is a sign of intense regularisation on the part of the Gaussian Process model.\nPractice M5 Question: Modify the phylogenetic distance example to use group size as the outcome and brain size as a predictor. Assuming brain size influences group size, what is your estimate of the effect? How does phylogeny influence the estimate?\nAnswer: This is the example from the book, but simply just switching the positions of group size and brain size in the model specification. Coincidentally, this is the model shown in the YouTube Lecture series by Richard McElreath.\nFor now, we start by loading the data as was done in the book and establish our first data list for subsequent modelling:\ndata(Primates301)\rd \u0026lt;- Primates301\rd$name \u0026lt;- as.character(d$name)\rdstan \u0026lt;- d[complete.cases(d$group_size, d$body, d$brain), ]\rspp_obs \u0026lt;- dstan$name\rdat_list \u0026lt;- list(\rN_spp = nrow(dstan),\rM = standardize(log(dstan$body)),\rB = standardize(log(dstan$brain)),\rG = standardize(log(dstan$group_size)),\rImat = diag(nrow(dstan))\r)\r With this part of the observational data ready, I now turn to phylogenetic data which we can obtain and attach to our data list like so:\ndata(Primates301_nex)\rtree_trimmed \u0026lt;- keep.tip(Primates301_nex, spp_obs) # only keep tree that's relevant to our species\rRbm \u0026lt;- corBrownian(phy = tree_trimmed) # calculate expected covariance given a Brownian model\rV \u0026lt;- vcv(Rbm) # compute expected variances and covariances\rDmat \u0026lt;- cophenetic(tree_trimmed) # cophenetic distance matrix\rdat_list$V \u0026lt;- V[spp_obs, spp_obs] # covariances in speciesXspecies matrix\rdat_list$R \u0026lt;- dat_list$V / max(V) # relative covariances of speciesXspecies matrix\r And we are ready to run our first model! Because they book went through multiple candidate models so do I.\nHere, I start off with the basic, ordinary regression:\nm_M5Ordi \u0026lt;- ulam(\ralist(\rG ~ multi_normal(mu, SIGMA),\rmu \u0026lt;- a + bM * M + bB * B,\rmatrix[N_spp, N_spp]:SIGMA \u0026lt;- Imat * sigma_sq,\ra ~ normal(0, 1),\rc(bM, bB) ~ normal(0, 0.5),\rsigma_sq ~ exponential(1)\r),\rdata = dat_list, chains = 4, cores = 4\r)\r Next, I run the Brownian motion model:\nm_M5Brown \u0026lt;- ulam(\ralist(\rG ~ multi_normal(mu, SIGMA),\rmu \u0026lt;- a + bM * M + bB * B,\rmatrix[N_spp, N_spp]:SIGMA \u0026lt;- R * sigma_sq,\ra ~ normal(0, 1),\rc(bM, bB) ~ normal(0, 0.5),\rsigma_sq ~ exponential(1)\r),\rdata = dat_list, chains = 4, cores = 4\r)\r Lastly, I execute a Gaussian Process model. To do so, we need to convert our phylogenetic distance matrix into a relative measure of distance among our species:\ndat_list$Dmat \u0026lt;- Dmat[spp_obs, spp_obs] / max(Dmat)\rm_M5GP \u0026lt;- ulam(\ralist(\rG ~ multi_normal(mu, SIGMA),\rmu \u0026lt;- a + bM * M + bB * B,\rmatrix[N_spp, N_spp]:SIGMA \u0026lt;- cov_GPL1(Dmat, etasq, rhosq, 0.01),\ra ~ normal(0, 1),\rc(bM, bB) ~ normal(0, 0.5),\retasq ~ half_normal(1, 0.25),\rrhosq ~ half_normal(3, 0.25)\r),\rdata = dat_list, chains = 4, cores = 4\r)\r plot(coeftab(m_M5Ordi, m_M5Brown, m_M5GP), pars = c(\u0026quot;bM\u0026quot;, \u0026quot;bB\u0026quot;))\r From the above, we clearly see that model which does not take into account our phylogeny - m_M5Ordi - finds a clearly non-zero dependence of brain size on group size. However, both model which do include phylogenetic information - m_M5Brown and m_M5GP - do not show this relationship. Adding phylogenetic information seems to reduce the evidence for a causal link between brain size and group size.\nHard Exercises Practice H1 Question: Let’s revisit the Bangladesh fertility data, data(bangladesh), from the practice problems for Chapter 13. Fit a model with both varying intercepts by district_id and varying slopes of urban by district_id. You are still predicting use.contraception.\nInspect the correlation between the intercepts and slopes. Can you interpret this correlation, in terms of what it tells you about the pattern of contraceptive use in the sample? It might help to plot the mean (or median) varying effect estimates for both the intercepts and slopes, by district. Then you can visualize the correlation and maybe more easily think through what it means to have a particular correlation. Plotting predicted proportion of women using contraception, with urban women on one axis and rural on the other, might also help.\nAnswer: Once more, I start by loading the data and preparing it as was done in a previous chapter:\ndata(bangladesh)\rd \u0026lt;- bangladesh\rdat_list \u0026lt;- list(\rC = d$use.contraception,\rdid = as.integer(as.factor(d$district)),\rurban = d$urban\r)\r Now I can run my model:\nm_H1 \u0026lt;- ulam(\ralist(\rC ~ bernoulli(p),\rlogit(p) \u0026lt;- a[did] + b[did] * urban,\rc(a, b)[did] ~ multi_normal(c(abar, bbar), Rho, Sigma),\rabar ~ normal(0, 1),\rbbar ~ normal(0, 0.5),\rRho ~ lkj_corr(2),\rSigma ~ exponential(1)\r),\rdata = dat_list, chains = 4, cores = 4, iter = 4000\r)\r And now look at the posterior estimates of average effects:\nprecis(m_H1)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## abar -0.6842219 0.1003302 -0.8475050 -0.5301731 6158.562 1.000395\r## bbar 0.6369826 0.1590421 0.3866908 0.8900233 4474.285 1.000145\r Unsurprisingly, I find a positive effect for bbar which indicates that contraception is used more frequently in urban areas.\nLooking deeper into the posterior estimates:\nprecis(m_H1, depth = 3, pars = c(\u0026quot;Rho\u0026quot;, \u0026quot;Sigma\u0026quot;))\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## Rho[1,1] 1.0000000 0.000000e+00 1.0000000 1.0000000 NaN NaN\r## Rho[1,2] -0.6512997 1.696069e-01 -0.8680436 -0.3443487 1431.4457 1.0003693\r## Rho[2,1] -0.6512997 1.696069e-01 -0.8680436 -0.3443487 1431.4457 1.0003693\r## Rho[2,2] 1.0000000 5.972661e-17 1.0000000 1.0000000 7485.2487 0.9994999\r## Sigma[1] 0.5762512 9.710360e-02 0.4308600 0.7404430 1990.0617 1.0021542\r## Sigma[2] 0.7731623 1.991282e-01 0.4617857 1.0991674 967.7497 1.0034399\r shows a negative correlation between the intercepts and slopes (Rho[1,2] or Rho[2,1]).\nLet\u0026rsquo;s plot this relationship between the varying effects to get a better understanding of what is happening:\npost \u0026lt;- extract.samples(m_H1)\ra \u0026lt;- apply(post$a, 2, mean)\rb \u0026lt;- apply(post$b, 2, mean)\rplot(a, b, xlab = \u0026quot;a (intercept)\u0026quot;, ylab = \u0026quot;b (urban slope)\u0026quot;)\rabline(h = 0, lty = 2)\rabline(v = 0, lty = 2)\rR \u0026lt;- apply(post$Rho, 2:3, mean)\rs \u0026lt;- apply(post$Sigma, 2, mean)\rS \u0026lt;- diag(s) %*% R %*% diag(s)\rll \u0026lt;- c(0.5, 0.67, 0.89, 0.97)\rfor (l in ll) {\rel \u0026lt;- ellipse(S, centre = c(mean(post$abar), mean(post$bbar)), level = l)\rlines(el, col = \u0026quot;black\u0026quot;, lwd = 0.5)\r}\r So districts with higher use of contraception outside of urban areas come with smaller slopes. Basically, what this means is that districts which boast a high use of contraception outside of urban areas do not have a marked shift in use of contraceptives when moving to urban areas.\nWe can also show this in probability scale by applying inverse logit transformation to our estimates:\nu0 \u0026lt;- inv_logit(a)\ru1 \u0026lt;- inv_logit(a + b)\rplot(u0, u1, xlim = c(0, 1), ylim = c(0, 1), xlab = \u0026quot;urban = 0\u0026quot;, ylab = \u0026quot;urban = 1\u0026quot;)\rabline(h = 0.5, lty = 2)\rabline(v = 0.5, lty = 2)\r Practice H2 Question: Varying effects models are useful for modelling time series, as well as spatial clustering. In a time series, the observations cluster by entities that have continuity through time, such as individuals. Since observations within individuals are likely highly correlated, the multilevel structure can help quite a lot. You’ll use the data in data(Oxboys), which is 234 height measurements on 26 boys from an Oxford Boys Club (I think these were like youth athletic leagues?), at 9 different ages (centred and standardized) per boy.\nYou’ll be interested in predicting height, using age, clustered by Subject (individual boy). Fit a model with varying intercepts and slopes (on age), clustered by Subject. Present and interpret the parameter estimates. Which varying effect contributes more variation to the heights, the intercept or the slope?\nAnswer: I start with loading the data, standardising the age data, and making the subject IDs into an index:\ndata(Oxboys)\rd \u0026lt;- Oxboys\rd$A \u0026lt;- standardize(d$age)\rd$id \u0026lt;- coerce_index(d$Subject)\r Armed with my data, I can now turn to modelling:\nm_H2 \u0026lt;- ulam(\ralist(\rheight ~ dnorm(mu, sigma),\rmu \u0026lt;- a_bar + a[id] + (b_bar + b[id]) * A,\ra_bar ~ dnorm(150, 10),\rb_bar ~ dnorm(0, 10),\rc(a, b)[id] ~ multi_normal(0, Rho_id, sigma_id),\rsigma_id ~ dexp(1),\rRho_id ~ dlkjcorr(2),\rsigma ~ dexp(1)\r),\rdata = d, chains = 4, cores = 4, iter = 4000\r)\r The model has compiled and I am interested in the output it produced concerning average effects and variation:\nprecis(m_H2, depth = 2, pars = c(\u0026quot;a_bar\u0026quot;, \u0026quot;b_bar\u0026quot;, \u0026quot;sigma_id\u0026quot;))\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a_bar 149.523993 1.3844230 147.2887666 151.690432 293.0144 1.011856\r## b_bar 4.230315 0.2073667 3.8999943 4.554123 414.4092 1.003962\r## sigma_id[1] 7.331832 0.8789976 6.0675622 8.840290 4173.7730 1.001038\r## sigma_id[2] 1.065676 0.1525730 0.8508899 1.336301 4141.6398 1.000750\r Since age is standardised, a_bar represent the average height at average age in the data set. The average slope b_bar represents change in height for a one-unit change in standardised age.\nI don\u0026rsquo;t like interpreting standardised data coefficients like that. Let\u0026rsquo;s rather plot it:\nplot(height ~ age, type = \u0026quot;n\u0026quot;, data = d)\rfor (i in 1:26) {\rh \u0026lt;- d$height[d$Subject == i]\ra \u0026lt;- d$age[d$Subject == i]\rlines(a, h, col = col.alpha(\u0026quot;slateblue\u0026quot;, 0.5), lwd = 2)\r}\r Now the the task at hand. Which effect contributes more to the overall heights of our individuals? Given the plot above, I\u0026rsquo;d argue that it is the varying intercepts which provide us with most of the variation in heights. However, this is very much down to the data and should not be generalised beyond this data set. It might completely fall apart if we had longer time-series of data values.\nPractice H3 Question: Now consider the correlation between the varying intercepts and slopes. Can you explain its value? How would this estimated correlation influence your predictions about a new sample of boys?\nAnswer: For this, we look at the correlation matrix Rho_id:\nprecis(m_H2, depth = 3, pars = \u0026quot;Rho_id\u0026quot;)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## Rho_id[1,1] 1.0000000 0.000000e+00 1.0000000 1.0000000 NaN NaN\r## Rho_id[1,2] 0.5307351 1.283373e-01 0.3046972 0.7170573 4627.842 1.0007918\r## Rho_id[2,1] 0.5307351 1.283373e-01 0.3046972 0.7170573 4627.842 1.0007918\r## Rho_id[2,2] 1.0000000 7.886203e-17 1.0000000 1.0000000 7829.277 0.9994999\r So there is a positive correlation. Let\u0026rsquo;s visualise that:\nggplot() +\rstat_halfeye(aes(x = extract.samples(m_H2)$Rho_id[, 1, 2])) +\rtheme_bw() +\rlabs(x = \u0026quot;Rho\u0026quot;)\r The positive correlation implies that larger intercepts are associated with steeper slopes. What this means is that taller boys grow faster.\nPractice H4 Question: Use mvrnorm (in library(MASS)) or rmvnorm (in library(mvtnorm)) to simulate a new sample of boys, based upon the posterior mean values of the parameters.\nThat is, try to simulate varying intercepts and slopes, using the relevant parameter estimates, and then plot the predicted trends of height on age, one trend for each simulated boy you produce. A sample of 10 simulated boys is plenty, to illustrate the lesson. You can ignore uncertainty in the posterior, just to make the problem a little easier. But if you want to include the uncertainty about the parameters, go for it.\nNote that you can construct an arbitrary variance-covariance matrix to pass to either mvrnorm or rmvnorm with something like:\nS \u0026lt;- matrix(c(sa^2, sa * sb * rho, sa * sb * rho, sb^2), nrow = 2)\r where sa is the standard deviation of the first variable, sb is the standard deviation of the second variable, and rho is the correlation between them.\nAnswer: To simulate new observations we need to obtain the estimates of our model so far:\npost \u0026lt;- extract.samples(m_H2)\rrho \u0026lt;- mean(post$Rho_id[, 1, 2])\rsb \u0026lt;- mean(post$sigma_id[, 2])\rsa \u0026lt;- mean(post$sigma_id[, 1])\rsigma \u0026lt;- mean(post$sigma)\ra \u0026lt;- mean(post$a_bar)\rb \u0026lt;- mean(post$b_bar)\r Now we can define the variance-covariance matrix:\nS \u0026lt;- matrix(c(sa^2, sa * sb * rho, sa * sb * rho, sb^2), nrow = 2)\rround(S, 2)\r ## [,1] [,2]\r## [1,] 53.76 4.15\r## [2,] 4.15 1.14\r Subsequently, we can sample from the multivariate normal distribution given our variance-covariance matrix to obtain a bivariate distribution of intercepts and slopes:\nve \u0026lt;- mvrnorm(10, c(0, 0), Sigma = S)\rve\r ## [,1] [,2]\r## [1,] -0.2914409 -0.8985609\r## [2,] 8.8137562 0.3436168\r## [3,] -1.5233131 1.5530926\r## [4,] -9.5179212 -0.6967038\r## [5,] 7.6547083 -0.3622056\r## [6,] 5.4710535 -0.3060008\r## [7,] -0.3548003 0.1445644\r## [8,] 7.2706590 3.0081540\r## [9,] 2.8143313 0.1653603\r## [10,] -6.3582595 -1.0162374\r These are individual intercepts and slopes of 10 random boys have which we only need to add to the average intercept and slope values to generate predicted heights for them. Here, we simulate the trend for each boy and add it to a plot:\nage.seq \u0026lt;- seq(from = -1, to = 1, length.out = 9)\rplot(0, 0, type = \u0026quot;n\u0026quot;, xlim = range(d$age), ylim = range(d$height), xlab = \u0026quot;age (centered)\u0026quot;, ylab = \u0026quot;height\u0026quot;)\rfor (i in 1:nrow(ve)) {\rh \u0026lt;- rnorm(9,\rmean = a + ve[i, 1] + (b + ve[i, 2]) * age.seq,\rsd = sigma\r)\rlines(age.seq, h, col = col.alpha(\u0026quot;slateblue\u0026quot;, 0.5))\r}\r Session Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] tidybayes_2.3.1 ape_5.5 ellipse_0.4.2 MASS_7.3-53.1 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] sass_0.3.1 tidyr_1.1.3 jsonlite_1.7.2 R.utils_2.10.1 bslib_0.2.4 RcppParallel_5.1.2 assertthat_0.2.1 distributional_0.2.2 highr_0.9 ## [10] stats4_4.0.5 ggdist_2.4.0 yaml_2.2.1 pillar_1.6.0 backports_1.2.1 lattice_0.20-41 glue_1.4.2 arrayhelpers_1.1-0 digest_0.6.27 ## [19] colorspace_2.0-0 htmltools_0.5.1.1 R.oo_1.24.0 plyr_1.8.6 pkgconfig_2.0.3 svUnit_1.0.6 bookdown_0.22 purrr_0.3.4 mvtnorm_1.1-1 ## [28] scales_1.1.1 processx_3.5.1 tibble_3.1.1 styler_1.4.1 generics_0.1.0 farver_2.1.0 ellipsis_0.3.2 withr_2.4.2 cli_3.0.0 ## [37] magrittr_2.0.1 crayon_1.4.1 evaluate_0.14 ps_1.6.0 R.methodsS3_1.8.1 fansi_0.4.2 R.cache_0.14.0 nlme_3.1-152 forcats_0.5.1 ## [46] pkgbuild_1.2.0 blogdown_1.3 tools_4.0.5 loo_2.4.1 prettyunits_1.1.1 lifecycle_1.0.0 matrixStats_0.61.0 stringr_1.4.0 V8_3.4.1 ## [55] munsell_0.5.0 callr_3.7.0 compiler_4.0.5 jquerylib_0.1.4 rlang_0.4.11 grid_4.0.5 labeling_0.4.2 rmarkdown_2.7 gtable_0.3.0 ## [64] codetools_0.2-18 inline_0.3.17 DBI_1.1.1 curl_4.3.2 rematch2_2.1.2 R6_2.5.0 gridExtra_2.3 knitr_1.33 dplyr_1.0.5 ## [73] utf8_1.2.1 shape_1.4.5 stringi_1.5.3 Rcpp_1.0.7 vctrs_0.3.7 tidyselect_1.1.0 xfun_0.22 coda_0.19-4\r ","date":1618531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618570800,"objectID":"7d2ffcbcde22814d80e9cd31140e39c3","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-14/","publishdate":"2021-04-16T00:00:00Z","relpermalink":"/courses/rethinking/chapter-14/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 14 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 14","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"\rKrigR is currently undergoing development. As a result, this part of the workshop has become deprecated. Please refer to the setup quick guide portions of this material as these are up-to-date. \r\r\r\rThis part of the workshop is dependant on set-up and preparation done previously here.\r\r\rFirst, we load KrigR:\nlibrary(KrigR)\r \rStatistical downscaling with KrigR is handled via the krigR() function and requires a set of spatial covariates.\r\r\r\rFor an introduction to the statistical downscaling process, I will first walk you through the SpatialPolygons spatial preference.\r\r\rFirst, we load the data we wish to statistically downscale. We established these data here.\nSpatialPolygonsRaw \u0026lt;- stack(file.path(Dir.Data, \u0026quot;SpatialPolygonsRaw.nc\u0026quot;))\r We are now ready to begin our journey to high-spatial resolution data products!\nCovariates First, we use the download_DEM() function which comes with KrigR to obtain elevation data as our covariate of choice. This produces two rasters:\n A raster of training resolution which matches the input data in all attributes except for the data in each cell. A raster of target resolution which matches the input data as closely as possible in all attributes except for the resolution (which is specified by the user).  Both of these products are bundled into a list where the first element corresponds to the training resolution and the second element contains the target resolution covariate data. Here, we specify a target resolution of .02.\nThis is how we specify download_DEM() to prepare DEM covariates for us:\nCovs_ls \u0026lt;- download_DEM(Train_ras = SpatialPolygonsRaw, # the data we want to downscale\rTarget_res = .02, # the resolution we want to downscale to\rShape = Shape_shp, # extra spatial preferences\rDir = Dir.Covariates # where to store the covariate files\r)\r For now, let\u0026rsquo;s simply inspect our list of covariate rasters:\nCovs_ls\r ## [[1]]\r## class : RasterLayer ## dimensions : 34, 54, 1836 (nrow, ncol, ncell)\r## resolution : 0.1000189, 0.09999998 (x, y)\r## extent : 9.726991, 15.12801, 49.75, 53.15 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : DEM ## values : 20.11554, 861.7248 (min, max)\r## ## ## [[2]]\r## class : RasterLayer ## dimensions : 204, 324, 66096 (nrow, ncol, ncell)\r## resolution : 0.01666667, 0.01666667 (x, y)\r## extent : 9.72486, 15.12486, 49.74986, 53.14986 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : DEM ## values : 15.75, 1128 (min, max)\r You will find that the target resolution covariate data comes at a resolution of 0.017 instead of the 0.02 resolution we specified. This happens because download_DEM() calls upon the raster::aggregate() function when aggregating the high-resolution covariate data to your desired target resolution and is thus only capable of creating target-resolution covariates in multiples of the base resolution of the GMTED 2010 DEM we are using as our default covariate. This happens only when the Target_res argument is specified to be a number.\n\rSpecifying the Target_res argument as a number will lead to best approximation of the desired resolution due to usage of the raster::aggregate() within download_DEM(). If you need an exact resolution to match pre-existing data, please refer to this part of the workshop.\r\r\rNotice that despite the covariate rasters (and input rasters, for that matter) containing 1836 and 6.6096\\times 10^{4} for training and target resolution respectively, we only obtain data for 826 and 26247 cells respectively due to our specification of SpatialPolygons. This will come in handy when doing the statistical interpolation (see this section for details).\nBefore moving on, let\u0026rsquo;s visualise the covariate data:\nPlot_Covs(Covs_ls, Shape_shp)\r Notice just how much more clearly the mountainous areas in our study region show up at our target resolution.\nConsiderations for download_DEM() Target_res Alternatively to specifying a target resolution, you can specify a different raster which should be matched in all attributes by the raster at target resolution. We get to this again when discussing third-party data usage.\n\rTarget_res can be used for a numeric input or to match a pre-existing raster object.\r\r\rShape Spatial preferences with download_DEM() are specified slightly differently when compared to download_ERA(). Whereas download_ERA() uses the Extent argument, download_DEM() uses the Shape argument. The reason? download_DEM() automatically reads out the extent of the input raster and carries out extent limitation according to this. SpatialPolygons and data.frame inputs are supported. For clarity, we simply recognise them with the Shape argument to avoid confusion and unnecessary extent inputs.\n\rSpatial preferences are handed to download_DEM() using the Shape argument.\r\r\rKeep_Temporary By default, this argument is set to FALSE and raw, global DEM data will be deleted when the covariates you queried have been established. Setting this argument to TRUE will retain the raw data and make it so you do not have to re-download the DEM data for later use.\n\rSetting Keep_Temporary = TRUE will retain global DEM data on your hard drive.\r\r\rSource This argument specifies where to download the DEM data from. By default, we query the data from the official USGS website. However, this website has given some users issues with connection instabilities. Consequently, the raw DEM data is also available from a dropbox which you can query download from by setting Source = \u0026quot;Drive\u0026quot;.\n\rWhen experiencing connection issues with the USGS servers, we recommend setting Source = \u0026quot;Drive\u0026quot; to obtain covariate data.\r\r\rKriging \rKriging can be a very computationally expensive exercise.\r\r\rThe expense of kriging is largely determined by three factors:\n Change in spatial resolution. Number of cells containing data; i.e. Spatial Limitation. Localisation of Kriging; i.e. Localisation of Results.  \rWe explore two of these further down in this workshop material. For more information, please consult this publication (Figure 4).\r\r\rFinally, we are ready to interpolate our input data given our covariates with the krigR() function:\nSpatialPolygonsKrig \u0026lt;- krigR(Data = SpatialPolygonsRaw, # data we want to krig as a raster object\rCovariates_coarse = Covs_ls[[1]], # training covariate as a raster object\rCovariates_fine = Covs_ls[[2]], # target covariate as a raster object\rKeep_Temporary = FALSE, # we don't want to retain the individually kriged layers on our hard-drive\rCores = 1, # we want to krig on just one core\rFileName = \u0026quot;SpatialPolygonsKrig\u0026quot;, # the file name for our full kriging output\rDir = Dir.Exports # which directory to save our final input in\r)\r ## Commencing Kriging\r ## Kriging of remaining 3 data layers should finish around: 2023-04-03 16:35:08\r ## | | | 0%\r| |==================== | 25%\r| |======================================== | 50%\r| |============================================================ | 75%\r| |================================================================================| 100%\r Just like with the download_ERA() function, krigR() updates you on what it is currently working on. Again, I implemented this to make sure people don\u0026rsquo;t get too anxious staring at an empty console in R. If this feature is not appealing to you, you can turn this progress tracking off by setting verbose = FALSE in the function call to krigR().\n\rFor the rest of this workshop, I suppress messages from krigR() via other means so that when you execute, you get progress tracking.\r\r\rThere we go. As output of the krigR() function, we obtain a list of downscaled data as the first element and downscaling standard errors as the second list element. Let\u0026rsquo;s look at that:\nSpatialPolygonsKrig[-3] # we will talk later about the third element\r ## $Kriging_Output\r## class : RasterBrick ## dimensions : 175, 309, 54075, 4 (nrow, ncol, ncell, nlayers)\r## resolution : 0.01666667, 0.01666667 (x, y)\r## extent : 9.87486, 15.02486, 50.14986, 53.06653 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : var1.pred.1, var1.pred.2, var1.pred.3, var1.pred.4 ## min values : 269.3269, 266.6584, 265.8426, 261.2555 ## max values : 275.0150, 273.3421, 272.1410, 270.0713 ## ## ## $Kriging_SE\r## class : RasterBrick ## dimensions : 175, 309, 54075, 4 (nrow, ncol, ncell, nlayers)\r## resolution : 0.01666667, 0.01666667 (x, y)\r## extent : 9.87486, 15.02486, 50.14986, 53.06653 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : var1.stdev.1, var1.stdev.2, var1.stdev.3, var1.stdev.4 ## min values : 0.1184605, 0.1265206, 0.1142046, 0.1283697 ## max values : 0.1308865, 0.1426154, 0.1535409, 0.2638671\r All the data has been downscaled and we do have uncertainties recorded for all of our outputs. Let\u0026rsquo;s visualise the data:\nPlot_Krigs(SpatialPolygonsKrig, Shp = Shape_shp,\rDates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;, \u0026quot;03-1995\u0026quot;, \u0026quot;04-1995\u0026quot;)\r)\r As you can see, the elevation patterns show up clearly in our kriged air temperature output. Furthermore, you can see that our certainty of Kriging predictions drops on the 04/01/1995 in comparison to the preceding days. However, do keep in mind that a maximum standard error of 0.131, 0.143, 0.154, 0.264 (for each layer of our output respectively) on a total range of data of 5.688, 6.684, 6.298, 8.816 (again, for each layer in the output respectively) is evident of a downscaling result we can be confident in. We also demonstrated reliability of kriging in this publication (Figure 3).\nFinally, this SpatialPolygons-informed downscaling took roughly 57 minutes on my machine (this may vary drastically on other devices).\nSpatial Limitation \rKriging can be sped up tremendously by limiting downscaling efforts to smaller regions.\r\r\rTo demonstrate how spatial limitation affects computational time, we downscale all of our remaining target data (i.e., extent and data.frame time-series specifications).\n Click here for kriging calls \rextent Data Point-Data (data.frame) PtsRaw \u0026lt;- stack(file.path(Dir.Data, \u0026quot;PointsRaw.nc\u0026quot;))\rCovs_ls \u0026lt;- download_DEM(Train_ras = PtsRaw,\rTarget_res = .02,\rShape = Mountains_df,\rBuffer = 0.5,\rID = \u0026quot;Mountain\u0026quot;,\rDir = Dir.Covariates,\rKeep_Temporary = TRUE)\rPtsKrig \u0026lt;- krigR(Data = PtsRaw, Covariates_coarse = Covs_ls[[1]], Covariates_fine = Covs_ls[[2]], Keep_Temporary = FALSE, Cores = 1, FileName = \u0026quot;PointsKrig\u0026quot;,\rDir = Dir.Exports\r)\r \rHow long did the kriging for each data set take? Let me list these out to highlight just how much of a difference the spatial limitation makes here:\n extent specification (7344 data cells in training resolution) - roughly 30 minutes SpatialPolygons specification (3752 data cells in training resolution) - roughly 4 minutes Point (data.frame) specification (1908 data cells in training resolution) - roughly 30 seconds  As you can see, there is a huge benefit to reducing the cells containing data to speed up computation. But what is the impact of doing so for our points of interest?\n Click here for data extraction and plotting \rExtract_df \u0026lt;- data.frame(\rAirTemp = c(\rraster::extract(\rx = SpatialPolygonsKrig[[1]][[1]],\ry = Mountains_df[, c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;)]), raster::extract(\rx = ExtKrig[[1]][[1]],\ry = Mountains_df[, c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;)]), raster::extract(\rx = PtsKrig[[1]][[1]],\ry = Mountains_df[, c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;)])\r), Uncertainty = c(\rraster::extract(\rx = SpatialPolygonsKrig[[2]][[1]],\ry = Mountains_df[, c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;)]), raster::extract(\rx = ExtKrig[[2]][[1]],\ry = Mountains_df[, c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;)]), raster::extract(\rx = PtsKrig[[2]][[1]],\ry = Mountains_df[, c(\u0026quot;Lon\u0026quot;, \u0026quot;Lat\u0026quot;)])\r), Mountain = rep(Mountains_df$Mountain, 3),\rSpatial = rep(c(\u0026quot;Polygons\u0026quot;, \u0026quot;Extent\u0026quot;, \u0026quot;Points\u0026quot;), each = nrow(Mountains_df))\r)\r ggplot(data = Extract_df, aes(y = Mountain, x = AirTemp, col = Spatial)) +\rgeom_point(cex = 5, pch = 18) +\rgeom_errorbar(aes(xmin = AirTemp - Uncertainty/2, xmax = AirTemp + Uncertainty/2)) +\rtheme_bw()\r \rAs you can see, the differences between the different data sets at our points of interest are noticeable and often times not negligible (as far as statistical interpolation uncertainty, i.e., error bars) are concerned.\n\rWhen statistically downscaling data products it is vital you inspect the output data for inconsistencies or other issues.\nKriging is not a one-size-fits all solution to spatial resolution needs!\n\r\rLocalisation of Results \rBy default Kriging of the krigR() function uses all cells in a spatial product to downscale individual cells of rasters.\r\r\r\rThe nmax argument can circumvent this.\r\r\rLet’s build further on our above example by adding the nmax argument (passed on to gstat::krige()) to our krigR() function call. This argument controls how many of the closest cells the Kriging algorithm should consider in the downscaling of individual coarse, training cells.\nFirst, we need to re-establish our covariate data:\nCovs_ls \u0026lt;- download_DEM(Train_ras = SpatialPolygonsRaw,\rTarget_res = .02,\rShape = Shape_shp,\rDir = Dir.Covariates,\rKeep_Temporary = TRUE)\r Now we may use locally weighted kriging:\nSpatialPolygonsLocalKrig \u0026lt;- krigR(Data = SpatialPolygonsRaw,\rCovariates_coarse = Covs_ls[[1]],\rCovariates_fine = Covs_ls[[2]],\rKeep_Temporary = FALSE,\rCores = 1, nmax = 10,\rFileName = \u0026quot;SpatialPolygonsLocalKrig\u0026quot;,\rDir = Dir.Exports\r)\rPlot_Krigs(SpatialPolygonsLocalKrig, Shp = Shape_shp,\rDates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;, \u0026quot;03-1995\u0026quot;, \u0026quot;04-1995\u0026quot;)\r)\r The air temperature prediction/downscaling results look just like the ones that we obtained above (we will investigate this claim in a second here). However, we seriously improved our localised understanding of Kriging uncertainties (i.e., we see much more localised patterns of Kriging standard error). In the case of our study region, uncertainties seem to be highest for areas where the landscape is dominated by large, abrupt changes in elevation (e.g. around the mountainous areas) and water-dominated areas such as streams and lakes (e.g. the lakes around Leipzig in the North of Saxony).\n\rUsing the nmax argument helps to identify highly localised patterns in the Kriging uncertainty as well as predictions!\r\r\rNow let\u0026rsquo;s investigate how much of a difference there is between our two predictions of statistically downscaled air temperature when using locally weighted kriging or domain-average kriging as before:\nPlot_Raw(SpatialPolygonsLocalKrig[[1]]-SpatialPolygonsKrig[[1]], Shp = Shape_shp,\rDates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;, \u0026quot;03-1995\u0026quot;, \u0026quot;04-1995\u0026quot;))\r Again, limiting the number of data points that the Kriging algorithm has access to changes the data we obtain. Therefore, let me reiterate:\n\rWhen statistically downscaling data products it is vital you inspect the output data for inconsistencies or other issues.\nKriging is not a one-size-fits all solution to spatial resolution needs!\n\r\rConsiderations for krigR() krigR() is a complex function with many things happening under the hood. To make sure you have the best experience with this function, I have compiled a few bits of good-to-know information about the workings of krigR().\nCores Kriging is computationally expensive and can be a time-consuming exercise first and foremost. However, the gstat::krige() function which krigR() makes calls to, and which carries out the kriging itself, does not support multi-core processing. Conclusively, we can hand separate kriging jobs to separate cores in our machines and drastically reduce computation time. We do so via the Cores argument.\n\rUsing the Cores argument, krigR() carries out parallel kriging of multi-layer rasters.\r\r\rnmax and maxdist Localised kriging is achieved through either nmax or maxdist.\n\rWhen using nmax or maxdist, we recommend you ensure that the distance represented by these arguments approximates the area of typical weather system (around 150km).\r\r\rFor the purpose of showing clear patterns in the localisation of uncertainty patterns, we did not to so in the above.\nKeep_Temporary Kriging is time-consuming. Particularly for multi-layer rasters with many layers. To make it so you can interrupt kriging of multi-layer rasters and resume the process at a later time, we have implemented temporary file saving. krigR() checks for presence of temporary files and only loads already kriged layers rather than kriging them again. Upon completion and saving of the final output, you may choose to delete the temporary files or keep them.\nKrigingEquation krigR() can accommodate any covariate pair (training and target resolution) you supply. However, when using third-party covariates in non-linear combinations, you will need to use the KrigingEquation argument to do so.\n\rWith the KrigingEquation argument, you may specify non-linear combinations of covariates for your call to krigR().\r\r\rKriging Reliability Kriging reliability and robustness is largely dependant on the statistical link between your target variable and covariates of your choice.\n\rElevation will not be a useful covariate for all climate variables!\r\r\rWe demonstrate that Kriging is a reliable interpolation method when carefully choosing covariates in this publication (Figure 3). One large factor in reliability of kriging is the change in resolution between training and target resolutions - as a rule of thumb, we do not recommend downscaling representing more than roughly one order of magnitude. If you attempt to do so krigR() will throw a warning message, but proceed regardless.\n\rKriging is a very flexible tool for statistical interpolation. Consider your choice of covariates and change in resolutions carefully. Always inspect your data.\r\r\rCall List So far, we have only ever looked at the first two elements in the list returned by krigR(). A quick look at the help file, the code, or this guide reveals that there is a third list element - the call list. When coding this feature into krigR() I intended for this to be a neat, clean, storage-friendly way of keeping track of how the spatial product was created. It does so without storing additional spatial products. Let\u0026rsquo;s have a look at it:\n Click here for call list query and output \rSpatialPolygonsKrig[[3]]\r ## $Data\r## $Data$Class\r## [1] \u0026quot;RasterStack\u0026quot;\r## attr(,\u0026quot;package\u0026quot;)\r## [1] \u0026quot;raster\u0026quot;\r## ## $Data$Dimensions\r## $Data$Dimensions$nrow\r## [1] 34\r## ## $Data$Dimensions$ncol\r## [1] 54\r## ## $Data$Dimensions$ncell\r## [1] 1836\r## ## ## $Data$Extent\r## class : Extent ## xmin : 9.726991 ## xmax : 15.12801 ## ymin : 49.75 ## ymax : 53.15 ## ## $Data$CRS\r## Coordinate Reference System:\r## Deprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs ## WKT2 2019 representation:\r## GEOGCRS[\u0026quot;unknown\u0026quot;,\r## DATUM[\u0026quot;World Geodetic System 1984\u0026quot;,\r## ELLIPSOID[\u0026quot;WGS 84\u0026quot;,6378137,298.257223563,\r## LENGTHUNIT[\u0026quot;metre\u0026quot;,1]],\r## ID[\u0026quot;EPSG\u0026quot;,6326]],\r## PRIMEM[\u0026quot;Greenwich\u0026quot;,0,\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433],\r## ID[\u0026quot;EPSG\u0026quot;,8901]],\r## CS[ellipsoidal,2],\r## AXIS[\u0026quot;longitude\u0026quot;,east,\r## ORDER[1],\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433,\r## ID[\u0026quot;EPSG\u0026quot;,9122]]],\r## AXIS[\u0026quot;latitude\u0026quot;,north,\r## ORDER[2],\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433,\r## ID[\u0026quot;EPSG\u0026quot;,9122]]]] ## ## $Data$layers\r## [1] \u0026quot;X1\u0026quot; \u0026quot;X2\u0026quot; \u0026quot;X3\u0026quot; \u0026quot;X4\u0026quot;\r## ## ## $Covariates_coarse\r## $Covariates_coarse$Class\r## [1] \u0026quot;RasterLayer\u0026quot;\r## attr(,\u0026quot;package\u0026quot;)\r## [1] \u0026quot;raster\u0026quot;\r## ## $Covariates_coarse$Dimensions\r## $Covariates_coarse$Dimensions$nrow\r## [1] 34\r## ## $Covariates_coarse$Dimensions$ncol\r## [1] 54\r## ## $Covariates_coarse$Dimensions$ncell\r## [1] 1836\r## ## ## $Covariates_coarse$Extent\r## class : Extent ## xmin : 9.726991 ## xmax : 15.12801 ## ymin : 49.75 ## ymax : 53.15 ## ## $Covariates_coarse$CRS\r## Coordinate Reference System:\r## Deprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs ## WKT2 2019 representation:\r## GEOGCRS[\u0026quot;unknown\u0026quot;,\r## DATUM[\u0026quot;World Geodetic System 1984\u0026quot;,\r## ELLIPSOID[\u0026quot;WGS 84\u0026quot;,6378137,298.257223563,\r## LENGTHUNIT[\u0026quot;metre\u0026quot;,1]],\r## ID[\u0026quot;EPSG\u0026quot;,6326]],\r## PRIMEM[\u0026quot;Greenwich\u0026quot;,0,\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433],\r## ID[\u0026quot;EPSG\u0026quot;,8901]],\r## CS[ellipsoidal,2],\r## AXIS[\u0026quot;longitude\u0026quot;,east,\r## ORDER[1],\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433,\r## ID[\u0026quot;EPSG\u0026quot;,9122]]],\r## AXIS[\u0026quot;latitude\u0026quot;,north,\r## ORDER[2],\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433,\r## ID[\u0026quot;EPSG\u0026quot;,9122]]]] ## ## $Covariates_coarse$layers\r## [1] \u0026quot;DEM\u0026quot;\r## ## ## $Covariates_fine\r## $Covariates_fine$Class\r## [1] \u0026quot;RasterLayer\u0026quot;\r## attr(,\u0026quot;package\u0026quot;)\r## [1] \u0026quot;raster\u0026quot;\r## ## $Covariates_fine$Dimensions\r## $Covariates_fine$Dimensions$nrow\r## [1] 204\r## ## $Covariates_fine$Dimensions$ncol\r## [1] 324\r## ## $Covariates_fine$Dimensions$ncell\r## [1] 66096\r## ## ## $Covariates_fine$Extent\r## class : Extent ## xmin : 9.72486 ## xmax : 15.12486 ## ymin : 49.74986 ## ymax : 53.14986 ## ## $Covariates_fine$CRS\r## Coordinate Reference System:\r## Deprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs ## WKT2 2019 representation:\r## GEOGCRS[\u0026quot;unknown\u0026quot;,\r## DATUM[\u0026quot;World Geodetic System 1984\u0026quot;,\r## ELLIPSOID[\u0026quot;WGS 84\u0026quot;,6378137,298.257223563,\r## LENGTHUNIT[\u0026quot;metre\u0026quot;,1]],\r## ID[\u0026quot;EPSG\u0026quot;,6326]],\r## PRIMEM[\u0026quot;Greenwich\u0026quot;,0,\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433],\r## ID[\u0026quot;EPSG\u0026quot;,8901]],\r## CS[ellipsoidal,2],\r## AXIS[\u0026quot;longitude\u0026quot;,east,\r## ORDER[1],\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433,\r## ID[\u0026quot;EPSG\u0026quot;,9122]]],\r## AXIS[\u0026quot;latitude\u0026quot;,north,\r## ORDER[2],\r## ANGLEUNIT[\u0026quot;degree\u0026quot;,0.0174532925199433,\r## ID[\u0026quot;EPSG\u0026quot;,9122]]]] ## ## $Covariates_fine$layers\r## [1] \u0026quot;DEM\u0026quot;\r## ## ## $KrigingEquation\r## ERA ~ DEM\r## \u0026lt;environment: 0x7fee0d4450e8\u0026gt;\r## ## $Cores\r## [1] 1\r## ## $FileName\r## [1] \u0026quot;SpatialPolygonsKrig\u0026quot;\r## ## $Keep_Temporary\r## [1] FALSE\r## ## $nmax\r## [1] Inf\r## ## $Data_Retrieval\r## [1] \u0026quot;None needed. Data was not queried via krigR function, but supplied by user.\u0026quot;\r \rThis lengthy list should contain all information you need to trace how you created a certain data set using krigR(). If you feel like anything is missing in this list, please contact us.\nAggregate Uncertainty \rEvery climate data product is subject to an error-rate / range of data uncertainty. Unfortunately, almost none of the established climate data products communicate associated uncertainties. This leads to a dangerous overestimation of data credibility.\r\r\r\rWith the KrigR workflow, it is trivial to obtain uncertainty flags for all of your data - no matter the spatial or temporal resolution.\r\r\rTo understand the full certainty of our data obtained via the KrigR workflow, we should combine dynamical uncertainty with the statistical uncertainty we obtained from the krigR() function call above.\nTo do so, we require two data sets:\n SpatialPoylgonsKrig - created above containing statistical uncertainty in the second list position SpatialPoylgonsEns - created here; download here containing dynamical uncertainty  First, we load the data and assign them to objects with shorter names:\nSpatialPolygonsEns \u0026lt;- stack(file.path(Dir.Data, \u0026quot;SpatialPolygonsEns.nc\u0026quot;))\rDynUnc \u0026lt;- SpatialPolygonsEns\rKrigUnc \u0026lt;- SpatialPolygonsKrig[[2]]\r Next, we need to align the rasters of statistical uncertainty (resolution: 0.017) and dynamical uncertainty (resolution: 0.5). As you can see, these are of differing resolutions and so cannot easily be combined using raster math. Instead, we first disaggregate the coarser-resolution raster (DynUnc) as disaggregation does not attempt any interpolation thus preserving the data, but representing it with smaller cells. To fix final remaining alignment issues, we allow for some resampling between the two raster:\nEnsDisagg \u0026lt;- disaggregate(DynUnc, fact=res(DynUnc)[1]/res(KrigUnc)[1])\rDynUnc \u0026lt;- resample(EnsDisagg, KrigUnc)\r Finally, we combine the two uncertainty data products to form an aggregate uncertainty product:\nFullUnc \u0026lt;- DynUnc + KrigUnc\r Now, we are ready to plot our aggregate uncertainty:\nPlot_Raw(FullUnc, Shp = Shape_shp, Dates = c(\u0026quot;01-1995\u0026quot;, \u0026quot;02-1995\u0026quot;, \u0026quot;03-1995\u0026quot;, \u0026quot;04-1995\u0026quot;), COL = rev(viridis(100)))\r As you can see, at short time-scales dynamic uncertainty eclipses statistical uncertainty. However, this phenomenon reverses at longer time-scales as shown in this publication (Figure 1).\nSession Info sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] mapview_2.11.0 rnaturalearthdata_0.1.0 rnaturalearth_0.3.2 ## [4] gimms_1.2.1 ggmap_3.0.2 cowplot_1.1.1 ## [7] viridis_0.6.2 viridisLite_0.4.1 ggplot2_3.4.1 ## [10] tidyr_1.3.0 KrigR_0.1.2 terra_1.7-21 ## [13] httr_1.4.5 stars_0.6-0 abind_1.4-5 ## [16] fasterize_1.0.4 sf_1.0-12 lubridate_1.9.2 ## [19] automap_1.1-9 doSNOW_1.0.20 snow_0.4-4 ## [22] doParallel_1.0.17 iterators_1.0.14 foreach_1.5.2 ## [25] rgdal_1.6-5 raster_3.6-20 sp_1.6-0 ## [28] stringr_1.5.0 keyring_1.3.1 ecmwfr_1.5.0 ## [31] ncdf4_1.21 ## ## loaded via a namespace (and not attached):\r## [1] leafem_0.2.0 colorspace_2.1-0 class_7.3-21 ## [4] leaflet_2.1.2 satellite_1.0.4 base64enc_0.1-3 ## [7] rstudioapi_0.14 proxy_0.4-27 farver_2.1.1 ## [10] fansi_1.0.4 codetools_0.2-19 cachem_1.0.7 ## [13] knitr_1.42 jsonlite_1.8.4 png_0.1-8 ## [16] Kendall_2.2.1 compiler_4.2.3 assertthat_0.2.1 ## [19] fastmap_1.1.1 cli_3.6.0 htmltools_0.5.4 ## [22] tools_4.2.3 gtable_0.3.1 glue_1.6.2 ## [25] dplyr_1.1.0 Rcpp_1.0.10 jquerylib_0.1.4 ## [28] vctrs_0.6.1 blogdown_1.16 crosstalk_1.2.0 ## [31] lwgeom_0.2-11 xfun_0.37 timechange_0.2.0 ## [34] lifecycle_1.0.3 rnaturalearthhires_0.2.1 zoo_1.8-11 ## [37] scales_1.2.1 gstat_2.1-0 yaml_2.3.7 ## [40] curl_5.0.0 memoise_2.0.1 gridExtra_2.3 ## [43] sass_0.4.5 reshape_0.8.9 stringi_1.7.12 ## [46] highr_0.10 e1071_1.7-13 boot_1.3-28.1 ## [49] intervals_0.15.3 RgoogleMaps_1.4.5.3 rlang_1.1.0 ## [52] pkgconfig_2.0.3 bitops_1.0-7 evaluate_0.20 ## [55] lattice_0.20-45 purrr_1.0.1 htmlwidgets_1.6.1 ## [58] labeling_0.4.2 tidyselect_1.2.0 plyr_1.8.8 ## [61] magrittr_2.0.3 bookdown_0.33 R6_2.5.1 ## [64] generics_0.1.3 DBI_1.1.3 pillar_1.8.1 ## [67] withr_2.5.0 units_0.8-1 xts_0.13.0 ## [70] tibble_3.2.1 spacetime_1.2-8 KernSmooth_2.23-20 ## [73] utf8_1.2.3 rmarkdown_2.20 jpeg_0.1-10 ## [76] grid_4.2.3 zyp_0.11-1 FNN_1.1.3.2 ## [79] digest_0.6.31 classInt_0.4-9 webshot_0.5.4 ## [82] stats4_4.2.3 munsell_0.5.0 bslib_0.4.2\r ","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"48b8fcdc0f2804ed01901a26f43efa12","permalink":"https://www.erikkusch.com/courses/krigr/kriging/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/kriging/","section":"courses","summary":"Kriging specifications and considerations with `KrigR`.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Statistical Downscaling","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Missing Data and Other Opportunities Material  \rSlides Chapter 15  Introduction These are answers and solutions to the exercises at the end of chapter 15 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from\nthe solutions provided to instructors by Richard McElreath himself.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(gtools)\r Easy Exercises Practice E1 Question: Rewrite the Oceanic tools model (from Chapter 11) below so that it assumes measured error on the log population sizes of each society. You don’t need to fit the model to data. Just modify the mathematical formula below. $$T_i ∼ Poisson(µ_i)$$ $$log(µ_i) = α + β*log(P_i)$$ $$α ∼ Normal(0, 1.5)$$ $$β ∼ Normal(0, 1)$$\nAnswer: The population variable ($P_i$) is a predictor in this model. In order to estimate/account for measurement error in a predictor variable, all we need to do is add a distribution to the observed values ($P^\\star_i$) with a given error ($σ_P$):\n$$log(P_i) ∼ Normal(P^\\star_i, σ_P)$$\nThe final model specification combines the above line with the previous model specification and substitutes $P^\\star_i$ in place of $P_i$:\n$$T_i ∼ Poisson(µ_i)$$\n$$log(µ_i) = α + β* P^\\star_i $$\n$$log(P_i) ∼ Normal(P^\\star_i, σ_P)$$\n$$α ∼ Normal(0, 1.5)$$\n$$β ∼ Normal(0, 1)$$\n$$σ_P \\sim Exponential(1)$$\nOf course, we also need a prior for $σ_P$. I don\u0026rsquo;t know enough about the data to take a good educated guess for this parameter and so I just run the usual prior for standard deviations used in the book.\nPractice E2 Question: Rewrite the same model so that it allows imputation of missing values for log population. There aren’t any missing values in the variable, but you can still write down a model formula that would imply imputation, if any values were missing.\nAnswer: Imputation comes into play when measurement error is so intense that we have missing data - \u0026ldquo;missing data is grown-up measurement error\u0026rdquo;. The trick with missing data is to establish adaptive priors for the missing data which is informed by the observations for which we do have data:\n$$T_i ∼ Poisson(µ_i)$$\n$$log(µ_i) = α + β * P^\\star_i$$\n$$P^\\star_i ∼ Normal(\\overline{ P^\\star }, σ_P)$$\n$$α ∼ Normal(0, 1.5)$$ $$β ∼ Normal(0, 1)$$ $$P^\\star \\sim Normal(0, 1)$$ $$σ_P \\sim Exponential(1)$$\nWith the new specification, values of $P^\\star_i$ (observed log-populations) are either assumed to be data or parameters according to whether data is present for observation $i$ or not.\nMedium Exercises Practice M1 Question: Using the mathematical form of the imputation model in the chapter, explain what is being assumed about how the missing values were generated.\nAnswer: As a reminder, the mathematical form of the imputation model in the chapter is as follows:\n$$K_i ∼ Normal(µ_i, σ)$$ $$µ_i = α + β_BB_i + β_M * log(M_i)$$ $$B_i ∼ Normal(ν, σ_B)$$ $$α ∼ Normal(0, 0.5)$$ $$β_B ∼ Normal(0, 0.5)$$ $$β_M ∼ Normal(0, 0.5)$$ $$σ ∼ Exponential(1)$$ $$ν ∼ Normal(0.5, 1)$$ $$σ_B ∼ Exponential(1)$$\nThe assumption about which distribution our predictor with missing data ($B$) does not contain any information about individual cases. It simply just assumes that missing values are randomly placed across the cases. As such, the model assumes that there is no causation at play for how the data came to be missing/not reported, but only states that information that is missing follows a certain distribution which is the same distribution against which to test the data which we do have.\nPractice M2 Question: In earlier chapters, we threw away cases from the primate milk data, so we could use the neocortex variable. Now repeat the WAIC model comparison example from Chapter 6, but use imputation on the neocortex variable so that you can include all of the cases in the original data. The simplest form of imputation is acceptable. How are the model comparison results affected by being able to include all of the cases?\nAnswer: Unfortunately, chapter 6 does not include a neocortex model in the version of the book I am working with and pulling these exercises from. However, chapter 5 does. To begin with this exercise, I load the data and prepare it the same way we did back in chapter 5, by standardising our variables for energy content of milk (K), and body mass (M). Contrary to chapter 5, I do not standardise the neocortex portion (P), but leave it as a proportion between 0 and 1:\ndata(milk)\rd \u0026lt;- milk\rd$neocortex.prop \u0026lt;- d$neocortex.perc / 100\rd$logmass \u0026lt;- log(d$mass)\r## Incomplete cases allowed\rdat_list \u0026lt;- list(\rK = standardize(d$kcal.per.g),\rP = d$neocortex.prop,\rM = standardize(d$logmass)\r)\r Why did I set the neocortex variable (P) to be non-standardised? So I could use priors more readily and make sure this proportion always stays between 0 and 1 - everything outside these bounds would be biological nonsense.\nWith the data ready, we can now run our three models from chapter 5, but this time, in a way so as to account for missing data:\n## Mass effect (not the video game franchise); no imputation needed here\rm_M2_5.6 \u0026lt;- ulam(\ralist(\rK ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bM * M,\ra ~ dnorm(0, 0.2),\rbM ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = dat_list[-2], chains = 4, cores = 4, iter = 2000, log_lik = TRUE\r)\r## Neocortex effect\rm_M2_5.5 \u0026lt;- ulam(\ralist(\rK ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bP * (P - 0.67), # 0.67 is the average value of P --\u0026gt; Intercept now represents K at average P\rP ~ dbeta2(nu, theta), # bound between 0 and 1, but wide\rnu ~ dbeta(2, 2), # bound between 0 and 1\ra ~ dnorm(0, 0.2), # same as before\rbP ~ dnorm(0, 10), # another wide prior, since there is little variation in values of P\rtheta ~ dexp(1), # standard stdev prior\rsigma ~ dexp(1), # same as before\rvector[12]:P_impute ~ uniform(0, 1) # there are 12 NA-values for P, we bound them between 0 and 1\r),\rdata = dat_list, chains = 4, cores = 4, iter = 2000, log_lik = TRUE\r)\r## Both predictors\rm_M2_5.7 \u0026lt;- ulam(\ralist(\rK ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bP * (P - 0.67) + bM * M, # 0.67 is the average value of P --\u0026gt; Intercept now represents K at average P\rP ~ dbeta2(nu, theta), # bound between 0 and 1, but wide\rnu ~ dbeta(2, 2), # bound between 0 and 1\ra ~ dnorm(0, 0.2), # same as before\rbM ~ dnorm(0, 0.5), # same as before\rbP ~ dnorm(0, 10), # another wide prior, since there is little variation in values of P\rtheta ~ dexp(1), # standard stdev prior\rsigma ~ dexp(1), # same as before\rvector[12]:P_impute ~ uniform(0, 1) # there are 12 NA-values for P, we bound them between 0 and 1\r),\rdata = dat_list, chains = 4, cores = 4, iter = 2000, log_lik = TRUE\r)\r All three models are compiled. Time to compare how they perform:\ncompare(m_M2_5.5, m_M2_5.6, m_M2_5.7)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m_M2_5.7 79.50850 5.831506 0.000000 NA 4.565835 0.74491310\r## m_M2_5.6 82.17410 5.870788 2.665598 1.455532 1.678415 0.19646189\r## m_M2_5.5 84.59271 5.291591 5.084212 3.492726 2.344498 0.05862501\r Unsurprisingly, the full model outperforms both one-effect models here. Interestingly, the mass-only model still pulls ahead of the (now imputation-driven) neocortex-only model.\nVisualising what our full imputation model sees, we obtain:\npost \u0026lt;- extract.samples(m_M2_5.7)\rP_impute_mu \u0026lt;- apply(post$P_impute, 2, mean)\rP_impute_ci \u0026lt;- apply(post$P_impute, 2, PI)\rpar(mfrow = c(1, 2))\r# P vs K\rplot(dat_list$P,\rdat_list$K,\rpch = 16, col = rangi2,\rxlab = \u0026quot;neocortex percent\u0026quot;, ylab = \u0026quot;kcal milk (std)\u0026quot;, xlim = c(0, 1)\r)\rmiss_idx \u0026lt;- which(is.na(dat_list$P))\rKi \u0026lt;- dat_list$K[miss_idx]\rpoints(P_impute_mu, Ki)\rfor (i in 1:12) lines(P_impute_ci[, i], rep(Ki[i], 2))\r# M vs B\rplot(dat_list$M, dat_list$P, pch = 16, col = rangi2, ylab = \u0026quot;neocortex percent (std)\u0026quot;, xlab = \u0026quot;log body mass (std)\u0026quot;, ylim = c(0, 1))\rMi \u0026lt;- dat_list$M[miss_idx]\rpoints(Mi, P_impute_mu)\rfor (i in 1:12) lines(rep(Mi[i], 2), P_impute_ci[, i])\r These are the same plots as in the book in chapter 15. The only difference is that our imputed neocortex percent values now fall into clearly readable (and sensible) ranges between 0 and 1.\nPractice M3 Question: Repeat the divorce data measurement error models, but this time double the standard errors. Can you explain how doubling the standard errors impacts inference?\nAnswer: Again, I prepare the data the same way as the book does it:\ndata(WaffleDivorce)\rd \u0026lt;- WaffleDivorce\rdlist \u0026lt;- list(\rD_obs = standardize(d$Divorce),\rD_sd = d$Divorce.SE / sd(d$Divorce),\rM = standardize(d$Marriage),\rA = standardize(d$MedianAgeMarriage),\rN = nrow(d)\r)\r Now, I simply take the model from the book and run it:\nm15.1 \u0026lt;- ulam(\ralist(\rD_obs ~ dnorm(D_true, D_sd),\rvector[N]:D_true ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bA * A + bM * M,\ra ~ dnorm(0, 0.2),\rbA ~ dnorm(0, 0.5),\rbM ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = dlist, chains = 4, cores = 4\r)\r Now that we have our baseline model, it is time to double the standard error variable D_sd:\nm_M3 \u0026lt;- ulam(\ralist(\rD_obs ~ dnorm(D_true, D_sd * 2.0),\rvector[N]:D_true ~ dnorm(mu, sigma),\rmu \u0026lt;- a + bA * A + bM * M,\ra ~ dnorm(0, 0.2),\rbA ~ dnorm(0, 0.5),\rbM ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = dlist, chains = 4, cores = 4, iter = 4000\r)\r Let\u0026rsquo;s compare the two models for now and see what is happening:\nprecis(m15.1)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.05218494 0.09615369 -0.2026636 0.1001795 1835.1415 1.001424\r## bA -0.61413500 0.16450611 -0.8828791 -0.3543928 916.8593 1.002451\r## bM 0.05837404 0.16475940 -0.2017307 0.3267334 961.6816 1.002555\r## sigma 0.58800945 0.10284935 0.4284475 0.7570348 784.5056 1.000690\r precis(m_M3)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.1177004 0.1007595 -0.27064731 0.04738969 401.47170 1.008286\r## bA -0.6323619 0.1522011 -0.88505387 -0.38786285 510.81804 1.015609\r## bM 0.2072101 0.1808927 -0.08675262 0.47906692 420.57867 1.022198\r## sigma 0.1541612 0.1131281 0.02439099 0.36471832 97.19502 1.065839\r Oof. Without going into any detail on the parameter estimates, I have to point out that I don\u0026rsquo;t like the effective sample sizes (n_eff) on our new model one bit. They are much, MUCH smaller than those of our baseline model. This highlights that out second model struggled with efficient exploration of posterior parameter space. I reckon this is a result of the increased standard deviation making the posterior landscape less easy to identify.\nOne way to work around this issue is to rewrite the model in a non-centred parametrisation:\nm_M3B \u0026lt;- ulam(\ralist(\rD_obs ~ dnorm(mu + z_true * sigma, D_sd * 2.0),\rvector[N]:z_true ~ dnorm(0, 1), # gotten rid of the prior dependency here\rmu \u0026lt;- a + bA * A + bM * M,\ra ~ dnorm(0, 0.2),\rbA ~ dnorm(0, 0.5),\rbM ~ dnorm(0, 0.5),\rsigma ~ dexp(1)\r),\rdata = dlist, chains = 4, cores = 4, iter = 4000,\rcontrol = list(max_treedepth = 14)\r)\r And now, let\u0026rsquo;s compare these again:\nprecis(m15.1)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.05218494 0.09615369 -0.2026636 0.1001795 1835.1415 1.001424\r## bA -0.61413500 0.16450611 -0.8828791 -0.3543928 916.8593 1.002451\r## bM 0.05837404 0.16475940 -0.2017307 0.3267334 961.6816 1.002555\r## sigma 0.58800945 0.10284935 0.4284475 0.7570348 784.5056 1.000690\r precis(m_M3B)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.1185044 0.09953924 -0.2778272 0.03741466 10901.282 0.9996237\r## bA -0.6444853 0.16468812 -0.9085568 -0.37653366 7171.900 0.9996660\r## bM 0.1948245 0.19042617 -0.1056664 0.50037111 8322.124 1.0000969\r## sigma 0.1431878 0.10844390 0.0117172 0.34538107 4706.223 0.9998725\r Nice. That got rid off our issues of non-effective sampling of posteriors. Now we can actually compare the model results. The biggest difference between these two models is found in the estimates for bM (the effect of marriage rate on divorce rate) and sigma (the standard deviation of the normal distribution from which the divorce rates are pulled). By increasing the standard error, we have effectively allowed individual states to exert much greater influence on the regression slope estimates thus shifting the result around.\nIt is also worth pointing out right now that the non-centred model performs much more effective sampling, but the parameter estimates are ultimately the same irrespective of parametrisation in this example.\nHard Exercises Practice H1 Question: The data in data(elephants) are counts of matings observed for bull elephants of differing ages. There is a strong positive relationship between age and matings. However, age is not always assessed accurately. First, fit a Poisson model predicting MATINGS with AGE as a predictor. Second, assume that the observed AGE values are uncertain and have a standard error of $\\pm$ 5 years. Re-estimate the relationship between MATINGS and AGE, incorporating this measurement error. Compare the inferences of the two models.\nAnswer: First, I load the data and take a glance at its contents:\ndata(elephants)\rd \u0026lt;- elephants\rstr(d)\r ## 'data.frame':\t41 obs. of 2 variables:\r## $ AGE : int 27 28 28 28 28 29 29 29 29 29 ...\r## $ MATINGS: int 0 1 1 1 3 0 0 0 2 2 ...\r Now we can run some models. Before we get started, it is worth pointing out that there are a multitude of ways in which age could influence number of matings - exponential, logarithmic, poisson, etc. Here, I run with a poisson-approach. If this were a real-world research problem, I should probably test all three variations of the model. Alas, ain\u0026rsquo;t nobody got time fo' that in an exercise.\nThe data starts with AGE values at 27. This suggests to me that this must be roughly around when elephants reach sexual maturity and will start to mate. Hence, I subtract 25 from all AGE values in my model - just to be safe and interpret the number of matings as \u0026ldquo;number of matings since reaching sexual maturity\u0026rdquo;:\n## Basic Model without uncertainty:\rm_H1_A \u0026lt;- ulam(\ralist(\rMATINGS ~ dpois(lambda),\rlambda \u0026lt;- exp(a) * (AGE - 25)^bA,\ra ~ dnorm(0, 1),\rbA ~ dnorm(0, 1)\r),\rdata = d, chains = 4, cores = 4\r)\rprecis(m_H1_A)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.6922235 0.3429011 -1.2307922 -0.1347450 388.4313 0.9986860\r## bA 0.7191531 0.1353220 0.5000447 0.9213017 379.1290 0.9988198\r Again, another not-so-efficient sampling model. How does it see the relationship between AGE and MATINGS?\n# ages in the data range from 27 to 53\rA_seq \u0026lt;- seq(from = 25, to = 55, length.out = 30)\rlambda \u0026lt;- link(m_H1_A, data = list(AGE = A_seq))\rlambda_mu \u0026lt;- apply(lambda, 2, mean)\rlambda_PI \u0026lt;- apply(lambda, 2, PI)\rplot(d$AGE, d$MATINGS,\rpch = 16, col = rangi2,\rxlab = \u0026quot;age\u0026quot;, ylab = \u0026quot;matings\u0026quot;\r)\rlines(A_seq, lambda_mu)\rshade(lambda_PI, A_seq)\r That\u0026rsquo;s a pretty reliably positive relationship. Older elephants mate more.\nOn to the measurement error model:\nd$AGE0 \u0026lt;- d$AGE - 25 # add the sexual maturity consideration to the data\rm_H1_B \u0026lt;- ulam(\ralist(\rMATINGS ~ dpois(lambda), # same outcome as before\rlambda \u0026lt;- exp(a) * AGE_est[i]^bA, # log-scale predictors\rAGE0 ~ dnorm(AGE_est, 5), # Gaussian distribution with error 5\rvector[41]:AGE_est ~ dunif(0, 50), # prior for individual observed ages\ra ~ dnorm(0, 1),\rbA ~ dnorm(0, 1)\r),\rdata = d, chains = 4, cores = 4\r)\r precis(m_H1_B)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.7742834 0.4801451 -1.6114596 -0.04176099 1049.624 1.003248\r## bA 0.7360628 0.1803691 0.4590526 1.05008454 1060.533 1.003109\r Interestingly enough, the estimate of bA has not changed between these models. Why? Because we added completely symmetric measurement error that remains unchanged across all ages of our elephants. Hence, we don\u0026rsquo;t end up biasing our model because the error in the data is not biased (at least we assume so).\nLet\u0026rsquo;s finish this off by looking at what our model expects the ages to be like for different matings:\npost \u0026lt;- extract.samples(m_H1_B) # extract samples\rAGE_est \u0026lt;- apply(post$AGE_est, 2, mean) + 25 # add 25 back to ages\rMATINGS_j \u0026lt;- jitter(d$MATINGS) # jitter MATINGS for better readability\rplot(d$AGE, MATINGS_j, pch = 16, col = rangi2, xlab = \u0026quot;age\u0026quot;, ylab = \u0026quot;matings\u0026quot;, xlim = c(23, 55)) # observed ages\rpoints(AGE_est, MATINGS_j) # estimated ages\rfor (i in 1:nrow(d)) lines(c(d$AGE[i], AGE_est[i]), rep(MATINGS_j[i], 2)) # shrinkage lines\rlines(A_seq, lambda_mu) # linear regression from previous model\r The blue dots represent the observed ages, while the open circles depict the estimated true ages from our model. We see some shrinkage. Fascinatingly, the shrinkage appears to switch direction around the regression line, however. Values above the regression line are shrunk to higher age ranges, while the reverse is true below the regression line. What this means is that the model assumed elephants with unexpectedly high mating numbers for their observed age to be older than our data implies and vice versa.\nPractice H2 Question: Repeat the model fitting problem above, now increasing the assumed standard error on AGE. How large does the standard error have to get before the posterior mean for the coefficient on AGE reaches zero?\nAnswer: To solve this, I just run the model above again, but increase the standard error. I did several times with ever-increasing standard errors. Finally I landed on a standard error of 100:\nm_H2 \u0026lt;- ulam(\ralist(\rMATINGS ~ dpois(lambda),\rlambda \u0026lt;- exp(a) * AGE_est[i]^bA,\rAGE0 ~ dnorm(AGE_est, 100), # increase standard error here\rvector[41]:AGE_est ~ dunif(0, 50),\ra ~ dnorm(0, 1),\rbA ~ dnorm(0, 1)\r),\rdata = d, chains = 4, cores = 4\r)\rprecis(m_H2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## a -0.3487762 1.1358880 -1.7265552 1.9908366 6.393092 1.409652\r## bA 0.4246873 0.3829174 -0.4010691 0.8592536 5.932438 1.454539\r Albeit not having reached 0, the mean estimate of bA is closer to 0 now and the percentile interval around it is so large that we would not be able to identify the effect here.\nPractice H3 Question: The fact that information flows in all directions among parameters sometimes leads to rather unintuitive conclusions. Here’s an example from missing data imputation, in which imputation of a single datum reverses the direction of an inferred relationship. Use these data:\nset.seed(100)\rx \u0026lt;- c(rnorm(10), NA)\ry \u0026lt;- c(rnorm(10, x), 100)\rd \u0026lt;- list(x = x, y = y)\r These data comprise 11 cases, one of which has a missing predictor value. You can quickly confirm that a regression of $y$ on $x$ for only the complete cases indicates a strong positive relationship between the two variables. But now fit this model, imputing the one missing value for $x$:\n$$y_i ∼ Normal(µ_i, σ)$$ $$µ_i = α + βx_i$$ $$x_i ∼ Normal(0, 1)$$ $$α ∼ Normal(0, 100)$$ $$β ∼ Normal(0, 100)$$ $$σ ∼ HalfCauchy(0, 1)$$\nWhat has happened to the posterior distribution of $β$? Be sure to inspect the full density. Can you explain the change in inference?\nAnswer: Interestingly, the rethinking functions also work on basic lm objects:\nprecis(lm(y ~ x, d))\r ## mean sd 5.5% 94.5%\r## (Intercept) 0.2412995 0.2774524 -0.2021231 0.6847221\r## x 1.4236779 0.5209135 0.5911574 2.2561983\r On to the imputation model:\nm_H3 \u0026lt;- ulam(\ralist(\ry ~ dnorm(mu, sigma),\rmu \u0026lt;- a + b * x,\rx ~ dnorm(0, 1),\rc(a, b) ~ dnorm(0, 100),\rsigma ~ dexp(1)\r),\rdata = d, chains = 4, cores = 4, iter = 4000,\rcontrol = list(adapt_delta = 0.99)\r)\r precis(m_H3)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## b -10.972553 19.300190 -27.944113 24.271345 2.066259 5.340370\r## a 1.869767 3.346405 -3.361028 7.168704 4172.209841 1.003406\r## sigma 10.294366 2.054437 7.383010 13.871396 75.915321 1.033777\r Well those percentile intervals look bad. The joint posterior distributions might help solve this mystery:\npairs(m_H3)\r We have a few bi-modal distributions which place the plausible values for b and x_impute either strongly in the negative or strongly in the positive realm. This feels like the issue of unidentifiable parameters all over again.\nThe outcome variable value for which we are missing the predictor variable value is very extreme given the range of all other outcome variable values. This means, we can flip our predictor value to either extreme and still be consistent with the data and model thus forcing the regression line to be either positive or negative.\nLet\u0026rsquo;s extract positive and negative regression estimates and their positions in our extracted samples from the posterior:\npost \u0026lt;- extract.samples(m_H3)\rpost_pos \u0026lt;- post\rpost_neg \u0026lt;- post\rfor (i in 1:length(post)) {\rpost_pos[[i]] \u0026lt;- post[[i]][post$b \u0026gt; 0]\rpost_neg[[i]] \u0026lt;- post[[i]][post$b \u0026lt; 0]\r}\r With this at hand, we can now compute the two regression lines and plot them:\npar(mfrow = c(1, 2))\r## positive\rx_seq \u0026lt;- seq(from = -2.6, to = 4, length.out = 30)\rmu_link \u0026lt;- function(x, post) post$a + post$b * x\rmu \u0026lt;- sapply(x_seq, mu_link, post = post_pos)\rmu_mu \u0026lt;- apply(mu, 2, mean)\rmu_PI \u0026lt;- apply(mu, 2, PI)\rx_impute \u0026lt;- mean(post_pos$x_impute)\rplot(y ~ x, d, pch = 16, col = rangi2, xlim = c(-0.85, x_impute))\rpoints(x_impute, 100)\rlines(x_seq, mu_mu)\rshade(mu_PI, x_seq)\r## negative\rx_seq \u0026lt;- seq(from = -4, to = 4, length.out = 50)\rmu \u0026lt;- sapply(x_seq, mu_link, post = post_neg)\rmu_mu \u0026lt;- apply(mu, 2, mean)\rmu_PI \u0026lt;- apply(mu, 2, PI)\rx_impute \u0026lt;- mean(post_neg$x_impute)\rplot(y ~ x, d, pch = 16, col = rangi2, xlim = c(-3.7, 0.9))\rpoints(x_impute, 100)\rlines(x_seq, mu_mu)\rshade(mu_PI, x_seq)\r This should make it obvious just how extreme the outcome variable value is and how our model could agree with either extreme imputed variable.\nPractice H4 Question: Some lad named Andrew made an eight-sided spinner. He wanted to know if it is fair. So he spun it a bunch of times, recording the counts of each value. Then he accidentally spilled coffee over the 4s and 5s. The surviving data are summarized below.\n| Value | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | | Frequency | 18 | 19 | 22 | ? | ? | 19 | 20 | 22 |\nYour job is to impute the two missing values in the table above. Andrew doesn’t remember how many times he spun the spinner. So you will have to assign a prior distribution for the total number of spins and then marginalize over the unknown total. Andrew is not sure the spinner is fair (every value is equally likely), but he’s confident that none of the values is twice as likely as any other. Use a Dirichlet distribution to capture this prior belief. Plot the joint posterior distribution of 4s and 5s.\nAnswer: First, I enter the data into R:\ny \u0026lt;- c(18, 19, 22, NA, NA, 19, 20, 22)\r What data do I need to somehow get to for my model?\n N - total number of spins  For N, we can say that is no smaller than 120 - the sum of all spins which we have observed outcomes for. The number of spins would be a count variable and so it would make sense to assign a Poisson distribution to them - especially seeing how we lack a sensible upper bound to the total number of spins. So what should our expected value be? Well, from the data above, it would be sensible to expect that the spins for sides 4 and 5 are 20 respectively - this is just a guess. As such, we could set a prior as:\n$$N \\sim Poisson(40) + 120$$ Why 40 and why 120? 40 is the expected number of missing spins from our data table, 120 defines the lower bound of our total spins. We have data for 120 spins.\nProbs - vector of probabilities for each side of the spinner  As for the vector of probabilities, we want to use the Dirichlet prior as outlined by the exercise text. The Dirichlet prior is used for categorical outcomes like these. We know that none of the outcomes is twice as likely as any other. Dirichlet doesn\u0026rsquo;t give us that control directly, unfortunately. What we can do is simulate:\np \u0026lt;- rdirichlet(1e3, alpha = rep(4, 8))\rplot(NULL, xlim = c(1, 8), ylim = c(0, 0.3), xlab = \u0026quot;outcome\u0026quot;, ylab = \u0026quot;probability\u0026quot;)\rfor (i in 1:10) lines(1:8, p[i, ], type = \u0026quot;b\u0026quot;, col = grau(), lwd = 2)\r It is difficult to judge from this what our prior is assuming and whether our assumption is met. We can identify this numerically though:\ntwicer \u0026lt;- function(p) {\ro \u0026lt;- order(p)\rif (p[o][8] / p[o][1] \u0026gt; 2) {\rreturn(TRUE)\r} else {\rreturn(FALSE)\r}\r}\rsum(apply(p, 1, twicer))\r ## [1] 977\r Our prior clearly needs to be tighter since our criterion of no category being twice as likely as any other category is being violated quite heavily.\np \u0026lt;- rdirichlet(1e3, alpha = rep(50, 8))\rsum(apply(p, 1, twicer))\r ## [1] 17\r That looks much better! Let\u0026rsquo;s plot that:\nplot(NULL, xlim = c(1, 8), ylim = c(0, 0.3), xlab = \u0026quot;outcome\u0026quot;, ylab = \u0026quot;probability\u0026quot;)\rfor (i in 1:10) lines(1:8, p[i, ], type = \u0026quot;b\u0026quot;, col = grau(), lwd = 2)\r N4 and N5 - the counts of observations of the side 4 and 5, respectively  This is what we want to get to to help Andrew get around his coffee-spillage mishap. What we need to do here is to marginalize over all combinations of 4s and 5s. I will freely admit that I was completely lost here and took the STAN code directly from the solutions by Richard McElreath. Looking at it, there are some loops in here, which I couldn\u0026rsquo;t have been able to code myself (yet). I have added some comments to indciate what I understood:\ncode15H7 \u0026lt;- \u0026quot;\rdata{\rint N;\rint y[N];\rint y_max; // consider at most this many spins for y4 and y5\rint S_mean;\r}\rparameters{\rsimplex[N] p; // probabilities of each outcome\r}\rmodel{\rvector[(1+y_max)*(1+y_max)] terms; // all combinations of spins for 4 and 5\rint k = 1; // counter to index above vector of combinations\rp ~ dirichlet(rep_vector(50, N)); // Dirichlet prior\r// loop over possible values for unknown cells 4 and 5\r// this code updates posterior of p\rfor(y4 in 0:y_max){\rfor(y5 in 0:y_max){\rint Y[N] = y; // probability of complete vector of individual spins\rY[4] = y4; // spins for 4s\rY[5] = y5; // spins for 5s\rterms[k] = poisson_lpmf(y4+y5|S_mean-120) + multinomial_lpmf(Y|p); // poisson prior for individual spins and multinomial prior for vector of counts conditional on number of spins n and prior p\rk = k + 1;\r}//y5\r}//y4\rtarget += log_sum_exp(terms);\r}\rgenerated quantities{ // repeates much of the above to compute posterior probability\rmatrix[y_max+1, y_max+1] P45; // prob y4, y5 takes joint values\r// now compute Prob(y4, y5|p)\r{\rmatrix[(1+y_max), (1+y_max)] terms;\rint k = 1;\rreal Z;\rfor(y4 in 0:y_max){\rfor(y5 in 0:y_max){\rint Y[N] = y;\rY[4] = y4;\rY[5] = y5;\rterms[y4+1, y5+1] = poisson_lpmf(y4+y5|S_mean-120) + multinomial_lpmf(Y|p);\r}//y5\r}//y4\rZ = log_sum_exp(to_vector(terms));\rfor(y4 in 0:y_max)\rfor(y5 in 0:y_max)\rP45[y4+1, y5+1] = exp(terms[y4+1, y5+1] - Z); // make sure all probabilities sum to 1\r}\r}\r\u0026quot;\r Here\u0026rsquo;s the data that the model needs. STAN doesn\u0026rsquo;t accept NAs, hence why the NA values below are now encoded as -1:\ny \u0026lt;- c(18, 19, 22, -1, -1, 19, 20, 22)\rdat \u0026lt;- list(\rN = length(y),\ry = y,\rS_mean = 160,\ry_max = 40\r)\r Finally, let\u0026rsquo;s run the model and plot some samples from it:\nm15H7 \u0026lt;- stan(model_code = code15H7, data = dat, chains = 4, cores = 4)\r post \u0026lt;- extract.samples(m15H7)\ry_max \u0026lt;- dat$y_max\rplot(NULL,\rxlim = c(10, y_max - 10), ylim = c(10, y_max - 10),\rxlab = \u0026quot;number of 4s\u0026quot;, ylab = \u0026quot;number of 5s\u0026quot;\r)\rmtext(\u0026quot;posterior distribution of 4s and 5s\u0026quot;)\rfor (y4 in 0:y_max) {\rfor (y5 in 0:y_max) {\rk \u0026lt;- grau(mean(post$P45[, y4 + 1, y5 + 1]) / 0.01)\rpoints(y4, y5, col = k, pch = 16, cex = 1.5)\r}\r}\r From this, it is apparent that 20 spins for the 4s and 5s respectively is the most likely and that there is a negative correlation between these respective spins - more spins resulting in side 4 make less spins resulting in side 5 more likely.\nAndrew - don\u0026rsquo;t spill your coffee again.\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] gtools_3.8.2 rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 R6_2.5.0 ## [11] backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 ## [21] jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 xfun_0.22 ## [31] pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 codetools_0.2-18 matrixStats_0.61.0\r## [41] fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 lifecycle_1.0.0 ## [51] DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 KernSmooth_2.23-18 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 bslib_0.2.4 ellipsis_0.3.2 generics_0.1.0 ## [61] vctrs_0.3.7 rematch2_2.1.2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 colorspace_2.0-0 ## [71] knitr_1.33 sass_0.3.1\r ","date":1620259200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620320400,"objectID":"1907d12d524da53efbc41053b6518305","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-15/","publishdate":"2021-05-06T00:00:00Z","relpermalink":"/courses/rethinking/chapter-15/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 15 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 15","type":"docs"},{"authors":[],"categories":["Statistical Rethinking"],"content":"Generalised Linear Madness Material  \rSlides Chapter 16  Introduction These are answers and solutions to the exercises at the end of chapter 15 in Satistical Rethinking 2 by Richard McElreath. I have created these notes as a part of my ongoing involvement in the AU Bayes Study Group. Much of my inspiration for these solutions, where necessary, has been obtained from\nthe solutions provided to instructors by Richard McElreath himself.\nR Environment For today\u0026rsquo;s exercise, I load the following packages:\nlibrary(rethinking)\rlibrary(ggplot2)\r Easy Exercises Unfortunately, the PDF version of Satistical Rethinking 2, I am working with does not list any easy practice exercises for this chapter.\nMedium Exercises Practice M1 Question: Modify the cylinder height model, m16.1, so that the exponent 3 on height is instead a free parameter. Do you recover the value of 3 or not? Plot the posterior predictions for the new model. How do they differ from those of m16.1?\nAnswer: Before we move on, let me just remind all of us of the model itself:\n$W_i ∼ Log-Normal(µ_i, σ)$ [Distribution for weight]\n$exp(µ_i) = kπp^2h^3_i$ [expected median of weight]\n$k ∼ Beta(2, 18)$ [prior relation between weight and volume]\n$p ∼ Exponential(0.5)$ [prior proportionality of radius to height]\n$σ ∼ Exponential(1)$ [our old friend, sigma]\nAs for the exercise, I start by loading the data and rescaling the weight and height variables as was done in the chapter:\ndata(\u0026quot;Howell1\u0026quot;)\rd \u0026lt;- Howell1\rd$w \u0026lt;- d$weight / mean(d$weight)\rd$h \u0026lt;- d$height / mean(d$height)\r Now that the data is prepared, we can run the model. Before we run the model that we are asked for, however, I want to run the model from the chapter for later comparison:\nm16.1 \u0026lt;- ulam(\ralist(\rw ~ dlnorm(mu, sigma),\rexp(mu) \u0026lt;- 3.141593 * k * p^2 * h^3,\rp ~ beta(2, 18),\rk ~ exponential(0.5),\rsigma ~ exponential(1)\r),\rdata = d, chains = 4, cores = 4, log_lik = TRUE\r)\r I run this model as well as the subsequent one with log_lik = TRUE to allow for model comparison with WAIC.\nTo assign a free parameter to the exponent 3 of the chapter, I simply substitute the value 3 in the model code with a letter (e) to indicate a parameter. I also have to define a prior (I reckon the exponent should definitely be positive) for this new parameter, of course:\nm_M1 \u0026lt;- ulam(\ralist(\rw ~ dlnorm(mu, sigma),\rexp(mu) \u0026lt;- 3.141593 * k * p^2 * h^e,\rp ~ beta(2, 18),\rk ~ exponential(0.5),\rsigma ~ exponential(1),\re ~ exponential(1)\r),\rdata = d, chains = 4, cores = 4, log_lik = TRUE\r)\r precis(m_M1)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## p 0.2440124 0.056092318 0.1699713 0.3450251 692.9784 1.002353\r## k 5.7390657 2.482731435 2.5008291 10.2474462 812.8841 1.003970\r## sigma 0.1263219 0.003660893 0.1206056 0.1321993 1004.6100 1.000673\r## e 2.3234522 0.022774994 2.2877691 2.3598172 1108.6018 1.003564\r With the new model, we obtain an estimates of 2.32 for the exponent rather than the value of 3 that was assumed in the chapter.\nSo let\u0026rsquo;s get started with model comparison:\ncompare(m16.1, m_M1)\r ## WAIC SE dWAIC dSE pWAIC weight\r## m_M1 -845.6597 36.86898 0.0000 NA 3.441582 1.000000e+00\r## m16.1 -310.4014 44.39907 535.2583 54.80355 3.775032 5.890284e-117\r Seems like model comparison strongly favours our new model m_M1. What brings this difference about? Let\u0026rsquo;s look at the posterior predictions for the answer:\n## Getting the data\rh_seq \u0026lt;- seq(from = 0, to = max(d$h), length.out = nrow(d))\r# m_M1\rw_sim \u0026lt;- sim(m_M1, data = list(h = h_seq))\rm1_mean \u0026lt;- apply(w_sim, 2, mean)\rm1_CI \u0026lt;- apply(w_sim, 2, PI)\r# m16.1\rw_sim \u0026lt;- sim(m16.1, data = list(h = h_seq))\rm16.1_mean \u0026lt;- apply(w_sim, 2, mean)\rm16.1_CI \u0026lt;- apply(w_sim, 2, PI)\r## Making a data frame for plotting\rplot_df \u0026lt;- data.frame(\rseq = rep(h_seq, 2),\rmean = c(m1_mean, m16.1_mean),\rCI_l = c(m1_CI[1, ], m16.1_CI[1, ]),\rCI_U = c(m1_CI[2, ], m16.1_CI[2, ]),\ry = rep(d$w, 2),\rx = rep(d$h, 2),\rmodel = rep(c(\u0026quot;m_M1\u0026quot;, \u0026quot;m16.1\u0026quot;), each = length(h_seq))\r)\r## Plotting posterior\rggplot(plot_df, aes(x = x, y = y)) +\rgeom_point(col = \u0026quot;blue\u0026quot;) +\rgeom_line(aes(x = seq, y = mean)) +\rgeom_ribbon(aes(x = seq, ymin = CI_l, ymax = CI_U), alpha = 0.2) +\rlabs(x = \u0026quot;height (scaled)\u0026quot;, y = \u0026quot;weight (scaled)\u0026quot;) +\rfacet_wrap(~model) +\rtheme_bw()\r Compared to the original model m16.1, the new model m_M1 fits shorter individuals much better than the original model which comes at the detriment of fitting taller individuals correctly. Overall, the posterior uncertainty is tighter for our new model m_M1.\nPractice M2 Question: Conduct a prior predictive simulation for the cylinder height model. Begin with the priors in the chapter. Do these produce reasonable prior height distributions? If not, which modifications do you suggest?\nAnswer: Remember our priors from the chapter:\n$$p ∼ Beta(2, 18)$$ $$k ∼ Exponential(0.5)$$ $$\\sigma \\sim Exponential(1)$$ Now let\u0026rsquo;s simulate priors for a number of N cases:\nN \u0026lt;- 1e2\rp \u0026lt;- rbeta(N, 2, 18) # p ~ Beta(2, 18)\rk \u0026lt;- rexp(N, 0.5) # k ~ Exponential(0.5)\rsigma \u0026lt;- rexp(N, 1)\rprior \u0026lt;- list(p = p, k = k, sigma = sigma)\r The priors are all compiled into one list, now all we have to do is run the prior predictive check:\n## Making a data frame for plotting\rplot_df \u0026lt;- with(prior, 3.141593 * k[1] * p[1]^2 * d$h^3)\rfor (i in 2:N) {\rplot_df \u0026lt;- c(plot_df, with(prior, 3.141593 * k[i] * p[i]^2 * d$h^3))\r}\rplot_df \u0026lt;- data.frame(\rw = plot_df,\rseq = rep(d$h, N),\rprior = rep(1:N, each = nrow(d))\r)\r## Plotting\rggplot() +\rgeom_point(data = d, aes(x = h, y = w), col = \u0026quot;blue\u0026quot;) +\rgeom_line(data = plot_df, aes(x = seq, y = w, group = prior)) +\rlabs(x = \u0026quot;height (scaled)\u0026quot;, y = \u0026quot;weight (scaled)\u0026quot;) +\rtheme_bw()\r The combination of these priors seems to be too flat - weight is not increasing fast enough with height. Either $p$ or $k$ need to be larger on average:\n## New priors\rp \u0026lt;- rbeta(N, 4, 18)\rk \u0026lt;- rexp(N, 1 / 4)\rsigma \u0026lt;- rexp(N, 1)\rprior \u0026lt;- list(p = p, k = k, sigma = sigma)\r## Making a data frame for plotting\rplot_df \u0026lt;- with(prior, 3.141593 * k[1] * p[1]^2 * d$h^3)\rfor (i in 2:N) {\rplot_df \u0026lt;- c(plot_df, with(prior, 3.141593 * k[i] * p[i]^2 * d$h^3))\r}\rplot_df \u0026lt;- data.frame(\rw = plot_df,\rseq = rep(d$h, N),\rprior = rep(1:N, each = nrow(d))\r)\r## Plotting\rggplot() +\rgeom_point(data = d, aes(x = h, y = w), col = \u0026quot;blue\u0026quot;) +\rgeom_line(data = plot_df, aes(x = seq, y = w, group = prior)) +\rlabs(x = \u0026quot;height (scaled)\u0026quot;, y = \u0026quot;weight (scaled)\u0026quot;) +\rtheme_bw()\r There are some prior combinations here that are definitely way too extreme, but most priors still bunch up too much along the x-axis. Let\u0026rsquo;s alter the prior for $k$ (the density) some more by making it log-Normal:\n## New priors\rN \u0026lt;- 1e2\rp \u0026lt;- rbeta(N, 4, 18)\rk \u0026lt;- rlnorm(N, log(7), 0.2) # median of log(7)\rsigma \u0026lt;- rexp(N, 1)\rprior \u0026lt;- list(p = p, k = k, sigma = sigma)\r## Making a data frame for plotting\rplot_df \u0026lt;- with(prior, 3.141593 * k[1] * p[1]^2 * d$h^3)\rfor (i in 2:N) {\rplot_df \u0026lt;- c(plot_df, with(prior, 3.141593 * k[i] * p[i]^2 * d$h^3))\r}\rplot_df \u0026lt;- data.frame(\rw = plot_df,\rseq = rep(d$h, N),\rprior = rep(1:N, each = nrow(d))\r)\r## Plotting\rggplot() +\rgeom_point(data = d, aes(x = h, y = w), col = \u0026quot;blue\u0026quot;) +\rgeom_line(data = plot_df, aes(x = seq, y = w, group = prior)) +\rlabs(x = \u0026quot;height (scaled)\u0026quot;, y = \u0026quot;weight (scaled)\u0026quot;) +\rtheme_bw()\r This is much better! Remember - priors are not about fitting the data exactly but informing the model about plausibility.\nPractice M3 Question: Use prior predictive simulations to investigate the Lynx-hare model. Begin with the priors in the chapter. Which population dynamics do these produce? Can you suggest any improvements to the priors, on the basis of your simulations?\nAnswer: Again, let me remind us of the model in the chapter:\n$h_t ∼ LogNormal(log(p_HH_t), σ_H)$ [Probability of observed hare pelts]\n$ℓ_t ∼ LogNormal(log(p_LL_t), σ_L)$ [Probability observed lynx pelts]\n$H_1 ∼ LogNormal(log(10), 1)$ [Prior for initial hare population]\n$L_1 ∼ LogNormal(log(10), 1)$ [Prior for initial lynx population]\n$H_{T\u0026gt;1} = H_1 + \\int_1^TH_t(b_H −m_HL_t)d_t$ [Model for hare population]\n$L_{T\u0026gt;1} = L_1 + \\int_1^T L_t(b_LH_t −m_L)d_t$ [Model for lynx population]\n$σ_H ∼ Exponential(1)$ [Prior for measurement dispersion]\n$σ_L ∼ Exponential(1)$ [Prior for measurement dispersion]\n$p_H ∼ Beta(α_H, β_H)$ [Prior for hare trap probability]\n$p_L ∼ Beta(α_L, β_L)$ [Prior for lynx trap probability]\n$b_H ∼ HalfNormal(1, 0.5)$ [Prior hare birth rate]\n$b_L ∼ HalfNormal(0.05, 0.05)$ [Prior lynx birth rate]\n$m_H ∼ HalfNormal(0.05, 0.05)$ [Prior hare mortality rate]\n$m_L ∼ HalfNormal(1, 0.5)$ [Prior lynx mortality rate]\nLet\u0026rsquo;s get started on our exercise now by loading the data and preparing our priors. Here, we simply just draw theta parameters (these define halfnormal distributions) from normal distributions as defined above:\ndata(Lynx_Hare)\rN \u0026lt;- 12\rtheta \u0026lt;- matrix(NA, nrow = N, ncol = 4)\rtheta[, 1] \u0026lt;- rnorm(N, 1, 0.5) # b_H\rtheta[, 2] \u0026lt;- rnorm(N, 0.05, 0.05) # b_L\rtheta[, 3] \u0026lt;- rnorm(N, 1, 0.5) # m_L\rtheta[, 4] \u0026lt;- rnorm(N, 0.05, 0.05) # m_H\r We can now use these priors in combination with the sim_lynx_hare() function from the book:\nsim_lynx_hare \u0026lt;- function(n_steps, init, theta, dt = 0.002) {\rL \u0026lt;- rep(NA, n_steps)\rH \u0026lt;- rep(NA, n_steps)\rL[1] \u0026lt;- init[1]\rH[1] \u0026lt;- init[2]\rfor (i in 2:n_steps) {\rH[i] \u0026lt;- H[i - 1] + dt * H[i - 1] * (theta[1] - theta[2] * L[i - 1])\rL[i] \u0026lt;- L[i - 1] + dt * L[i - 1] * (theta[3] * H[i - 1] - theta[4])\r}\rreturn(cbind(L, H))\r}\r With the above function registered in our R environment, we are ready to simulate with our priors and produce some plots:\n## Simulate for first prior\rplot_df \u0026lt;- sim_lynx_hare(1e4, as.numeric(Lynx_Hare[1, 2:3]), theta[1, ])\rplot_df \u0026lt;- data.frame(plot_df)\rplot_df$prior \u0026lt;- rep(1, 1e4)\r## simulate for all other priors\rfor (i in 2:N) {\rz \u0026lt;- sim_lynx_hare(1e4, as.numeric(Lynx_Hare[1, 2:3]), theta[i, ])\rz \u0026lt;- data.frame(z)\rz$prior \u0026lt;- rep(i, 1e4)\rplot_df \u0026lt;- rbind(plot_df, z)\r}\rplot_df$seq \u0026lt;- rep(1:1e4, N)\r## Plotting\rggplot(plot_df, aes(x = seq)) +\rgeom_line(aes(y = L), col = \u0026quot;brown\u0026quot;) +\rgeom_line(aes(y = H), col = \u0026quot;blue\u0026quot;) +\rfacet_wrap(~prior, scales = \u0026quot;free\u0026quot;) +\rtheme_bw() +\rlabs(x = \u0026quot;Time\u0026quot;, y = \u0026quot;Population\u0026quot;) +\rtheme(axis.text.y = element_blank())\r Hare population estimates are shown in blue while Lynx population estimates are portrayed in brown. Nevermind that, however, these priors are clearly not good as far as building biological plausibility into our model. Why? There is no cycling in the blue trends depending on the brown trends (lynx eat hares and are thus coupled to them). In addition to that, although I have hidden the actual population estimates, I think it is evident from these plots that some of the prior estimates are just outlandish in terms of population size.\nLet\u0026rsquo;s see if we can do better. How would we do that? By making our priors more informative, of course. We should probably take this step-by-step:\n Hare birth rate - $b_H$:  I want to make this more conservative by lowering the expected birth rate of hares. To do so, the theta parameter for my halfnormal distribution will now be drawn from $Normal(0.5, 0.1)$ as opposed to the previous $Normal(1, 0.5)$.\n$$b_H ∼ HalfNormal(0.5, 0.1)$$\nLynx birth rate - $b_L$:  This one, I keep as it was previously. I strongly suspect that the base birth rate of lynx should be much smaller than that of hares. The new prior reflects that:\n$$b_L ∼ HalfNormal(0.05, 0.05)$$\nLynx mortality rate - $m_L$:  I want to drastically decrease the estimated lynx mortality rate since lynx don\u0026rsquo;t die as much as hares do (longer life, no predators, etc.):\n$$m_H ∼ HalfNormal(0.025, 0.05)$$\nHare mortality rate - $m_H$:  I increase the mortality rate of hares to reflect that they die much more frequently than lynx do for the aforementioned reasons:\n$$m_L ∼ HalfNormal(0.5, 0.1)$$\nLet\u0026rsquo;s simulate with these priors\n## New priors\rN \u0026lt;- 12\rtheta \u0026lt;- matrix(NA, nrow = N, ncol = 4)\rtheta[, 1] \u0026lt;- rnorm(N, 0.5, 0.1) # b_H\rtheta[, 2] \u0026lt;- rnorm(N, 0.05, 0.05) # b_L\rtheta[, 3] \u0026lt;- rnorm(N, 0.025, 0.05) # m_L\rtheta[, 4] \u0026lt;- rnorm(N, 0.5, 0.1) # m_H\r## Simulate for first prior\rplot_df \u0026lt;- sim_lynx_hare(1e4, as.numeric(Lynx_Hare[1, 2:3]), theta[1, ])\rplot_df \u0026lt;- data.frame(plot_df)\rplot_df$prior \u0026lt;- rep(1, 1e4)\r## simulate for all other priors\rfor (i in 2:N) {\rz \u0026lt;- sim_lynx_hare(1e4, as.numeric(Lynx_Hare[1, 2:3]), theta[i, ])\rz \u0026lt;- data.frame(z)\rz$prior \u0026lt;- rep(i, 1e4)\rplot_df \u0026lt;- rbind(plot_df, z)\r}\rplot_df$seq \u0026lt;- rep(1:1e4, N)\r## Plotting\rggplot(plot_df, aes(x = seq)) +\rgeom_line(aes(y = L), col = \u0026quot;brown\u0026quot;) +\rgeom_line(aes(y = H), col = \u0026quot;blue\u0026quot;) +\rfacet_wrap(~prior, scales = \u0026quot;free\u0026quot;) +\rtheme_bw() +\rlabs(x = \u0026quot;Time\u0026quot;, y = \u0026quot;Population\u0026quot;) +\rtheme(axis.text.y = element_blank())\r Still, there are some populations here that experience explosive growth, but at least we now have properly cycling population trends for both species!\nHard Exercises Practice H1 Question: Modify the Panda nut opening model so that male and female chimpanzees have different maximum adult body mass. The sex variable in data(Panda_nuts) provides the information you need. Be sure to incorporate the fact that you know, prior to seeing the data, that males are on average larger than females at maturity.\nAnswer: Once more, let me include the model specification from the chapter:\n$$n_i ∼ Poisson(λ_i)$$ $$λ_i = d_iϕ(1 − exp(−kt_i))^θ$$ $$ϕ ∼ LogNormal(log(1), 0.1)$$ $$k ∼ LogNormal(log(2), 0.25)$$ $$θ ∼ LogNormal(log(5), 0.25)$$\nOnce more, we move on to loading the data as was done in the chapter and creating an index variable for male individuals:\ndata(Panda_nuts)\rdat_list \u0026lt;- list(\rn = as.integer(Panda_nuts$nuts_opened),\rage = Panda_nuts$age / max(Panda_nuts$age),\rseconds = Panda_nuts$seconds\r)\rdat_list$male_id \u0026lt;- ifelse(Panda_nuts$sex == \u0026quot;m\u0026quot;, 1L, 0L)\r We need to alter the model above to allow for the effect of sex to take hold. How do we go about this? Well, the exercise states that the effect of sex is supposed to come about through the effect of body mass which, in turn, is included in the model through $\\phi$ which handles the conversion of body mass into strength. We can add the effect of sex to the model as such:\n$$n_i ∼ Poisson(λ_i)$$ $$λ_i = d_ip_mSϕ(1 − exp(−kt_i))^θ$$ $$p_m ∼ Exponential(2)$$ $$ϕ ∼ LogNormal(log(1), 0.1)$$ $$k ∼ LogNormal(log(2), 0.25)$$ $$θ ∼ LogNormal(log(5), 0.25)$$\nwhere $S$ stands for the maleness indicator we built above:\nm_H1 \u0026lt;- ulam(\ralist(\rn ~ poisson(lambda),\rlambda \u0026lt;- seconds * (1 + pm * male_id) * phi * (1 - exp(-k * age))^theta, # 1+ addedd for baseline of effect of sex\rphi ~ lognormal(log(1), 0.1),\rpm ~ exponential(2),\rk ~ lognormal(log(2), 0.25),\rtheta ~ lognormal(log(5), 0.25)\r),\rdata = dat_list, chains = 4, cores = 4\r)\r precis(m_H1)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## phi 0.5996689 0.04786004 0.5284066 0.6779957 976.2037 1.0013342\r## pm 0.6681319 0.13966484 0.4576800 0.9047816 991.7476 0.9993602\r## k 5.1615999 0.66777159 4.0568926 6.2455157 743.6989 1.0060706\r## theta 7.5940540 1.82343038 4.9655187 10.9163027 819.2285 1.0040457\r Due to how we built our model, the interpretation of $p_m$ is as follows: \u0026ldquo;Males are 0.67 times stronger than their female counterparts at maximum.\u0026rdquo;\nHow does this look when we plot it? I use the plotting scheme outlined by Richard McElreath in the chapter and modified in his solutions:\npost \u0026lt;- extract.samples(m_H1)\rplot(NULL, xlim = c(0, 1), ylim = c(0, 1.5), xlab = \u0026quot;age\u0026quot;, ylab = \u0026quot;nuts per second\u0026quot;, xaxt = \u0026quot;n\u0026quot;)\rat \u0026lt;- c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5)\raxis(1, at = at, labels = round(at * max(Panda_nuts$age)))\rpts \u0026lt;- dat_list$n / dat_list$seconds\rpoint_size \u0026lt;- normalize(dat_list$seconds)\rpoints(jitter(dat_list$age), pts,\rlwd = 2, cex = point_size * 3,\rcol = ifelse(dat_list$male_id == 1, \u0026quot;black\u0026quot;, \u0026quot;red\u0026quot;)\r)\r# 10 female curves\rfor (i in 1:10) {\rwith(\rpost,\rcurve(phi[i] * (1 - exp(-k[i] * x))^theta[i], add = TRUE, col = \u0026quot;red\u0026quot;)\r)\r}\r# 10 male curves\rfor (i in 1:10) {\rwith(\rpost,\rcurve((1 + pm[i]) * phi[i] * (1 - exp(-k[i] * x))^theta[i], add = TRUE, col = grau())\r)\r}\r There is clearly quite the difference between males (black) and females (red) here. Males benefit more from age in opening nuts most likely due to their higher strength at maximum body mass. It is also worth pointing out that females have not been observed often or for long in this study as is apparent by the few, small circles in red.\nPractice H2 Question: Now return to the Panda nut model and try to incorporate individual differences. There are two parameters, $ϕ$ and $k$, which plausibly vary by individual. Pick one of these, allow it to vary by individual, and use partial pooling to avoid overfitting. The variable chimpanzee in data(Panda_nuts) tells you which observations belong to which individuals.\nAnswer: This works off of the same model as we just used:\n$$n_i ∼ Poisson(λ_i)$$ $$λ_i = d_iϕ(1 − exp(−kt_i))^θ$$ $$ϕ ∼ LogNormal(log(1), 0.1)$$ $$k ∼ LogNormal(log(2), 0.25)$$ $$θ ∼ LogNormal(log(5), 0.25)$$\nTo incorporate individual effects here, we need to add our data about individuals into our data list:\ndat_list$id \u0026lt;- Panda_nuts$chimpanzee\r To incorporate this ID variable into our model, we want to create a different mass-strength conversion parameter $\\phi$ for each individual. Importantly, the average expected rate of opened nuts ($\\lambda$) has to stay positive for each individual - otherwise, Poisson will fail us. For this reason, we will want to use a distribution for our individual, varying intercepts that is constrained to be positive. Here, I settle on the exponential. Consequently, I envision to alter the model like this:\n$$n_i ∼ Poisson(λ_i)$$ $$λ_i = d_i*(ϕz_{ID}*\\tau)*(1 − exp(−kt_i))^θ$$ $$z_{ID} ~ Exponential(1)$$ $$\\tau ~ Exponential(1)$$ $$ϕ ∼ LogNormal(log(1), 0.1)$$ $$k ∼ LogNormal(log(2), 0.25)$$ $$θ ∼ LogNormal(log(5), 0.25)$$\nGiven our linear model and our constraint for positive values of $z_{ID}$ with a mean of 1, each value of $z_{ID}$ is a multiplicative effect with $\\phi$. Due to the mean of 1, we expect on average no effect of individuals. The data may tell us otherwise.\nThe model below bears two more important oddities:\n It is parametrised in a non-centred form to allow for more effective sampling of the posterior. The gq\u0026gt; part rescales our non-centred estimates of z and tau back to our scale of origin for better interpretation  Let\u0026rsquo;s run this model:\nm_H2 \u0026lt;- ulam(\ralist(\rn ~ poisson(lambda),\rlambda \u0026lt;- seconds * (phi * z[id] * tau) * (1 - exp(-k * age))^theta,\rphi ~ lognormal(log(1), 0.1),\rz[id] ~ exponential(1),\rtau ~ exponential(1),\rk ~ lognormal(log(2), 0.25),\rtheta ~ lognormal(log(5), 0.25),\rgq \u0026gt; vector[id]:zz \u0026lt;\u0026lt;- z * tau # rescaled\r),\rdata = dat_list, chains = 4, cores = 4,\rcontrol = list(adapt_delta = 0.99), iter = 4000\r)\r precis(m_H2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## phi 1.0013518 0.1004075 0.8481803 1.169319 8877.555 0.9998477\r## tau 0.6519607 0.2101021 0.3852493 1.030786 1702.305 1.0006857\r## k 3.0816213 0.7406724 2.0076499 4.342410 3954.259 1.0007966\r## theta 3.1730030 0.6639074 2.2740025 4.341821 5314.860 1.0009539\r tau tells us whether there are individual differences or not and it firmly identifies that there are some. To understand these effects, it is easiest to use our rescaled estimates stored in zz:\nplot(precis(m_H2, 2, pars = \u0026quot;zz\u0026quot;))\rabline(v = 1, lty = 2)\r Above, we see the proportion of $\\phi$ for each individual. Average values are found at 1. Values above 1 indicate stronger-than-average individuals.\nPractice H3 Question: The chapter asserts that a typical, geocentric time series model might be one that uses lag variables. Here you’ll fit such a model and compare it to ODE model in the chapter. An autoregressive time series uses earlier values of the state variables to predict new values of the same variables. These earlier values are called lag variables. You can construct the lag variables here with:\ndata(Lynx_Hare)\rdat_ar1 \u0026lt;- list(\rL = Lynx_Hare$Lynx[2:21],\rL_lag1 = Lynx_Hare$Lynx[1:20],\rH = Lynx_Hare$Hare[2:21],\rH_lag1 = Lynx_Hare$Hare[1:20]\r)\r Now you can use L_lag1 and H_lag1 as predictors of the outcomes L and H. Like this:\n$$L_t ∼ LogNormal(log (µ_{L,t}), σ_L)$$ $$µ_{L,t} = α_L + β_{LL}L_{t−1} + β_{LH}H_{t−1}$$ $$H_t ∼ LogNormal(log(µ_{H,t}), σ_H)$$ $$µ_{H,t} = α_H + β_{HH}H_{t−1} + β_{HL}L_{t−1}$$\nwhere $L_{t−1}$ and $H_{t−1}$ are the lag variables. Use ulam() to fit this model. Be careful of the priors of the $α$ and $β$ parameters. Compare the posterior predictions of the autoregressive model to the ODE model in the chapter. How do the predictions differ? Can you explain why, using the structures of the models?\nAnswer: Let\u0026rsquo;s quickly complete the model above in mathematical notation before we code it:\n$$H_t ∼ LogNormal(log(µ_{H,t}), σ_H)$$ $$L_t ∼ LogNormal(log (µ_{L,t}), σ_L)$$ $$µ_{H,t} = α_H + β_{HH}H_{t−1} + β_{HL}L_{t−1}$$ $$µ_{L,t} = α_L + β_{LL}L_{t−1} + β_{LH}H_{t−1}$$\n$$H_{T\u0026gt;1} = H_1 + \\int_1^TH_t(b_H −m_HL_t)d_t$$ $$L_{T\u0026gt;1} = L_1 + \\int_1^T L_t(b_LH_t −m_L)d_t$$\nNow on to the priors:\n  Mean population size of hares - $\\alpha_H$. I don\u0026rsquo;t have any strong idea about this one except for the fact that it has to be positive:\n$$\\alpha_H ∼ Exponential(1)$$\n  Mean population size of lynx - $\\alpha_L$. Same as above - must be positive:\n  $$\\alpha_L ∼ Exponential(1)$$\nEffect of hares on hares through lag - $\\beta_{HH}$. This one is probably rather positive than negative, but negative values are thinkable:  $$\\beta_{HH} \\sim Normal(1, 0.5)$$\nEffect of lynx on hares - $\\beta_{HL}$. Lynx eat hares, therefore I assume lynx have a negative effect on hare populations:  $$\\beta_{HL} \\sim Normal(-1, 0.5)$$\nEffect of lynx on lynx through lag - $\\beta_{LL}$. This one is probably rather positive than negative, but negative values are thinkable:  $$\\beta_{LL} \\sim Normal(1, 0.5)$$\nEffect of hares on lynx - $\\beta_{HL}$. Lynx eat hares, therefore I assume lynx populations grow when hares are abundant:  $$\\beta_{LH} \\sim Normal(1, 0.5)$$\nLet\u0026rsquo;s put this all into effect in a model:\nm_H3_A \u0026lt;- ulam(\ralist(\rH ~ lognormal(log(muh), sigmah),\rL ~ lognormal(log(mul), sigmal),\rmuh \u0026lt;- ah + b_hh * H_lag1 + b_hl * L_lag1,\rmul \u0026lt;- al + b_ll * L_lag1 + b_lh * H_lag1,\rc(ah, al) ~ normal(0, 1),\rb_hh ~ normal(1, 0.5),\rb_hl ~ normal(-1, 0.5),\rb_ll ~ normal(1, 0.5),\rb_lh ~ normal(1, 0.5),\rc(sigmah, sigmal) ~ exponential(1)\r),\rdata = dat_ar1, chains = 4, cores = 4\r)\r precis(m_H3_A)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## al -0.9086472 0.92283343 -2.3478379 0.58408534 1766.8222 0.9994495\r## ah 0.8030823 1.01577410 -0.7686795 2.39673796 1543.2587 1.0012806\r## b_hh 1.1575260 0.15494168 0.9220842 1.41288452 1165.4372 0.9993601\r## b_hl -0.1898141 0.10424140 -0.3427948 -0.01818273 955.5289 1.0004735\r## b_ll 0.5386323 0.09142832 0.3991584 0.68642887 1275.2896 1.0007976\r## b_lh 0.2555668 0.05003324 0.1773263 0.33463902 1033.0136 1.0021123\r## sigmal 0.3102309 0.06066444 0.2289059 0.42422181 1117.1826 1.0024006\r## sigmah 0.4482276 0.08050156 0.3354154 0.58483481 1407.6199 1.0005659\r Turns out, the data agree with my prior intuition here. The implied time-series looks like this:\npost \u0026lt;- extract.samples(m_H3_A)\rplot(dat_ar1$H, pch = 16, xlab = \u0026quot;Year\u0026quot;, ylab = \u0026quot;pelts (thousands)\u0026quot;, ylim = c(0, 100))\rpoints(dat_ar1$L, pch = 16, col = rangi2)\rmu \u0026lt;- link(m_H3_A)\rfor (s in 1:21) {\rlines(1:20, mu$muh[s, ], col = col.alpha(\u0026quot;black\u0026quot;, 0.2), lwd = 2) # hares\rlines(1:20, mu$mul[s, ], col = col.alpha(rangi2, 0.4), lwd = 2) # lynx\r}\r Lynx are portrayed in blue while hares are shown in black. The model in the chapter clearly does a better job at replicating these time-series, particularly that of lynx. Why is that? For starters, our model fails to appreciate measurement error on reported population sizes. Secondly, the effects are modelled as linear when we know them not to be.\nWhat about a lagged interaction model to resolve the issue of linear effects? Let\u0026rsquo;s try it by modelling as follows:\n$$µ_{H,t} = α_H + β_{HH}H_{t−1} + β_{HL}L_{t−1}H_{t−1}$$ $$µ_{L,t} = α_L + β_{LL}L_{t−1} + β_{LH}H_{t−1}L_{t−1}$$\nm_H3_B \u0026lt;- ulam(\ralist(\rH ~ lognormal(log(muh), sigmah),\rL ~ lognormal(log(mul), sigmal),\rmuh \u0026lt;- ah + b_hh * H_lag1 + b_hl * L_lag1 * H_lag1, # interaction here\rmul \u0026lt;- al + b_ll * L_lag1 + b_lh * H_lag1 * L_lag1, # interaction here\rc(ah, al) ~ normal(0, 1),\rb_hh ~ normal(1, 0.5),\rb_hl ~ normal(-1, 0.5),\rb_ll ~ normal(1, 0.5),\rb_lh ~ normal(1, 0.5),\rc(sigmah, sigmal) ~ exponential(1)\r),\rdata = dat_ar1, chains = 4, cores = 4\r)\r post \u0026lt;- extract.samples(m_H3_B)\rplot(dat_ar1$H, pch = 16, xlab = \u0026quot;Year\u0026quot;, ylab = \u0026quot;pelts (thousands)\u0026quot;, ylim = c(0, 100))\rpoints(dat_ar1$L, pch = 16, col = rangi2)\rmu \u0026lt;- link(m_H3_B)\rfor (s in 1:21) {\rlines(1:20, mu$muh[s, ], col = col.alpha(\u0026quot;black\u0026quot;, 0.2), lwd = 2) # hares\rlines(1:20, mu$mul[s, ], col = col.alpha(rangi2, 0.4), lwd = 2) # lynx\r}\r That\u0026rsquo;s already a lot better, but our lines now overshoot the peaks of lynx populations. I will leave it at that for this exercise although this model is far from perfect. The better model is in the book.\nPractice H4 Question: Adapt the autoregressive model to use a two-step lag variable. This means that $L_{t−2}$ and $H_{t−2}$, in addition to $L_{t−1}$ and $H_{t−1}$, will appear in the equation for $µ$. This implies that prediction depends upon not only what happened just before now, but also on what happened two time steps ago. How does this model perform, compared to the ODE model?\nAnswer: Let\u0026rsquo;s prepare the data:\ndat_ar2 \u0026lt;- list(\rL = Lynx_Hare$Lynx[3:21],\rL_lag1 = Lynx_Hare$Lynx[2:20],\rL_lag2 = Lynx_Hare$Lynx[1:19],\rH = Lynx_Hare$Hare[3:21],\rH_lag1 = Lynx_Hare$Hare[2:20],\rH_lag2 = Lynx_Hare$Hare[1:19]\r)\r Starting off with the basic, linear model we used above:\nm_H4_A \u0026lt;- ulam(\ralist(\rH ~ lognormal(log(muh), sigmah),\rL ~ lognormal(log(mul), sigmal),\rmuh \u0026lt;- ah + phi_hh * H_lag1 + phi_hl * L_lag1 +\rphi2_hh * H_lag2 + phi2_hl * L_lag2,\rmul \u0026lt;- al + phi_ll * L_lag1 + phi_lh * H_lag1 +\rphi2_ll * L_lag2 + phi2_lh * H_lag2,\rc(ah, al) ~ normal(0, 1),\rphi_hh ~ normal(1, 0.5),\rphi_hl ~ normal(-1, 0.5),\rphi_ll ~ normal(1, 0.5),\rphi_lh ~ normal(1, 0.5),\rphi2_hh ~ normal(0, 0.5),\rphi2_hl ~ normal(0, 0.5),\rphi2_ll ~ normal(0, 0.5),\rphi2_lh ~ normal(0, 0.5),\rc(sigmah, sigmal) ~ exponential(1)\r),\rdata = dat_ar2, chains = 4, cores = 4\r)\r precis(m_H4_A)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## al -0.4183636 0.91246723 -1.8486107 1.05960250 1606.2951 0.9992228\r## ah 0.3719553 0.99475941 -1.1590825 1.95140989 1990.4075 1.0009188\r## phi_hh 1.0099326 0.19248834 0.7119274 1.32914392 1045.2694 1.0034079\r## phi_hl -0.7399365 0.32827054 -1.2783735 -0.20488913 877.9196 1.0017976\r## phi_ll 0.9271154 0.24347415 0.5527803 1.31868956 939.7483 1.0037273\r## phi_lh 0.3897833 0.13124341 0.1862378 0.60413394 950.0423 1.0039032\r## phi2_hh 0.1847126 0.27004715 -0.2318049 0.62006465 917.6192 1.0019516\r## phi2_hl 0.3975250 0.15804542 0.1439605 0.64872790 998.1928 1.0016893\r## phi2_ll -0.1939459 0.10830081 -0.3702380 -0.02048142 1180.9072 1.0017758\r## phi2_lh -0.2402054 0.20086962 -0.5597479 0.06914398 876.4958 1.0041831\r## sigmal 0.3020739 0.06006007 0.2193412 0.40635405 1238.3004 0.9997003\r## sigmah 0.3949292 0.07801180 0.2906307 0.53267445 1440.4280 1.0019419\r All of these make sense still. As does the implied time-series:\nplot(dat_ar2$H, pch = 16, xlab = \u0026quot;Year\u0026quot;, ylab = \u0026quot;pelts (thousands)\u0026quot;, ylim = c(0, 100))\rpoints(dat_ar2$L, pch = 16, col = rangi2)\rmu \u0026lt;- link(m_H4_A)\rfor (s in 1:21) {\rlines(1:19, mu$muh[s, ], col = col.alpha(\u0026quot;black\u0026quot;, 0.2), lwd = 2)\rlines(1:19, mu$mul[s, ], col = col.alpha(rangi2, 0.4), lwd = 2)\r}\r This time-series hasn\u0026rsquo;t benefited much from including the second-order time-lag.\nLet\u0026rsquo;s try the interaction effect model with two lags:\nm_H4_B \u0026lt;- ulam(\ralist(\rH ~ lognormal(log(muh), sigmah),\rL ~ lognormal(log(mul), sigmal),\rmuh \u0026lt;- ah + phi_hh * H_lag1 + phi_hl * L_lag1 * H_lag1 +\rphi2_hh * H_lag2 + phi2_hl * L_lag2 * H_lag2,\rmul \u0026lt;- al + phi_ll * L_lag1 + phi_lh * H_lag1 * L_lag1 +\rphi2_ll * L_lag2 + phi2_lh * H_lag2 * L_lag2,\rc(ah, al) ~ normal(0, 1),\rphi_hh ~ normal(1, 0.5),\rphi_hl ~ normal(-1, 0.5),\rphi_ll ~ normal(1, 0.5),\rphi_lh ~ normal(1, 0.5),\rphi2_hh ~ normal(0, 0.5),\rphi2_hl ~ normal(0, 0.5),\rphi2_ll ~ normal(0, 0.5),\rphi2_lh ~ normal(0, 0.5),\rc(sigmah, sigmal) ~ exponential(1)\r),\rdata = dat_ar2, chains = 4, cores = 4\r)\r plot(dat_ar2$H, pch = 16, xlab = \u0026quot;Year\u0026quot;, ylab = \u0026quot;pelts (thousands)\u0026quot;, ylim = c(0, 100))\rpoints(dat_ar2$L, pch = 16, col = rangi2)\rmu \u0026lt;- link(m_H4_B)\rfor (s in 1:21) {\rlines(1:19, mu$muh[s, ], col = col.alpha(\u0026quot;black\u0026quot;, 0.2), lwd = 2)\rlines(1:19, mu$mul[s, ], col = col.alpha(rangi2, 0.4), lwd = 2)\r}\r This time-series also didn\u0026rsquo;t gain anything from adding second-order lag effects, I\u0026rsquo;m afraid.\nI reckon this exercise was designed to highlight that higher-order lag effects don\u0026rsquo;t have any causal meaning.\nPractice H5 Question: Population dynamic models are typically very difficult to fit to empirical data. The Lynx-hare example in the chapter was easy, partly because the data are unusually simple and partly because the chapter did the difficult prior selection for you. Here’s another data set that will impress upon you both how hard the task can be and how badly Lotka-Volterra fits empirical data in general. The data in data(Mites) are numbers of predator and prey mites living on fruit. Model these data using the same Lotka-Volterra ODE system from the chapter. These data are actual counts of individuals, not just their pelts. You will need to adapt the Stan code in data(Lynx_Hare_model). Note that the priors will need to be rescaled, because the outcome variables are on a different scale. Prior predictive simulation will help. Keep in mind as well that the time variable and the birth and death parameters go together. If you rescale the time dimension, that implies you must also rescale the parameters.\nAnswer: We have not worked with this data set before and so bet practise would have us load and plot it:\ndata(Mites)\rplot(Mites$day, Mites$prey)\rpoints(Mites$day, Mites$predator, pch = 16)\r Open circles show prey. Closed circles show predators. One could definitely argue that there are cycles here.\nLuckily, so the solutions by McElreath tell me, there is no measurement error here. Thank the heavens!\nFor prior predictive checks of our upcoming model and its priors we will want to repurpose the simulation function from the chapter that I used above:\nsim_mites \u0026lt;- function(n_steps, init, theta, dt = 0.002) {\rL \u0026lt;- rep(NA, n_steps)\rH \u0026lt;- rep(NA, n_steps)\rL[1] \u0026lt;- init[1]\rH[1] \u0026lt;- init[2]\rfor (i in 2:n_steps) {\rL[i] \u0026lt;- L[i - 1] + dt * L[i - 1] * (theta[3] * H[i - 1] - theta[4])\rH[i] \u0026lt;- H[i - 1] + dt * H[i - 1] * (theta[1] - theta[2] * L[i - 1])\r}\rreturn(cbind(L, H))\r}\r Now we need to define some priors for: (1) prey birth rate theta[1], (2) prey mortality rate theta[2], (3) predator mortality rate theta[3], and (4) predator birth rate theta[4]. Unfortunately, I lack a good understanding of mites and their prey to build intuitive priors.\nPlaying around with the code below will lead you to identifying some priors that look right (the code below just report what we settle on for this exercise):\nset.seed(41)\r## Priors\rN \u0026lt;- 16\rtheta \u0026lt;- matrix(NA, N, 4)\rtheta[, 1] \u0026lt;- rnorm(N, 1.5, 1) # prey birth rate\rtheta[, 2] \u0026lt;- rnorm(N, 0.005, 0.1) # prey mortality rate\rtheta[, 3] \u0026lt;- rnorm(N, 0.0005, 0.1) # predator mortality rate\rtheta[, 4] \u0026lt;- rnorm(N, 0.5, 1) # predator birth rate\r## Simulate for first prior\rplot_df \u0026lt;- sim_mites(1e4, as.numeric(Mites[1, 3:2]), theta[1, ])\rplot_df \u0026lt;- data.frame(plot_df)\rplot_df$prior \u0026lt;- rep(1, 1e4)\r## simulate for all other priors\rfor (i in 2:N) {\rz \u0026lt;- sim_mites(1e4, as.numeric(Mites[1, 3:2]), theta[i, ])\rz \u0026lt;- data.frame(z)\rz$prior \u0026lt;- rep(i, 1e4)\rplot_df \u0026lt;- rbind(plot_df, z)\r}\rplot_df$seq \u0026lt;- rep(1:1e4, N)\r## Plotting\rggplot(plot_df, aes(x = seq)) +\rgeom_line(aes(y = L), col = \u0026quot;brown\u0026quot;) +\rgeom_line(aes(y = H), col = \u0026quot;blue\u0026quot;) +\rfacet_wrap(~prior, scales = \u0026quot;free\u0026quot;) +\rtheme_bw() +\rlabs(x = \u0026quot;Time\u0026quot;, y = \u0026quot;Population\u0026quot;) +\rtheme(axis.text.y = element_blank())\r These are decent enough, some show nice cycles for a few.\nLet\u0026rsquo;s run with these anyways and take them forward to a model. The model below is just a broken-back version of the STAN model in the chapter:\nMites_STAN \u0026lt;- \u0026quot;// Mites model, L is the predator, H is the prey\rfunctions{\rreal[] dpop_dt(real t, // time\rreal[] pop_init, // initial state{lynx, hares}\rreal[] theta, // parameters\rreal[] x_r, int[] x_i){ // unused\rreal L = pop_init[1]; // prey population initialisation\rreal H = pop_init[2]; // predator population initialisation\rreal bh = theta[1]; // prey birth rate\rreal mh = theta[2]; // prey mortality\rreal ml = theta[3]; // predator mortality\rreal bl = theta[4]; // predator birth rate\r// differential equations\rreal dH_dt = (bh - mh * L) * H;\rreal dL_dt = (bl * H - ml) * L;\rreturn{ dL_dt, dH_dt };\r}\r}\rdata{\rint\u0026lt;lower=0\u0026gt; N; // number of measurement times\rint\u0026lt;lower=0\u0026gt; mites[N,2]; // measured populations\rreal\u0026lt;lower=0\u0026gt; days[N]; // days from start of experiment\r}\rparameters{\rreal\u0026lt;lower=0\u0026gt; theta[4]; //{ bh, mh, ml, bl }\rreal\u0026lt;lower=0\u0026gt; pop_init[2]; // initial population state\rreal\u0026lt;lower=0\u0026gt; sigma[2]; // measurement errors\r}\rtransformed parameters{\rreal pop[N, 2];\rpop[1,1] = pop_init[1]; // prey population initialisation\rpop[1,2] = pop_init[2]; // predator population initialisation\rpop[2:N,1:2] = integrate_ode_rk45(\rdpop_dt, pop_init, 0, days[2:N], theta,\rrep_array(0.0, 0), rep_array(0, 0), 1e-5, 1e-3, 5e2);\r}\rmodel{\r// priors\rtheta[1] ~ normal(1.5, 1); // prey birth rate\rtheta[2] ~ normal(0.005, 0.1); // prey mortality\rtheta[3] ~ normal(0.0005, 0.1); // predator mortality\rtheta[4] ~ normal(0.5, 1); // predator birth rate\rsigma ~ exponential(1);\rpop_init[1] ~ normal(mites[1,1], 50);\rpop_init[2] ~ normal(mites[1,2], 50);\r// observation model\r// connect latent population state to observed pelts\rfor (t in 1:N)\rfor (k in 1:2)\rmites[t,k] ~ lognormal(log(pop[t,k]), sigma[k]);\r}\rgenerated quantities{\rreal mites_pred[N,2];\rfor (t in 1:N)\rfor (k in 1:2)\rmites_pred[t,k] = lognormal_rng(log(pop[t,k]), sigma[k]);\r}\u0026quot;\r Preparing the data and running the model is quite straight-forward now:\ndat_mites \u0026lt;- list(\rN = nrow(Mites),\rmites = as.matrix(Mites[, 3:2]),\rdays = Mites[, 1] / 7\r)\rm_H5 \u0026lt;- stan(\rmodel_code = Mites_STAN, data = dat_mites, chains = 4, cores = 4, iter = 2000,\rcontrol = list(adapt_delta = 0.99)\r)\r precis(m_H5, 2)\r ## mean sd 5.5% 94.5% n_eff Rhat4\r## theta[1] 1.288983e+00 3.126271e-01 9.175982e-01 1.852993e+00 984.656 1.0012770\r## theta[2] 6.533764e-03 2.216549e-03 3.977740e-03 1.067107e-02 1095.219 1.0010345\r## theta[3] 3.250613e-01 7.149778e-02 2.071048e-01 4.392285e-01 1218.141 1.0008058\r## theta[4] 4.802551e-04 1.592542e-04 2.589479e-04 7.581328e-04 1473.000 1.0011075\r## pop_init[1] 1.164473e+02 1.961122e+01 8.879640e+01 1.502520e+02 1822.214 1.0000536\r## pop_init[2] 2.481791e+02 3.982614e+01 1.866272e+02 3.136870e+02 2611.777 0.9994916\r## sigma[1] 7.293284e-01 1.209180e-01 5.645224e-01 9.408383e-01 1600.917 1.0004918\r## sigma[2] 1.071276e+00 1.464701e-01 8.665494e-01 1.327090e+00 2048.149 1.0016011\r Without trying to interpret the parameters here, let\u0026rsquo;s just jump straight into the posterior predictions:\npost \u0026lt;- extract.samples(m_H5)\rmites \u0026lt;- dat_mites$mites\rplot(dat_mites$days, mites[, 2],\rpch = 16, ylim = c(0, 3000),\rxlab = \u0026quot;time (week)\u0026quot;, ylab = \u0026quot;mites\u0026quot;\r)\rpoints(dat_mites$days, mites[, 1], col = rangi2, pch = 16)\rfor (s in 1:21) {\rlines(dat_mites$days, post$pop[s, , 2], col = col.alpha(\u0026quot;black\u0026quot;, 0.2), lwd = 2)\rlines(dat_mites$days, post$pop[s, , 1], col = col.alpha(rangi2, 0.3), lwd = 2)\r}\r Yet again, our model struggles to reconstruct the underlying time-series. This is certainly what McElreath referred to in the chapter when he said we would come face-to-face with the limitations of Lotka-Volterra models in the exercises. Why does the model do so baldy then? Well, it assumes equal cycle times which the data does not support. In addition our model is purely deterministic and lacks stochasticity which could help fit closer to the underlying cycles.\nI would have loved to end this series of blogposts on a more upbeat note, I must say. If you have found any use out of this series of posts and/or my summary slides linked at the top of these, then I am very happy. I must say I personally enjoyed working through this book a lot and hope my posts will come in handy for others looking to validate their solutions. Take care!\nSession Info sessionInfo()\r ## R version 4.0.5 (2021-03-31)\r## Platform: x86_64-w64-mingw32/x64 (64-bit)\r## Running under: Windows 10 x64 (build 19043)\r## ## Matrix products: default\r## ## locale:\r## [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C ## [5] LC_TIME=English_United Kingdom.1252 ## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] rethinking_2.13 rstan_2.21.2 ggplot2_3.3.6 StanHeaders_2.21.0-7\r## ## loaded via a namespace (and not attached):\r## [1] Rcpp_1.0.7 mvtnorm_1.1-1 lattice_0.20-41 prettyunits_1.1.1 ps_1.6.0 assertthat_0.2.1 digest_0.6.27 utf8_1.2.1 V8_3.4.1 R6_2.5.0 ## [11] backports_1.2.1 stats4_4.0.5 evaluate_0.14 coda_0.19-4 highr_0.9 blogdown_1.3 pillar_1.6.0 rlang_0.4.11 curl_4.3.2 callr_3.7.0 ## [21] jquerylib_0.1.4 R.utils_2.10.1 R.oo_1.24.0 rmarkdown_2.7 styler_1.4.1 labeling_0.4.2 stringr_1.4.0 loo_2.4.1 munsell_0.5.0 compiler_4.0.5 ## [31] xfun_0.22 pkgconfig_2.0.3 pkgbuild_1.2.0 shape_1.4.5 htmltools_0.5.1.1 tidyselect_1.1.0 tibble_3.1.1 gridExtra_2.3 bookdown_0.22 codetools_0.2-18 ## [41] matrixStats_0.61.0 fansi_0.4.2 crayon_1.4.1 dplyr_1.0.5 withr_2.4.2 MASS_7.3-53.1 R.methodsS3_1.8.1 grid_4.0.5 jsonlite_1.7.2 gtable_0.3.0 ## [51] lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 scales_1.1.1 RcppParallel_5.1.2 cli_3.0.0 stringi_1.5.3 farver_2.1.0 bslib_0.2.4 ellipsis_0.3.2 ## [61] generics_0.1.0 vctrs_0.3.7 rematch2_2.1.2 tools_4.0.5 R.cache_0.14.0 glue_1.4.2 purrr_0.3.4 processx_3.5.1 yaml_2.2.1 inline_0.3.17 ## [71] colorspace_2.0-0 knitr_1.33 sass_0.3.1\r ","date":1620864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620925200,"objectID":"72f9601f5385ea7310f9c82f71ee33d4","permalink":"https://www.erikkusch.com/courses/rethinking/chapter-16/","publishdate":"2021-05-13T00:00:00Z","relpermalink":"/courses/rethinking/chapter-16/","section":"courses","summary":"Answers and solutions to the exercises belonging to chapter 16 in [Satistical Rethinking 2](https://xcelab.net/rm/statistical-rethinking/) by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics","AU Bayes Study Group"],"title":"Chapter 16","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"\rKrigR is currently undergoing development. As a result, this part of the workshop has become deprecated. Please refer to the setup quick guide portions of this material as these are up-to-date. \r\r\r\rThis part of the workshop is dependant on set-up and preparation done previously here.\r\r\rFor bioclimatic variable calculation, this workshop makes use of the SpatialPolygons spatial preferences which we set up here.\nFirst, we load KrigR:\nlibrary(KrigR)\r \rTo obtain bioclimatic data with KrigR we want to use the BioClim() function.\r\r\rIn the next sections, I will show you how to use it and how the resulting data objects may differ and why.\n\rBioclimatic variables are often treated as very robust metrics - I do not believe so and hope the following will demonstrate the nuance in bioclimatic metrics.\r\r\rOur First Bioclimatic Data Set Let\u0026rsquo;s start with the most basic of bioclimatic data products. So what are the specifications? Well, we:\n Query data for the period between 2010 (Y_start) and 2020 (Y_end, including 2020). Obtain data from the era5-land (DataSet) catalogue of data. Approximate water availability through precipitation (Water_Var) in keeping with typical practices. Extreme metrics for temperature minimum and maximum are calculated from daily (T_res) aggregates of the underlying hourly temperature data.  \rYou will see function call to BioClim() wrapped in if statements which check for whether the output is already present or not. BioClim compilation can take significant time and I do this here to avoid recompilation on changes to the text of the blogpost on my end.\r\r\r\rSetting the argument  Keep_Monthly = TRUE will prompt the function to retain monthly aggregates of temperature and water availability alongside the final output. When BioClim() recognises that any of the underlying data is already present, it will skip the steps necessary to create this data.\r\r\r\rClick here for file if download \u0026 processing takes too long:\rDownload Present_BC.nc and place it into your data directory.\r if(!file.exists(file.path(Dir.Data, \u0026quot;Present_BC.nc\u0026quot;))){\rBC2010_ras \u0026lt;- BioClim(\rWater_Var = \u0026quot;total_precipitation\u0026quot;,\rY_start = 2010,\rY_end = 2020,\rDataSet = \u0026quot;era5-land\u0026quot;,\rT_res = \u0026quot;day\u0026quot;,\rExtent = Shape_shp,\rDir = Dir.Data,\rKeep_Monthly = FALSE,\rFileName = \u0026quot;Present_BC\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key,\rCores = numberOfCores,\rTimeOut = 60^2*48,\rSingularDL = TRUE,\rverbose = TRUE,\rKeep_Raw = FALSE,\rTryDown = 5\r)\r}else{\rBC2010_ras \u0026lt;- stack(file.path(Dir.Data, \u0026quot;Present_BC.nc\u0026quot;))\r}\r Now let\u0026rsquo;s plot our results. Note that temperature is recorded in Kelvin and precipitation in cubic metres (i.e. litres). To do so, we use one of our user-defined plotting functions:\nPlot_BC(BC2010_ras, Shp = Shape_shp)\r There\u0026rsquo;s not much commenting on the output above as the output should look familiar to most macroecologists.\nTime-Frames \rTime window of baseline climate data (e.g; climatology time frames) ought to be adjusted to the specific needs of each study. This is true also for bioclimatic data. Pre-made data sets do not deliver on this need!\r\r\r\rWith KrigR, you can build the bioclimatic data sets you need for your study.\r\r\rLet\u0026rsquo;s move on to the first important functionality of the KrigR::BioClim() function: selection of time-frames. With this, you can obtain bioclimatic data for exactly the duration that your study requires. Here, we query data for the period between 1951 and 1960:\n\rClick here for file if download \u0026 processing takes too long:\rDownload Past_BC.nc and place it into your data directory.\r if(!file.exists(file.path(Dir.Data, \u0026quot;Past_BC.nc\u0026quot;))){\rBC1951_ras \u0026lt;- BioClim(\rWater_Var = \u0026quot;total_precipitation\u0026quot;,\rY_start = 1951,\rY_end = 1960,\rDataSet = \u0026quot;era5-land\u0026quot;,\rT_res = \u0026quot;day\u0026quot;,\rExtent = Shape_shp,\rDir = Dir.Data,\rKeep_Monthly = FALSE,\rFileName = \u0026quot;Past_BC\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key,\rCores = numberOfCores,\rTimeOut = 60^2*48,\rSingularDL = TRUE,\rverbose = TRUE\r)\r}else{\rBC1951_ras \u0026lt;- stack(file.path(Dir.Data, \u0026quot;Past_BC.nc\u0026quot;))\r}\r I will forego plotting the data itself and instead plot the difference between our bioclimatic data of the present which we created prior and the newly created bioclimatic product of the past. Let me walk you through them 1 by 1.\n\rThe below plots show the differences in bioclimatic data products of the 2010-2020 and 1951-1960.\r\r\rAnnual Temperature As you can see below, the time period of 2010 to 2020 was about 1.5-1.9 Kelvin warmer than the period of 1951 to 1960:\nPlot_BC(BC2010_ras-BC1951_ras, Shp = Shape_shp, which = 1)\r Temperatures Let\u0026rsquo;s bundle the differences for all remaining temperature-related bioclimatic variables:\nPlot_BC(BC2010_ras-BC1951_ras, Shp = Shape_shp, which = 2:11)\r Again, you should easily identify just how much the data changes when setting different calculation time frames for bioclimatic variables.\nWater Availability Now for the water-related bioclimatic variables:\nPlot_BC(BC2010_ras-BC1951_ras, Shp = Shape_shp, which = 12:19)\r Clearly, my home area turned much drier with more pronounced seasonality and extreme precipitation events.\nI hope that the above has clearly demonstrated on thing:\n\rAppropriate use of bioclimatic variables is largely dependant on data retrieval for relevant time frames.\r\r\rWater-Availability Variables \rPrecipitation might not be the most useful or appropriate water availability metric for your study region or requirements.\r\r\r\rWith KrigR, you can decide which water availability variable from the ERA5(-Land) catalogue to use for calculation of bioclimatic data sets.\r\r\rContrary to current practices in macroecology, I have gripes with the use of precipitation data in bioclimatic variable computation. Why is that? I strongly believe that other water availability variables are much better suited for our analyses for two reasons:\n Bioclimatic products are usually derived from observation-based climate products (such as WorldClim) which do not do a terrific job at accurately representing precipitation to begin with. Further downscaling of bioclimatic products containing precipitation information is terribly difficult.  Both issues are related to one central problem: Statistical interpolation of precipitation data is difficult and usually done insufficiently.\nLuckily, with ERA5(-Land), we aren\u0026rsquo;t tied to precipitation and can instead use other water availability metrics such as volumetric soil water content - also known as soil moisture. What\u0026rsquo;s more, this data is available in four distinct depth layers which can be linked to root depth and growth forms.\nHere, I demonstrate the use of the shallowest layer of soil moisture data. As you can see, we are using the same specification as for our basic bioclimatic product with the exception for the Water_Var argument:\n\rClick here for file if download \u0026 processing takes too long:\rDownload Qsoil_BC.nc and place it into your data directory.\r if(file.exists(file.path(Dir.Data, \u0026quot;Qsoil_BC.nc\u0026quot;))){\rBCq_ras \u0026lt;- stack(file.path(Dir.Data, \u0026quot;Qsoil_BC.nc\u0026quot;))\r}else{\rBCq_ras \u0026lt;- BioClim(\rWater_Var = \u0026quot;volumetric_soil_water_layer_1\u0026quot;,\rY_start = 2010,\rY_end = 2020,\rExtent = Shape_shp,\rDir = Dir.Data,\rKeep_Monthly = FALSE,\rFileName = \u0026quot;Qsoil_BC\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key,\rCores = numberOfCores,\rTimeOut = Inf,\rSingularDL = TRUE\r)\r}\r That\u0026rsquo;s how easy it is to obtain different bioclimatic products with KrigR. Let\u0026rsquo;s plot this:\nPlot_BC(BCq_ras, Shp = Shape_shp, Water_Var = \u0026quot;Soil Moisture\u0026quot;)\r Again, I would like to investigate the changes in how we understand the climatic regimes across our study area now that we are using soil moisture for our water availability as compared to when we used precipitation data.\nTemperatures As is hardly surprising, there are no differences in annual temperature data or any other temperature variable except for BIO8 and BIO9. Since we change by what we quantify dryness and wetness, there is tremendous potential in quantifying temperature of driest and wettest quarter differently:\nPlot_BC(BC2010_ras-BCq_ras, Shp = Shape_shp, which = 8:9)\r \rChanging water availability metric in bioclimatic considerations can drastically change even temperature metrics.\r\r\r\rVolumetric soil moisture exhibits more pronounced spatial patterns than precipitation records do thus supplying bioclimatic modelling exercises with more pronounced information.\r\r\rWater Availability Now for the water-related bioclimatic variables. This is where the rubber meets the road! Aside from the quantitative differences in water availability estimates when using soil moisture over precipitation records, please take note of the much more pronounced spatial patterns (particularly along the river throughout Saxony-Anhalt in the north-western region of our study area) when using soil moisture data. This is much more likely to accurately represent bioclimatic envelopes than the smooth patterns you can see for precipitation records.\nPlot_BC(BC2010_ras-BCq_ras, Shp = Shape_shp, which = 12:19)\r I hope that the above has clearly demonstrated on thing:\n\rChoice of water availability variable has strong implications for how we quantify bioclimatic envelopes.\r\r\rExtreme Value Calculations Lastly, let us concern ourselves with the retrieval of extreme climate metrics which will affect almost all of our temperature-reliant bioclimatic variables.\n\rExtreme event calculation is highly relevant for our understanding of bioclimatic envelopes and often turns into a blackbox exercise.\r\r\r\rWith KrigR, you can decide how to calculate extreme metrics.\r\r\rSo far, we have calculated monthly minimum and maximum temperatures from daily aggregates. However, with KrigR::BioClim() we can also obtain these extremes from hourly records simply by changing T_res:\n\rClick here for file if download \u0026 processing takes too long:\rDownload Hourly_BC.nc and place it into your data directory.\r if(file.exists(file.path(Dir.Data, \u0026quot;Hourly_BC.nc\u0026quot;))){\rBCh_ras \u0026lt;- stack(file.path(Dir.Data, \u0026quot;Hourly_BC.nc\u0026quot;))\r}else{\rBCh_ras \u0026lt;- BioClim(\rWater_Var = \u0026quot;volumetric_soil_water_layer_1\u0026quot;,\rY_start = 2010,\rY_end = 2020,\rT_res = \u0026quot;hour\u0026quot;,\rExtent = Shape_shp,\rDir = Dir.Data,\rKeep_Monthly = FALSE,\rFileName = \u0026quot;Hourly_BC\u0026quot;,\rAPI_User = API_User,\rAPI_Key = API_Key,\rCores = numberOfCores,\rTimeOut = Inf,\rSingularDL = TRUE\r)\r}\r Once again, let me plot the outcome of this.\nAnnual Temperature The differences in annual temperature are negligible and only arise through slight deviations in hourly aggregates to monthly aggregates and daily aggregates.\n Click here for the plot \rPlot_BC(BCq_ras - BCh_ras, Shp = Shape_shp, Water_Var = \u0026quot;Soil Moisture\u0026quot;, which = 1)\r \rTemperatures Let\u0026rsquo;s bundle the differences for all remaining temperature-related bioclimatic variables.\nYou will immediately see that all metrics reliant of mean values such as BIO4 and BIO8-BIO11 remain almost completely unaltered when using hourly aggregates. The stark differences manifest in all temperature-extreme variables:\nPlot_BC(BCq_ras - BCh_ras, Shp = Shape_shp, Water_Var = \u0026quot;Soil Moisture\u0026quot;, which = 2:11)\r \rExtraction of extremes at an hourly resolution amplifies said extremes.\r\r\rWater Availability Unsurprisingly, there are no changes to our quantification of water availability metrics. You may plot this for yourself if you are interested.\nI hope that the above has clearly demonstrated on thing:\n\rChoice of temporal resolution of extreme metrics changes how we quantify bioclimatic envelopes drastically.\r\r\rKriging Bioclimatic Products You might be unhappy with the spatial resolution of the bioclimatic data products generated through KrigR::BioClim(). You can remedy this through statistical interpolation which is conveniently built into KrigR.\nWhen you do so, you do it at your own risk as I can not guarantee that the results will always be sensible. Investigate them before using them. It would be wiser to downscale the underlying data rather than the finished product, but I don\u0026rsquo;t feel like spending days on end kriging the underlying data so instead I show you how kriging can be performed, but I do so for the entire product.\nSince I mentioned earlier that statistical interpolation of precipitation data is fraught with errors, I am demonstrating how to downscale the soil moisture product (BCq_ras). We have demonstrated capability of downscaling soil moisture data reliably using Kriging in this this publication (Figure 3).\nTemperatures Here, we follow the same basic kriging steps as demonstrated previously in this workshop material.\nFirst, we create our DEM covariate rasters:\nCovs_ls \u0026lt;- download_DEM(Train_ras = BCq_ras,\rTarget_res = .02,\rShape = Shape_shp,\rDir = Dir.Covariates,\rKeep_Temporary = TRUE)\r Next, we carry out the interpolation. A few things of note here: (1) I only hand the first 11 layers to the kriging call because those are the temperature data, (2) I leave out the Cores argument, so that krigR() determines how many cores your machine has and uses all of them to speed up the computation of the multi-layer raster, and (3) I set nmax to 80 to approximate a typical weather system in size:\nBC_Temperature_Krig \u0026lt;- krigR(Data = BCq_ras[[1:11]],\rCovariates_coarse = Covs_ls[[1]],\rCovariates_fine = Covs_ls[[2]],\rKeep_Temporary = FALSE,\rnmax = 80,\rFileName = \u0026quot;BC_Temperature_Krig\u0026quot;,\rDir = Dir.Exports\r)\r ## Commencing Kriging\r ## | | | 0%\r| |======= | 9%\r| |=============== | 18%\r| |====================== | 27%\r| |============================= | 36%\r| |==================================== | 45%\r| |============================================ | 55%\r| |=================================================== | 64%\r| |========================================================== | 73%\r| |================================================================= | 82%\r| |========================================================================= | 91%\r| |================================================================================| 100%\r ## Warning: [writeCDF] for better results use file extension '.nc' or '.cdf'\r## see: https://stackoverflow.com/a/65398262/635245\r ## Warning: [rast] unknown extent\r ## Warning: [writeCDF] for better results use file extension '.nc' or '.cdf'\r## see: https://stackoverflow.com/a/65398262/635245\r ## Warning: [rast] unknown extent\r Finally, we analyse the outputs of our plotting exercise. I break these up into smaller chunks for easier digestion.\nBIO1 - Annual Mean Temperature \rInterpolating this data is just like statistically downscaling any other temperature product and can be done without any problems.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 1), Shp = Shape_shp,\rDates = \u0026quot;BIO1 - Annual Mean Temperature\u0026quot;\r)\r  BIO2 - Mean Diurnal Range \rThis data product is calculated from extreme values and would be interpolated better by first statistically downscaling the underlying data rather than the final bioclimatic variable.\r\r\r\rClick here for plotting call and plot:\r\rThe smooth patterns in this plot clearly highlight the issue with using krigr() on the final bioclimatic product.\r\r\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 2), Shp = Shape_shp,\rDates = \u0026quot;BIO2 - Mean Diurnal Range\u0026quot;\r)\r \rBIO3 - Isothermality \rThis data product is calculated from BIO2 and BIO7 and thus relies on extreme values. Conclusively, it would be interpolated better by first statistically downscaling the underlying data rather than the final bioclimatic variable.\r\r\r\rClick here for plotting call and plot:\r\rThe smooth patterns in this plot clearly highlight the issue with using krigr() on the final bioclimatic product.\r\r\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 3), Shp = Shape_shp,\rDates = \u0026quot;BIO3 - Isothermality\u0026quot;\r)\r \rBIO4 - Temperature Seasonality \rThis data product is calculated using the standard deviation of mean values throughout our time frame. Conclusively, it would be interpolated better by first statistically downscaling the underlying data rather than the final bioclimatic variable.\r\r\r\rClick here for plotting call and plot:\r\rThe smooth patterns in this plot clearly highlight the issue with using krigr() on the final bioclimatic product.\r\r\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 4), Shp = Shape_shp,\rDates = \u0026quot;BIO4 - Temperature Seasonality\u0026quot;\r)\r \rBIO5 - Max Temperature of Warmest Month \rInterpolating this data is just like statistically downscaling any other temperature product and can be done without any problems.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 5), Shp = Shape_shp,\rDates = c(\u0026quot;BIO5 - Max Temperature of Warmest Month\u0026quot;)\r)\r \rBIO6 - Min Temperature of Coldest Month \rInterpolating this data is just like statistically downscaling any other temperature product and can be done without any problems.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 6), Shp = Shape_shp,\rDates = \u0026quot;BIO6 - Min Temperature of Coldest Month\u0026quot;\r)\r \rBIO7 - Temperature Annual Range (BIO5-BIO6) \rThis data product is calculated from BIO5 and BIO6 and thus relies on extreme values. Conclusively, it would be interpolated better by first statistically downscaling the underlying data rather than the final bioclimatic variable.\r\r\r\rClick here for plotting call and plot:\r\rThe smooth patterns in this plot clearly highlight the issue with using krigr() on the final bioclimatic product.\r\r\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 7), Shp = Shape_shp,\rDates = \u0026quot;BIO7 - Temperature Annual Range (BIO5-BIO6)\u0026quot;\r)\r \r\rSince BIO5 and BIO6 can be interpolated well themselves, one may chose to use the downscaled versions of BIO5 and BIO6 to create a downscaled version of BIO7.\r\r\r\rDoing so, however, raises the question of how to integrate the downscaling uncertainty associated with BIO5 and BIO6 into the product for BIO7. I have submitted a research proposal to assess best practice for issues like these.\r\r\r\rClick here for calculation, plotting call, and plot:\rHere, I visualise the differences between the interpolated BIO7 and the recalculated BIO7 (from interpolated BIO5 and BIO6):\nBIO7 \u0026lt;- lapply(BC_Temperature_Krig[1], \u0026quot;[[\u0026quot;, 5)[[1]] - lapply(BC_Temperature_Krig[1], \u0026quot;[[\u0026quot;, 6)[[1]]\rPlot_Raw(lapply(BC_Temperature_Krig[1], \u0026quot;[[\u0026quot;, 7)[[1]]-BIO7, Shp = Shape_shp,\rDates = \u0026quot;BIO7 - Temperature Annual Range (BIO5-BIO6)\u0026quot;\r)\r To be fair, these differences are rather small when compared to the data range in BIO7.\n\rBIO8 \u0026amp; BIO9 - Temperatures of Wettest and Driest Quarter \rI do not recommend you use these kriging outputs! They rely on water availability data which is not being interpolated here. Subsequently, the patchiness of the underlying data is lost and with it: information.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 8:9), Shp = Shape_shp,\rDates = c(\u0026quot;BIO8 - Mean Temperature of Wettest Quarter\u0026quot;, \u0026quot;BIO9 - Mean Temperature of Driest Quarter\u0026quot;)\r)\r \rBIO10 \u0026amp; BIO11 - Temperatures of Warmest and Coldest Quarter \rI do not recommend you use these kriging outputs! They rely on mean quarterly temperature data which is not being interpolated here. Subsequently, the patchiness of the underlying data is lost and with it: information.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Temperature_Krig[-3], \u0026quot;[[\u0026quot;, 10:11), Shp = Shape_shp,\rDates = c(\u0026quot;BIO10 - Mean Temperature of Warmest Quarter\u0026quot;, \u0026quot;BIO11 - Mean Temperature of Coldest Quarter\u0026quot;)\r)\r \rWater Availability \rStatistical downscaling of non-temperature data usually requires more than just elevation covariates.\r\r\r\rWith KrigR, you can use different sets of covariates. I demonstrate this in the workshop material regarding third-party covariates.\r\r\rSession Info sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] mapview_2.11.0 rnaturalearthdata_0.1.0 rnaturalearth_0.3.2 ## [4] gimms_1.2.1 ggmap_3.0.2 cowplot_1.1.1 ## [7] viridis_0.6.2 viridisLite_0.4.1 ggplot2_3.4.1 ## [10] tidyr_1.3.0 KrigR_0.1.2 terra_1.7-21 ## [13] httr_1.4.5 stars_0.6-0 abind_1.4-5 ## [16] fasterize_1.0.4 sf_1.0-12 lubridate_1.9.2 ## [19] automap_1.1-9 doSNOW_1.0.20 snow_0.4-4 ## [22] doParallel_1.0.17 iterators_1.0.14 foreach_1.5.2 ## [25] rgdal_1.6-5 raster_3.6-20 sp_1.6-0 ## [28] stringr_1.5.0 keyring_1.3.1 ecmwfr_1.5.0 ## [31] ncdf4_1.21 ## ## loaded via a namespace (and not attached):\r## [1] leafem_0.2.0 colorspace_2.1-0 class_7.3-21 ## [4] leaflet_2.1.2 satellite_1.0.4 base64enc_0.1-3 ## [7] rstudioapi_0.14 proxy_0.4-27 farver_2.1.1 ## [10] fansi_1.0.4 codetools_0.2-19 cachem_1.0.7 ## [13] knitr_1.42 jsonlite_1.8.4 png_0.1-8 ## [16] Kendall_2.2.1 compiler_4.2.3 assertthat_0.2.1 ## [19] fastmap_1.1.1 cli_3.6.0 htmltools_0.5.4 ## [22] tools_4.2.3 gtable_0.3.1 glue_1.6.2 ## [25] dplyr_1.1.0 Rcpp_1.0.10 jquerylib_0.1.4 ## [28] vctrs_0.6.1 blogdown_1.16 crosstalk_1.2.0 ## [31] lwgeom_0.2-11 xfun_0.37 timechange_0.2.0 ## [34] lifecycle_1.0.3 rnaturalearthhires_0.2.1 zoo_1.8-11 ## [37] scales_1.2.1 gstat_2.1-0 yaml_2.3.7 ## [40] curl_5.0.0 memoise_2.0.1 gridExtra_2.3 ## [43] sass_0.4.5 reshape_0.8.9 stringi_1.7.12 ## [46] highr_0.10 e1071_1.7-13 boot_1.3-28.1 ## [49] intervals_0.15.3 RgoogleMaps_1.4.5.3 rlang_1.1.0 ## [52] pkgconfig_2.0.3 bitops_1.0-7 evaluate_0.20 ## [55] lattice_0.20-45 purrr_1.0.1 htmlwidgets_1.6.1 ## [58] labeling_0.4.2 tidyselect_1.2.0 plyr_1.8.8 ## [61] magrittr_2.0.3 bookdown_0.33 R6_2.5.1 ## [64] generics_0.1.3 DBI_1.1.3 pillar_1.8.1 ## [67] withr_2.5.0 units_0.8-1 xts_0.13.0 ## [70] tibble_3.2.1 spacetime_1.2-8 KernSmooth_2.23-20 ## [73] utf8_1.2.3 rmarkdown_2.20 jpeg_0.1-10 ## [76] grid_4.2.3 zyp_0.11-1 FNN_1.1.3.2 ## [79] digest_0.6.31 classInt_0.4-9 webshot_0.5.4 ## [82] stats4_4.2.3 munsell_0.5.0 bslib_0.4.2\r ","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"a541dc54df6becc2c0b14f5f8b1959d2","permalink":"https://www.erikkusch.com/courses/krigr/bioclim/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/bioclim/","section":"courses","summary":"Using KrigR to obtain bioclimatic variables.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Bioclimatic Variables","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"\rKrigR is currently undergoing development. As a result, this part of the workshop has become deprecated. Please refer to the setup quick guide portions of this material as these are up-to-date. \r\r\r\rThis part of the workshop is dependant on set-up and preparation done previously here.\r\r\rFirst, we load KrigR:\nlibrary(KrigR)\r Matching Third-Party Data I expect that you won\u0026rsquo;t want to downscale to specific resolutions most of the time, but rather, match an already existing spatial data set in terms of spatial resolution and extent. Again, the KrigR package got you covered!\n\rUsually, you probably want to downscale data to match a certain pre-existing data set rather than a certain resolution.\r\r\rHere, we illustrate this with an NDVI-based example. The NDVI is a satellite-derived vegetation index which tells us how green the Earth is. It comes in bi-weekly intervals and at a spatial resolution of .08333 (roughly 9km). Here, we download all NDVI data for the year 2015 and then create the annual mean. This time, we do so for all of Germany because of its size and topographical variety.\nThird-Party Data Shape_shp \u0026lt;- ne_countries(country = \u0026quot;Germany\u0026quot;)\r ## downloading gimms data\rgimms_files \u0026lt;- downloadGimms(x = as.Date(\u0026quot;2015-01-01\u0026quot;), # download from January 1982\ry = as.Date(\u0026quot;2015-12-31\u0026quot;), # download to December 1982\rdsn = Dir.Data, # save downloads in data folder\rquiet = FALSE # show download progress\r)\r## prcoessing gimms data\rgimms_raster \u0026lt;- rasterizeGimms(x = gimms_files, # the data we rasterize\rremove_header = TRUE # we don't need the header of the data\r)\rindices \u0026lt;- monthlyIndices(gimms_files) # generate month indices from the data\rgimms_raster_mvc \u0026lt;- monthlyComposite(gimms_raster, # the data\rindices = indices # the indices\r)\rNegatives \u0026lt;- which(values(gimms_raster_mvc) \u0026lt; 0) # identify all negative values\rvalues(gimms_raster_mvc)[Negatives] \u0026lt;- 0 # set threshold for barren land (NDVI\u0026lt;0)\rgimms_raster_mvc \u0026lt;- crop(gimms_raster_mvc, extent(Shape_shp)) # crop to extent\rgimms_mask \u0026lt;- KrigR::mask_Shape(gimms_raster_mvc[[1]], Shape = Shape_shp) # create mask ith KrigR-internal function to ensure all edge cells are contained\rNDVI_ras \u0026lt;- mask(gimms_raster_mvc, gimms_mask) # mask out shape\rNDVI_ras \u0026lt;- calc(NDVI_ras, fun = mean, na.rm = TRUE) # annual mean\rwriteRaster(NDVI_ras, format = \u0026quot;CDF\u0026quot;, file = file.path(Dir.Data, \u0026quot;NDVI\u0026quot;)) # save file\r So what does this raster look like?\nNDVI_ras\r ## class : RasterStack ## dimensions : 92, 108, 9936, 1 (nrow, ncol, ncell, nlayers)\r## resolution : 0.08333333, 0.08333333 (x, y)\r## extent : 6, 15, 47.33333, 55 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## names : layer ## min values : 0.2430333 ## max values : 0.8339083\r And a visualisation of the same:\nPlot_Raw(NDVI_ras, Shp = Shape_shp,\rDates = \u0026quot;Mean NDVI 2015\u0026quot;, COL = viridis(100, begin = 0.5, direction = -1))\r As stated above, we want to match this with our output.\nKrigR Workflow We could do this whole analysis in our three steps as outlined above, but why bother when the pipeline gets the job done just as well?\n\rMatching Kriging outputs with a pre-existing data set is as easy as plugging the pre-existing raster into the Target_res argument of the krigR() or the download_DEM() function.\r\r\rThis time we want to downscale from ERA5 resolution (roughly 30km) because the ERA5-Land data already matches the NDVI resolution (roughly 9km). Here\u0026rsquo;s how we do this:\nNDVI_Krig \u0026lt;- krigR(\r## download_ERA block\rVariable = '2m_temperature',\rType = 'reanalysis',\rDataSet = 'era5',\rDateStart = '2015-01-01',\rDateStop = '2015-12-31',\rTResolution = 'year',\rTStep = 1,\rExtent = Shape_shp,\rAPI_User = API_User,\rAPI_Key = API_Key,\rSingularDL = TRUE,\r## download_DEM block\rTarget_res = NDVI_ras,\rSource = \u0026quot;Drive\u0026quot;,\r## krigR block\rCores = 1,\rFileName = \u0026quot;AirTemp_NDVI.nc\u0026quot;,\rnmax = 80, Dir = Dir.Exports)\r ## download_ERA() is starting. Depending on your specifications, this can take a significant time.\r ## User 39340 for cds service added successfully in keychain\r ## Staging 1 download(s).\r ## Staging your request as a singular download now. This can take a long time due to size of required product.\r ## 0001_2m_temperature_2015-01-01_2015-12-31_year.nc download queried\r ## Requesting data to the cds service with username 39340\r ## - staging data transfer at url endpoint or request id:\r ## 4d24fc1f-2be1-4b65-b588-be3ba2b5938b\r ## - timeout set to 10.0 hours\r ## - polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r\\ polling server for a data transfer\r| polling server for a data transfer\r/ polling server for a data transfer\r- polling server for a data transfer\r## Downloading file\r ## | | | 0%\r| |================================================================================| 100%\r ## - moved temporary file to -\u0026gt; /Users/erikkus/Documents/HomePage/content/courses/krigr/Exports/0001_2m_temperature_2015-01-01_2015-12-31_year.nc\r## - Delete data from queue for url endpoint or request id:\r## https://cds.climate.copernicus.eu/api/v2/tasks/4d24fc1f-2be1-4b65-b588-be3ba2b5938b\r## ## Checking for known data issues.\r## Loading downloaded data for masking and aggregation.\r## Masking according to shape/buffer polygon\r## Aggregating to temporal resolution of choice\r ## | | | 0%\r| |=========================== | 33%\r| |===================================================== | 67%\r| |================================================================================| 100%\r##  ## Commencing Kriging\r## Kriging of remaining 0 data layers should finish around: 2023-04-03 16:54:51\r ## | | | 0%\r| |================================================================================| 100%\r So? Did we match the pre-existing data?\nNDVI_Krig[[1]]\r ## class : RasterBrick ## dimensions : 92, 108, 9936, 1 (nrow, ncol, ncell, nlayers)\r## resolution : 0.08333333, 0.08333333 (x, y)\r## extent : 6, 15, 47.33333, 55 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory\r## names : var1.pred ## min values : 275.9705 ## max values : 285.7357\r We nailed this!\nLet\u0026rsquo;s take one final look at our (A) raw ERA5 data, (B) NDVI data, (C) Kriged ERA5 data, and (D) standard error of our Kriging output:\n Click here for download plotting calls \r### ERA-Plot\rERA_df \u0026lt;- as.data.frame(raster(file.path(Dir.Exports, \u0026quot;2m_temperature_2015-01-01_2015-12-31_year.nc\u0026quot;)), xy = TRUE) # turn raster into dataframe\rcolnames(ERA_df)[c(-1,-2)] \u0026lt;- \u0026quot;Air Temperature 2015 (ERA5)\u0026quot;\rERA_df \u0026lt;- gather(data = ERA_df, key = Values, value = \u0026quot;value\u0026quot;, colnames(ERA_df)[c(-1,-2)]) # make ggplot-ready\rRaw_plot \u0026lt;- ggplot() + # create a plot\rgeom_raster(data = ERA_df , aes(x = x, y = y, fill = value)) + # plot the raw data\rfacet_wrap(~Values) + # split raster layers up\rtheme_bw() + labs(x = \u0026quot;Longitude\u0026quot;, y = \u0026quot;Latitude\u0026quot;) + # make plot more readable\rscale_fill_gradientn(name = \u0026quot;Air Temperature [K]\u0026quot;, colours = inferno(100)) + # add colour and legend\rgeom_polygon(data = Shape_shp, aes(x = long, y = lat, group = group), colour = \u0026quot;black\u0026quot;, fill = \u0026quot;NA\u0026quot;) # add shape\r### NDVI-Plot\rNDVI_df \u0026lt;- as.data.frame(NDVI_ras, xy = TRUE) # turn raster into dataframe\rcolnames(NDVI_df)[c(-1,-2)] \u0026lt;- \u0026quot;NDVI 2015\u0026quot;\rNDVI_df \u0026lt;- gather(data = NDVI_df, key = Values, value = \u0026quot;value\u0026quot;, colnames(NDVI_df)[c(-1,-2)]) # make ggplot-ready\rNDVI_plot \u0026lt;- ggplot() + # create a plot\rgeom_raster(data = NDVI_df , aes(x = x, y = y, fill = value)) + # plot the raw data\rfacet_wrap(~Values) + # split raster layers up\rtheme_bw() + labs(x = \u0026quot;Longitude\u0026quot;, y = \u0026quot;Latitude\u0026quot;) + # make plot more readable\rscale_fill_gradientn(name = \u0026quot;NDVI\u0026quot;, colours = rev(terrain.colors(100))) + # add colour and legend\rgeom_polygon(data = Shape_shp, aes(x = long, y = lat, group = group), colour = \u0026quot;black\u0026quot;, fill = \u0026quot;NA\u0026quot;) # add shape\r### KRIGED-Plots\rDates = c(\u0026quot;Kriged Air Temperature 2015 (NDVI Resolution)\u0026quot;)\rType_vec \u0026lt;- c(\u0026quot;Prediction\u0026quot;, \u0026quot;Standard Error\u0026quot;) # these are the output types of krigR\rColours_ls \u0026lt;- list(inferno(100), rev(viridis(100))) # we want separate colours for the types\rPlots_ls \u0026lt;- as.list(NA, NA) # this list will be filled with the output plots\rKrigDF_ls \u0026lt;- as.list(NA, NA) # this list will be filled with the output data\rfor(Plot in 1:2){ # loop over both output types\rKrig_df \u0026lt;- as.data.frame(NDVI_Krig[[Plot]], xy = TRUE) # turn raster into dataframe\rcolnames(Krig_df)[c(-1,-2)] \u0026lt;- paste(Type_vec[Plot], Dates) # set colnames\rKrig_df \u0026lt;- gather(data = Krig_df, key = Values, value = \u0026quot;value\u0026quot;, colnames(Krig_df)[c(-1,-2)]) # make ggplot-ready\rPlots_ls[[Plot]] \u0026lt;- ggplot() + # create plot\rgeom_raster(data = Krig_df , aes(x = x, y = y, fill = value)) + # plot the kriged data\rfacet_wrap(~Values) + # split raster layers up\rtheme_bw() + labs(x = \u0026quot;Longitude\u0026quot;, y = \u0026quot;Latitude\u0026quot;) + # make plot more readable\rscale_fill_gradientn(name = \u0026quot;Air Temperature [K]\u0026quot;, colours = Colours_ls[[Plot]]) + # add colour and legend\rtheme(plot.margin = unit(c(0, 0, 0, 0), \u0026quot;cm\u0026quot;)) + # reduce margins (for fusing of plots)\rgeom_polygon(data = Shape_shp, aes(x = long, y = lat, group = group), colour = \u0026quot;black\u0026quot;, fill = \u0026quot;NA\u0026quot;) # add shape\rKrigDF_ls[[Plot]] \u0026lt;- Krig_df\r} # end of type-loop\r \rplot_grid(plotlist = list(Raw_plot, NDVI_plot, Plots_ls[[1]], Plots_ls[[2]]), nrow = 2, labels = \u0026quot;AUTO\u0026quot;)\r So what can we learn from this? Let\u0026rsquo;s plot the relation between temperature and NDVI:\nplot_df \u0026lt;- as.data.frame(cbind(KrigDF_ls[[1]][,4], KrigDF_ls[[2]][,4],\rNDVI_df[,4]))\rcolnames(plot_df) \u0026lt;- c(\u0026quot;Temperature\u0026quot;, \u0026quot;Uncertainty\u0026quot;, \u0026quot;NDVI\u0026quot;)\rggplot(plot_df,\raes(x = Temperature, y = NDVI, size = Uncertainty)) + geom_point(alpha = 0.15) + theme_bw()\r Looks like NDVI increases as mean annual temperatures rise, but reaches a peak around 281-282 Kelvin with a subsequent decrease as mean annual temperatures rise higher.\nUsing Third-Party Data \rATTENTION: Kriging only works on square-cell spatial products!\r\r\rThe krigR() function is designed to work with non-ERA5(-Land) data as well as non-GMTED2010 covariate data. To downscale your own spatial products using different covariate data than the GMTED2010 DEM we use as a default, you need to step into the three-step workflow.\n\rMost spatial products won\u0026rsquo;t be reliably downscaled using only elevation covariate data.\r\r\rkrigR() supports any combination of ERA5-family reanalysis, GMTED2010, third-party climate data, and third-party covariate data. Here, we just demonstrate the use of other covariates than the GMTED2010 used by KrigR by default.\nThe product we will focus on here is the soil moisture data contained in our BCq_ras product established here. With this data set, we also revert back to our original study region:\nThe reason we focus on soil moisture for this exercise? In this publication (Figure 3), we demonstrate that soil moisture data can be statistically downscales using kriging with some third-party covariates. As such, we pick up from where we left off when we discussed kriging of bioclimatic products.\n\rClick here for file:\rDownload Qsoil_BC.nc and place it into your data directory.\r BCq_ras \u0026lt;- stack(file.path(Dir.Data, \u0026quot;Qsoil_BC.nc\u0026quot;))\r Third-Party Data Covariates In this publication, we demonstrate how soil moisture data can be reliably statistically downscaled using soil property data which we obtain from the Land-Atmosphere Interaction Research Group at Sun Yat-sen University.\nBelow, you will find the code needed to obtain the data of global coverage at roughly 1km spatial resolution. The code chunk below also crops and masks the data according to our study region and subsequently deletes the storage-heavy global files (3.5GB each in size). This process takes a long time due to download speeds.\n\rClick here for the covariate file to save yourself downloading and processing of global data:\rDownload SoilCovs.nc and place it into your covariates directory.\r # documentation of these can be found here http://globalchange.bnu.edu.cn/research/soil4.jsp\rSoilCovs_vec \u0026lt;- c(\u0026quot;tkdry\u0026quot;, \u0026quot;tksat\u0026quot;, \u0026quot;csol\u0026quot;, \u0026quot;k_s\u0026quot;, \u0026quot;lambda\u0026quot;, \u0026quot;psi\u0026quot;, \u0026quot;theta_s\u0026quot;) # need these names for addressing soil covariates\rif(!file.exists(file.path(Dir.Covariates, \u0026quot;SoilCovs.nc\u0026quot;))){\rprint(\u0026quot;#### Loading SOIL PROPERTY covariate data. ####\u0026quot;) # create lists to combine soil data into one\rSoilCovs_ls \u0026lt;- as.list(rep(NA, length(SoilCovs_vec)))\rnames(SoilCovs_ls) \u0026lt;- c(SoilCovs_vec)\r## Downloading, unpacking, and loading\rfor(Soil_Iter in SoilCovs_vec){\rif(!file.exists(file.path(Dir.Covariates, paste0(Soil_Iter, \u0026quot;.nc\u0026quot;)))) { # if not downloaded and processed yet\rprint(paste(\u0026quot;Handling\u0026quot;, Soil_Iter, \u0026quot;data.\u0026quot;))\rDir.Soil \u0026lt;- file.path(Dir.Covariates, Soil_Iter)\rdir.create(Dir.Soil)\rdownload.file(paste0(\u0026quot;http://globalchange.bnu.edu.cn/download/data/worldptf/\u0026quot;, Soil_Iter,\u0026quot;.zip\u0026quot;),\rdestfile = file.path(Dir.Soil, paste0(Soil_Iter, \u0026quot;.zip\u0026quot;))\r) # download data\runzip(file.path(Dir.Soil, paste0(Soil_Iter, \u0026quot;.zip\u0026quot;)), exdir = Dir.Soil) # unzip data\rFile \u0026lt;- list.files(Dir.Soil, pattern = \u0026quot;.nc\u0026quot;)[1] # only keep first soil layer\rSoil_ras \u0026lt;- raster(file.path(Dir.Soil, File)) # load data\rSoilCovs_ls[[which(names(SoilCovs_ls) == Soil_Iter)]] \u0026lt;- Soil_ras # save to list\rwriteRaster(x = Soil_ras, filename = file.path(Dir.Covariates, Soil_Iter), format = \u0026quot;CDF\u0026quot;)\runlink(Dir.Soil, recursive = TRUE)\r}else{\rprint(paste(Soil_Iter, \u0026quot;already downloaded and processed.\u0026quot;))\rSoilCovs_ls[[which(names(SoilCovs_ls) == Soil_Iter)]] \u0026lt;- raster(file.path(Dir.Covariates, paste0(Soil_Iter, \u0026quot;.nc\u0026quot;)))\r}\r}\r## data handling and manipulation\rSoilCovs_stack \u0026lt;- stack(SoilCovs_ls) # stacking raster layers from list\rSoilCovs_stack \u0026lt;- crop(SoilCovs_stack, extent(BCq_ras)) # cropping to extent of data we have\rSoilCovs_mask \u0026lt;- KrigR::mask_Shape(SoilCovs_stack[[1]], Shape = Shape_shp) # create mask with KrigR-internal function to ensure all edge cells are contained\rSoilCovs_stack \u0026lt;- mask(SoilCovs_stack, SoilCovs_mask) # mask out shape\r## writing the data\rwriteRaster(x = SoilCovs_stack, filename = file.path(Dir.Covariates, \u0026quot;SoilCovs\u0026quot;), format = \u0026quot;CDF\u0026quot;)\r## removing the global files due to their size\runlink(file.path(Dir.Covariates, paste0(SoilCovs_vec, \u0026quot;.nc\u0026quot;)))\r}\rSoilCovs_stack \u0026lt;- stack(file.path(Dir.Covariates, \u0026quot;SoilCovs.nc\u0026quot;))\rnames(SoilCovs_stack) \u0026lt;- SoilCovs_vec\r Let\u0026rsquo;s have a look at these data:\nSoilCovs_stack\r ## class : RasterStack ## dimensions : 408, 648, 264384, 7 (nrow, ncol, ncell, nlayers)\r## resolution : 0.008333333, 0.008333333 (x, y)\r## extent : 9.725, 15.125, 49.75, 53.15 (xmin, xmax, ymin, ymax)\r## crs : +proj=longlat +datum=WGS84 +no_defs ## names : tkdry, tksat, csol, k_s, lambda, psi, theta_s ## min values : 5.200000e-02, 1.337000e+00, 2.141000e+06, 5.212523e+00, 8.600000e-02, -5.307258e+01, 3.230000e-01 ## max values : 2.070000e-01, 2.862000e+00, 2.346400e+06, 2.461686e+02, 3.330000e-01, -5.205317e+00, 5.320000e-01\r Now we need to establish target and training resolution of our covariate data.\nFirst, we focus on the training resolution covariate data. We match our covariate data to our spatial product which we wish to downscale by resampling the covariate data to the coarser resolution:\nCoarsecovs \u0026lt;- resample(x = SoilCovs_stack, y = BCq_ras)\r Second, we aggregate the covariate data to our desired resolution. In this case, 0.02 as done previously here:\nFinecovs \u0026lt;- aggregate(SoilCovs_stack, fact = 0.02/res(SoilCovs_stack)[1])\r Finally, we combine these into a list like the output of download_DEM():\nCovs_ls \u0026lt;- list(Coarsecovs, Finecovs)\rPlot_Covs(Covs = Covs_ls, Shape_shp)\r \rOur development goals include creating a function that automatically carries out all of the above for you with a specification alike to download_DEM().\r\r\rKriging Third-Party Data Finally, we can statistically downscale our soil moisture data using the soil property covariates. For this, we need to specify a new KrigingEquation.\n\rWith the KrigingEquation argument, you may specify non-linear combinations of covariates for your call to krigR().\r\r\r\rIf you don\u0026rsquo;t specify a KrigingEquation in krigR() and your covariates do not contain a layer called \u0026quot;DEM\u0026quot;, krigR() will notify you that its default formula cannot be executed and will attempt to build an additive formula from the data it can find. krigr() will inform you of this and ask for your approval before proceeding.\r\r\rThis auto-generated formula would be the same as the one we specify here - an additive combination of all covariates found both at coarse and fine resolutions. Of course, this formula can also be specified to reflect interactive effects.\nHere, I automate the generation of our KrigingEquation:\nKrigingEquation \u0026lt;- paste0(\u0026quot;ERA ~ \u0026quot;, paste(SoilCovs_vec, collapse = \u0026quot; + \u0026quot;))\rKrigingEquation\r ## [1] \u0026quot;ERA ~ tkdry + tksat + csol + k_s + lambda + psi + theta_s\u0026quot;\r In accordance with our downscaling of the temperature-portion of the bioclimatic data, (1) I only hand the last 8 layers to the kriging call because those are the soil moisture data, (2) I leave out the Cores argument, so that krigR() determines how many cores your machine has and uses all of them to speed up the computation of the multi-layer raster, and (3) I set nmax to 80 to approximate a typical weather system in size:\nBC_Water_Krig \u0026lt;- krigR(Data = BCq_ras[[12:19]], Covariates_coarse = Covs_ls[[1]], Covariates_fine = Covs_ls[[2]],\rKrigingEquation = KrigingEquation, FileName = \u0026quot;BC_Water_Krig\u0026quot;,\rDir = Dir.Covariates,\rnmax = 80\r)\r ## Warning: [writeCDF] for better results use file extension '.nc' or '.cdf'\r## see: https://stackoverflow.com/a/65398262/635245\r ## Warning: [rast] unknown extent\r ## Warning: [writeCDF] for better results use file extension '.nc' or '.cdf'\r## see: https://stackoverflow.com/a/65398262/635245\r ## Warning: [rast] unknown extent\r BIO12 - Annual Mean Soil Moisture \rInterpolating this data is just like statistically downscaling any other soil moisture product and can be done without any problems.\r\r\r\rClick here for plotting call and plot:\r\rLook at how well the river Elbe sows up in this!\r\r\rPlot_Krigs(lapply(BC_Water_Krig[-3], \u0026quot;[[\u0026quot;, 1), Shp = Shape_shp,\rDates = \u0026quot;BIO12 - Annual Mean Soil Moisture\u0026quot;)\r \rBIO13 - Soil Moisture of Wettest Month \rInterpolating this data is just like statistically downscaling any other soil moisture product and can be done without any problems.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Water_Krig[-3], \u0026quot;[[\u0026quot;, 2), Shp = Shape_shp,\rDates = \u0026quot;BIO13 - Soil Moisture of Wettest Month\u0026quot;)\r \rBIO14 - Soil Moisture of Driest Month \rInterpolating this data is just like statistically downscaling any other soil moisture product and can be done without any problems.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Water_Krig[-3], \u0026quot;[[\u0026quot;, 3), Shp = Shape_shp,\rDates = \u0026quot;BIO13 - Soil Moisture of Driest Month\u0026quot;)\r \rBIO15 - Soil Moisture Seasonality \rThis data product is calculated using the standard deviation of mean values throughout our time frame. Conclusively, it would be interpolated better by first statistically downscaling the underlying data rather than the final bioclimatic variable.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Water_Krig[-3], \u0026quot;[[\u0026quot;, 4), Shp = Shape_shp,\rDates = \u0026quot;BIO15 - Precipitation Seasonality\u0026quot;)\r \rBIO16 \u0026amp; BIO17 - Soil Moisture of Wettest and Driest Quarter \rI do not recommend you use these kriging outputs! They rely on mean quarterly soil moisture data which is not being interpolated here. Subsequently, the patchiness of the underlying data is lost and with it: information.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Water_Krig[-3], \u0026quot;[[\u0026quot;, 5:6), Shp = Shape_shp,\rDates = c(\u0026quot;BIO16 - Soil Moisture of Wettest Quarter\u0026quot;, \u0026quot;BIO17 - Soil Moisture of Driest Quarter\u0026quot;)\r)\r \rBIO18 \u0026amp; BIO19 - Precipitation of Warmest and Coldest Quarter \rI do not recommend you use these kriging outputs! They rely on mean quarterly temperature data which is not being interpolated here. Subsequently, the patchiness of the underlying data is lost and with it: information.\r\r\r\rClick here for plotting call and plot:\rPlot_Krigs(lapply(BC_Water_Krig[-3], \u0026quot;[[\u0026quot;, 7:8), Shp = Shape_shp,\rDates = c(\u0026quot;BIO16 - Soil Moisture of Warmest Quarter\u0026quot;, \u0026quot;BIO17 - Soil Moisture of Coldest Quarter\u0026quot;)\r)\r \rThis concludes our exercise for using third-party data in KrigR.\nSession Info sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] mapview_2.11.0 rnaturalearthdata_0.1.0 rnaturalearth_0.3.2 ## [4] gimms_1.2.1 ggmap_3.0.2 cowplot_1.1.1 ## [7] viridis_0.6.2 viridisLite_0.4.1 ggplot2_3.4.1 ## [10] tidyr_1.3.0 KrigR_0.1.2 terra_1.7-21 ## [13] httr_1.4.5 stars_0.6-0 abind_1.4-5 ## [16] fasterize_1.0.4 sf_1.0-12 lubridate_1.9.2 ## [19] automap_1.1-9 doSNOW_1.0.20 snow_0.4-4 ## [22] doParallel_1.0.17 iterators_1.0.14 foreach_1.5.2 ## [25] rgdal_1.6-5 raster_3.6-20 sp_1.6-0 ## [28] stringr_1.5.0 keyring_1.3.1 ecmwfr_1.5.0 ## [31] ncdf4_1.21 ## ## loaded via a namespace (and not attached):\r## [1] leafem_0.2.0 colorspace_2.1-0 class_7.3-21 ## [4] leaflet_2.1.2 satellite_1.0.4 base64enc_0.1-3 ## [7] rstudioapi_0.14 proxy_0.4-27 farver_2.1.1 ## [10] fansi_1.0.4 codetools_0.2-19 cachem_1.0.7 ## [13] knitr_1.42 jsonlite_1.8.4 png_0.1-8 ## [16] Kendall_2.2.1 compiler_4.2.3 assertthat_0.2.1 ## [19] fastmap_1.1.1 cli_3.6.0 htmltools_0.5.4 ## [22] tools_4.2.3 gtable_0.3.1 glue_1.6.2 ## [25] dplyr_1.1.0 Rcpp_1.0.10 jquerylib_0.1.4 ## [28] vctrs_0.6.1 blogdown_1.16 crosstalk_1.2.0 ## [31] lwgeom_0.2-11 xfun_0.37 timechange_0.2.0 ## [34] lifecycle_1.0.3 rnaturalearthhires_0.2.1 zoo_1.8-11 ## [37] scales_1.2.1 gstat_2.1-0 yaml_2.3.7 ## [40] curl_5.0.0 memoise_2.0.1 gridExtra_2.3 ## [43] sass_0.4.5 reshape_0.8.9 stringi_1.7.12 ## [46] highr_0.10 e1071_1.7-13 boot_1.3-28.1 ## [49] intervals_0.15.3 RgoogleMaps_1.4.5.3 rlang_1.1.0 ## [52] pkgconfig_2.0.3 bitops_1.0-7 evaluate_0.20 ## [55] lattice_0.20-45 purrr_1.0.1 htmlwidgets_1.6.1 ## [58] labeling_0.4.2 tidyselect_1.2.0 plyr_1.8.8 ## [61] magrittr_2.0.3 bookdown_0.33 R6_2.5.1 ## [64] generics_0.1.3 DBI_1.1.3 pillar_1.8.1 ## [67] withr_2.5.0 units_0.8-1 xts_0.13.0 ## [70] tibble_3.2.1 spacetime_1.2-8 KernSmooth_2.23-20 ## [73] utf8_1.2.3 rmarkdown_2.20 jpeg_0.1-10 ## [76] grid_4.2.3 zyp_0.11-1 FNN_1.1.3.2 ## [79] digest_0.6.31 classInt_0.4-9 webshot_0.5.4 ## [82] stats4_4.2.3 munsell_0.5.0 bslib_0.4.2\r ","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"e32d59fad2f96a64f35e7515f642e385","permalink":"https://www.erikkusch.com/courses/krigr/third-party/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/third-party/","section":"courses","summary":"Using `KrigR` with third-party data.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Third-Party Data","type":"docs"},{"authors":[],"categories":["KrigR","Climate Data"],"content":"\rKrigR is currently undergoing development. As a result, this part of the workshop has become deprecated. Please refer to the setup quick guide portions of this material as these are up-to-date. \r\r\r\rThis part of the workshop is dependant on set-up and preparation done previously here.\r\r\rFirst, we load KrigR:\nlibrary(KrigR)\r I expect that you will often be interested not just in past and current climatic conditions, but also in future projections of climate data at high spatial resolutions.\n\rThe KrigR workflow can be used to establish high-resolution, bias-corrected climate projection products.\r\r\rThis time, we run our exercise for all of Germany because of its size and topographical variety.\nShape_shp \u0026lt;- ne_countries(country = \u0026quot;Germany\u0026quot;)\r KrigR Process for Projections We published the the KrigR workflow for downscaled climate projections in this publication (Section 3.5) and I will walk you through the contents thereof here.\nTo achieve downscaled projection products we require three data products:\n Historical climate data from ERA5(-Land) Historical climate data from projection source Future climate data from projection source  Subsequently, the data products are downscaled to the desired spatial resolution using krigR(). Finally, the difference between the downscaled projection-sourced data are added to the historical baseline obtained from (downscaled) ERA5(-Land) data. This achieves bias correction.\nObtaining ERA5(-Land) Data Now, let\u0026rsquo;s obtain the historical baseline from ERA5-Land for the same time-period as our CMIP6 historical data.\n\rClick here for file if download takes too long:\rDownload Germany_Hist_ERA.nc and place it into your data directory.\r if(!file.exists(file.path(Dir.Data, \u0026quot;Germany_Hist_ERA.nc\u0026quot;))){\rHist_ERA_ras \u0026lt;- download_ERA(Variable = \u0026quot;2m_temperature\u0026quot;,\rDateStart = \u0026quot;1981-01-01\u0026quot;,\rDateStop = \u0026quot;1999-12-31\u0026quot;,\rTResolution = \u0026quot;month\u0026quot;,\rTStep = 1,\rExtent = Shape_shp,\rDir = Dir.Data,\rFileName = \u0026quot;Germany_Hist_ERA\u0026quot;, API_Key = API_Key,\rAPI_User = API_User,\rSingularDL = TRUE)\rIndex \u0026lt;- rep(1:12, length = nlayers(Hist_ERA_ras))\rHist_ERA_ras \u0026lt;- stackApply(Hist_ERA_ras, indices = Index, fun = mean)\rwriteRaster(Hist_ERA_ras, filename = file.path(Dir.Data, \u0026quot;Germany_Hist_ERA\u0026quot;), format = \u0026quot;CDF\u0026quot;)\r}\rHist_ERA_ras \u0026lt;- mean(stack(file.path(Dir.Data, \u0026quot;Germany_Hist_ERA.nc\u0026quot;)))\r Obtaining Projection Data Here, we use CMIP6 projection data manually sourced from the ECMWF CDS distribution.\n\rOur development goals include development of download_ERA() to work with other ECWMF CDS data sets aside from ERA5(-Land). This includes this CMIP6 data set.\r\r\rHistorical Baseline \rClick here for file:\rDownload historical_tas_1981-2000.nc and place it into your data directory.\r train_HIST \u0026lt;- mean(stack(file.path(Dir.Data, \u0026quot;historical_tas_1981-2000.nc\u0026quot;)))\rtrain_HIST \u0026lt;- crop(train_HIST,extent(Hist_ERA_ras))\rtrain_mask \u0026lt;- KrigR::mask_Shape(train_HIST, Shape_shp)\rtrain_HIST \u0026lt;- mask(train_HIST, train_mask)\r Future Projection \rClick here for file:\rDownload ssp585_tas_2041-2060.nc and place it into your data directory.\r train_SSP \u0026lt;- mean(stack(file.path(Dir.Data, \u0026quot;ssp585_tas_2041-2060.nc\u0026quot;)))\rtrain_SSP \u0026lt;- crop(train_SSP,extent(Hist_ERA_ras))\rtrain_mask \u0026lt;- KrigR::mask_Shape(train_SSP, Shape_shp)\rtrain_SSP \u0026lt;- mask(train_SSP, train_mask)\r Visualisation of CMIP6 Data Plot_Raw(stack(train_HIST, train_SSP), Shp = Shape_shp,\rDates = c(\u0026quot;Historic CMIP6\u0026quot;, \u0026quot;Future CMIP6\u0026quot;))\r Already, we can see that quite a bit of warming is projected to happen all across Germany. However, we want to know about this at higher spatial resolutions. That\u0026rsquo;s where KrigR comes in.\nEstablishing Kriged Products For the first time in this workshop material, we will push our spatial resolution to the finest scale supported by our default GMTED 2010 DEM covariate data: 0.008333 / ~1km.\n\rThese operations take quite some time - grab a tea or coffee, go for a walk, or stretch a bit.\r\r\rThe downscaling calls should be familiar by now so I will forego explaining them. In case, the following code snippets do not make sense to you, please consult the portion of this workshop concerned with statistical downscaling.\nHistorical CMIP6 ## Covariate Data\rGMTED_DE \u0026lt;- download_DEM(\rTrain_ras = train_HIST,\rTarget_res = 0.008334,\rShape = Shape_shp,\rKeep_Temporary = TRUE,\rDir = Dir.Covariates\r)\r## Kriging\rOutput_HIST \u0026lt;- krigR(\rData = train_HIST,\rCovariates_coarse = GMTED_DE[[1]], Covariates_fine = GMTED_DE[[2]], Keep_Temporary = FALSE,\rCores = 1,\rDir = Dir.Exports, FileName = \u0026quot;DE_CMIP-HIST\u0026quot;, nmax = 40\r)\r Plot_Krigs(Output_HIST,\rShp = Shape_shp,\rDates = \u0026quot;CMIP6 Historical\u0026quot;, columns = 2)\r Future CMIP6 ## Covariate Data\rGMTED_DE \u0026lt;- download_DEM(\rTrain_ras = train_SSP,\rTarget_res = 0.008334,\rShape = Shape_shp,\rKeep_Temporary = TRUE,\rDir = Dir.Covariates\r)\r## Kriging\rOutput_SSP \u0026lt;- krigR(\rData = train_SSP,\rCovariates_coarse = GMTED_DE[[1]], Covariates_fine = GMTED_DE[[2]], Keep_Temporary = FALSE,\rCores = 1,\rDir = Dir.Exports, FileName = \u0026quot;DE_SSP585_2041-2060\u0026quot;, nmax = 40\r)\r Plot_Krigs(Output_SSP,\rShp = Shape_shp,\rDates = \u0026quot;CMIP6 Future\u0026quot;, columns = 2)\r Historical ERA5-Land ## Covariate Data\rGMTED_DE \u0026lt;- download_DEM(\rTrain_ras = Hist_ERA_ras,\rTarget_res = 0.008334,\rShape = Shape_shp,\rKeep_Temporary = TRUE,\rDir = Dir.Covariates\r)\r## Kriging\rOutput_ERA \u0026lt;- krigR(\rData = Hist_ERA_ras,\rCovariates_coarse = GMTED_DE[[1]], Covariates_fine = GMTED_DE[[2]], Keep_Temporary = FALSE,\rCores = 1,\rDir = Dir.Exports, FileName = \u0026quot;DE_hist\u0026quot;, nmax = 40\r)\r Plot_Krigs(Output_ERA,\rShp = Shape_shp,\rDates = \u0026quot;ERA5-Land Historical\u0026quot;, columns = 2)\r Putting It All Together To establish a final product of high-resolution climate projection data, we simply add the difference between the kriged CMIP6 products to the kriged ERA5-Land product:\n## Creating Difference and Projection raster\rDifference_ras \u0026lt;- Output_SSP[[1]] - Output_HIST[[1]]\rProjection_ras \u0026lt;- Output_ERA[[1]] + Difference_ras\r## Adding min and max values to ocean cells to ensure same colour scale\rOutput_ERA[[1]][10] \u0026lt;- maxValue(Projection_ras)\rOutput_ERA[[1]][12] \u0026lt;- minValue(Projection_ras)\rProjection_ras[10] \u0026lt;- maxValue(Output_ERA[[1]])\rProjection_ras[12] \u0026lt;- minValue(Output_ERA[[1]])\r## Individual plots\rA_gg \u0026lt;- Plot_Raw(Output_ERA[[1]], Shp = Shape_shp, Dates = \u0026quot;Historical ERA5-Land (1981-2000)\u0026quot;)\rB_gg \u0026lt;- Plot_Raw(Difference_ras[[1]], Shp = Shape_shp, Dates = \u0026quot;Anomalies of SSP585 - Historical CMIP-6\u0026quot;,\rCOL = rev(viridis(100)))\rC_gg \u0026lt;- Plot_Raw(Projection_ras[[1]], Shp = Shape_shp, Dates = \u0026quot;Future Projection (ERA5-Land + Anomalies)\u0026quot;)\r## Fuse the plots into one big plot\rggPlot \u0026lt;- plot_grid(plotlist = list(A_gg, B_gg, C_gg), ncol = 3, labels = \u0026quot;AUTO\u0026quot;) ggPlot\r And there we have it - a downscaled, bias-corrected projection of air temperature across Germany.\nConsiderations for Projection Kriging Projection kriging is easily the most flexible exercise you can undertake with KrigR.\n\rI have submitted a research proposal to establish best practice for projection kriging.\r\r\rSo far, two particular aspects stand out to me and should be considered by you when using KrigR to obtain high-resolution projection data.\n\rDo not statistically downscale precipitation data and do not use products that do so!\r\r\rReliability Just like with all statistical downscaling exercises, it is pivotal to consider variables interpolated and consistency of statistical relationships with covariates across spatial resolutions.\n\rKriging is a very flexible tool for statistical interpolation. Consider your choice of covariates and change in resolutions carefully. Always inspect your data.\r\r\rUncertainty Integration of multiple kriged data sets with statistical uncertainty and each of which comes with its own underlying dynamical data uncertainty raises the question of how to combine uncertainties for meaningful uncertainty flags.\n\rI have submitted a research proposal to assess best practice for uncertainty integration across data products.\r\r\rSession Info sessionInfo()\r ## R version 4.2.3 (2023-03-15)\r## Platform: x86_64-apple-darwin17.0 (64-bit)\r## Running under: macOS Big Sur ... 10.16\r## ## Matrix products: default\r## BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\r## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\r## ## locale:\r## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r## ## attached base packages:\r## [1] parallel stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] mapview_2.11.0 rnaturalearthdata_0.1.0 rnaturalearth_0.3.2 ## [4] gimms_1.2.1 ggmap_3.0.2 cowplot_1.1.1 ## [7] viridis_0.6.2 viridisLite_0.4.1 ggplot2_3.4.1 ## [10] tidyr_1.3.0 KrigR_0.1.2 terra_1.7-21 ## [13] httr_1.4.5 stars_0.6-0 abind_1.4-5 ## [16] fasterize_1.0.4 sf_1.0-12 lubridate_1.9.2 ## [19] automap_1.1-9 doSNOW_1.0.20 snow_0.4-4 ## [22] doParallel_1.0.17 iterators_1.0.14 foreach_1.5.2 ## [25] rgdal_1.6-5 raster_3.6-20 sp_1.6-0 ## [28] stringr_1.5.0 keyring_1.3.1 ecmwfr_1.5.0 ## [31] ncdf4_1.21 ## ## loaded via a namespace (and not attached):\r## [1] leafem_0.2.0 colorspace_2.1-0 class_7.3-21 ## [4] leaflet_2.1.2 satellite_1.0.4 base64enc_0.1-3 ## [7] rstudioapi_0.14 proxy_0.4-27 farver_2.1.1 ## [10] fansi_1.0.4 codetools_0.2-19 cachem_1.0.7 ## [13] knitr_1.42 jsonlite_1.8.4 png_0.1-8 ## [16] Kendall_2.2.1 compiler_4.2.3 assertthat_0.2.1 ## [19] fastmap_1.1.1 cli_3.6.0 htmltools_0.5.4 ## [22] tools_4.2.3 gtable_0.3.1 glue_1.6.2 ## [25] dplyr_1.1.0 Rcpp_1.0.10 jquerylib_0.1.4 ## [28] vctrs_0.6.1 blogdown_1.16 crosstalk_1.2.0 ## [31] lwgeom_0.2-11 xfun_0.37 timechange_0.2.0 ## [34] lifecycle_1.0.3 rnaturalearthhires_0.2.1 zoo_1.8-11 ## [37] scales_1.2.1 gstat_2.1-0 yaml_2.3.7 ## [40] curl_5.0.0 memoise_2.0.1 gridExtra_2.3 ## [43] sass_0.4.5 reshape_0.8.9 stringi_1.7.12 ## [46] highr_0.10 e1071_1.7-13 boot_1.3-28.1 ## [49] intervals_0.15.3 RgoogleMaps_1.4.5.3 rlang_1.1.0 ## [52] pkgconfig_2.0.3 bitops_1.0-7 evaluate_0.20 ## [55] lattice_0.20-45 purrr_1.0.1 htmlwidgets_1.6.1 ## [58] labeling_0.4.2 tidyselect_1.2.0 plyr_1.8.8 ## [61] magrittr_2.0.3 bookdown_0.33 R6_2.5.1 ## [64] generics_0.1.3 DBI_1.1.3 pillar_1.8.1 ## [67] withr_2.5.0 units_0.8-1 xts_0.13.0 ## [70] tibble_3.2.1 spacetime_1.2-8 KernSmooth_2.23-20 ## [73] utf8_1.2.3 rmarkdown_2.20 jpeg_0.1-10 ## [76] grid_4.2.3 zyp_0.11-1 FNN_1.1.3.2 ## [79] digest_0.6.31 classInt_0.4-9 webshot_0.5.4 ## [82] stats4_4.2.3 munsell_0.5.0 bslib_0.4.2\r ","date":1653523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622055600,"objectID":"47847411ce53dd98c3cd6ede3d0b52a2","permalink":"https://www.erikkusch.com/courses/krigr/projections/","publishdate":"2022-05-26T00:00:00Z","relpermalink":"/courses/krigr/projections/","section":"courses","summary":"KrigR is currently undergoing development. As a result, this part of the workshop has become deprecated. Please refer to the setup quick guide portions of this material as these are up-to-date.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Projection Downscaling","type":"docs"},{"authors":["Taimur Khan","Koen de Koning","Dag Endresen","Desalegn Chala Gelete","Erik Kusch"],"categories":null,"content":"","date":1721779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721779200,"objectID":"a91d7175888c70c95c539d634ea53a72","permalink":"https://www.erikkusch.com/publication/twineco-a-unified-framework-for-dynamic-data-driven-digital-twins-in-ecology/","publishdate":"2024-07-24T00:00:00Z","relpermalink":"/publication/twineco-a-unified-framework-for-dynamic-data-driven-digital-twins-in-ecology/","section":"publication","summary":"Design framework for digital twins in ecological applications.","tags":["Digital Twin","BioDT","Design Framework"],"title":"TwinEco - A Unified Framework for Dynamic Data-Driven Digital Twins in Ecology","type":"publication"},{"authors":["Desalegn Chala","Erik Kusch","Claus Weiland","Carrie Andrew","Jonas Grieb","Tuomas Rossi","Tomas Martinovic","Dag Endresen"],"categories":null,"content":"","date":1718064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718064000,"objectID":"71da7d3f34b2ee84e0a74f2fb207af53","permalink":"https://www.erikkusch.com/publication/prototype-biodiversity-digital-twin-crop-wild-relatives-genetic-resources-for-food-security/","publishdate":"2024-06-11T00:00:00Z","relpermalink":"/publication/prototype-biodiversity-digital-twin-crop-wild-relatives-genetic-resources-for-food-security/","section":"publication","summary":"Early-stage outcome of my contributions to the BioDT project.","tags":["Digital Twin","Crop Wild Relatives"],"title":"Prototype biodiversity digital twin - crop wild relatives genetic resources for food security","type":"publication"},{"authors":["Aud H. Halbritter","Vigdis Vandvik","Sehoya H. Cotner","William Farfan-Rios","Brian S. Maitner","Sean T. Michaletz","Imma Oliveras Menor","Richard J. Telford","Adam Ccahuana","Rudi Cruz","Jhonatan Sallo-Bravo","Paul Efren Santos-Andrade","Lucely L. Vilca-Bustamante","Matiss Castorena","Julia Chacón-Labella","Casper Tai Christiansen","Sandra M. Duran","Dagmar D. Egelkraut","Ragnhild Gya","Siri Vatsø Haugum","Lorah Seltzer","Miles R. Silman","Tanya Strydom","Marcus P. Spiegel","Agustina Barros","Kristine Birkeli","Mickey Boakye","Fernanda Chiappero","Adam Chmurzynski","Josef C. Garen","Joseph Gaudard","Tasha-Leigh J. Gauthier","Sonya R. Geange","Fiorella N. Gonzales","Jonathan J. Henn","Kristýna Hošková","Anders Isaksen","Laura H. Jessup","Will Johnson","Erik Kusch","Kai Lepley","Mackenzie Lift","Trace E. Martyn","Miguel Muñoz Mazon","Sara L. Middleton","Natalia L. Quinteros Casaverde","Jocelyn Navarro","Verónica Zepeda","Korina Ocampo-Zuleta","Andrea Carmeli Palomino-Cardenas","Samuel Pastor Ploskonka","Maria Elisa Pierfederici","Verónica Pinelli","Jess Rickenback","Ruben E. Roos","Hilde Stokland Rui","Eugenia Sanchez Diaz","Andrea Sánchez-Tapia","Alyssa Smith","Erickson Urquiaga-Flores","Jonathan von Oppen","Brian J. Enquist"],"categories":null,"content":"","date":1708473600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708473600,"objectID":"ebf0c702aaed07652421060fed730381","permalink":"https://www.erikkusch.com/publication/plant-trait-and-vegetation-data-along-a-1314-m-elevation-gradient-with-fire-history-in-puna-grasslands-peru/","publishdate":"2024-02-21T00:00:00Z","relpermalink":"/publication/plant-trait-and-vegetation-data-along-a-1314-m-elevation-gradient-with-fire-history-in-puna-grasslands-peru/","section":"publication","summary":"Plant Functional Trait Campaign Dataset from the Peruvian Andes.","tags":["Data Base","Plant Functional Traits"],"title":"Plant trait and vegetation data along a 1314m elevation gradient with fire history in Puna grasslands, Perú","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1692280800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692280800,"objectID":"a61c71695b5bf41e1961eb29de25e08b","permalink":"https://www.erikkusch.com/talk/2023_08_tangledbank/","publishdate":"2023-08-17T00:00:00Z","relpermalink":"/talk/2023_08_tangledbank/","section":"talk","summary":"An introduction to my PhD work and ongoing research for colleagues at UiO.","tags":["Biological Networks","Macroecology","Resilience","Climate Data","Active","PhD"],"title":"Integrating Ecological Networks in Macroecological Research - Enhancing Projections of Biodiversity in the Anthropocene","type":"talk"},{"authors":["Erik Kusch","Anna C. Vinton"],"categories":null,"content":"","date":1691366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691366400,"objectID":"9450342b5090339581c9d3686772b0d8","permalink":"https://www.erikkusch.com/publication/a-novel-simulation-framework-for-validation-of-ecological-network-inference/","publishdate":"2023-08-07T00:00:00Z","relpermalink":"/publication/a-novel-simulation-framework-for-validation-of-ecological-network-inference/","section":"publication","summary":"Simulation framework for generation of data ready for ecological network inference and validation of network inference approaches.","tags":["Cooccurrence","Biological Networks","Ecological Networks","Ecological Network Inference","Macroecology","Method Comparison","Network Topology","Spatial Scale","Species Associations"],"title":"A Novel Simulation Framework for Validation of Ecological Network Inference","type":"publication"},{"authors":["Erik Kusch","Alejandro Ordonez"],"categories":null,"content":"","date":1691366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691366400,"objectID":"b16857986481f4e564700b6563590d32","permalink":"https://www.erikkusch.com/publication/ecological-network-resilience-extinction-proxies-updating-projections-of-ecological-networks/","publishdate":"2023-08-07T00:00:00Z","relpermalink":"/publication/ecological-network-resilience-extinction-proxies-updating-projections-of-ecological-networks/","section":"publication","summary":"Exploration of biodiversity scenarios of 81 mutualistic networks following extinction simulations according to different primary extinction risk proxies, ecological network resilience characteristics, and extinction cascade directionalities.","tags":["Cooccurrence","Biological Networks","Ecological Networks","Macroecology","Network Topology","Spatial Scale","Species Associations","Extinction Risk","Extinction Cascades","Biodiversity","Ecosystem Projections","Climate Safety Margins","IUCN","Network Resilience","Rewiring"],"title":"Ecological Network Resilience \u0026 Extinction Proxies - Updating Projections of Ecological Networks","type":"publication"},{"authors":["Erik Kusch","Malyon Bimler","James A. Lutz","Alejandro Ordonez"],"categories":null,"content":"","date":1690934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690934400,"objectID":"c30f95c30bbd9b0956cf3b63ab2d98f9","permalink":"https://www.erikkusch.com/publication/ecological-network-inference-is-not-consistent-across-sales-or-approaches/","publishdate":"2023-08-02T00:00:00Z","relpermalink":"/publication/ecological-network-inference-is-not-consistent-across-sales-or-approaches/","section":"publication","summary":"Comparison of ecological network inferred with contemporary methodology across ecologically relevant scales.","tags":["Cooccurrence","Biological Networks","Ecological Networks","Ecological Network Inference","Macroecology","Method Comparison","Network Topology","Spatial Scale","Species Associations"],"title":"Ecological Network Inference is not Consistent Across Scales or Approaches","type":"publication"},{"authors":["M.Isidora Ávila-Thieme","Erik Kusch","Derek Corcoran","Simón P. Castillo","Fernanda S. Valdovinos","Sergio A. Navarrete","Pablo A. Marquet"],"categories":null,"content":"","date":1685664000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685664000,"objectID":"18283291abf15b70bf8f29106eed4194","permalink":"https://www.erikkusch.com/publication/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/","publishdate":"2023-06-02T00:00:00Z","relpermalink":"/publication/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/","section":"publication","summary":"R package for exploration of extinction and rewiring processes in ecological networks.","tags":["network topology","disturbance","robustness","extinction thresholds","food webs","mutualistic networks","network science"],"title":"NetworkExtinction - An R Package to Simulate Extinction Propagation and Rewiring Potential in Ecological Networks","type":"publication"},{"authors":["Connor Bernard","Gabriel Silva Santos","Jacques Deere","Roberto Rodriguez-Caro","Pol Capdevila","Erik Kusch","Samuel J L Gascoigne","John Jackson","Roberto Salguero-Gómez"],"categories":null,"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685577600,"objectID":"c44a9643191e10b4190f259d7940b197","permalink":"https://www.erikkusch.com/publication/mosaic-a-unified-trait-database-to-complement-structured-population-models/","publishdate":"2023-06-01T00:00:00Z","relpermalink":"/publication/mosaic-a-unified-trait-database-to-complement-structured-population-models/","section":"publication","summary":"Integration of multiple demographic data bases into one easily accessible one-stop-shop for your demographic needs.","tags":["Data Base","Demography"],"title":"MOSAIC - A Unified Trait Database to Complement Structured Population Models","type":"publication"},{"authors":["Erik Kusch"],"categories":["GBIF","Biodiversity","Open Science"],"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1684627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684627200,"objectID":"8068110a83fb0f11f8deba44ce7ad68d","permalink":"https://www.erikkusch.com/courses/gbif/","publishdate":"2023-05-21T00:00:00Z","relpermalink":"/courses/gbif/","section":"courses","summary":"Workshop material introducing concepts and giving practical examples for obtaining GBIF data using `rgbif`. Presented at the Living Norway Colloquium 2023 in Trondheim.","tags":["GBIF","Biodiversity","Open Science"],"title":"Accessing, handling, and referencing open biodiversity data using the Global Biodiversity Information Facility (GBIF)","type":"courses"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1677888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677888000,"objectID":"14213741112fc6ed503ed46062093db7","permalink":"https://www.erikkusch.com/project/biodt/","publishdate":"2023-03-04T00:00:00Z","relpermalink":"/project/biodt/","section":"project","summary":"My work at Oslo University is part of this bigger project.","tags":["Active","Open Science","Data Science","BioDT"],"title":"Biodiversity Digitial Twin (BioDT)","type":"project"},{"authors":["M.Isidora Ávila-Thieme","Derek Corcoran","Erik Kusch","Simón P. Castillo","Fernanda S. Valdovinos","Sergio A. Navarrete","Pablo A. Marquet"],"categories":null,"content":"","date":1670198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670198400,"objectID":"e8fecbdfea425f6e307b210af63e5b6c","permalink":"https://www.erikkusch.com/publication/in-review/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/","publishdate":"2022-12-05T00:00:00Z","relpermalink":"/publication/in-review/networkextinction-an-r-package-to-simulate-extinctions-propagation-and-rewiring-potential-in-ecological-networks/","section":"publication","summary":"R package for exploration of exctinction and rewiring processes in ecological networks.","tags":["network topology","disturbance","robustness","extinction thresholds","food webs","mutualistic networks","network science"],"title":"NetworkExtinction - an R package to simulate extinction’s propagation and rewiring potential in ecological networks","type":"publication"},{"authors":["Erik Kusch","Malyon Bimler","James A. Lutz","Alejandro Ordonez"],"categories":null,"content":"","date":1660003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660003200,"objectID":"71c68f24f830c3fe126fb58c054af84e","permalink":"https://www.erikkusch.com/publication/in-review/ecological-network-inference-is-not-consistent-across-sales-or-approaches/","publishdate":"2022-08-09T00:00:00Z","relpermalink":"/publication/in-review/ecological-network-inference-is-not-consistent-across-sales-or-approaches/","section":"publication","summary":"Comparison of ecological network inferred with contemporary methodology across ecologically relevant scales.","tags":["Cooccurrence","Biological Networks","Ecological Networks","Ecological Network Inference","Macroecology","Method Comparison","Network Topology","Spatial Scale","Species Associations"],"title":"Ecological network inference is not consistent across sales or approaches","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1654513200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654513200,"objectID":"781124f9795efc70de162cc5817b2083","permalink":"https://www.erikkusch.com/talk/2022_06_oikos/","publishdate":"2022-02-24T00:00:00Z","relpermalink":"/talk/2022_06_oikos/","section":"talk","summary":"A practical guide to the `KrigR` package.","tags":["Statistical Downscaling","Climate Data","KrigR"],"title":"KrigR - Climate Data for your Study Needs","type":"talk"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1654513200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654513200,"objectID":"3831d5cb51ec7fd51287bbbfe20693fa","permalink":"https://www.erikkusch.com/talk/2022_05_clim4ecol/","publishdate":"2022-02-24T00:00:00Z","relpermalink":"/talk/2022_05_clim4ecol/","section":"talk","summary":"Another comprehensive overview of the `KrigR` package.","tags":["Statistical Downscaling","Climate Data","KrigR"],"title":"KrigR — A tool for downloading and statistically downscaling climate reanalysis data","type":"talk"},{"authors":["Erick Lundgren","Daniel Ramp","Owen Middleton","Eamonn Wooster","Erik Kusch","Mairin Balisi","William Ripple","Chris Hasselerharm","Jessica Sanchez","Mystyn Mills","Arian Wallach"],"categories":null,"content":"","date":1653264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653264000,"objectID":"62673756397c00ac67d8bb93378a2bb0","permalink":"https://www.erikkusch.com/publication/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/","publishdate":"2022-05-23T00:00:00Z","relpermalink":"/publication/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/","section":"publication","summary":"Analysis of spatio-temporal behaviour of donkeys and other grazers in response to predation by cougars.","tags":["Predation","Trophic Cascade"],"title":"A novel trophic cascade between cougars and feral donkeys shapes desert wetlands","type":"publication"},{"authors":["Erick Lundgren","Daniel Ramp","Owen Middleton","Eamonn Wooster","Erik Kusch","Mairin Balisi","William Ripple","Chris Hasselerharm","Jessica Sanchez","Mystyn Mills","Arian Wallach"],"categories":null,"content":"","date":1653264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653264000,"objectID":"370eefb10d1e2ac165ac6a052606357c","permalink":"https://www.erikkusch.com/publication/journal-article/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/","publishdate":"2022-05-23T00:00:00Z","relpermalink":"/publication/journal-article/a-novel-trophic-cascade-between-cougars-and-feral-donkeys-shapes-desert-wetlands/","section":"publication","summary":"Analysis of spatio-temporal behaviour of donkeys and other grazers in response to predation by cougars.","tags":["Predation","Trophic Cascade"],"title":"A novel trophic cascade between cougars and feral donkeys shapes desert wetlands","type":"publication"},{"authors":["Erik Kusch","Richard Davy","Alistair Seddon"],"categories":null,"content":"","date":1649808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649808000,"objectID":"70913807faa5709591444e34f7fefc34","permalink":"https://www.erikkusch.com/publication/journal-article/vegetation-memory-effects-and-their-association-with-vegetation-resilience-in-global-drylands/","publishdate":"2022-04-13T00:00:00Z","relpermalink":"/publication/journal-article/vegetation-memory-effects-and-their-association-with-vegetation-resilience-in-global-drylands/","section":"publication","summary":"Expanding on my M.Sc. thesis by applying my vegetation memory framework to global drylands.","tags":["Vegetation Memory","Resilience","Remote Sensing","Drylands"],"title":"Vegetation memory effects and their association with vegetation resilience in global drylands","type":"publication"},{"authors":["Erik Kusch","Richard Davy","Alistair Seddon"],"categories":null,"content":"","date":1649808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649808000,"objectID":"d846945e81214bebbd963fb5a02f92d7","permalink":"https://www.erikkusch.com/publication/vegetation-memory-effects-and-their-association-with-vegetation-resilience-in-global-drylands/","publishdate":"2022-04-13T00:00:00Z","relpermalink":"/publication/vegetation-memory-effects-and-their-association-with-vegetation-resilience-in-global-drylands/","section":"publication","summary":"Expanding on my M.Sc. thesis by applying my vegetation memory framework to global drylands.","tags":["Vegetation Memory","Resilience","Remote Sensing","Drylands"],"title":"Vegetation memory effects and their association with vegetation resilience in global drylands","type":"publication"},{"authors":["Connor Bernard","Gabriel Silva Santos","Jacques Deere","Roberto Rodriguez-Caro","Pol Capdevila","Erik Kusch","Samuel J L Gascoigne","John Jackson","Roberto Salguero-Gómez"],"categories":null,"content":"","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647216000,"objectID":"0ca0de448adf538d9c298b63bfa73cac","permalink":"https://www.erikkusch.com/publication/in-review/mosaic-a-unified-trait-database-to-complement-structured-population-models/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/publication/in-review/mosaic-a-unified-trait-database-to-complement-structured-population-models/","section":"publication","summary":"Integration of multiple demographic data bases into one easily accessible one-stop-shop for your demographic needs.","tags":["Data Base","Demography"],"title":"MOSAIC - A Unified Trait Database to Complement Structured Population Models","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1645700400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645700400,"objectID":"758fc82c296f141f2ac12a31467700c9","permalink":"https://www.erikkusch.com/talk/2022_02_climate-coffee/","publishdate":"2022-02-24T00:00:00Z","relpermalink":"/talk/2022_02_climate-coffee/","section":"talk","summary":"A comprehensive overview of the `KrigR` package.","tags":["Statistical Downscaling","Climate Data","KrigR"],"title":"Climate Data Pipelines for the 21st Century - Efficient Data Retrieval and Processing","type":"talk"},{"authors":["Erik Kusch","Richard Davy"],"categories":null,"content":"","date":1641513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641513600,"objectID":"d6bad3a9de2da327a42c3430cba42242","permalink":"https://www.erikkusch.com/publication/journal-article/krigr-a-tool-for-statistically-downscaling-climate-reanalysis-data-for-ecological-applications/","publishdate":"2022-01-07T00:00:00Z","relpermalink":"/publication/journal-article/krigr-a-tool-for-statistically-downscaling-climate-reanalysis-data-for-ecological-applications/","section":"publication","summary":"An R Package aimed at end-users of state-of-the-art climate reanalysis data to streamline retrieval, pre-processing, and statistical interpolation of ERA5(-Land) data.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"KrigR – A tool for downloading and statistically downscaling climate reanalysis data","type":"publication"},{"authors":["Erik Kusch","Richard Davy"],"categories":null,"content":"","date":1641513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641513600,"objectID":"1800d84cbc01023ac92b9d6df543f08b","permalink":"https://www.erikkusch.com/publication/krigr-a-tool-for-statistically-downscaling-climate-reanalysis-data-for-ecological-applications/","publishdate":"2022-01-07T00:00:00Z","relpermalink":"/publication/krigr-a-tool-for-statistically-downscaling-climate-reanalysis-data-for-ecological-applications/","section":"publication","summary":"An R Package aimed at end-users of state-of-the-art climate reanalysis data to streamline retrieval, pre-processing, and statistical interpolation of ERA5(-Land) data.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"KrigR – A tool for downloading and statistically downscaling climate reanalysis data","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1639393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639393200,"objectID":"a38315d9adce0031d0709f04dfbda663","permalink":"https://www.erikkusch.com/talk/2021_12_bes/","publishdate":"2021-12-13T00:00:00Z","relpermalink":"/talk/2021_12_bes/","section":"talk","summary":"A look at initial results of my second PhD chapter.","tags":["Biological Networks","Resilience"],"title":"Data Simplification  for Ecological Network Inference","type":"talk"},{"authors":["Richard Davy","Erik Kusch"],"categories":null,"content":"","date":1637020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637020800,"objectID":"579ce382b06b3cc032f6910bb565077c","permalink":"https://www.erikkusch.com/publication/journal-article/reconciling-high-resolution-climate-datasets-using-krigr/","publishdate":"2021-11-16T00:00:00Z","relpermalink":"/publication/journal-article/reconciling-high-resolution-climate-datasets-using-krigr/","section":"publication","summary":"Exploration of the usage of KrigR and implications for the wider field of climate data products for the use in Life Science research.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Reconciling high resolution climate datasets using KrigR","type":"publication"},{"authors":["Richard Davy","Erik Kusch"],"categories":null,"content":"","date":1637020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637020800,"objectID":"393a912ea9bf490e32282f2ef07610d1","permalink":"https://www.erikkusch.com/publication/reconciling-high-resolution-climate-datasets-using-krigr/","publishdate":"2021-11-16T00:00:00Z","relpermalink":"/publication/reconciling-high-resolution-climate-datasets-using-krigr/","section":"publication","summary":"Exploration of the usage of KrigR and implications for the wider field of climate data products for the use in Life Science research.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"Reconciling high resolution climate datasets using KrigR","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1631203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631203200,"objectID":"d8a298e6200c83fb4a76c264d08fafec","permalink":"https://www.erikkusch.com/talk/2021_09_statisticaleducation/","publishdate":"2021-09-09T00:00:00Z","relpermalink":"/talk/2021_09_statisticaleducation/","section":"talk","summary":"My personal musings on statistical education for biologists.","tags":["Statistics","Biostatistics","Teaching","Education","R","Coding"],"title":"Statistical Education for Biologists","type":"talk"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1625738400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625738400,"objectID":"24fdda7432e421733f79ad2ac5b9c1d1","permalink":"https://www.erikkusch.com/talk/2021_07_salgoteam/","publishdate":"2021-07-08T00:00:00Z","relpermalink":"/talk/2021_07_salgoteam/","section":"talk","summary":"Some of my ideas for how to improve coding practices that I presented to the SalGo-Team.","tags":["Coding","R"],"title":"Coding Practices in R","type":"talk"},{"authors":["Erik Kusch"],"categories":null,"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"0330ee6990b8fadecc79e1fcc13bf981","permalink":"https://www.erikkusch.com/courses/an-introduction-to-biostatistics/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/an-introduction-to-biostatistics/","section":"courses","summary":"Lectures and seminars for B.Sc. students of biology which should serve as an introduction to the basics of biostatistics using `R`.","tags":["Statistics"],"title":"An Introduction to Biostatistics","type":"courses"},{"authors":["Erik Kusch"],"categories":null,"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"70e7a83c792d11760e555531df35a309","permalink":"https://www.erikkusch.com/courses/bayes-nets/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/bayes-nets/","section":"courses","summary":"An exploration of bayesian networks as a tool for identification of causal relationships.","tags":["Bayes","Networks","Bayesian Statistics","Statistics"],"title":"Bayesian Networks","type":"courses"},{"authors":["Erik Kusch"],"categories":null,"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"79b37065425f8d1f087e2bad0b4eaf0e","permalink":"https://www.erikkusch.com/courses/bftp-biome-detection/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/bftp-biome-detection/","section":"courses","summary":"First steps in macroecological analyses in `R` using cluster analyses on remote sensing data and tracking shifting biomes through time.","tags":["Statistics"],"title":"BFTP - Biome Detection through Remote Sensing","type":"courses"},{"authors":["Erik Kusch"],"categories":null,"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"39167f68e53c8745d953f4aa6989a0dc","permalink":"https://www.erikkusch.com/courses/biostat101/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/biostat101/","section":"courses","summary":"BioStat 101 material which ought to serve as an introduction to the basics of biostatistics using `R` for B.Sc. students of biology.","tags":["Statistics"],"title":"BioStat 101 - An Introduction to Biostatistics","type":"courses"},{"authors":["Erik Kusch"],"categories":null,"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f3339b1f2ab2f96fa04441f3d6161e8","permalink":"https://www.erikkusch.com/courses/excursions-into-biostatistics/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/excursions-into-biostatistics/","section":"courses","summary":"A collection of talks predominantly aimed at M.Sc. students and related to general topics of biostatistical concern I have given throughout the years.","tags":["Statistics"],"title":"Excursions into Biostatistics","type":"courses"},{"authors":["Erik Kusch"],"categories":["KrigR","Climate Data"],"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"8a7f5583d5bc1d038968f975ee185983","permalink":"https://www.erikkusch.com/courses/krigr/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/krigr/","section":"courses","summary":"Workshop material for getting started and becoming adept at using the `R` Package `KrigR` which provides a flexible and easy-to-use workflow for state-of-the-art climate data practices.","tags":["Climate Data","Statistical Downscaling","KrigR"],"title":"KrigR Workshop","type":"courses"},{"authors":["Erik Kusch"],"categories":null,"content":"If you are seeing this page, something went awry in the build of the website. Please find the first course material for this course here.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"5717ed8810f5e94cabfc4a5787edc982","permalink":"https://www.erikkusch.com/courses/rethinking/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/rethinking/","section":"courses","summary":"An introduction to Bayesian statistics through summaries and solutions to exercises contained in the Statistical Rethinking material by Richard McElreath.","tags":["Statistics","Bayes","Bayesian Statistics"],"title":"Statistical Rethinking","type":"courses"},{"authors":["Erik Kusch"],"categories":null,"content":"Disclaimer This project is currently on hold.\nMotivation Throughout my previous project concerning Vegetation Memory across Global Dryland Regions, I identified prominent spatial patterns of intrinsic and extrinsic vegetation memory components. These patterns may serve us in discerning global and local resistance and recovery potential of vegetation communities to perturbations.\nHowever, these patterns alone only tell part of the story. How do these come about? How are they maintained? Understanding these mechanisms would undoubtedly go a long way in predicting responses of vegetation to anthropogenic and climate change-driven disturbances. Ultimately, I expect this exercise to create valuable knowledge for conservation biology and the agricultural sector.\nDescription MODIS EVI data is aggregated at bi-weekly intervals and used as a proxy of vegetation response in the dryland study regions between January 2000 and December 2019. Independent climate data is provided using the KrigR package (\rKrigR - Downloading and Downscaling of ERA5(-Land) data using R). Doing so allows us to make use of the high temporal resolution of the European Centre for Medium-range Weather Forecasts ReAnalysis 5 (ERA5) data from the European Centre for Medium-Range Weather Forecasts (ECMWF) at spatial resolutions of roughly 1x1km. Effectively, this increases the spatial resolution of vegetation memory products by almost one order of magnitude when compared to my previous project at 9x9km resolution. Vegetation memory is calculated the same way as during my previous project.\nUsing these high-resolution vegetation memory products, we can reasonably argue that ground-data obtained through functional trait campaigns or vegetation plot exercises represents the 1x1km grid reasonably well. Thus we are able to assess correlations between the different vegetation components and ground-truthed expressions of plant life. To identify what shapes vegetation memory expressions, I am investigating a range of three potential predictor families:\n Plant Functional Traits - I expect investment in certain functional characteristics to greatly influence resistance and recovery potential. For example, sturdy leaves should grant resistance to temperature fluctuations but are costly to recover once lost. Life History Traits - Life history speed and timing undoubtedly alters vegetation memory expressions. But which life history traits fair best at explaining these processes? For example, a short-lived population may be less resistant to a perturbation than a long-lived one, but surely boasts a reproduction rate that achieves fast recovery. Abiotic Legacies - Biological organisms adapt to their surroundings. On varying time-scales and through varying processes, but they adapt nonetheless. I aim to investigate how strong these adaptations become by computing the impact of the legacy mean and standard deviation of abiotic conditions on vegetation memory components. For example, a species in a highly variable aridity regime may be more resistant to fluctuations in aridity than one used to stable, moist conditions  ","date":1609200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609200000,"objectID":"5e183699f2a9fd7e3b411c0526959a7b","permalink":"https://www.erikkusch.com/project/functional-traits-and-life-history-effects-on-high-resolution-vegetation-memory/","publishdate":"2020-12-29T00:00:00Z","relpermalink":"/project/functional-traits-and-life-history-effects-on-high-resolution-vegetation-memory/","section":"project","summary":"Throughout this project, I aim to identify underlying causes - biological and abiotic - to the striking patterns of vegetation memory I identified in a previous project.","tags":["Resilience","Life History","Functional Traits","Statistical Downscaling","Archived"],"title":"Causes and Processes of Dryland Vegetation Memory","type":"project"},{"authors":["Erik Kusch"],"categories":null,"content":"My PhD project was a part of the greater BIORATES project.\nMotivation Species rarely occur in isolation. Instead, they assemble into multi-species communities wherein individuals interact within and across species groups. These pairwise species interactions affect responses of biological communities to environmental conditions and perturbations. To understand and forecast changes within the Ecosphere, it is thus vital to quantify such interactions and explore their implications. Changes in pairwise species interactions are largely spurred by processes of the Anthropocene (e.g., changes in temperature, habitat availability). These affect entire ecosystems simultaneously thus necessitating the exploration of biological interactions at macroecological scales. Despite the complexity of biological interactions and the networks they form at macroecological scales, their study can be carried out readily via ecological networks.\nHere, I develop methodology and carry out analyses to address (1) the failure of contemporary macroecological research to incorporate state-of-the-art climate data by updating macroecological research practices, (2) the implications of mechanisms of extinction cascades within ecological networks with respect to interaction magnitude and potential/realised interactions thus using ecological networks as forecast tools, and finally (3) the lack of ecological network quantification at macroecological scales by inferring biological interactions from proxies.\nWork Packages Chapter 1 - Updating Macroecological Research Practices Environmental conditions which regulate species distributions determine whether pairwise biological interactions can be realised (i.e., species which do not coincide cannot directly interact). Furthermore, changes in abiotic conditions alter the expression of realised interactions. Therefore, it is crucial to explicitly consider environmental conditions when quantifying and forecasting biological interactions, particularly at macroecological scales which are characterized by prominent environmental heterogeneity (e.g. thermal gradients). However, macroecological research, at present, does not leverage the most recent and accurate climate data products available. Therefore, we require changes to macroecological research practices to integrate state-of-the-art climate data.\nTo resolve this issue, I have developed the KrigR R package which provides an easy-to-use and highly flexible infrastructure for access, temporal aggregation, spatial limitation, and statistical downloading of state of the art climate data from ECMWF. The resulting data products outperform legacy data products commonly used in macroecological research in (1) temporal resolution, (2) data accuracy, (3) provisioning of climate variables, (4) flexibility, and (5) applicability to specific research requirements.\nThis work has been published in Kusch \u0026amp; Davy, 2022 and Davy \u0026amp; Kusch, 2021. Due to the ongoing development of KrigR, I have transferred any ongoing work on these issues to the KrigR project\nChapter 2 - Using Ecological Networks as Forecast Tools Biological interactions range in identity (i.e, present, absent), sign (i.e., positive and negative), and magnitude which determine the importance of an interaction for the persistence of interacting species and entire communities. This impact manifests especially through extinction cascades which exacerbate the biodiversity loss and change of network topologies spurred by Anthropogenic impacts. Such cascades are characterized by the loss of biological interactions following the extinction of a species leading to additional species extinctions. Thus, to forecast future community structures and quantify risk to ecosystem stability and functioning, it is vital to consider both the potential for and sign as well as magnitude of species interactions. Flexible and easy-to-use methodology for this purpose is currently lacking. Consequently, exploration of extinction cascades has remained simplistic and ought to be updated to facilitate the exploration of realistic future scenarios of the Ecosphere.\nIn addressing this knowledge gap, I have co-developed the NetworkExtinction R package which enables simulations of extinction cascades within trophic as well as mutualistic networks with varying levels of link-importance and realisation of potential interactions. Using this tool, I subsequently explore network resilience landscapes defined by link-loss sensitivity and rewiring probability thresholds for a collection of empirical mutualistic networks across the Earth.\nThe NetworkExtinction package has been published as Ávila-Thieme \u0026amp; Kusch et. al, 2023 while the exploration of mutualistic network resilience landscapes (\rKusch, Ordonez) is currently being prepared for submission.\nChapter 3 - Inferring Biological Interactions from Proxies Ecological networks are affected by the scales (e.g., local, regional, and continental) at which they are represented. Thus, locally quantified biological interactions cannot be used reliably to represent macroecological processes. However, sourcing networks at macroecological scales via traditional in-situ observations is prohibitively labour-intensive thus requiring the inference of biological interactions from macroecological proxies. However, the accuracy of already established biological interaction inference approaches remains understudied, calling into question their utility. Therefore, consistency and performance of interaction inference ought to be evaluated for use at macroecological scales.\nWithin this final chapter of my PhD, I assess the consistency of four different interaction inference approaches (COOCCUR, NETASSOC, HMSC, and NDD-RIM) across ecologically relevant skills. Finding little consistency between the inferred ecological networks, I subsequently develop a demographic simulation framework of populations of interacting species across time and space and establish guidelines for assessment of ecological network inference performance.\nWhile the study of inference consistency is already submitted for review as Kusch et. al, 2023, a publication of Kusch \u0026amp; Vinton is to follow presenting the simulation framework.\nImplications To ensure ecosystem management and conservation efforts are targeted appropriately under climate change, my work highlights that macroecological research practices ought to undergo a paradigm shift away from one-size-fits-all climate datasets towards reproducible and flexible data workflows for generation of climate datasets with respect to specific study purposes and requirements. Additionally, my explicit integration of ecological network resilience mechanisms towards extinction cascades reveals that contemporary approaches are likely overly optimistic in their projections of biodiversity loss throughout the Anthropocene. Lastly, I caution against naive use of ecological network inference within macroecological research. Instead, to render knowledge of ecological networks at macroecological scales, I argue that extensive assessments of network inference performance are required for which I present important groundwork.\nUltimately, my dissertation represents a key advancement of use-cases of ecological networks at macroecological scales. Thus, adopting the novel methodology I have developed for macroecological use and inference of ecological networks is pressing in order to ensure adequate ecosystem management throughout the Anthropocene.\n","date":1609113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609113600,"objectID":"a31659fa881e85d881535a8074f6ece9","permalink":"https://www.erikkusch.com/project/phd-packages/","publishdate":"2020-12-28T00:00:00Z","relpermalink":"/project/phd-packages/","section":"project","summary":"My PhD project and its working packages.","tags":["Biological Networks","Macroecology","Resilience","Climate Data","Active","PhD"],"title":"A Macroecological Perspective to Ecological Networks","type":"project"},{"authors":["Erik Kusch"],"categories":null,"content":"\rThis study group has come to an end. All information about it can still be found below. We are now coordinating through Slack to get our fix of all things Bayes. Our Slack Workspace is open to anyone who wants to join us. To do so, simply let me know by contacting me and shortly introduce yourself.\r\r\rMotivation Have you ever read a paper and thought: “Wow, this is really cool”, then read on only to find the word “Bayesian” in the analysis specification and promptly get lost at the terminology and approach to statistics?\nIf you did/do, you are obviously not alone and I think it might be time we do something about it. To this end, I have created a Bayes Study Group (formerly AU Bayes Study Group) within which we work our way through (1) a lecture series by Bayes Wunderkind Richard McElreath, (2) his corresponding book (“\rStatistical Rethinking”), and (3) a few practical examples in R.\nConduct \u0026amp; Logistics Below, you will find a few key facts outlining how this Bayes Study Group sessions are run. You will find that what we do is quite a lot (I would like to think it quite exhaustive, actually). We are following the example set by some colleagues at the University of Oxford here and I have added some extra bits to the material and schedule. Go big or go home, right?\nThat being said, I realise that what I propose is quite a big-time commitment – both in per-week hours and for how long this study group is supposed to run.\nMeetings:  Scheduling:  Friday 1300-1600 GMT+1 (sessions end earlier if we are done earlier, of course) Weekly for 20 sessions including 4 input talks by practicioneers of Bayesian analyses    Contents  We follow the material noted further down under Group Material We prepare ourselves by working through the material noted for each session At the start of each session, either me or a volunteer quickly presents a summary of the preparation material. This does not mean a presenter should have mastered the material at all – simply be able to provide a red-thread through the contents and get a discussion going. We then go into questions/challenges concerning the material, practical examples, and personal implementations.  Material  Lecture Recording “Statistical Rethinking” by Richard McElreath; available here Book “Statistical Rethinking” by Richard McElreath; available here Practical Examples:  Course Material Statistical Rethinking Book “Introduction to WinBUGS for Ecologists” by Marc Kéry; available here Book “Bayesian Population Analysis using WinBUGS” by Marc Kéry and Michael Schaub; available here   Further Input (all prospective)  ","date":1609113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609113600,"objectID":"3fd2d359bb16fa68f8da504f680c0c6a","permalink":"https://www.erikkusch.com/project/aubayes/","publishdate":"2020-12-28T00:00:00Z","relpermalink":"/project/aubayes/","section":"project","summary":"I have established and run a group-exercise for learning Bayesian Statistics from the ground up with an assortment of colleagues. This group was run through zoom and open to anyone.","tags":["Statistics","Bayes","Bayesian Statistics","Statistical Rethinking","Archived"],"title":"Bayes Study Group","type":"project"},{"authors":["Erik Kusch"],"categories":null,"content":"\rThis study group has come to an end. All information about it can still be found below. We are now coordinating through Slack to get our fix of all things Bayes. Our Slack Workspace is open to anyone who wants to join us. To do so, simply let me know by contacting me and shortly introduce yourself.\r\r\rMotivation Building on the success of the Bayes Study Group I ran two years ago, I have decided to create another study group this time focusing on explicit inference and analysis of Bayesian Networks which I believe are a neat tool for hypothesis testing.\nConduct \u0026amp; Logistics Below, you will find a few key facts outlining how this Bayesian Network Study Group sessions are run. You will find that what we do is quite a lot (I would like to think it quite exhaustive, actually).\nThat being said, I realise that what I propose is quite a big-time commitment – both in per-week hours and for how long this study group is supposed to run.\nMeetings:  Scheduling:  Tuesday 1500-1700 CEST (sessions end earlier if we are done earlier, of course) Weekly for 8 sessions    Contents  We follow the material noted further down under Group Material We prepare ourselves by working through the material noted for each session the proposed schedule At the start of each session, either me or a volunteer quickly presents a summary of the preparation material. This does not mean a presenter should have mastered the material at all – simply be able to provide a red-thread through the contents and get a discussion going. We then go into questions/challenges concerning the material, practical examples, and personal implementations.  Material  Book “Bayesian Networks With Examples in R” by Marco Scutari \u0026amp; Jean-Baptiste Denis; available here Book “Bayesian Networks in R with Applications in Systems Biology” by Radhakrishnan Nagarajan, Marco Scutari \u0026amp; Sophie Lèbre; available here  ","date":1609113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609113600,"objectID":"f135e2a4ca4389dabd61baca5b8433b2","permalink":"https://www.erikkusch.com/project/bayesnets/","publishdate":"2020-12-28T00:00:00Z","relpermalink":"/project/bayesnets/","section":"project","summary":"I have established and am running a group-exercise for learning Bayesian Network methdology and inference from the ground up with an assortment of colleagues. This group is run through zoom and open to anyone.","tags":["Archived","Statistics","Bayes","Bayesian Statistics","Bayesian Networks","Biological Networks","Networks"],"title":"Bayesian Networks Study Group","type":"project"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1609113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609113600,"objectID":"50c244e3a88fd2109475b2fdc36c32b5","permalink":"https://www.erikkusch.com/project/biorates/","publishdate":"2020-12-28T00:00:00Z","relpermalink":"/project/biorates/","section":"project","summary":"My PhD project is a part of this greater research framework within which my colleagues and I investigate how species compositions and interactions are shaped.","tags":["Biological Networks","Resilience","PhD","Archived"],"title":"BIOlogical response RATES to current rates of environmental changes","type":"project"},{"authors":["Erik Kusch"],"categories":null,"content":"\rI am continuing to develop KrigR, add to its functionality, and broaden its scope. For any suggestions of development goals, novel functionality as well as any issues you might face with KrigR, please register an issue on GitHub. where I track these issues. Please refrain from inquiries via direct E-mail.\r\r\rMotivation Contemporary studies of remote sensing and macroecology largely rely on legacy climate data which is surpassed by state-of-the-art climate reanalysis data sets such as the European Centre for Medium-range Weather Forecasts ReAnalysis 5 (ERA5) data catalogue which represents the forefront of advances in data assimilation and climate modelling.\nUsing these data sets within R – the most prominent statistical software in macroecology – is a complicated task that involves downloading of data via shell scripts, reformatting of coordinate system, and might even require rescaling of the climate data.\nIn order to make the use of ERA5(-Land) in future analyses more streamlined, I am developing an R Package (KrigR) which will handle downloading and reformatting of ERA5(-Land) data. Furthermore, this package offers rescaling capabilities via the Kriging functionality of the automap package whilst enabling multi-core processing for faster computation of time-series data.\nDescription The superiority of ERA5(-Land) data over legacy data sets is largely due to:\n The volume of observational data used to create the ERA5 product. This includes a large volume of satellite data, ground-based weather station/independent institute data collection efforts, and other station data from a wide variety of data providers. This is in contrast to gridded observational datasets which are often characterised by their individual biases in sampling, coverage, and choice of interpolation and homogenization to create a gridded product. The advances in data assimilation procedures. Data assimilation for geophysical application has greatly developed as a field in recent decades. This has included fundamental methodological advancements, such as the development of the ensemble Kalman filter, as well developments specific to geophysical application of data assimilation, such as approaches to localisation. The complexity of the underlying models. Reanalysis products have been widely used to shed light on physical processes. ERA5 was created using the ECMWF’s integrated forecasting system which is the world’s best forecast model and is continuously developed using the latest understanding of the physics of the climate system.  KrigR is a tool to streamline and standardise the implementation of state-of-the-art ERA5(-Land) data and time series in large-scale analyses. As such, the R Package includes the following functionality:\n Download functions for:  ERA5(-Land) data GMTED2010 covariate data (kriging will not be limited to GMTED2010 alone)   Preprocessing of ERA5(-Land) data Statistical downscaling of ERA5(-Land) data using kriging methodology Selection of regions by shapefiles or extents Variable list with guidelines for statistical downscaling (this is currently being developed)  KrigR downloads ERA5(-Land) upon having been provided with the required ECMWF API key and includes several self-checking statements to avoid the most common issues with the kriging methodology.\nUsers are be able to start the process of the KrigR workflow at any given function of the package, but it is recommended to let KrigR handle the entire workflow as intended.\n","date":1609113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609113600,"objectID":"a5313ba113824e6218e7b8befa26b761","permalink":"https://www.erikkusch.com/project/krigr/","publishdate":"2020-12-28T00:00:00Z","relpermalink":"/project/krigr/","section":"project","summary":"An `R` package designed for intuitive downloading, aggregating, and statistical downscaling of ERA5(-Land) data.","tags":["Climate Data","Statistical Downscaling","KrigR","PhD","Active"],"title":"KrigR - Downloading and Downscaling of ERA5(-Land) data using R","type":"project"},{"authors":["Erik Kusch"],"categories":null,"content":"Motivation Vegetation memory describes the effect of antecedent environmental and ecosystem states on ecosystem state in the present and has been used as an important proxy for ecosystem recovery rates potentially a key component of vegetation resilience, at a global scale. In particular, strong vegetation memory effects have been identified in dryland regions coinciding with decreased vegetation sensitivity towards climatological drivers.\nHere, we aim to test the components and drivers of vegetation memory in dryland regions using state-of the-art climate reanalysis data and refined approaches to identify vegetation-memory characteristics across global dryland regions. We show that (1) dryland regions are characterised by strong vegetation memory (intrinsic and extrinsic), (2) it is possible to distinguish intrinsic and extrinsic vegetation memory to a hitherto unachieved degree using climate reanalysis data sets, (3) the link between intrinsic vegetation memory and resilience may be an oversimplification, and (4) dryland vegetation does not react to bioclimatic forcing in the same way across the Earth.\nDescription GIMMS NDVI 3g data was used as a proxy of vegetation response in the dryland study regions between January 1982 and December 2015. The NDVI is a compound vegetation index made up from reflectance in the red and near-infrared reflectance bands. For independent climate data in this study, we used European Centre for Medium-range Weather Forecasts ReAnalysis 5 (ERA5) data from the European Centre for Medium-Range Weather Forecasts (ECMWF). ERA5 data is available for hourly intervals (which we assembled to monthly time steps) from 1950 to present day at a 30km × 30km spatial resolution of global coverage making the resolution of ERA5 and AVHRR-based GIMMS NDVI 3g incompatible. We resolved this issue by statistically downscaling ERA5 data using the kriging methodology (KrigR package of my KrigR - Downloading and Downscaling of ERA5(-Land) data using R project).\nTo assess the relative importance of intrinsic memory and extrinsic climate forcing we used a linear modelling approach akin to DeKeersmaecker et al, 2015. We use NDVI anomalies on a one-month lag, air temperature (Tair) and soil moisture (Qsoil) data on different temporal lags to model anomalies of monthly NDVI values over three decades. Due to issues of multi-collinearity, we do so using a principal component regression approach.\nThe results contain information about relative importance of vegetation memory components, their temporal lags,and are presented in the context of contemporary vegetation memory and sensitivity literature.\nOur findings demonstrate novel observations of vegetation memory patterns across dryland regions such as regional differences of processes forming vegetation memory capabilities. Consequently, this study provides a helpful stepping stone for refining and combining already existing methodology which could, in turn, generate important knowledge of ecosystem functioning and resilience.\n","date":1609113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609113600,"objectID":"0be035c23e0d37c41e8334032dc141a9","permalink":"https://www.erikkusch.com/project/vegetation-memory-across-global-dryland-regions/","publishdate":"2020-12-28T00:00:00Z","relpermalink":"/project/vegetation-memory-across-global-dryland-regions/","section":"project","summary":"Vegetation memory has been proposed as a proxy for ecosystem resilience. Here, I investigate how well this proxy captures processes of vegetation performance.","tags":["Resilience","Statistical Downscaling","KrigR","Archived"],"title":"Vegetation Memory across Global Dryland Regions","type":"project"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1607011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607011200,"objectID":"edb11bcb8338379b5c099b324458ae19","permalink":"https://www.erikkusch.com/talk/2020_12_salgoteam/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2020_12_salgoteam/","section":"talk","summary":"A presentation of my PhD plans to the SalGo-Team.","tags":["Biological Networks"],"title":"Species Associations Across Scales of Organisation","type":"talk"},{"authors":["Erik Kusch","Richard Davy"],"categories":null,"content":"","date":1605186000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605186000,"objectID":"2c43f9c7dd08a445bf41b9ef6cb6d686","permalink":"https://www.erikkusch.com/talk/2020_11-krigrworkshop/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2020_11-krigrworkshop/","section":"talk","summary":"A web-based workshop to introduce the `R`-Package `KrigR` which introduces intuitive downloading and downscaling methods for ERA5(-Land) climate reanalysis data to `R`-users.","tags":["Statistical Downscaling","Climate Data","KrigR"],"title":"KrigR - Downscaling State-of-the-Art Climate Data for Macroecologists","type":"talk"},{"authors":["Erik Kusch","Richard Davy","Roberto Salguero-Gómez","Alistair Seddon"],"categories":null,"content":"","date":1593082800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593082800,"objectID":"07124df1a3fd1abcc503c4f2d1351a1b","permalink":"https://www.erikkusch.com/talk/2020_06_isec_poster/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2020_06_isec_poster/","section":"talk","summary":"A poster about my recent vegetation memory in global dryland research I presented at ISEC 2020.","tags":["Vegetation Memory","Resilience","Statistical Downscaling"],"title":"Intrinsic vegetation memory as a proxy of engineering resilience may be an oversimplification.","type":"talk"},{"authors":["Erik Kusch","Richard Davy"],"categories":null,"content":"","date":1593081000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593081000,"objectID":"29a5b3dc87cc909d3939ba9b1729c3bf","permalink":"https://www.erikkusch.com/talk/2020_06_isec_presentation/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2020_06_isec_presentation/","section":"talk","summary":"A short introduction talk to my `R`-Package `KrigR` in its early development.","tags":["Statistical Downscaling","Climate Data","KrigR"],"title":"KrigR - Climate Data for Your Spatial Study","type":"talk"},{"authors":["Erik Kusch","Richard Davy","Roberto Salguero-Gómez","Alistair Seddon"],"categories":null,"content":"","date":1570194000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570194000,"objectID":"577a7b2bd7f69dcd78cd7e0dfcd4d27a","permalink":"https://www.erikkusch.com/talk/2010_09_isem_talk/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2010_09_isem_talk/","section":"talk","summary":"A presentation about my recent vegetation memory in global dryland research I presented and won some awards for at ISEM 2019.","tags":["Vegetation Memory","Resilience","Statistical Downscaling"],"title":"Identifying Ecological Memory Patterns in Drylands Using Remote Sensing and State-of-the-art Climate Reanalysis Products","type":"talk"},{"authors":["Erik Kusch","Richard Davy","Roberto Salguero-Gómez","Alistair Seddon"],"categories":null,"content":"","date":1570100400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570100400,"objectID":"e98f4340fb9bef03093740f866a88d1b","permalink":"https://www.erikkusch.com/talk/2010_09_isem_poster/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2010_09_isem_poster/","section":"talk","summary":"A poster about my recent vegetation memory in global dryland research I presented and won some awards for at ISEM 2019.","tags":["Vegetation Memory","Resilience","Statistical Downscaling"],"title":"Intrinsic vegetation memory as a proxy of engineering resilience may be an oversimplification.","type":"talk"},{"authors":["Erik Kusch","Richard Davy","Roberto Salguero-Gómez","Alistair Seddon"],"categories":null,"content":"","date":1562329800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562329800,"objectID":"5686cf25eb2be2f21f777e387ac4acd8","permalink":"https://www.erikkusch.com/talk/2019_mscdefense/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2019_mscdefense/","section":"talk","summary":"The defense of my [M.Sc](/publication/journal-article/m.sc._inferring-vegetation-memory-from-remote-copy/) thesis.","tags":["Vegetation Memory","Resilience","Statistical Downscaling"],"title":"Inferring Vegetation Memory from Remote Sensing Data using novel Climate Reconstruction Products","type":"talk"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1558224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558224000,"objectID":"9bcb90cc17b8816ce89ef1ac86984037","permalink":"https://www.erikkusch.com/publication/journal-article/m.sc._inferring-vegetation-memory-from-remote-copy/","publishdate":"2019-05-19T00:00:00Z","relpermalink":"/publication/journal-article/m.sc._inferring-vegetation-memory-from-remote-copy/","section":"publication","summary":"My M.Sc. thesis at the University of Bergen.","tags":["Vegetation Memory","Resilience","Remote Sensing","Drylands"],"title":"Inferring Vegetation Memory from Remote Sensing Data using novel Climate Reconstruction Products","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1558224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558224000,"objectID":"0ae069f647b2df63aa7c731fc1934450","permalink":"https://www.erikkusch.com/publication/m.sc._inferring-vegetation-memory-from-remote-copy/","publishdate":"2019-05-19T00:00:00Z","relpermalink":"/publication/m.sc._inferring-vegetation-memory-from-remote-copy/","section":"publication","summary":"My M.Sc. thesis at the University of Bergen.","tags":["Vegetation Memory","Resilience","Remote Sensing","Drylands"],"title":"Inferring Vegetation Memory from Remote Sensing Data using novel Climate Reconstruction Products","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1489104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489104000,"objectID":"7d50b47fd617a77fa7a9943f46720571","permalink":"https://www.erikkusch.com/publication/b.sc._inferring-vegetation-memory-from-remote/","publishdate":"2017-03-10T00:00:00Z","relpermalink":"/publication/b.sc._inferring-vegetation-memory-from-remote/","section":"publication","summary":"My B.Sc. thesis at the Technical University of Dresden and University of Bergen.","tags":["Resilience","Biome Shifts","Remote Sensing"],"title":"Remote Sensing And Predicting Shifts In Biome Distribution And Resilience Using NDVI Data","type":"publication"},{"authors":["Erik Kusch"],"categories":null,"content":"","date":1489104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489104000,"objectID":"78e1ed6817247cd5e9de1c09e0f02cf0","permalink":"https://www.erikkusch.com/publication/journal-article/b.sc._inferring-vegetation-memory-from-remote/","publishdate":"2017-03-10T00:00:00Z","relpermalink":"/publication/journal-article/b.sc._inferring-vegetation-memory-from-remote/","section":"publication","summary":"My B.Sc. thesis at the Technical University of Dresden and University of Bergen.","tags":["Resilience","Biome Shifts","Remote Sensing"],"title":"Remote Sensing And Predicting Shifts In Biome Distribution And Resilience Using NDVI Data","type":"publication"},{"authors":["Erik Kusch","Alistair Seddon"],"categories":null,"content":"","date":1487939400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487939400,"objectID":"2e46e4e3649b76b342ea3c56e3dc2a00","permalink":"https://www.erikkusch.com/talk/2017_bscdefense/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/talk/2017_bscdefense/","section":"talk","summary":"The defense of my [B.Sc](/publication/journal-article/b.sc._inferring-vegetation-memory-from-remote/) thesis.","tags":["Biome Shifts","Resilience","Remote Sensing"],"title":"Remote Sensing And Predicting Shifts In Biome Distribution And Resilience Using NDVI Data","type":"talk"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://www.erikkusch.com/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://www.erikkusch.com/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]